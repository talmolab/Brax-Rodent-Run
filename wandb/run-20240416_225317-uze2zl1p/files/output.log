
Before into ConvNet + vmap shape: (1, 64, 64, 3)
This is out of CovNet (1, 8, 8, 1)
this is out of full ppo network (1, 60)
Before into ConvNet + vmap shape: (1, 64, 64, 3)
This is out of CovNet (1, 8, 8, 1)
this is out of full ppo network (1, 1)
Before into ConvNet + vmap shape: (128, 64, 64, 3)
This is out of CovNet (128, 8, 8, 1)
this is out of full ppo network (128, 60)
{'eval/walltime': 130.375736951828, 'eval/episode_distance_from_origin': Array(1.0089269, dtype=float32), 'eval/episode_forward_reward': Array(-0.04489689, dtype=float32), 'eval/episode_reward': Array(0.1501284, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04489689, dtype=float32), 'eval/episode_reward_quadctrl': Array(-0.8036278, dtype=float32), 'eval/episode_train_reward': Array(-0.00134691, dtype=float32), 'eval/episode_x_position': Array(1.0070944, dtype=float32), 'eval/episode_x_velocity': Array(-0.04489689, dtype=float32), 'eval/episode_y_position': Array(0.0005574, dtype=float32), 'eval/episode_y_velocity': Array(0.00079394, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583411, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04464497, dtype=float32), 'eval/episode_reward_std': Array(0.14038174, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04464497, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.13293962, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133935, dtype=float32), 'eval/episode_x_position_std': Array(0.005794, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04464497, dtype=float32), 'eval/episode_y_position_std': Array(0.00551621, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01179859, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 130.375736951828, 'eval/sps': 981.7777678011837, 'num_steps': 0}
Before into ConvNet + vmap shape: (1, 64, 64, 3)
This is out of CovNet (1, 8, 8, 1)
this is out of full ppo network (1, 60)
Before into ConvNet + vmap shape: (5, 32, 64, 64, 3)
This is out of CovNet (5, 32, 8, 8, 1)
this is out of full ppo network (5, 32, 60)
Before into ConvNet + vmap shape: (5, 32, 64, 64, 3)
This is out of CovNet (5, 32, 8, 8, 1)
this is out of full ppo network (5, 32, 1)
Before into ConvNet + vmap shape: (32, 64, 64, 3)
This is out of CovNet (32, 8, 8, 1)
this is out of full ppo network (32, 1)
{'eval/walltime': 151.11131739616394, 'training/sps': 41.37620171421666, 'training/walltime': 123.74262952804565, 'training/entropy_loss': Array(-0.01918843, dtype=float32), 'training/policy_loss': Array(-0.1050825, dtype=float32), 'training/total_loss': Array(-0.12421988, dtype=float32), 'training/v_loss': Array(5.1057552e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086712, dtype=float32), 'eval/episode_forward_reward': Array(-0.0365985, dtype=float32), 'eval/episode_reward': Array(-2.0368629, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0365985, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9991665, dtype=float32), 'eval/episode_train_reward': Array(-0.00109795, dtype=float32), 'eval/episode_x_position': Array(1.0067555, dtype=float32), 'eval/episode_x_velocity': Array(-0.0365985, dtype=float32), 'eval/episode_y_position': Array(0.00058849, dtype=float32), 'eval/episode_y_velocity': Array(-0.00141455, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00546849, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04435183, dtype=float32), 'eval/episode_reward_std': Array(0.04644046, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04435183, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00593594, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133056, dtype=float32), 'eval/episode_x_position_std': Array(0.00544567, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04435183, dtype=float32), 'eval/episode_y_position_std': Array(0.00622745, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00765169, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.735580444335938, 'eval/sps': 6172.964405004831, 'num_steps': 5120}
{'eval/walltime': 171.78059697151184, 'training/sps': 127.37263804698246, 'training/walltime': 163.9396457672119, 'training/entropy_loss': Array(-0.01836842, dtype=float32), 'training/policy_loss': Array(-0.17105404, dtype=float32), 'training/total_loss': Array(-0.18937798, dtype=float32), 'training/v_loss': Array(4.447726e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0172285, dtype=float32), 'eval/episode_forward_reward': Array(-0.03875839, dtype=float32), 'eval/episode_reward': Array(-2.053469, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03875839, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0213604, dtype=float32), 'eval/episode_train_reward': Array(-0.00116275, dtype=float32), 'eval/episode_x_position': Array(1.015326, dtype=float32), 'eval/episode_x_velocity': Array(-0.03875839, dtype=float32), 'eval/episode_y_position': Array(-6.120413e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00143887, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08856194, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0415237, dtype=float32), 'eval/episode_reward_std': Array(0.1799291, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0415237, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26453978, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124571, dtype=float32), 'eval/episode_x_position_std': Array(0.08829067, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0415237, dtype=float32), 'eval/episode_y_position_std': Array(0.00586091, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01353376, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.6692795753479, 'eval/sps': 6192.7654291669005, 'num_steps': 10240}
{'eval/walltime': 192.40546584129333, 'training/sps': 127.22871362840338, 'training/walltime': 204.18213391304016, 'training/entropy_loss': Array(-0.01733586, dtype=float32), 'training/policy_loss': Array(-0.1871029, dtype=float32), 'training/total_loss': Array(-0.20439824, dtype=float32), 'training/v_loss': Array(4.0516e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092862, dtype=float32), 'eval/episode_forward_reward': Array(-0.03519095, dtype=float32), 'eval/episode_reward': Array(-2.034753, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03519095, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985063, dtype=float32), 'eval/episode_train_reward': Array(-0.00105573, dtype=float32), 'eval/episode_x_position': Array(1.0074027, dtype=float32), 'eval/episode_x_velocity': Array(-0.03519095, dtype=float32), 'eval/episode_y_position': Array(0.00057693, dtype=float32), 'eval/episode_y_velocity': Array(2.417015e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058493, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04246045, dtype=float32), 'eval/episode_reward_std': Array(0.04593644, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04246045, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00952884, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127381, dtype=float32), 'eval/episode_x_position_std': Array(0.00582001, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04246045, dtype=float32), 'eval/episode_y_position_std': Array(0.00579003, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01388978, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.624868869781494, 'eval/sps': 6206.100063382176, 'num_steps': 15360}
{'eval/walltime': 213.05372834205627, 'training/sps': 127.25461702376579, 'training/walltime': 244.41643047332764, 'training/entropy_loss': Array(-0.01595689, dtype=float32), 'training/policy_loss': Array(-0.19064182, dtype=float32), 'training/total_loss': Array(-0.2065633, dtype=float32), 'training/v_loss': Array(3.539586e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090704, dtype=float32), 'eval/episode_forward_reward': Array(-0.03918431, dtype=float32), 'eval/episode_reward': Array(-2.0402145, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03918431, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9998546, dtype=float32), 'eval/episode_train_reward': Array(-0.00117553, dtype=float32), 'eval/episode_x_position': Array(1.0071671, dtype=float32), 'eval/episode_x_velocity': Array(-0.03918431, dtype=float32), 'eval/episode_y_position': Array(0.0005504, dtype=float32), 'eval/episode_y_velocity': Array(0.00258871, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596416, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04324846, dtype=float32), 'eval/episode_reward_std': Array(0.04464221, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04324846, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00072029, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129745, dtype=float32), 'eval/episode_x_position_std': Array(0.00593958, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04324846, dtype=float32), 'eval/episode_y_position_std': Array(0.00546127, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01673815, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64826250076294, 'eval/sps': 6199.0688076185825, 'num_steps': 20480}
{'eval/walltime': 233.7207019329071, 'training/sps': 127.29672971529543, 'training/walltime': 284.63741660118103, 'training/entropy_loss': Array(-0.01447312, dtype=float32), 'training/policy_loss': Array(-0.19138765, dtype=float32), 'training/total_loss': Array(-0.20582989, dtype=float32), 'training/v_loss': Array(3.087373e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016551, dtype=float32), 'eval/episode_forward_reward': Array(-0.03944058, dtype=float32), 'eval/episode_reward': Array(-2.0551057, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03944058, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0222945, dtype=float32), 'eval/episode_train_reward': Array(-0.00118322, dtype=float32), 'eval/episode_x_position': Array(1.0146614, dtype=float32), 'eval/episode_x_velocity': Array(-0.03944058, dtype=float32), 'eval/episode_y_position': Array(-0.00074104, dtype=float32), 'eval/episode_y_velocity': Array(-4.4419285e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08758437, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04458443, dtype=float32), 'eval/episode_reward_std': Array(0.18012309, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04458443, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26434734, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133753, dtype=float32), 'eval/episode_x_position_std': Array(0.08731126, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04458443, dtype=float32), 'eval/episode_y_position_std': Array(0.00583619, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00934605, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.66697359085083, 'eval/sps': 6193.456407021538, 'num_steps': 25600}
{'eval/walltime': 254.354022026062, 'training/sps': 127.26783515094323, 'training/walltime': 324.8675343990326, 'training/entropy_loss': Array(-0.01291379, dtype=float32), 'training/policy_loss': Array(-0.19435245, dtype=float32), 'training/total_loss': Array(-0.2072404, dtype=float32), 'training/v_loss': Array(2.5827656e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083258, dtype=float32), 'eval/episode_forward_reward': Array(-0.03890173, dtype=float32), 'eval/episode_reward': Array(-2.037582, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03890173, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975133, dtype=float32), 'eval/episode_train_reward': Array(-0.00116705, dtype=float32), 'eval/episode_x_position': Array(1.0064964, dtype=float32), 'eval/episode_x_velocity': Array(-0.03890173, dtype=float32), 'eval/episode_y_position': Array(-0.00075736, dtype=float32), 'eval/episode_y_velocity': Array(0.00272293, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559854, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0445167, dtype=float32), 'eval/episode_reward_std': Array(0.04860217, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0445167, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01329574, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013355, dtype=float32), 'eval/episode_x_position_std': Array(0.00556492, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0445167, dtype=float32), 'eval/episode_y_position_std': Array(0.005672, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01420488, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.633320093154907, 'eval/sps': 6203.558100301266, 'num_steps': 30720}
{'eval/walltime': 274.98797631263733, 'training/sps': 127.22596543248642, 'training/walltime': 365.11089181900024, 'training/entropy_loss': Array(-0.01109913, dtype=float32), 'training/policy_loss': Array(-0.1922712, dtype=float32), 'training/total_loss': Array(-0.20334837, dtype=float32), 'training/v_loss': Array(2.1954944e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100112, dtype=float32), 'eval/episode_forward_reward': Array(-0.03593042, dtype=float32), 'eval/episode_reward': Array(-2.0345848, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03593042, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975765, dtype=float32), 'eval/episode_train_reward': Array(-0.00107791, dtype=float32), 'eval/episode_x_position': Array(1.0081272, dtype=float32), 'eval/episode_x_velocity': Array(-0.03593042, dtype=float32), 'eval/episode_y_position': Array(0.00047783, dtype=float32), 'eval/episode_y_velocity': Array(-0.00070978, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00610997, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04239536, dtype=float32), 'eval/episode_reward_std': Array(0.04336281, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04239536, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01321065, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127186, dtype=float32), 'eval/episode_x_position_std': Array(0.00608861, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04239536, dtype=float32), 'eval/episode_y_position_std': Array(0.00582197, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01102611, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.633954286575317, 'eval/sps': 6203.367431286704, 'num_steps': 35840}
{'eval/walltime': 295.62811064720154, 'training/sps': 127.10658712781938, 'training/walltime': 405.39204573631287, 'training/entropy_loss': Array(-0.00923124, dtype=float32), 'training/policy_loss': Array(-0.19253927, dtype=float32), 'training/total_loss': Array(-0.20175365, dtype=float32), 'training/v_loss': Array(1.684945e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093727, dtype=float32), 'eval/episode_forward_reward': Array(-0.03604599, dtype=float32), 'eval/episode_reward': Array(-2.0328054, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03604599, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995678, dtype=float32), 'eval/episode_train_reward': Array(-0.00108138, dtype=float32), 'eval/episode_x_position': Array(1.0074522, dtype=float32), 'eval/episode_x_velocity': Array(-0.03604599, dtype=float32), 'eval/episode_y_position': Array(0.00013503, dtype=float32), 'eval/episode_y_velocity': Array(-0.00128106, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00544464, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04245845, dtype=float32), 'eval/episode_reward_std': Array(0.0452087, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04245845, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01617088, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127375, dtype=float32), 'eval/episode_x_position_std': Array(0.00547452, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04245845, dtype=float32), 'eval/episode_y_position_std': Array(0.00639038, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01112016, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64013433456421, 'eval/sps': 6201.51002533204, 'num_steps': 40960}
{'eval/walltime': 316.2620143890381, 'training/sps': 127.36725246460476, 'training/walltime': 445.59076166152954, 'training/entropy_loss': Array(-0.00730796, dtype=float32), 'training/policy_loss': Array(-0.1920824, dtype=float32), 'training/total_loss': Array(-0.199377, dtype=float32), 'training/v_loss': Array(1.3379311e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086136, dtype=float32), 'eval/episode_forward_reward': Array(-0.04361151, dtype=float32), 'eval/episode_reward': Array(-2.0435488, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04361151, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986289, dtype=float32), 'eval/episode_train_reward': Array(-0.00130835, dtype=float32), 'eval/episode_x_position': Array(1.0067506, dtype=float32), 'eval/episode_x_velocity': Array(-0.04361151, dtype=float32), 'eval/episode_y_position': Array(1.935201e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00255264, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059317, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04513884, dtype=float32), 'eval/episode_reward_std': Array(0.04844671, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04513884, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00969345, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135417, dtype=float32), 'eval/episode_x_position_std': Array(0.00595619, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04513884, dtype=float32), 'eval/episode_y_position_std': Array(0.00586849, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01739209, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.633903741836548, 'eval/sps': 6203.382627033967, 'num_steps': 46080}
{'eval/walltime': 336.9141893386841, 'training/sps': 127.3216545611458, 'training/walltime': 485.8038740158081, 'training/entropy_loss': Array(-0.00522583, dtype=float32), 'training/policy_loss': Array(-0.19531028, dtype=float32), 'training/total_loss': Array(-0.20052543, dtype=float32), 'training/v_loss': Array(1.0678756e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0175304, dtype=float32), 'eval/episode_forward_reward': Array(-0.03886285, dtype=float32), 'eval/episode_reward': Array(-2.0539305, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03886285, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0217142, dtype=float32), 'eval/episode_train_reward': Array(-0.00116589, dtype=float32), 'eval/episode_x_position': Array(1.015641, dtype=float32), 'eval/episode_x_velocity': Array(-0.03886285, dtype=float32), 'eval/episode_y_position': Array(5.128153e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0007156, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08947722, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04022007, dtype=float32), 'eval/episode_reward_std': Array(0.17842355, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04022007, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2644964, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012066, dtype=float32), 'eval/episode_x_position_std': Array(0.08920271, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04022007, dtype=float32), 'eval/episode_y_position_std': Array(0.00606432, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0163982, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.652174949645996, 'eval/sps': 6197.894425748804, 'num_steps': 51200}
{'eval/walltime': 357.56501054763794, 'training/sps': 127.12250684153679, 'training/walltime': 526.0799834728241, 'training/entropy_loss': Array(-0.00301117, dtype=float32), 'training/policy_loss': Array(-0.1816533, dtype=float32), 'training/total_loss': Array(-0.1846556, dtype=float32), 'training/v_loss': Array(8.868003e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100472, dtype=float32), 'eval/episode_forward_reward': Array(-0.03455773, dtype=float32), 'eval/episode_reward': Array(-2.033441, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03455773, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978468, dtype=float32), 'eval/episode_train_reward': Array(-0.00103673, dtype=float32), 'eval/episode_x_position': Array(1.0081493, dtype=float32), 'eval/episode_x_velocity': Array(-0.03455773, dtype=float32), 'eval/episode_y_position': Array(-0.00056986, dtype=float32), 'eval/episode_y_velocity': Array(-0.00164139, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557219, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04217495, dtype=float32), 'eval/episode_reward_std': Array(0.04362405, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04217495, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01105611, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126525, dtype=float32), 'eval/episode_x_position_std': Array(0.00559122, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04217495, dtype=float32), 'eval/episode_y_position_std': Array(0.00600816, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01128085, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.650821208953857, 'eval/sps': 6198.300721547155, 'num_steps': 56320}
{'eval/walltime': 378.24008202552795, 'training/sps': 127.18754910231914, 'training/walltime': 566.3354961872101, 'training/entropy_loss': Array(-0.00094344, dtype=float32), 'training/policy_loss': Array(-0.19290978, dtype=float32), 'training/total_loss': Array(-0.19384667, dtype=float32), 'training/v_loss': Array(6.5383247e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094945, dtype=float32), 'eval/episode_forward_reward': Array(-0.03518638, dtype=float32), 'eval/episode_reward': Array(-2.0354834, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03518638, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9992414, dtype=float32), 'eval/episode_train_reward': Array(-0.00105559, dtype=float32), 'eval/episode_x_position': Array(1.0075815, dtype=float32), 'eval/episode_x_velocity': Array(-0.03518638, dtype=float32), 'eval/episode_y_position': Array(-0.00066594, dtype=float32), 'eval/episode_y_velocity': Array(0.00097663, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588421, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04338878, dtype=float32), 'eval/episode_reward_std': Array(0.04448404, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04338878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00761255, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130166, dtype=float32), 'eval/episode_x_position_std': Array(0.00583946, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04338878, dtype=float32), 'eval/episode_y_position_std': Array(0.00544999, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01350545, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.675071477890015, 'eval/sps': 6191.030591448431, 'num_steps': 61440}
{'eval/walltime': 398.8930871486664, 'training/sps': 127.2584109116785, 'training/walltime': 606.5685932636261, 'training/entropy_loss': Array(0.00161925, dtype=float32), 'training/policy_loss': Array(-0.18415084, dtype=float32), 'training/total_loss': Array(-0.18252635, dtype=float32), 'training/v_loss': Array(5.2498235e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099497, dtype=float32), 'eval/episode_forward_reward': Array(-0.0476997, dtype=float32), 'eval/episode_reward': Array(-2.047482, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0476997, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998351, dtype=float32), 'eval/episode_train_reward': Array(-0.00143099, dtype=float32), 'eval/episode_x_position': Array(1.0081351, dtype=float32), 'eval/episode_x_velocity': Array(-0.0476997, dtype=float32), 'eval/episode_y_position': Array(0.00039059, dtype=float32), 'eval/episode_y_velocity': Array(0.00170271, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00565978, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04231132, dtype=float32), 'eval/episode_reward_std': Array(0.04404547, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04231132, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01163151, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126934, dtype=float32), 'eval/episode_x_position_std': Array(0.00564429, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04231132, dtype=float32), 'eval/episode_y_position_std': Array(0.00624089, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01103087, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.653005123138428, 'eval/sps': 6197.645293594404, 'num_steps': 66560}
{'eval/walltime': 419.5561320781708, 'training/sps': 127.29793403453225, 'training/walltime': 646.7891988754272, 'training/entropy_loss': Array(0.00435978, dtype=float32), 'training/policy_loss': Array(-0.17225674, dtype=float32), 'training/total_loss': Array(-0.1678932, dtype=float32), 'training/v_loss': Array(3.7437337e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009598, dtype=float32), 'eval/episode_forward_reward': Array(-0.03656287, dtype=float32), 'eval/episode_reward': Array(-2.0354457, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03656287, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977858, dtype=float32), 'eval/episode_train_reward': Array(-0.00109689, dtype=float32), 'eval/episode_x_position': Array(1.0077324, dtype=float32), 'eval/episode_x_velocity': Array(-0.03656287, dtype=float32), 'eval/episode_y_position': Array(0.00023593, dtype=float32), 'eval/episode_y_velocity': Array(-0.00034823, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585734, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0425251, dtype=float32), 'eval/episode_reward_std': Array(0.04465216, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0425251, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01151715, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127575, dtype=float32), 'eval/episode_x_position_std': Array(0.00587651, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0425251, dtype=float32), 'eval/episode_y_position_std': Array(0.00573939, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01200308, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.663044929504395, 'eval/sps': 6194.633967873297, 'num_steps': 71680}
{'eval/walltime': 440.1812117099762, 'training/sps': 127.06369718803501, 'training/walltime': 687.0839495658875, 'training/entropy_loss': Array(0.00652926, dtype=float32), 'training/policy_loss': Array(-0.18434158, dtype=float32), 'training/total_loss': Array(-0.17780942, dtype=float32), 'training/v_loss': Array(2.8924028e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009733, dtype=float32), 'eval/episode_forward_reward': Array(-0.04026193, dtype=float32), 'eval/episode_reward': Array(-2.0413857, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04026193, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9999158, dtype=float32), 'eval/episode_train_reward': Array(-0.00120786, dtype=float32), 'eval/episode_x_position': Array(1.007854, dtype=float32), 'eval/episode_x_velocity': Array(-0.04026193, dtype=float32), 'eval/episode_y_position': Array(0.00017696, dtype=float32), 'eval/episode_y_velocity': Array(-0.00101666, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00597524, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04408636, dtype=float32), 'eval/episode_reward_std': Array(0.04537716, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04408636, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00039731, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132259, dtype=float32), 'eval/episode_x_position_std': Array(0.00593956, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04408636, dtype=float32), 'eval/episode_y_position_std': Array(0.00568985, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01563331, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62507963180542, 'eval/sps': 6206.03664495018, 'num_steps': 76800}
{'eval/walltime': 460.8731291294098, 'training/sps': 127.32638628955634, 'training/walltime': 727.2955675125122, 'training/entropy_loss': Array(0.00920314, dtype=float32), 'training/policy_loss': Array(-0.17351611, dtype=float32), 'training/total_loss': Array(-0.16431081, dtype=float32), 'training/v_loss': Array(2.1379635e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094082, dtype=float32), 'eval/episode_forward_reward': Array(-0.03444846, dtype=float32), 'eval/episode_reward': Array(-2.03273, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03444846, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972484, dtype=float32), 'eval/episode_train_reward': Array(-0.00103345, dtype=float32), 'eval/episode_x_position': Array(1.0075097, dtype=float32), 'eval/episode_x_velocity': Array(-0.03444846, dtype=float32), 'eval/episode_y_position': Array(0.00016679, dtype=float32), 'eval/episode_y_velocity': Array(0.00031343, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00615335, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04397446, dtype=float32), 'eval/episode_reward_std': Array(0.04862523, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04397446, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0138755, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131923, dtype=float32), 'eval/episode_x_position_std': Array(0.00611631, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04397446, dtype=float32), 'eval/episode_y_position_std': Array(0.00561501, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01340139, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.691917419433594, 'eval/sps': 6185.990278493185, 'num_steps': 81920}
{'eval/walltime': 481.51172733306885, 'training/sps': 127.23387718098226, 'training/walltime': 767.5364224910736, 'training/entropy_loss': Array(0.01235997, dtype=float32), 'training/policy_loss': Array(-0.16073884, dtype=float32), 'training/total_loss': Array(-0.1483774, dtype=float32), 'training/v_loss': Array(1.4686727e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092723, dtype=float32), 'eval/episode_forward_reward': Array(-0.03782404, dtype=float32), 'eval/episode_reward': Array(-2.0369482, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03782404, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979894, dtype=float32), 'eval/episode_train_reward': Array(-0.00113472, dtype=float32), 'eval/episode_x_position': Array(1.0074275, dtype=float32), 'eval/episode_x_velocity': Array(-0.03782404, dtype=float32), 'eval/episode_y_position': Array(0.00109684, dtype=float32), 'eval/episode_y_velocity': Array(0.00074514, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590244, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04142122, dtype=float32), 'eval/episode_reward_std': Array(0.04282323, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04142122, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00967307, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124264, dtype=float32), 'eval/episode_x_position_std': Array(0.00590444, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04142122, dtype=float32), 'eval/episode_y_position_std': Array(0.00561424, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01587204, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.638598203659058, 'eval/sps': 6201.971603735501, 'num_steps': 87040}
{'eval/walltime': 502.1804826259613, 'training/sps': 127.19532423229397, 'training/walltime': 807.7894744873047, 'training/entropy_loss': Array(0.0149704, dtype=float32), 'training/policy_loss': Array(-0.15615891, dtype=float32), 'training/total_loss': Array(-0.14118746, dtype=float32), 'training/v_loss': Array(1.0478443e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088298, dtype=float32), 'eval/episode_forward_reward': Array(-0.03505242, dtype=float32), 'eval/episode_reward': Array(-2.0353138, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03505242, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99921, dtype=float32), 'eval/episode_train_reward': Array(-0.00105157, dtype=float32), 'eval/episode_x_position': Array(1.0069394, dtype=float32), 'eval/episode_x_velocity': Array(-0.03505242, dtype=float32), 'eval/episode_y_position': Array(0.00040469, dtype=float32), 'eval/episode_y_velocity': Array(-0.00217337, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561077, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04153052, dtype=float32), 'eval/episode_reward_std': Array(0.0430954, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04153052, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00546, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124592, dtype=float32), 'eval/episode_x_position_std': Array(0.00559186, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04153052, dtype=float32), 'eval/episode_y_position_std': Array(0.00576861, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01055437, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.668755292892456, 'eval/sps': 6192.922514497835, 'num_steps': 92160}
{'eval/walltime': 522.8419070243835, 'training/sps': 127.41677255491477, 'training/walltime': 847.97256731987, 'training/entropy_loss': Array(0.01733678, dtype=float32), 'training/policy_loss': Array(-0.16861464, dtype=float32), 'training/total_loss': Array(-0.15127707, dtype=float32), 'training/v_loss': Array(7.9367277e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009483, dtype=float32), 'eval/episode_forward_reward': Array(-0.03961062, dtype=float32), 'eval/episode_reward': Array(-2.0400343, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03961062, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9992352, dtype=float32), 'eval/episode_train_reward': Array(-0.00118832, dtype=float32), 'eval/episode_x_position': Array(1.0076134, dtype=float32), 'eval/episode_x_velocity': Array(-0.03961062, dtype=float32), 'eval/episode_y_position': Array(-5.581716e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00284048, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00534849, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04400489, dtype=float32), 'eval/episode_reward_std': Array(0.04597248, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04400489, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00596531, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132015, dtype=float32), 'eval/episode_x_position_std': Array(0.00533812, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04400489, dtype=float32), 'eval/episode_y_position_std': Array(0.006038, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0162187, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66142439842224, 'eval/sps': 6195.11982967517, 'num_steps': 97280}
{'eval/walltime': 543.5122961997986, 'training/sps': 127.35860128245127, 'training/walltime': 888.1740138530731, 'training/entropy_loss': Array(0.02095927, dtype=float32), 'training/policy_loss': Array(-0.14044835, dtype=float32), 'training/total_loss': Array(-0.11948856, dtype=float32), 'training/v_loss': Array(5.1866743e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099435, dtype=float32), 'eval/episode_forward_reward': Array(-0.03726982, dtype=float32), 'eval/episode_reward': Array(-2.0374956, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03726982, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9991078, dtype=float32), 'eval/episode_train_reward': Array(-0.00111809, dtype=float32), 'eval/episode_x_position': Array(1.0080419, dtype=float32), 'eval/episode_x_velocity': Array(-0.03726982, dtype=float32), 'eval/episode_y_position': Array(0.00051934, dtype=float32), 'eval/episode_y_velocity': Array(-0.00044451, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589403, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04347876, dtype=float32), 'eval/episode_reward_std': Array(0.04623225, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04347876, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00880075, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130436, dtype=float32), 'eval/episode_x_position_std': Array(0.00590018, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04347876, dtype=float32), 'eval/episode_y_position_std': Array(0.00588085, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01162465, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67038917541504, 'eval/sps': 6192.4329974512875, 'num_steps': 102400}
{'eval/walltime': 564.1442818641663, 'training/sps': 127.23589598016885, 'training/walltime': 928.4142303466797, 'training/entropy_loss': Array(0.0242759, dtype=float32), 'training/policy_loss': Array(-0.14619716, dtype=float32), 'training/total_loss': Array(-0.12192093, dtype=float32), 'training/v_loss': Array(3.2664718e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.00926, dtype=float32), 'eval/episode_forward_reward': Array(-0.046595, dtype=float32), 'eval/episode_reward': Array(-2.047045, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.046595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.999052, dtype=float32), 'eval/episode_train_reward': Array(-0.00139785, dtype=float32), 'eval/episode_x_position': Array(1.0074506, dtype=float32), 'eval/episode_x_velocity': Array(-0.046595, dtype=float32), 'eval/episode_y_position': Array(-0.00011011, dtype=float32), 'eval/episode_y_velocity': Array(-0.00192321, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00530518, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04455294, dtype=float32), 'eval/episode_reward_std': Array(0.04651808, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04455294, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00548882, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133659, dtype=float32), 'eval/episode_x_position_std': Array(0.00531947, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04455294, dtype=float32), 'eval/episode_y_position_std': Array(0.00567381, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0127991, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.631985664367676, 'eval/sps': 6203.959331993017, 'num_steps': 107520}
{'eval/walltime': 584.8244163990021, 'training/sps': 127.41820746416025, 'training/walltime': 968.5968706607819, 'training/entropy_loss': Array(0.03243902, dtype=float32), 'training/policy_loss': Array(0.26488122, dtype=float32), 'training/total_loss': Array(0.29732051, dtype=float32), 'training/v_loss': Array(2.312604e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096366, dtype=float32), 'eval/episode_forward_reward': Array(-0.0447433, dtype=float32), 'eval/episode_reward': Array(-2.0432563, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0447433, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971707, dtype=float32), 'eval/episode_train_reward': Array(-0.0013423, dtype=float32), 'eval/episode_x_position': Array(1.0078144, dtype=float32), 'eval/episode_x_velocity': Array(-0.0447433, dtype=float32), 'eval/episode_y_position': Array(-0.00072487, dtype=float32), 'eval/episode_y_velocity': Array(-0.00180737, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595745, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04300083, dtype=float32), 'eval/episode_reward_std': Array(0.04485627, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04300083, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01400245, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129003, dtype=float32), 'eval/episode_x_position_std': Array(0.00596617, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04300083, dtype=float32), 'eval/episode_y_position_std': Array(0.00590901, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01331585, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680134534835815, 'eval/sps': 6189.514859508443, 'num_steps': 112640}
{'eval/walltime': 605.4543685913086, 'training/sps': 127.37611938956415, 'training/walltime': 1008.7927882671356, 'training/entropy_loss': Array(0.01567629, dtype=float32), 'training/policy_loss': Array(0.2742311, dtype=float32), 'training/total_loss': Array(0.2899122, dtype=float32), 'training/v_loss': Array(4.797669e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090584, dtype=float32), 'eval/episode_forward_reward': Array(-0.04230882, dtype=float32), 'eval/episode_reward': Array(-2.0424273, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04230882, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998849, dtype=float32), 'eval/episode_train_reward': Array(-0.00126926, dtype=float32), 'eval/episode_x_position': Array(1.0072019, dtype=float32), 'eval/episode_x_velocity': Array(-0.04230882, dtype=float32), 'eval/episode_y_position': Array(0.00053387, dtype=float32), 'eval/episode_y_velocity': Array(-0.0013283, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570349, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04319204, dtype=float32), 'eval/episode_reward_std': Array(0.04496984, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04319204, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00553223, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129576, dtype=float32), 'eval/episode_x_position_std': Array(0.00568061, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04319204, dtype=float32), 'eval/episode_y_position_std': Array(0.00583007, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01091502, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62995219230652, 'eval/sps': 6204.570849550236, 'num_steps': 117760}
{'eval/walltime': 626.0656359195709, 'training/sps': 127.2847609564504, 'training/walltime': 1049.0175564289093, 'training/entropy_loss': Array(0.01293493, dtype=float32), 'training/policy_loss': Array(-0.1952574, dtype=float32), 'training/total_loss': Array(-0.18231991, dtype=float32), 'training/v_loss': Array(2.5861727e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169228, dtype=float32), 'eval/episode_forward_reward': Array(-0.04279878, dtype=float32), 'eval/episode_reward': Array(-2.0579212, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04279878, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.021651, dtype=float32), 'eval/episode_train_reward': Array(-0.00128396, dtype=float32), 'eval/episode_x_position': Array(1.0150371, dtype=float32), 'eval/episode_x_velocity': Array(-0.04279878, dtype=float32), 'eval/episode_y_position': Array(0.00055849, dtype=float32), 'eval/episode_y_velocity': Array(-0.00101514, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08883432, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04340081, dtype=float32), 'eval/episode_reward_std': Array(0.17969964, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04340081, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2645629, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130202, dtype=float32), 'eval/episode_x_position_std': Array(0.08856225, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04340081, dtype=float32), 'eval/episode_y_position_std': Array(0.00605315, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01234632, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.61126732826233, 'eval/sps': 6210.195518859989, 'num_steps': 122880}
{'eval/walltime': 646.6934130191803, 'training/sps': 127.18102900143968, 'training/walltime': 1089.275132894516, 'training/entropy_loss': Array(0.01485842, dtype=float32), 'training/policy_loss': Array(-0.19021255, dtype=float32), 'training/total_loss': Array(-0.17535257, dtype=float32), 'training/v_loss': Array(1.5572199e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101953, dtype=float32), 'eval/episode_forward_reward': Array(-0.0412988, dtype=float32), 'eval/episode_reward': Array(-2.0419588, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0412988, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9994211, dtype=float32), 'eval/episode_train_reward': Array(-0.00123896, dtype=float32), 'eval/episode_x_position': Array(1.0083251, dtype=float32), 'eval/episode_x_velocity': Array(-0.0412988, dtype=float32), 'eval/episode_y_position': Array(9.21287e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00069866, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00562671, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0435686, dtype=float32), 'eval/episode_reward_std': Array(0.04575083, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0435686, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00605258, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130706, dtype=float32), 'eval/episode_x_position_std': Array(0.00567781, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0435686, dtype=float32), 'eval/episode_y_position_std': Array(0.00572965, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01241625, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.627777099609375, 'eval/sps': 6205.225089543163, 'num_steps': 128000}
{'eval/walltime': 667.3889331817627, 'training/sps': 127.33187260575346, 'training/walltime': 1129.4850182533264, 'training/entropy_loss': Array(0.0172367, dtype=float32), 'training/policy_loss': Array(-0.18445683, dtype=float32), 'training/total_loss': Array(-0.16721901, dtype=float32), 'training/v_loss': Array(1.1322585e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087507, dtype=float32), 'eval/episode_forward_reward': Array(-0.04045371, dtype=float32), 'eval/episode_reward': Array(-2.0395203, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04045371, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997853, dtype=float32), 'eval/episode_train_reward': Array(-0.00121361, dtype=float32), 'eval/episode_x_position': Array(1.0068891, dtype=float32), 'eval/episode_x_velocity': Array(-0.04045371, dtype=float32), 'eval/episode_y_position': Array(0.00032131, dtype=float32), 'eval/episode_y_velocity': Array(-0.00038118, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0060664, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04497513, dtype=float32), 'eval/episode_reward_std': Array(0.0494906, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04497513, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0137399, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134925, dtype=float32), 'eval/episode_x_position_std': Array(0.00606084, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04497513, dtype=float32), 'eval/episode_y_position_std': Array(0.00572042, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01225623, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.695520162582397, 'eval/sps': 6184.913401279212, 'num_steps': 133120}
{'eval/walltime': 688.0458927154541, 'training/sps': 127.50973264410696, 'training/walltime': 1169.6388158798218, 'training/entropy_loss': Array(0.01934029, dtype=float32), 'training/policy_loss': Array(-0.18704814, dtype=float32), 'training/total_loss': Array(-0.16770704, dtype=float32), 'training/v_loss': Array(8.017994e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097895, dtype=float32), 'eval/episode_forward_reward': Array(-0.03461649, dtype=float32), 'eval/episode_reward': Array(-2.034503, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03461649, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998848, dtype=float32), 'eval/episode_train_reward': Array(-0.00103849, dtype=float32), 'eval/episode_x_position': Array(1.007866, dtype=float32), 'eval/episode_x_velocity': Array(-0.03461649, dtype=float32), 'eval/episode_y_position': Array(0.00066059, dtype=float32), 'eval/episode_y_velocity': Array(-0.00051091, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00628094, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04316786, dtype=float32), 'eval/episode_reward_std': Array(0.04587222, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04316786, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00894886, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129504, dtype=float32), 'eval/episode_x_position_std': Array(0.00624066, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04316786, dtype=float32), 'eval/episode_y_position_std': Array(0.00528827, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00813801, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.656959533691406, 'eval/sps': 6196.458863717702, 'num_steps': 138240}
{'eval/walltime': 708.649176120758, 'training/sps': 127.35641544547194, 'training/walltime': 1209.8409523963928, 'training/entropy_loss': Array(0.02181593, dtype=float32), 'training/policy_loss': Array(-0.18033746, dtype=float32), 'training/total_loss': Array(-0.15852095, dtype=float32), 'training/v_loss': Array(5.812471e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0081027, dtype=float32), 'eval/episode_forward_reward': Array(-0.03930119, dtype=float32), 'eval/episode_reward': Array(-2.037754, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03930119, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997274, dtype=float32), 'eval/episode_train_reward': Array(-0.00117904, dtype=float32), 'eval/episode_x_position': Array(1.0062578, dtype=float32), 'eval/episode_x_velocity': Array(-0.03930119, dtype=float32), 'eval/episode_y_position': Array(-0.00033676, dtype=float32), 'eval/episode_y_velocity': Array(-0.00086453, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560076, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04415064, dtype=float32), 'eval/episode_reward_std': Array(0.04732354, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04415064, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01374979, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132452, dtype=float32), 'eval/episode_x_position_std': Array(0.0056006, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04415064, dtype=float32), 'eval/episode_y_position_std': Array(0.00589717, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01369563, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.603283405303955, 'eval/sps': 6212.602015028761, 'num_steps': 143360}
{'eval/walltime': 729.2611482143402, 'training/sps': 127.32383694036456, 'training/walltime': 1250.0533754825592, 'training/entropy_loss': Array(0.02450686, dtype=float32), 'training/policy_loss': Array(-0.15900168, dtype=float32), 'training/total_loss': Array(-0.13449438, dtype=float32), 'training/v_loss': Array(4.212718e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097516, dtype=float32), 'eval/episode_forward_reward': Array(-0.04045735, dtype=float32), 'eval/episode_reward': Array(-2.0390224, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04045735, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973512, dtype=float32), 'eval/episode_train_reward': Array(-0.00121372, dtype=float32), 'eval/episode_x_position': Array(1.0078678, dtype=float32), 'eval/episode_x_velocity': Array(-0.04045735, dtype=float32), 'eval/episode_y_position': Array(0.0001295, dtype=float32), 'eval/episode_y_velocity': Array(-0.00066776, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582419, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04391066, dtype=float32), 'eval/episode_reward_std': Array(0.04651143, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04391066, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01296576, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131732, dtype=float32), 'eval/episode_x_position_std': Array(0.00584978, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04391066, dtype=float32), 'eval/episode_y_position_std': Array(0.00591271, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01437887, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.611972093582153, 'eval/sps': 6209.983179622814, 'num_steps': 148480}
{'eval/walltime': 749.8513495922089, 'training/sps': 127.34050958555498, 'training/walltime': 1290.2605335712433, 'training/entropy_loss': Array(0.02682221, dtype=float32), 'training/policy_loss': Array(-0.16120629, dtype=float32), 'training/total_loss': Array(-0.13438377, dtype=float32), 'training/v_loss': Array(3.111491e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092607, dtype=float32), 'eval/episode_forward_reward': Array(-0.03952968, dtype=float32), 'eval/episode_reward': Array(-2.0394464, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03952968, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998731, dtype=float32), 'eval/episode_train_reward': Array(-0.00118589, dtype=float32), 'eval/episode_x_position': Array(1.0074129, dtype=float32), 'eval/episode_x_velocity': Array(-0.03952968, dtype=float32), 'eval/episode_y_position': Array(0.00074971, dtype=float32), 'eval/episode_y_velocity': Array(-0.00101991, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599365, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04377028, dtype=float32), 'eval/episode_reward_std': Array(0.04641634, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04377028, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00950817, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131311, dtype=float32), 'eval/episode_x_position_std': Array(0.00593568, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04377028, dtype=float32), 'eval/episode_y_position_std': Array(0.00568558, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01301482, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.590201377868652, 'eval/sps': 6216.549204690179, 'num_steps': 153600}
{'eval/walltime': 770.4964215755463, 'training/sps': 127.04671061256202, 'training/walltime': 1330.5606718063354, 'training/entropy_loss': Array(0.03009332, dtype=float32), 'training/policy_loss': Array(-0.1431756, dtype=float32), 'training/total_loss': Array(-0.1130821, dtype=float32), 'training/v_loss': Array(2.013424e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091323, dtype=float32), 'eval/episode_forward_reward': Array(-0.0335093, dtype=float32), 'eval/episode_reward': Array(-2.031933, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0335093, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974186, dtype=float32), 'eval/episode_train_reward': Array(-0.00100528, dtype=float32), 'eval/episode_x_position': Array(1.007207, dtype=float32), 'eval/episode_x_velocity': Array(-0.0335093, dtype=float32), 'eval/episode_y_position': Array(0.0002073, dtype=float32), 'eval/episode_y_velocity': Array(0.0012719, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580576, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04172248, dtype=float32), 'eval/episode_reward_std': Array(0.04578946, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04172248, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01399332, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125167, dtype=float32), 'eval/episode_x_position_std': Array(0.00578481, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04172248, dtype=float32), 'eval/episode_y_position_std': Array(0.00566492, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01028294, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.645071983337402, 'eval/sps': 6200.026820120005, 'num_steps': 158720}
{'eval/walltime': 791.0961456298828, 'training/sps': 127.32337116861345, 'training/walltime': 1370.7732419967651, 'training/entropy_loss': Array(0.03350439, dtype=float32), 'training/policy_loss': Array(-0.10891032, dtype=float32), 'training/total_loss': Array(-0.07540581, dtype=float32), 'training/v_loss': Array(1.2506683e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0178871, dtype=float32), 'eval/episode_forward_reward': Array(-0.04099915, dtype=float32), 'eval/episode_reward': Array(-2.0569112, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04099915, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0224946, dtype=float32), 'eval/episode_train_reward': Array(-0.00122997, dtype=float32), 'eval/episode_x_position': Array(1.0159988, dtype=float32), 'eval/episode_x_velocity': Array(-0.04099915, dtype=float32), 'eval/episode_y_position': Array(0.00017782, dtype=float32), 'eval/episode_y_velocity': Array(0.00183404, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08968025, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04456417, dtype=float32), 'eval/episode_reward_std': Array(0.17805874, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04456417, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26434022, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133693, dtype=float32), 'eval/episode_x_position_std': Array(0.08941115, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04456417, dtype=float32), 'eval/episode_y_position_std': Array(0.00582062, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01282491, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.599724054336548, 'eval/sps': 6213.675467805798, 'num_steps': 163840}
{'eval/walltime': 811.7317144870758, 'training/sps': 127.39628590874821, 'training/walltime': 1410.9627966880798, 'training/entropy_loss': Array(0.0371517, dtype=float32), 'training/policy_loss': Array(-0.09605953, dtype=float32), 'training/total_loss': Array(-0.05890774, dtype=float32), 'training/v_loss': Array(8.4996856e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017689, dtype=float32), 'eval/episode_forward_reward': Array(-0.03766517, dtype=float32), 'eval/episode_reward': Array(-2.0536883, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03766517, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0227056, dtype=float32), 'eval/episode_train_reward': Array(-0.00112996, dtype=float32), 'eval/episode_x_position': Array(1.0157743, dtype=float32), 'eval/episode_x_velocity': Array(-0.03766517, dtype=float32), 'eval/episode_y_position': Array(-0.00058752, dtype=float32), 'eval/episode_y_velocity': Array(-0.00118253, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08827206, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04264247, dtype=float32), 'eval/episode_reward_std': Array(0.177025, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04264247, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26427212, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127927, dtype=float32), 'eval/episode_x_position_std': Array(0.08800289, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04264247, dtype=float32), 'eval/episode_y_position_std': Array(0.00585207, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0113917, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.635568857192993, 'eval/sps': 6202.882066678899, 'num_steps': 168960}
{'eval/walltime': 832.3564329147339, 'training/sps': 127.3487739140284, 'training/walltime': 1451.1673455238342, 'training/entropy_loss': Array(0.11026516, dtype=float32), 'training/policy_loss': Array(0.254281, dtype=float32), 'training/total_loss': Array(0.3645462, dtype=float32), 'training/v_loss': Array(5.1574872e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088646, dtype=float32), 'eval/episode_forward_reward': Array(-0.04107428, dtype=float32), 'eval/episode_reward': Array(-2.0413752, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04107428, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9990687, dtype=float32), 'eval/episode_train_reward': Array(-0.00123223, dtype=float32), 'eval/episode_x_position': Array(1.0069869, dtype=float32), 'eval/episode_x_velocity': Array(-0.04107428, dtype=float32), 'eval/episode_y_position': Array(0.00044495, dtype=float32), 'eval/episode_y_velocity': Array(-0.00147738, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600181, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0443104, dtype=float32), 'eval/episode_reward_std': Array(0.04552842, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0443104, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00789761, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132931, dtype=float32), 'eval/episode_x_position_std': Array(0.00599054, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0443104, dtype=float32), 'eval/episode_y_position_std': Array(0.00574634, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01497529, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62471842765808, 'eval/sps': 6206.1453323091155, 'num_steps': 174080}
{'eval/walltime': 853.0184485912323, 'training/sps': 127.41584116642149, 'training/walltime': 1491.350732088089, 'training/entropy_loss': Array(0.02248608, dtype=float32), 'training/policy_loss': Array(0.27985063, dtype=float32), 'training/total_loss': Array(0.30288792, dtype=float32), 'training/v_loss': Array(0.00055121, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099409, dtype=float32), 'eval/episode_forward_reward': Array(-0.03927116, dtype=float32), 'eval/episode_reward': Array(-2.0391345, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03927116, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986854, dtype=float32), 'eval/episode_train_reward': Array(-0.00117813, dtype=float32), 'eval/episode_x_position': Array(1.0080643, dtype=float32), 'eval/episode_x_velocity': Array(-0.03927116, dtype=float32), 'eval/episode_y_position': Array(-0.00083757, dtype=float32), 'eval/episode_y_velocity': Array(-0.00064612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573365, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04337624, dtype=float32), 'eval/episode_reward_std': Array(0.04553105, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04337624, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00704725, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130129, dtype=float32), 'eval/episode_x_position_std': Array(0.00567225, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04337624, dtype=float32), 'eval/episode_y_position_std': Array(0.0060008, dtype=float32), 'eval/episode_y_velocity_std': Array(0.010095, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.662015676498413, 'eval/sps': 6194.942545977786, 'num_steps': 179200}
{'eval/walltime': 873.6818261146545, 'training/sps': 127.13219696037063, 'training/walltime': 1531.6237716674805, 'training/entropy_loss': Array(-0.01929634, dtype=float32), 'training/policy_loss': Array(-0.14079903, dtype=float32), 'training/total_loss': Array(-0.15991566, dtype=float32), 'training/v_loss': Array(0.00017972, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093219, dtype=float32), 'eval/episode_forward_reward': Array(-0.04124836, dtype=float32), 'eval/episode_reward': Array(-2.0382977, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04124836, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995812, dtype=float32), 'eval/episode_train_reward': Array(-0.00123745, dtype=float32), 'eval/episode_x_position': Array(1.0074757, dtype=float32), 'eval/episode_x_velocity': Array(-0.04124836, dtype=float32), 'eval/episode_y_position': Array(-0.00015268, dtype=float32), 'eval/episode_y_velocity': Array(-0.0020073, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00543908, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04405612, dtype=float32), 'eval/episode_reward_std': Array(0.04891479, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04405612, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01585169, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132168, dtype=float32), 'eval/episode_x_position_std': Array(0.00545644, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04405612, dtype=float32), 'eval/episode_y_position_std': Array(0.005672, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01027199, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66337752342224, 'eval/sps': 6194.534260186174, 'num_steps': 184320}
{'eval/walltime': 894.3666296005249, 'training/sps': 127.09771029733959, 'training/walltime': 1571.9077389240265, 'training/entropy_loss': Array(-0.01924985, dtype=float32), 'training/policy_loss': Array(-0.18321523, dtype=float32), 'training/total_loss': Array(-0.20240939, dtype=float32), 'training/v_loss': Array(5.569968e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090312, dtype=float32), 'eval/episode_forward_reward': Array(-0.04330658, dtype=float32), 'eval/episode_reward': Array(-2.04101, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04330658, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964042, dtype=float32), 'eval/episode_train_reward': Array(-0.0012992, dtype=float32), 'eval/episode_x_position': Array(1.0071821, dtype=float32), 'eval/episode_x_velocity': Array(-0.04330658, dtype=float32), 'eval/episode_y_position': Array(-0.00012995, dtype=float32), 'eval/episode_y_velocity': Array(-0.00254616, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570785, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04515818, dtype=float32), 'eval/episode_reward_std': Array(0.04808459, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04515818, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01595726, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135475, dtype=float32), 'eval/episode_x_position_std': Array(0.0056797, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04515818, dtype=float32), 'eval/episode_y_position_std': Array(0.00551653, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01279259, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68480348587036, 'eval/sps': 6188.117769039279, 'num_steps': 189440}
{'eval/walltime': 915.0209331512451, 'training/sps': 127.17856078741178, 'training/walltime': 1612.166096687317, 'training/entropy_loss': Array(-0.01851434, dtype=float32), 'training/policy_loss': Array(-0.1859443, dtype=float32), 'training/total_loss': Array(-0.20440966, dtype=float32), 'training/v_loss': Array(4.9001013e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167091, dtype=float32), 'eval/episode_forward_reward': Array(-0.0411092, dtype=float32), 'eval/episode_reward': Array(-2.0538654, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0411092, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0193357, dtype=float32), 'eval/episode_train_reward': Array(-0.00123328, dtype=float32), 'eval/episode_x_position': Array(1.0148449, dtype=float32), 'eval/episode_x_velocity': Array(-0.0411092, dtype=float32), 'eval/episode_y_position': Array(0.00037577, dtype=float32), 'eval/episode_y_velocity': Array(-0.00029171, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08898465, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04410539, dtype=float32), 'eval/episode_reward_std': Array(0.17980039, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04410539, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26499414, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132316, dtype=float32), 'eval/episode_x_position_std': Array(0.08870865, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04410539, dtype=float32), 'eval/episode_y_position_std': Array(0.00586988, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01254878, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.654303550720215, 'eval/sps': 6197.255680186643, 'num_steps': 194560}
{'eval/walltime': 935.621499300003, 'training/sps': 127.24260039093964, 'training/walltime': 1652.4041929244995, 'training/entropy_loss': Array(-0.01747669, dtype=float32), 'training/policy_loss': Array(-0.1886473, dtype=float32), 'training/total_loss': Array(-0.20608121, dtype=float32), 'training/v_loss': Array(4.2765634e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092334, dtype=float32), 'eval/episode_forward_reward': Array(-0.03595712, dtype=float32), 'eval/episode_reward': Array(-2.0351949, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03595712, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998159, dtype=float32), 'eval/episode_train_reward': Array(-0.00107871, dtype=float32), 'eval/episode_x_position': Array(1.0073481, dtype=float32), 'eval/episode_x_velocity': Array(-0.03595712, dtype=float32), 'eval/episode_y_position': Array(0.00050583, dtype=float32), 'eval/episode_y_velocity': Array(-0.00015922, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566132, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04267256, dtype=float32), 'eval/episode_reward_std': Array(0.04592773, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04267256, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00965136, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128018, dtype=float32), 'eval/episode_x_position_std': Array(0.00565993, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04267256, dtype=float32), 'eval/episode_y_position_std': Array(0.00623967, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01020603, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.600566148757935, 'eval/sps': 6213.4214698617625, 'num_steps': 199680}
{'eval/walltime': 956.19633436203, 'training/sps': 127.28705599506624, 'training/walltime': 1692.6282358169556, 'training/entropy_loss': Array(-0.01637715, dtype=float32), 'training/policy_loss': Array(-0.18809167, dtype=float32), 'training/total_loss': Array(-0.20443012, dtype=float32), 'training/v_loss': Array(3.8687704e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083394, dtype=float32), 'eval/episode_forward_reward': Array(-0.04399708, dtype=float32), 'eval/episode_reward': Array(-2.0440369, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04399708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987197, dtype=float32), 'eval/episode_train_reward': Array(-0.00131991, dtype=float32), 'eval/episode_x_position': Array(1.0065047, dtype=float32), 'eval/episode_x_velocity': Array(-0.04399708, dtype=float32), 'eval/episode_y_position': Array(0.00103519, dtype=float32), 'eval/episode_y_velocity': Array(-0.00194531, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572358, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04474738, dtype=float32), 'eval/episode_reward_std': Array(0.04613166, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04474738, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00970032, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134242, dtype=float32), 'eval/episode_x_position_std': Array(0.00568936, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04474738, dtype=float32), 'eval/episode_y_position_std': Array(0.0052512, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01691857, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.574835062026978, 'eval/sps': 6221.1920345469725, 'num_steps': 204800}
{'eval/walltime': 976.8175985813141, 'training/sps': 127.25137833402187, 'training/walltime': 1732.8635563850403, 'training/entropy_loss': Array(-0.01524044, dtype=float32), 'training/policy_loss': Array(-0.18997021, dtype=float32), 'training/total_loss': Array(-0.2051776, dtype=float32), 'training/v_loss': Array(3.305859e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085449, dtype=float32), 'eval/episode_forward_reward': Array(-0.04627106, dtype=float32), 'eval/episode_reward': Array(-2.045299, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04627106, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99764, dtype=float32), 'eval/episode_train_reward': Array(-0.00138813, dtype=float32), 'eval/episode_x_position': Array(1.0067096, dtype=float32), 'eval/episode_x_velocity': Array(-0.04627106, dtype=float32), 'eval/episode_y_position': Array(-0.00038728, dtype=float32), 'eval/episode_y_velocity': Array(-0.00229281, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057836, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04619705, dtype=float32), 'eval/episode_reward_std': Array(0.05172961, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04619705, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01392854, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138591, dtype=float32), 'eval/episode_x_position_std': Array(0.00576541, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04619705, dtype=float32), 'eval/episode_y_position_std': Array(0.00591861, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01101209, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.621264219284058, 'eval/sps': 6207.184905778002, 'num_steps': 209920}
{'eval/walltime': 997.439906835556, 'training/sps': 127.26257155329604, 'training/walltime': 1773.0953381061554, 'training/entropy_loss': Array(-0.0138284, dtype=float32), 'training/policy_loss': Array(-0.18861857, dtype=float32), 'training/total_loss': Array(-0.20241919, dtype=float32), 'training/v_loss': Array(2.7793874e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088251, dtype=float32), 'eval/episode_forward_reward': Array(-0.03325776, dtype=float32), 'eval/episode_reward': Array(-2.0324807, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03325776, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982255, dtype=float32), 'eval/episode_train_reward': Array(-0.00099773, dtype=float32), 'eval/episode_x_position': Array(1.0069051, dtype=float32), 'eval/episode_x_velocity': Array(-0.03325776, dtype=float32), 'eval/episode_y_position': Array(-0.00029266, dtype=float32), 'eval/episode_y_velocity': Array(-0.00266966, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058354, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04189957, dtype=float32), 'eval/episode_reward_std': Array(0.04272328, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04189957, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00902892, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125699, dtype=float32), 'eval/episode_x_position_std': Array(0.00580158, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04189957, dtype=float32), 'eval/episode_y_position_std': Array(0.00586158, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01368398, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.622308254241943, 'eval/sps': 6206.870657830983, 'num_steps': 215040}
{'eval/walltime': 1018.1079099178314, 'training/sps': 127.06049752832169, 'training/walltime': 1813.3911035060883, 'training/entropy_loss': Array(-0.01231367, dtype=float32), 'training/policy_loss': Array(-0.1858352, dtype=float32), 'training/total_loss': Array(-0.19812481, dtype=float32), 'training/v_loss': Array(2.4059966e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090246, dtype=float32), 'eval/episode_forward_reward': Array(-0.04091052, dtype=float32), 'eval/episode_reward': Array(-2.0398188, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04091052, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997681, dtype=float32), 'eval/episode_train_reward': Array(-0.00122732, dtype=float32), 'eval/episode_x_position': Array(1.0071747, dtype=float32), 'eval/episode_x_velocity': Array(-0.04091052, dtype=float32), 'eval/episode_y_position': Array(-0.00028738, dtype=float32), 'eval/episode_y_velocity': Array(-0.00060202, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.005693, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04292509, dtype=float32), 'eval/episode_reward_std': Array(0.04476677, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04292509, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01278421, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128775, dtype=float32), 'eval/episode_x_position_std': Array(0.00571652, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04292509, dtype=float32), 'eval/episode_y_position_std': Array(0.00622385, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0113022, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66800308227539, 'eval/sps': 6193.147905506707, 'num_steps': 220160}
{'eval/walltime': 1038.7365686893463, 'training/sps': 127.35275769745054, 'training/walltime': 1853.594394683838, 'training/entropy_loss': Array(-0.01073462, dtype=float32), 'training/policy_loss': Array(-0.18733454, dtype=float32), 'training/total_loss': Array(-0.19804858, dtype=float32), 'training/v_loss': Array(2.058268e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094808, dtype=float32), 'eval/episode_forward_reward': Array(-0.03948777, dtype=float32), 'eval/episode_reward': Array(-2.0374842, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03948777, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968119, dtype=float32), 'eval/episode_train_reward': Array(-0.00118463, dtype=float32), 'eval/episode_x_position': Array(1.0076473, dtype=float32), 'eval/episode_x_velocity': Array(-0.03948777, dtype=float32), 'eval/episode_y_position': Array(5.471197e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00050173, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00538855, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04223842, dtype=float32), 'eval/episode_reward_std': Array(0.04669033, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04223842, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01431734, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126715, dtype=float32), 'eval/episode_x_position_std': Array(0.00534046, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04223842, dtype=float32), 'eval/episode_y_position_std': Array(0.00603464, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01453778, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.628658771514893, 'eval/sps': 6204.959877311508, 'num_steps': 225280}
{'eval/walltime': 1059.3937184810638, 'training/sps': 127.30155467533146, 'training/walltime': 1893.8138563632965, 'training/entropy_loss': Array(-0.00925252, dtype=float32), 'training/policy_loss': Array(-0.19248185, dtype=float32), 'training/total_loss': Array(-0.20171672, dtype=float32), 'training/v_loss': Array(1.7649127e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085986, dtype=float32), 'eval/episode_forward_reward': Array(-0.03788286, dtype=float32), 'eval/episode_reward': Array(-2.03498, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03788286, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959607, dtype=float32), 'eval/episode_train_reward': Array(-0.00113649, dtype=float32), 'eval/episode_x_position': Array(1.0067244, dtype=float32), 'eval/episode_x_velocity': Array(-0.03788286, dtype=float32), 'eval/episode_y_position': Array(0.00040127, dtype=float32), 'eval/episode_y_velocity': Array(-0.00074895, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585533, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04282582, dtype=float32), 'eval/episode_reward_std': Array(0.0459012, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04282582, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01647898, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128477, dtype=float32), 'eval/episode_x_position_std': Array(0.00584795, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04282582, dtype=float32), 'eval/episode_y_position_std': Array(0.00562415, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0102485, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65714979171753, 'eval/sps': 6196.401792628793, 'num_steps': 230400}
{'eval/walltime': 1080.0588533878326, 'training/sps': 127.22355577089495, 'training/walltime': 1934.0579760074615, 'training/entropy_loss': Array(-0.00749265, dtype=float32), 'training/policy_loss': Array(-0.1928271, dtype=float32), 'training/total_loss': Array(-0.20030504, dtype=float32), 'training/v_loss': Array(1.4704443e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083144, dtype=float32), 'eval/episode_forward_reward': Array(-0.0393764, dtype=float32), 'eval/episode_reward': Array(-2.0366192, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0393764, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960613, dtype=float32), 'eval/episode_train_reward': Array(-0.00118129, dtype=float32), 'eval/episode_x_position': Array(1.0064514, dtype=float32), 'eval/episode_x_velocity': Array(-0.0393764, dtype=float32), 'eval/episode_y_position': Array(0.00105318, dtype=float32), 'eval/episode_y_velocity': Array(0.00157375, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00611449, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04282198, dtype=float32), 'eval/episode_reward_std': Array(0.04772382, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04282198, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01725862, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128466, dtype=float32), 'eval/episode_x_position_std': Array(0.00611171, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04282198, dtype=float32), 'eval/episode_y_position_std': Array(0.0057575, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01719692, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6651349067688, 'eval/sps': 6194.007470915373, 'num_steps': 235520}
{'eval/walltime': 1100.7214183807373, 'training/sps': 127.29246724210847, 'training/walltime': 1974.2803089618683, 'training/entropy_loss': Array(-0.0058123, dtype=float32), 'training/policy_loss': Array(-0.18890454, dtype=float32), 'training/total_loss': Array(-0.19470413, dtype=float32), 'training/v_loss': Array(1.2716426e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096066, dtype=float32), 'eval/episode_forward_reward': Array(-0.04069732, dtype=float32), 'eval/episode_reward': Array(-2.040578, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04069732, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986596, dtype=float32), 'eval/episode_train_reward': Array(-0.00122092, dtype=float32), 'eval/episode_x_position': Array(1.0077515, dtype=float32), 'eval/episode_x_velocity': Array(-0.04069732, dtype=float32), 'eval/episode_y_position': Array(0.00058798, dtype=float32), 'eval/episode_y_velocity': Array(-0.00181503, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572837, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04238241, dtype=float32), 'eval/episode_reward_std': Array(0.04258297, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04238241, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00844356, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127147, dtype=float32), 'eval/episode_x_position_std': Array(0.00570445, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04238241, dtype=float32), 'eval/episode_y_position_std': Array(0.00560361, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01044075, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.662564992904663, 'eval/sps': 6194.777852795819, 'num_steps': 240640}
{'eval/walltime': 1121.3991754055023, 'training/sps': 127.3114487228946, 'training/walltime': 2014.4966449737549, 'training/entropy_loss': Array(-0.00377707, dtype=float32), 'training/policy_loss': Array(-0.18578964, dtype=float32), 'training/total_loss': Array(-0.18955705, dtype=float32), 'training/v_loss': Array(9.654688e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017408, dtype=float32), 'eval/episode_forward_reward': Array(-0.03900325, dtype=float32), 'eval/episode_reward': Array(-2.0547886, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03900325, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.022428, dtype=float32), 'eval/episode_train_reward': Array(-0.0011701, dtype=float32), 'eval/episode_x_position': Array(1.0155334, dtype=float32), 'eval/episode_x_velocity': Array(-0.03900325, dtype=float32), 'eval/episode_y_position': Array(-1.8160397e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00093217, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08923657, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0422048, dtype=float32), 'eval/episode_reward_std': Array(0.17830725, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0422048, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26428926, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126614, dtype=float32), 'eval/episode_x_position_std': Array(0.088971, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0422048, dtype=float32), 'eval/episode_y_position_std': Array(0.00527978, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01346979, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.677757024765015, 'eval/sps': 6190.226524409729, 'num_steps': 245760}
{'eval/walltime': 1142.045033454895, 'training/sps': 127.11884370517048, 'training/walltime': 2054.773915052414, 'training/entropy_loss': Array(-0.00209212, dtype=float32), 'training/policy_loss': Array(-0.19817375, dtype=float32), 'training/total_loss': Array(-0.20025828, dtype=float32), 'training/v_loss': Array(7.587407e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093505, dtype=float32), 'eval/episode_forward_reward': Array(-0.0323349, dtype=float32), 'eval/episode_reward': Array(-2.0296702, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0323349, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963653, dtype=float32), 'eval/episode_train_reward': Array(-0.00097005, dtype=float32), 'eval/episode_x_position': Array(1.007448, dtype=float32), 'eval/episode_x_velocity': Array(-0.0323349, dtype=float32), 'eval/episode_y_position': Array(0.00024973, dtype=float32), 'eval/episode_y_velocity': Array(0.00144938, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00607062, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03968599, dtype=float32), 'eval/episode_reward_std': Array(0.0443261, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03968599, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01544976, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119058, dtype=float32), 'eval/episode_x_position_std': Array(0.00608595, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03968599, dtype=float32), 'eval/episode_y_position_std': Array(0.00618029, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01114845, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6458580493927, 'eval/sps': 6199.790761603397, 'num_steps': 250880}
{'eval/walltime': 1162.6640436649323, 'training/sps': 127.31535544616226, 'training/walltime': 2094.989017009735, 'training/entropy_loss': Array(6.421095e-05, dtype=float32), 'training/policy_loss': Array(-0.1920208, dtype=float32), 'training/total_loss': Array(-0.1919503, dtype=float32), 'training/v_loss': Array(6.292687e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094006, dtype=float32), 'eval/episode_forward_reward': Array(-0.04640734, dtype=float32), 'eval/episode_reward': Array(-2.0451221, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04640734, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973226, dtype=float32), 'eval/episode_train_reward': Array(-0.00139222, dtype=float32), 'eval/episode_x_position': Array(1.0075555, dtype=float32), 'eval/episode_x_velocity': Array(-0.04640734, dtype=float32), 'eval/episode_y_position': Array(0.00018452, dtype=float32), 'eval/episode_y_velocity': Array(-0.00252781, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00534386, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04384993, dtype=float32), 'eval/episode_reward_std': Array(0.04785468, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04384993, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01386068, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013155, dtype=float32), 'eval/episode_x_position_std': Array(0.00534858, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04384993, dtype=float32), 'eval/episode_y_position_std': Array(0.00596139, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01064042, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61901021003723, 'eval/sps': 6207.863456883601, 'num_steps': 256000}
{'eval/walltime': 1183.2846357822418, 'training/sps': 127.31210989027106, 'training/walltime': 2135.2051441669464, 'training/entropy_loss': Array(0.00246653, dtype=float32), 'training/policy_loss': Array(-0.18580455, dtype=float32), 'training/total_loss': Array(-0.18333316, dtype=float32), 'training/v_loss': Array(4.87963e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088696, dtype=float32), 'eval/episode_forward_reward': Array(-0.03968459, dtype=float32), 'eval/episode_reward': Array(-2.0366066, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03968459, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957314, dtype=float32), 'eval/episode_train_reward': Array(-0.00119054, dtype=float32), 'eval/episode_x_position': Array(1.006994, dtype=float32), 'eval/episode_x_velocity': Array(-0.03968459, dtype=float32), 'eval/episode_y_position': Array(3.1725212e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00066609, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059036, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04234233, dtype=float32), 'eval/episode_reward_std': Array(0.04665324, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04234233, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01681909, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127027, dtype=float32), 'eval/episode_x_position_std': Array(0.0058848, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04234233, dtype=float32), 'eval/episode_y_position_std': Array(0.0058069, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01435863, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62059211730957, 'eval/sps': 6207.387221075615, 'num_steps': 261120}
{'eval/walltime': 1203.9442958831787, 'training/sps': 127.25633484043709, 'training/walltime': 2175.4388976097107, 'training/entropy_loss': Array(0.00449, dtype=float32), 'training/policy_loss': Array(-0.20127186, dtype=float32), 'training/total_loss': Array(-0.19677827, dtype=float32), 'training/v_loss': Array(3.61194e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099971, dtype=float32), 'eval/episode_forward_reward': Array(-0.03963119, dtype=float32), 'eval/episode_reward': Array(-2.0355072, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03963119, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994687, dtype=float32), 'eval/episode_train_reward': Array(-0.00118894, dtype=float32), 'eval/episode_x_position': Array(1.0081269, dtype=float32), 'eval/episode_x_velocity': Array(-0.03963119, dtype=float32), 'eval/episode_y_position': Array(-0.00084674, dtype=float32), 'eval/episode_y_velocity': Array(-0.00223374, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593389, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04132054, dtype=float32), 'eval/episode_reward_std': Array(0.04775428, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04132054, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02007782, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123962, dtype=float32), 'eval/episode_x_position_std': Array(0.00597673, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04132054, dtype=float32), 'eval/episode_y_position_std': Array(0.00575777, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01002727, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65966010093689, 'eval/sps': 6195.648881667485, 'num_steps': 266240}
{'eval/walltime': 1224.5715482234955, 'training/sps': 127.00916262608852, 'training/walltime': 2215.750949859619, 'training/entropy_loss': Array(0.00725714, dtype=float32), 'training/policy_loss': Array(-0.19183221, dtype=float32), 'training/total_loss': Array(-0.18457241, dtype=float32), 'training/v_loss': Array(2.6608893e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096579, dtype=float32), 'eval/episode_forward_reward': Array(-0.03534051, dtype=float32), 'eval/episode_reward': Array(-2.0314035, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03534051, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995003, dtype=float32), 'eval/episode_train_reward': Array(-0.00106022, dtype=float32), 'eval/episode_x_position': Array(1.0077784, dtype=float32), 'eval/episode_x_velocity': Array(-0.03534051, dtype=float32), 'eval/episode_y_position': Array(-0.00074193, dtype=float32), 'eval/episode_y_velocity': Array(-0.00029811, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00547533, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0407646, dtype=float32), 'eval/episode_reward_std': Array(0.04843981, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0407646, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01975552, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122294, dtype=float32), 'eval/episode_x_position_std': Array(0.00547655, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0407646, dtype=float32), 'eval/episode_y_position_std': Array(0.00582263, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01186752, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.627252340316772, 'eval/sps': 6205.382951069008, 'num_steps': 271360}
{'eval/walltime': 1245.2146334648132, 'training/sps': 126.99115053876827, 'training/walltime': 2256.0687198638916, 'training/entropy_loss': Array(0.00956362, dtype=float32), 'training/policy_loss': Array(-0.19339031, dtype=float32), 'training/total_loss': Array(-0.18382469, dtype=float32), 'training/v_loss': Array(2.0094203e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0081592, dtype=float32), 'eval/episode_forward_reward': Array(-0.03959029, dtype=float32), 'eval/episode_reward': Array(-2.0390804, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03959029, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983025, dtype=float32), 'eval/episode_train_reward': Array(-0.00118771, dtype=float32), 'eval/episode_x_position': Array(1.0062549, dtype=float32), 'eval/episode_x_velocity': Array(-0.03959029, dtype=float32), 'eval/episode_y_position': Array(-0.00050095, dtype=float32), 'eval/episode_y_velocity': Array(-0.00071686, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00520749, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04386088, dtype=float32), 'eval/episode_reward_std': Array(0.04667639, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04386088, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01157685, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131583, dtype=float32), 'eval/episode_x_position_std': Array(0.00523954, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04386088, dtype=float32), 'eval/episode_y_position_std': Array(0.00562986, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01612923, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64308524131775, 'eval/sps': 6200.623526167697, 'num_steps': 276480}
{'eval/walltime': 1265.8391613960266, 'training/sps': 127.20990676476514, 'training/walltime': 2296.3171575069427, 'training/entropy_loss': Array(0.01170719, dtype=float32), 'training/policy_loss': Array(-0.1913208, dtype=float32), 'training/total_loss': Array(-0.17961216, dtype=float32), 'training/v_loss': Array(1.4564696e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092709, dtype=float32), 'eval/episode_forward_reward': Array(-0.04597164, dtype=float32), 'eval/episode_reward': Array(-2.0435092, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04597164, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961586, dtype=float32), 'eval/episode_train_reward': Array(-0.00137915, dtype=float32), 'eval/episode_x_position': Array(1.0074356, dtype=float32), 'eval/episode_x_velocity': Array(-0.04597164, dtype=float32), 'eval/episode_y_position': Array(5.889096e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00031261, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599735, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04456068, dtype=float32), 'eval/episode_reward_std': Array(0.04825288, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04456068, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01846176, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133682, dtype=float32), 'eval/episode_x_position_std': Array(0.00594079, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04456068, dtype=float32), 'eval/episode_y_position_std': Array(0.00590954, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01441604, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62452793121338, 'eval/sps': 6206.202654766388, 'num_steps': 281600}
{'eval/walltime': 1286.5114359855652, 'training/sps': 127.02800410015803, 'training/walltime': 2336.623230457306, 'training/entropy_loss': Array(0.01422521, dtype=float32), 'training/policy_loss': Array(-0.1870558, dtype=float32), 'training/total_loss': Array(-0.17282951, dtype=float32), 'training/v_loss': Array(1.087396e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088747, dtype=float32), 'eval/episode_forward_reward': Array(-0.03869653, dtype=float32), 'eval/episode_reward': Array(-2.0394611, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03869653, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9996037, dtype=float32), 'eval/episode_train_reward': Array(-0.0011609, dtype=float32), 'eval/episode_x_position': Array(1.0070024, dtype=float32), 'eval/episode_x_velocity': Array(-0.03869653, dtype=float32), 'eval/episode_y_position': Array(0.00140499, dtype=float32), 'eval/episode_y_velocity': Array(-0.00031057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582288, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04436132, dtype=float32), 'eval/episode_reward_std': Array(0.04623588, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04436132, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00428236, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133084, dtype=float32), 'eval/episode_x_position_std': Array(0.00585396, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04436132, dtype=float32), 'eval/episode_y_position_std': Array(0.00551898, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01098817, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672274589538574, 'eval/sps': 6191.868216803572, 'num_steps': 286720}
{'eval/walltime': 1307.1949291229248, 'training/sps': 127.36746775828881, 'training/walltime': 2376.8218784332275, 'training/entropy_loss': Array(0.01689401, dtype=float32), 'training/policy_loss': Array(-0.18439314, dtype=float32), 'training/total_loss': Array(-0.16749834, dtype=float32), 'training/v_loss': Array(8.037312e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0172783, dtype=float32), 'eval/episode_forward_reward': Array(-0.03863708, dtype=float32), 'eval/episode_reward': Array(-2.052987, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03863708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0210035, dtype=float32), 'eval/episode_train_reward': Array(-0.00115911, dtype=float32), 'eval/episode_x_position': Array(1.0153811, dtype=float32), 'eval/episode_x_velocity': Array(-0.03863708, dtype=float32), 'eval/episode_y_position': Array(0.00024176, dtype=float32), 'eval/episode_y_velocity': Array(0.0003494, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08818033, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04239661, dtype=float32), 'eval/episode_reward_std': Array(0.17875777, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04239661, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26463678, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012719, dtype=float32), 'eval/episode_x_position_std': Array(0.08791126, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04239661, dtype=float32), 'eval/episode_y_position_std': Array(0.00592882, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01172042, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.68349313735962, 'eval/sps': 6188.509801025806, 'num_steps': 291840}
{'eval/walltime': 1327.8158628940582, 'training/sps': 127.26967551420185, 'training/walltime': 2417.051414489746, 'training/entropy_loss': Array(0.01896376, dtype=float32), 'training/policy_loss': Array(-0.1968569, dtype=float32), 'training/total_loss': Array(-0.17789257, dtype=float32), 'training/v_loss': Array(5.7158235e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095301, dtype=float32), 'eval/episode_forward_reward': Array(-0.04120567, dtype=float32), 'eval/episode_reward': Array(-2.038851, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04120567, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964092, dtype=float32), 'eval/episode_train_reward': Array(-0.00123617, dtype=float32), 'eval/episode_x_position': Array(1.0077007, dtype=float32), 'eval/episode_x_velocity': Array(-0.04120567, dtype=float32), 'eval/episode_y_position': Array(-0.00030324, dtype=float32), 'eval/episode_y_velocity': Array(-0.00102148, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059496, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04304809, dtype=float32), 'eval/episode_reward_std': Array(0.04707542, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04304809, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01413732, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129144, dtype=float32), 'eval/episode_x_position_std': Array(0.00594895, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04304809, dtype=float32), 'eval/episode_y_position_std': Array(0.00608396, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01627996, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.620933771133423, 'eval/sps': 6207.284375219858, 'num_steps': 296960}
{'eval/walltime': 1348.4727947711945, 'training/sps': 127.22041362488339, 'training/walltime': 2457.2965281009674, 'training/entropy_loss': Array(0.02185832, dtype=float32), 'training/policy_loss': Array(-0.18872064, dtype=float32), 'training/total_loss': Array(-0.16686189, dtype=float32), 'training/v_loss': Array(4.1952583e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088321, dtype=float32), 'eval/episode_forward_reward': Array(-0.04256696, dtype=float32), 'eval/episode_reward': Array(-2.0405982, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04256696, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9967542, dtype=float32), 'eval/episode_train_reward': Array(-0.00127701, dtype=float32), 'eval/episode_x_position': Array(1.0069971, dtype=float32), 'eval/episode_x_velocity': Array(-0.04256696, dtype=float32), 'eval/episode_y_position': Array(9.450712e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00061782, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567081, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04192066, dtype=float32), 'eval/episode_reward_std': Array(0.04694255, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04192066, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01466774, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125762, dtype=float32), 'eval/episode_x_position_std': Array(0.00565643, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04192066, dtype=float32), 'eval/episode_y_position_std': Array(0.00576937, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01238793, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65693187713623, 'eval/sps': 6196.46715985323, 'num_steps': 302080}
{'eval/walltime': 1369.1221706867218, 'training/sps': 127.27765832881911, 'training/walltime': 2497.5235409736633, 'training/entropy_loss': Array(0.02465585, dtype=float32), 'training/policy_loss': Array(-0.1822289, dtype=float32), 'training/total_loss': Array(-0.15757275, dtype=float32), 'training/v_loss': Array(2.875377e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096796, dtype=float32), 'eval/episode_forward_reward': Array(-0.03975739, dtype=float32), 'eval/episode_reward': Array(-2.0392137, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03975739, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982634, dtype=float32), 'eval/episode_train_reward': Array(-0.00119272, dtype=float32), 'eval/episode_x_position': Array(1.0078176, dtype=float32), 'eval/episode_x_velocity': Array(-0.03975739, dtype=float32), 'eval/episode_y_position': Array(-0.00021962, dtype=float32), 'eval/episode_y_velocity': Array(-0.00020156, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570651, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04387261, dtype=float32), 'eval/episode_reward_std': Array(0.04530433, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04387261, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01121305, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131618, dtype=float32), 'eval/episode_x_position_std': Array(0.00569715, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04387261, dtype=float32), 'eval/episode_y_position_std': Array(0.005656, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01222304, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.649375915527344, 'eval/sps': 6198.734553703878, 'num_steps': 307200}
{'eval/walltime': 1389.8021602630615, 'training/sps': 127.43132575653439, 'training/walltime': 2537.702044725418, 'training/entropy_loss': Array(0.02782248, dtype=float32), 'training/policy_loss': Array(-0.16609137, dtype=float32), 'training/total_loss': Array(-0.13826868, dtype=float32), 'training/v_loss': Array(2.08881e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092728, dtype=float32), 'eval/episode_forward_reward': Array(-0.03451784, dtype=float32), 'eval/episode_reward': Array(-2.0318663, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03451784, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963129, dtype=float32), 'eval/episode_train_reward': Array(-0.00103554, dtype=float32), 'eval/episode_x_position': Array(1.0073674, dtype=float32), 'eval/episode_x_velocity': Array(-0.03451784, dtype=float32), 'eval/episode_y_position': Array(7.849748e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00125303, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572588, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04218527, dtype=float32), 'eval/episode_reward_std': Array(0.04718581, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04218527, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01708982, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126556, dtype=float32), 'eval/episode_x_position_std': Array(0.00569829, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04218527, dtype=float32), 'eval/episode_y_position_std': Array(0.00549773, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00893787, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67998957633972, 'eval/sps': 6189.558245544121, 'num_steps': 312320}
{'eval/walltime': 1410.4495136737823, 'training/sps': 127.21698977441302, 'training/walltime': 2577.9482414722443, 'training/entropy_loss': Array(0.03037206, dtype=float32), 'training/policy_loss': Array(-0.17030752, dtype=float32), 'training/total_loss': Array(-0.13993531, dtype=float32), 'training/v_loss': Array(1.4678267e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089412, dtype=float32), 'eval/episode_forward_reward': Array(-0.04071129, dtype=float32), 'eval/episode_reward': Array(-2.0401502, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04071129, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982176, dtype=float32), 'eval/episode_train_reward': Array(-0.00122134, dtype=float32), 'eval/episode_x_position': Array(1.0071027, dtype=float32), 'eval/episode_x_velocity': Array(-0.04071129, dtype=float32), 'eval/episode_y_position': Array(0.00041851, dtype=float32), 'eval/episode_y_velocity': Array(-0.00054605, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057973, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04423562, dtype=float32), 'eval/episode_reward_std': Array(0.04600501, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04423562, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01017905, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132707, dtype=float32), 'eval/episode_x_position_std': Array(0.00581007, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04423562, dtype=float32), 'eval/episode_y_position_std': Array(0.00571617, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01381856, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647353410720825, 'eval/sps': 6199.341748736569, 'num_steps': 317440}
{'eval/walltime': 1431.125459432602, 'training/sps': 127.16893664700305, 'training/walltime': 2618.209645986557, 'training/entropy_loss': Array(0.03312077, dtype=float32), 'training/policy_loss': Array(-0.1467386, dtype=float32), 'training/total_loss': Array(-0.11361773, dtype=float32), 'training/v_loss': Array(1.0793556e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092721, dtype=float32), 'eval/episode_forward_reward': Array(-0.04046053, dtype=float32), 'eval/episode_reward': Array(-2.0404348, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04046053, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987607, dtype=float32), 'eval/episode_train_reward': Array(-0.00121382, dtype=float32), 'eval/episode_x_position': Array(1.0074058, dtype=float32), 'eval/episode_x_velocity': Array(-0.04046053, dtype=float32), 'eval/episode_y_position': Array(0.00017382, dtype=float32), 'eval/episode_y_velocity': Array(-0.00073274, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569686, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04362475, dtype=float32), 'eval/episode_reward_std': Array(0.0442211, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04362475, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00943142, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130874, dtype=float32), 'eval/episode_x_position_std': Array(0.00569372, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04362475, dtype=float32), 'eval/episode_y_position_std': Array(0.00574983, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01122602, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67594575881958, 'eval/sps': 6190.768804150109, 'num_steps': 322560}
{'eval/walltime': 1451.7832934856415, 'training/sps': 127.32802224492924, 'training/walltime': 2658.420747280121, 'training/entropy_loss': Array(0.0364756, dtype=float32), 'training/policy_loss': Array(-0.11392829, dtype=float32), 'training/total_loss': Array(-0.07745262, dtype=float32), 'training/v_loss': Array(7.4233185e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090715, dtype=float32), 'eval/episode_forward_reward': Array(-0.03768201, dtype=float32), 'eval/episode_reward': Array(-2.0371475, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03768201, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998335, dtype=float32), 'eval/episode_train_reward': Array(-0.00113046, dtype=float32), 'eval/episode_x_position': Array(1.0072128, dtype=float32), 'eval/episode_x_velocity': Array(-0.03768201, dtype=float32), 'eval/episode_y_position': Array(0.00075415, dtype=float32), 'eval/episode_y_velocity': Array(-0.00045464, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574596, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04326743, dtype=float32), 'eval/episode_reward_std': Array(0.04590776, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04326743, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00930469, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129802, dtype=float32), 'eval/episode_x_position_std': Array(0.00577148, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04326743, dtype=float32), 'eval/episode_y_position_std': Array(0.00585842, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01377846, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65783405303955, 'eval/sps': 6196.196545647357, 'num_steps': 327680}
{'eval/walltime': 1472.453652381897, 'training/sps': 127.18329921024345, 'training/walltime': 2698.67760515213, 'training/entropy_loss': Array(0.03913928, dtype=float32), 'training/policy_loss': Array(-0.10993725, dtype=float32), 'training/total_loss': Array(-0.07079791, dtype=float32), 'training/v_loss': Array(5.1110256e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101173, dtype=float32), 'eval/episode_forward_reward': Array(-0.03727091, dtype=float32), 'eval/episode_reward': Array(-2.0310986, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03727091, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9927096, dtype=float32), 'eval/episode_train_reward': Array(-0.00111813, dtype=float32), 'eval/episode_x_position': Array(1.0082418, dtype=float32), 'eval/episode_x_velocity': Array(-0.03727091, dtype=float32), 'eval/episode_y_position': Array(0.00079926, dtype=float32), 'eval/episode_y_velocity': Array(0.00012966, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578184, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04227082, dtype=float32), 'eval/episode_reward_std': Array(0.04920221, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04227082, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02348713, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126812, dtype=float32), 'eval/episode_x_position_std': Array(0.00572504, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04227082, dtype=float32), 'eval/episode_y_position_std': Array(0.0055552, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01438854, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.670358896255493, 'eval/sps': 6192.442068491981, 'num_steps': 332800}
{'eval/walltime': 1493.0992777347565, 'training/sps': 127.1155464609913, 'training/walltime': 2738.955919981003, 'training/entropy_loss': Array(0.05500377, dtype=float32), 'training/policy_loss': Array(0.24578802, dtype=float32), 'training/total_loss': Array(0.30079183, dtype=float32), 'training/v_loss': Array(3.3885968e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097156, dtype=float32), 'eval/episode_forward_reward': Array(-0.04226707, dtype=float32), 'eval/episode_reward': Array(-2.04106, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04226707, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975247, dtype=float32), 'eval/episode_train_reward': Array(-0.00126801, dtype=float32), 'eval/episode_x_position': Array(1.0078506, dtype=float32), 'eval/episode_x_velocity': Array(-0.04226707, dtype=float32), 'eval/episode_y_position': Array(-0.00019456, dtype=float32), 'eval/episode_y_velocity': Array(1.8370978e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00601014, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04282778, dtype=float32), 'eval/episode_reward_std': Array(0.04522903, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04282778, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01265298, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128483, dtype=float32), 'eval/episode_x_position_std': Array(0.0059768, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04282778, dtype=float32), 'eval/episode_y_position_std': Array(0.00568971, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01000747, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.645625352859497, 'eval/sps': 6199.860639351935, 'num_steps': 337920}
{'eval/walltime': 1513.736266374588, 'training/sps': 127.24879127097103, 'training/walltime': 2779.1920585632324, 'training/entropy_loss': Array(0.03094197, dtype=float32), 'training/policy_loss': Array(0.27392393, dtype=float32), 'training/total_loss': Array(0.30486602, dtype=float32), 'training/v_loss': Array(9.2314146e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100296, dtype=float32), 'eval/episode_forward_reward': Array(-0.03481843, dtype=float32), 'eval/episode_reward': Array(-2.0340412, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03481843, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998178, dtype=float32), 'eval/episode_train_reward': Array(-0.00104455, dtype=float32), 'eval/episode_x_position': Array(1.0081056, dtype=float32), 'eval/episode_x_velocity': Array(-0.03481843, dtype=float32), 'eval/episode_y_position': Array(-7.141396e-05, dtype=float32), 'eval/episode_y_velocity': Array(-1.4335732e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00549403, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04200162, dtype=float32), 'eval/episode_reward_std': Array(0.04576461, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04200162, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01033439, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126005, dtype=float32), 'eval/episode_x_position_std': Array(0.00550614, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04200162, dtype=float32), 'eval/episode_y_position_std': Array(0.00597863, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00904337, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.636988639831543, 'eval/sps': 6202.455321070761, 'num_steps': 343040}
{'eval/walltime': 1534.3619647026062, 'training/sps': 127.2270711788837, 'training/walltime': 2819.4350662231445, 'training/entropy_loss': Array(0.02586139, dtype=float32), 'training/policy_loss': Array(-0.19633114, dtype=float32), 'training/total_loss': Array(-0.17046842, dtype=float32), 'training/v_loss': Array(1.3431048e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089741, dtype=float32), 'eval/episode_forward_reward': Array(-0.03411815, dtype=float32), 'eval/episode_reward': Array(-2.0314813, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03411815, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963398, dtype=float32), 'eval/episode_train_reward': Array(-0.00102354, dtype=float32), 'eval/episode_x_position': Array(1.0070763, dtype=float32), 'eval/episode_x_velocity': Array(-0.03411815, dtype=float32), 'eval/episode_y_position': Array(-0.00060642, dtype=float32), 'eval/episode_y_velocity': Array(0.00019386, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00550762, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04196396, dtype=float32), 'eval/episode_reward_std': Array(0.04649808, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04196396, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01774391, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125892, dtype=float32), 'eval/episode_x_position_std': Array(0.00540642, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04196396, dtype=float32), 'eval/episode_y_position_std': Array(0.00599524, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01169621, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62569832801819, 'eval/sps': 6205.850486338361, 'num_steps': 348160}
{'eval/walltime': 1555.0049223899841, 'training/sps': 127.33282843728308, 'training/walltime': 2859.644649744034, 'training/entropy_loss': Array(0.02764007, dtype=float32), 'training/policy_loss': Array(-0.19325538, dtype=float32), 'training/total_loss': Array(-0.16561472, dtype=float32), 'training/v_loss': Array(5.778669e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0181292, dtype=float32), 'eval/episode_forward_reward': Array(-0.03940721, dtype=float32), 'eval/episode_reward': Array(-2.054264, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03940721, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0214872, dtype=float32), 'eval/episode_train_reward': Array(-0.00118222, dtype=float32), 'eval/episode_x_position': Array(1.016217, dtype=float32), 'eval/episode_x_velocity': Array(-0.03940721, dtype=float32), 'eval/episode_y_position': Array(-8.552171e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00101483, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08817093, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04468317, dtype=float32), 'eval/episode_reward_std': Array(0.17861442, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04468317, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26449922, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013405, dtype=float32), 'eval/episode_x_position_std': Array(0.08789911, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04468317, dtype=float32), 'eval/episode_y_position_std': Array(0.00619479, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01214974, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.64295768737793, 'eval/sps': 6200.661840152159, 'num_steps': 353280}
{'eval/walltime': 1575.6674711704254, 'training/sps': 127.24905366720967, 'training/walltime': 2899.880705356598, 'training/entropy_loss': Array(0.02965448, dtype=float32), 'training/policy_loss': Array(-0.17874634, dtype=float32), 'training/total_loss': Array(-0.14909144, dtype=float32), 'training/v_loss': Array(4.2817788e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094774, dtype=float32), 'eval/episode_forward_reward': Array(-0.0455066, dtype=float32), 'eval/episode_reward': Array(-2.0448976, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0455066, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998026, dtype=float32), 'eval/episode_train_reward': Array(-0.0013652, dtype=float32), 'eval/episode_x_position': Array(1.0076319, dtype=float32), 'eval/episode_x_velocity': Array(-0.0455066, dtype=float32), 'eval/episode_y_position': Array(0.0006379, dtype=float32), 'eval/episode_y_velocity': Array(-0.00308753, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580389, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04311554, dtype=float32), 'eval/episode_reward_std': Array(0.04650162, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04311554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01104462, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129347, dtype=float32), 'eval/episode_x_position_std': Array(0.00577476, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04311554, dtype=float32), 'eval/episode_y_position_std': Array(0.00568737, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01756117, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.662548780441284, 'eval/sps': 6194.782713406683, 'num_steps': 358400}
{'eval/walltime': 1596.3236289024353, 'training/sps': 127.29317801175137, 'training/walltime': 2940.102813720703, 'training/entropy_loss': Array(0.03208333, dtype=float32), 'training/policy_loss': Array(-0.16528317, dtype=float32), 'training/total_loss': Array(-0.13319954, dtype=float32), 'training/v_loss': Array(3.1275624e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094264, dtype=float32), 'eval/episode_forward_reward': Array(-0.03476092, dtype=float32), 'eval/episode_reward': Array(-2.0319128, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03476092, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996109, dtype=float32), 'eval/episode_train_reward': Array(-0.00104283, dtype=float32), 'eval/episode_x_position': Array(1.00751, dtype=float32), 'eval/episode_x_velocity': Array(-0.03476092, dtype=float32), 'eval/episode_y_position': Array(0.00021523, dtype=float32), 'eval/episode_y_velocity': Array(-0.00084325, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00609978, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04231225, dtype=float32), 'eval/episode_reward_std': Array(0.04801406, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04231225, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01665017, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126937, dtype=float32), 'eval/episode_x_position_std': Array(0.00609517, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04231225, dtype=float32), 'eval/episode_y_position_std': Array(0.0060948, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01348963, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.656157732009888, 'eval/sps': 6196.699389143623, 'num_steps': 363520}
{'eval/walltime': 1616.9635133743286, 'training/sps': 127.26341170861578, 'training/walltime': 2980.334329843521, 'training/entropy_loss': Array(0.03362648, dtype=float32), 'training/policy_loss': Array(-0.1770406, dtype=float32), 'training/total_loss': Array(-0.14341389, dtype=float32), 'training/v_loss': Array(2.4607152e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098233, dtype=float32), 'eval/episode_forward_reward': Array(-0.03942405, dtype=float32), 'eval/episode_reward': Array(-2.0379515, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03942405, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997345, dtype=float32), 'eval/episode_train_reward': Array(-0.00118272, dtype=float32), 'eval/episode_x_position': Array(1.0079608, dtype=float32), 'eval/episode_x_velocity': Array(-0.03942405, dtype=float32), 'eval/episode_y_position': Array(-0.00045645, dtype=float32), 'eval/episode_y_velocity': Array(-0.00182135, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00606607, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04254002, dtype=float32), 'eval/episode_reward_std': Array(0.04501685, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04254002, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01333176, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012762, dtype=float32), 'eval/episode_x_position_std': Array(0.00600659, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04254002, dtype=float32), 'eval/episode_y_position_std': Array(0.00565433, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01389229, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63988447189331, 'eval/sps': 6201.585099679508, 'num_steps': 368640}
{'eval/walltime': 1637.6105163097382, 'training/sps': 127.16267672941358, 'training/walltime': 3020.597716331482, 'training/entropy_loss': Array(0.03595838, dtype=float32), 'training/policy_loss': Array(-0.17675336, dtype=float32), 'training/total_loss': Array(-0.14079478, dtype=float32), 'training/v_loss': Array(1.7385787e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086465, dtype=float32), 'eval/episode_forward_reward': Array(-0.0345277, dtype=float32), 'eval/episode_reward': Array(-2.0332975, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0345277, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977343, dtype=float32), 'eval/episode_train_reward': Array(-0.00103583, dtype=float32), 'eval/episode_x_position': Array(1.0067639, dtype=float32), 'eval/episode_x_velocity': Array(-0.0345277, dtype=float32), 'eval/episode_y_position': Array(-0.00051634, dtype=float32), 'eval/episode_y_velocity': Array(-0.00120293, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614535, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04382201, dtype=float32), 'eval/episode_reward_std': Array(0.04898276, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04382201, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01543498, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131466, dtype=float32), 'eval/episode_x_position_std': Array(0.0061492, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04382201, dtype=float32), 'eval/episode_y_position_std': Array(0.0058589, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01254133, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647002935409546, 'eval/sps': 6199.446980291769, 'num_steps': 373760}
{'eval/walltime': 1658.2442207336426, 'training/sps': 127.32910258737553, 'training/walltime': 3060.808476448059, 'training/entropy_loss': Array(0.03860234, dtype=float32), 'training/policy_loss': Array(-0.15355805, dtype=float32), 'training/total_loss': Array(-0.1149556, dtype=float32), 'training/v_loss': Array(1.15591845e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089083, dtype=float32), 'eval/episode_forward_reward': Array(-0.03653936, dtype=float32), 'eval/episode_reward': Array(-2.0352151, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03653936, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975796, dtype=float32), 'eval/episode_train_reward': Array(-0.00109618, dtype=float32), 'eval/episode_x_position': Array(1.0070167, dtype=float32), 'eval/episode_x_velocity': Array(-0.03653936, dtype=float32), 'eval/episode_y_position': Array(6.5266504e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00016494, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00603593, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04196199, dtype=float32), 'eval/episode_reward_std': Array(0.04514926, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04196199, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01315467, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125886, dtype=float32), 'eval/episode_x_position_std': Array(0.00601332, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04196199, dtype=float32), 'eval/episode_y_position_std': Array(0.00596801, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01162491, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63370442390442, 'eval/sps': 6203.442550612012, 'num_steps': 378880}
{'eval/walltime': 1678.8638653755188, 'training/sps': 127.13855398700808, 'training/walltime': 3101.0795023441315, 'training/entropy_loss': Array(0.04121947, dtype=float32), 'training/policy_loss': Array(-0.12791908, dtype=float32), 'training/total_loss': Array(-0.08669952, dtype=float32), 'training/v_loss': Array(8.726288e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089767, dtype=float32), 'eval/episode_forward_reward': Array(-0.04517512, dtype=float32), 'eval/episode_reward': Array(-2.0462549, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04517512, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9997244, dtype=float32), 'eval/episode_train_reward': Array(-0.00135525, dtype=float32), 'eval/episode_x_position': Array(1.0071632, dtype=float32), 'eval/episode_x_velocity': Array(-0.04517512, dtype=float32), 'eval/episode_y_position': Array(0.00060268, dtype=float32), 'eval/episode_y_velocity': Array(-0.00176832, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590004, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04337914, dtype=float32), 'eval/episode_reward_std': Array(0.04475817, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04337914, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00156389, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130137, dtype=float32), 'eval/episode_x_position_std': Array(0.00587431, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04337914, dtype=float32), 'eval/episode_y_position_std': Array(0.00579878, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01162018, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61964464187622, 'eval/sps': 6207.67245134992, 'num_steps': 384000}
{'eval/walltime': 1699.5329096317291, 'training/sps': 127.15654768273916, 'training/walltime': 3141.344829559326, 'training/entropy_loss': Array(0.04345244, dtype=float32), 'training/policy_loss': Array(-0.10785231, dtype=float32), 'training/total_loss': Array(-0.06439981, dtype=float32), 'training/v_loss': Array(5.9201035e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097623, dtype=float32), 'eval/episode_forward_reward': Array(-0.04265768, dtype=float32), 'eval/episode_reward': Array(-2.0422163, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04265768, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982786, dtype=float32), 'eval/episode_train_reward': Array(-0.00127973, dtype=float32), 'eval/episode_x_position': Array(1.0078957, dtype=float32), 'eval/episode_x_velocity': Array(-0.04265768, dtype=float32), 'eval/episode_y_position': Array(-0.00015217, dtype=float32), 'eval/episode_y_velocity': Array(-0.00092174, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600414, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04274741, dtype=float32), 'eval/episode_reward_std': Array(0.04661553, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04274741, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01071392, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128242, dtype=float32), 'eval/episode_x_position_std': Array(0.00601179, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04274741, dtype=float32), 'eval/episode_y_position_std': Array(0.00558706, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01554673, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.669044256210327, 'eval/sps': 6192.835934421131, 'num_steps': 389120}
{'eval/walltime': 1720.1779010295868, 'training/sps': 127.02235835889223, 'training/walltime': 3181.6526939868927, 'training/entropy_loss': Array(0.05281971, dtype=float32), 'training/policy_loss': Array(0.26434407, dtype=float32), 'training/total_loss': Array(0.3171638, dtype=float32), 'training/v_loss': Array(4.28561e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016809, dtype=float32), 'eval/episode_forward_reward': Array(-0.03919091, dtype=float32), 'eval/episode_reward': Array(-2.0521793, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03919091, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0196254, dtype=float32), 'eval/episode_train_reward': Array(-0.00117573, dtype=float32), 'eval/episode_x_position': Array(1.0149295, dtype=float32), 'eval/episode_x_velocity': Array(-0.03919091, dtype=float32), 'eval/episode_y_position': Array(-0.00069189, dtype=float32), 'eval/episode_y_velocity': Array(-0.00073508, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08823872, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04333739, dtype=float32), 'eval/episode_reward_std': Array(0.18023752, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04333739, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2649515, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130012, dtype=float32), 'eval/episode_x_position_std': Array(0.08795559, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04333739, dtype=float32), 'eval/episode_y_position_std': Array(0.00560919, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01402489, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.644991397857666, 'eval/sps': 6200.051021250732, 'num_steps': 394240}
{'eval/walltime': 1740.815057516098, 'training/sps': 127.2877335074947, 'training/walltime': 3221.8765227794647, 'training/entropy_loss': Array(0.05535705, dtype=float32), 'training/policy_loss': Array(0.26934755, dtype=float32), 'training/total_loss': Array(0.32470462, dtype=float32), 'training/v_loss': Array(3.2564916e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098367, dtype=float32), 'eval/episode_forward_reward': Array(-0.03585026, dtype=float32), 'eval/episode_reward': Array(-2.0333045, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03585026, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963787, dtype=float32), 'eval/episode_train_reward': Array(-0.00107551, dtype=float32), 'eval/episode_x_position': Array(1.0079572, dtype=float32), 'eval/episode_x_velocity': Array(-0.03585026, dtype=float32), 'eval/episode_y_position': Array(0.00026731, dtype=float32), 'eval/episode_y_velocity': Array(-4.4506858e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578056, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04091645, dtype=float32), 'eval/episode_reward_std': Array(0.0454394, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04091645, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01528749, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122749, dtype=float32), 'eval/episode_x_position_std': Array(0.00576592, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04091645, dtype=float32), 'eval/episode_y_position_std': Array(0.00551044, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01087833, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63715648651123, 'eval/sps': 6202.4048750932725, 'num_steps': 399360}
{'eval/walltime': 1761.4623975753784, 'training/sps': 127.15889984159877, 'training/walltime': 3262.1411051750183, 'training/entropy_loss': Array(0.05622072, dtype=float32), 'training/policy_loss': Array(0.27052212, dtype=float32), 'training/total_loss': Array(0.32674286, dtype=float32), 'training/v_loss': Array(4.1057817e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099444, dtype=float32), 'eval/episode_forward_reward': Array(-0.04713804, dtype=float32), 'eval/episode_reward': Array(-2.046722, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04713804, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981697, dtype=float32), 'eval/episode_train_reward': Array(-0.00141414, dtype=float32), 'eval/episode_x_position': Array(1.0080888, dtype=float32), 'eval/episode_x_velocity': Array(-0.04713804, dtype=float32), 'eval/episode_y_position': Array(0.00043002, dtype=float32), 'eval/episode_y_velocity': Array(0.00010022, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560918, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04262318, dtype=float32), 'eval/episode_reward_std': Array(0.04560542, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04262318, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01090309, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012787, dtype=float32), 'eval/episode_x_position_std': Array(0.00557532, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04262318, dtype=float32), 'eval/episode_y_position_std': Array(0.00599974, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01315017, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647340059280396, 'eval/sps': 6199.345757492264, 'num_steps': 404480}
{'eval/walltime': 1782.1067984104156, 'training/sps': 127.1578103385043, 'training/walltime': 3302.406032562256, 'training/entropy_loss': Array(0.03080183, dtype=float32), 'training/policy_loss': Array(0.27133694, dtype=float32), 'training/total_loss': Array(0.30213892, dtype=float32), 'training/v_loss': Array(1.4721871e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009337, dtype=float32), 'eval/episode_forward_reward': Array(-0.04022483, dtype=float32), 'eval/episode_reward': Array(-2.0372653, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04022483, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958339, dtype=float32), 'eval/episode_train_reward': Array(-0.00120674, dtype=float32), 'eval/episode_x_position': Array(1.0074656, dtype=float32), 'eval/episode_x_velocity': Array(-0.04022483, dtype=float32), 'eval/episode_y_position': Array(-6.694667e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00119701, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589117, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04382356, dtype=float32), 'eval/episode_reward_std': Array(0.0506997, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04382356, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01913211, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131471, dtype=float32), 'eval/episode_x_position_std': Array(0.00588089, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04382356, dtype=float32), 'eval/episode_y_position_std': Array(0.005787, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01090053, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64440083503723, 'eval/sps': 6200.228382640254, 'num_steps': 409600}
{'eval/walltime': 1802.7853083610535, 'training/sps': 127.24735338895672, 'training/walltime': 3342.642625808716, 'training/entropy_loss': Array(0.02608217, dtype=float32), 'training/policy_loss': Array(-0.18866162, dtype=float32), 'training/total_loss': Array(-0.16257896, dtype=float32), 'training/v_loss': Array(4.8604596e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087138, dtype=float32), 'eval/episode_forward_reward': Array(-0.04622185, dtype=float32), 'eval/episode_reward': Array(-2.046463, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04622185, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9988546, dtype=float32), 'eval/episode_train_reward': Array(-0.00138666, dtype=float32), 'eval/episode_x_position': Array(1.0069056, dtype=float32), 'eval/episode_x_velocity': Array(-0.04622185, dtype=float32), 'eval/episode_y_position': Array(3.9102306e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00086111, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583333, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04511932, dtype=float32), 'eval/episode_reward_std': Array(0.04646286, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04511932, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00892677, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135358, dtype=float32), 'eval/episode_x_position_std': Array(0.00581218, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04511932, dtype=float32), 'eval/episode_y_position_std': Array(0.00560961, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01504725, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.678509950637817, 'eval/sps': 6190.001131878069, 'num_steps': 414720}
{'eval/walltime': 1823.4109308719635, 'training/sps': 127.22151927477861, 'training/walltime': 3382.8873896598816, 'training/entropy_loss': Array(0.02870627, dtype=float32), 'training/policy_loss': Array(-0.16602795, dtype=float32), 'training/total_loss': Array(-0.13732138, dtype=float32), 'training/v_loss': Array(3.029981e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097102, dtype=float32), 'eval/episode_forward_reward': Array(-0.03829583, dtype=float32), 'eval/episode_reward': Array(-2.0360932, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03829583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966486, dtype=float32), 'eval/episode_train_reward': Array(-0.00114887, dtype=float32), 'eval/episode_x_position': Array(1.0078489, dtype=float32), 'eval/episode_x_velocity': Array(-0.03829583, dtype=float32), 'eval/episode_y_position': Array(0.00035974, dtype=float32), 'eval/episode_y_velocity': Array(0.00168721, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596858, dtype=float32), 'eval/episode_forward_reward_std': Array(0.042703, dtype=float32), 'eval/episode_reward_std': Array(0.04769758, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.042703, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01548049, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128109, dtype=float32), 'eval/episode_x_position_std': Array(0.00595085, dtype=float32), 'eval/episode_x_velocity_std': Array(0.042703, dtype=float32), 'eval/episode_y_position_std': Array(0.00623815, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01194081, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.625622510910034, 'eval/sps': 6205.87329823833, 'num_steps': 419840}
{'eval/walltime': 1844.0729043483734, 'training/sps': 127.32829100765424, 'training/walltime': 3423.0984060764313, 'training/entropy_loss': Array(0.02997254, dtype=float32), 'training/policy_loss': Array(-0.1812652, dtype=float32), 'training/total_loss': Array(-0.15129243, dtype=float32), 'training/v_loss': Array(2.2693615e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084884, dtype=float32), 'eval/episode_forward_reward': Array(-0.03494284, dtype=float32), 'eval/episode_reward': Array(-2.0338843, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03494284, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978929, dtype=float32), 'eval/episode_train_reward': Array(-0.00104829, dtype=float32), 'eval/episode_x_position': Array(1.0066025, dtype=float32), 'eval/episode_x_velocity': Array(-0.03494284, dtype=float32), 'eval/episode_y_position': Array(5.2208343e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00170254, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590657, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04322306, dtype=float32), 'eval/episode_reward_std': Array(0.04747387, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04322306, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0111709, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129669, dtype=float32), 'eval/episode_x_position_std': Array(0.00587854, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04322306, dtype=float32), 'eval/episode_y_position_std': Array(0.00575609, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00982711, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.661973476409912, 'eval/sps': 6194.9551985505905, 'num_steps': 424960}
{'eval/walltime': 1864.6981353759766, 'training/sps': 127.17900365794473, 'training/walltime': 3463.356623649597, 'training/entropy_loss': Array(0.03263691, dtype=float32), 'training/policy_loss': Array(-0.18299286, dtype=float32), 'training/total_loss': Array(-0.15035579, dtype=float32), 'training/v_loss': Array(1.675169e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0170729, dtype=float32), 'eval/episode_forward_reward': Array(-0.0364002, dtype=float32), 'eval/episode_reward': Array(-2.0523634, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0364002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0226836, dtype=float32), 'eval/episode_train_reward': Array(-0.00109201, dtype=float32), 'eval/episode_x_position': Array(1.0151459, dtype=float32), 'eval/episode_x_velocity': Array(-0.0364002, dtype=float32), 'eval/episode_y_position': Array(0.00016706, dtype=float32), 'eval/episode_y_velocity': Array(0.00052781, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09001958, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04384926, dtype=float32), 'eval/episode_reward_std': Array(0.17856613, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04384926, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2642425, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131548, dtype=float32), 'eval/episode_x_position_std': Array(0.08975448, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04384926, dtype=float32), 'eval/episode_y_position_std': Array(0.00604364, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01051184, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.62523102760315, 'eval/sps': 6205.991090654698, 'num_steps': 430080}
{'eval/walltime': 1885.2972457408905, 'training/sps': 127.31788935912317, 'training/walltime': 3503.5709252357483, 'training/entropy_loss': Array(0.03499516, dtype=float32), 'training/policy_loss': Array(-0.16457751, dtype=float32), 'training/total_loss': Array(-0.12958223, dtype=float32), 'training/v_loss': Array(1.15831234e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008704, dtype=float32), 'eval/episode_forward_reward': Array(-0.03905152, dtype=float32), 'eval/episode_reward': Array(-2.0369778, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03905152, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9967546, dtype=float32), 'eval/episode_train_reward': Array(-0.00117155, dtype=float32), 'eval/episode_x_position': Array(1.0068262, dtype=float32), 'eval/episode_x_velocity': Array(-0.03905152, dtype=float32), 'eval/episode_y_position': Array(-0.00012204, dtype=float32), 'eval/episode_y_velocity': Array(-2.4955065e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581811, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04446847, dtype=float32), 'eval/episode_reward_std': Array(0.04859812, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04446847, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01406965, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133405, dtype=float32), 'eval/episode_x_position_std': Array(0.00581372, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04446847, dtype=float32), 'eval/episode_y_position_std': Array(0.00584468, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00927522, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.59911036491394, 'eval/sps': 6213.860585844517, 'num_steps': 435200}
{'eval/walltime': 1905.9608690738678, 'training/sps': 127.4343066696384, 'training/walltime': 3543.7484891414642, 'training/entropy_loss': Array(0.03719261, dtype=float32), 'training/policy_loss': Array(-0.16846697, dtype=float32), 'training/total_loss': Array(-0.13127428, dtype=float32), 'training/v_loss': Array(9.000614e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0172079, dtype=float32), 'eval/episode_forward_reward': Array(-0.04281732, dtype=float32), 'eval/episode_reward': Array(-2.0581622, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04281732, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.021873, dtype=float32), 'eval/episode_train_reward': Array(-0.00128452, dtype=float32), 'eval/episode_x_position': Array(1.0153322, dtype=float32), 'eval/episode_x_velocity': Array(-0.04281732, dtype=float32), 'eval/episode_y_position': Array(-0.00025879, dtype=float32), 'eval/episode_y_velocity': Array(-0.00318788, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08775017, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04427312, dtype=float32), 'eval/episode_reward_std': Array(0.17776783, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04427312, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26450288, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132819, dtype=float32), 'eval/episode_x_position_std': Array(0.08746385, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04427312, dtype=float32), 'eval/episode_y_position_std': Array(0.00600134, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0133187, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.663623332977295, 'eval/sps': 6194.460571477967, 'num_steps': 440320}
{'eval/walltime': 1926.5570707321167, 'training/sps': 127.28804435079978, 'training/walltime': 3583.9722197055817, 'training/entropy_loss': Array(0.03959538, dtype=float32), 'training/policy_loss': Array(-0.1582995, dtype=float32), 'training/total_loss': Array(-0.11870407, dtype=float32), 'training/v_loss': Array(5.965037e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090016, dtype=float32), 'eval/episode_forward_reward': Array(-0.04566934, dtype=float32), 'eval/episode_reward': Array(-2.0456192, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04566934, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99858, dtype=float32), 'eval/episode_train_reward': Array(-0.00137008, dtype=float32), 'eval/episode_x_position': Array(1.0071495, dtype=float32), 'eval/episode_x_velocity': Array(-0.04566934, dtype=float32), 'eval/episode_y_position': Array(-0.00024327, dtype=float32), 'eval/episode_y_velocity': Array(5.7533383e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00598755, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04533973, dtype=float32), 'eval/episode_reward_std': Array(0.04807617, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04533973, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00883722, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136019, dtype=float32), 'eval/episode_x_position_std': Array(0.00595407, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04533973, dtype=float32), 'eval/episode_y_position_std': Array(0.00596103, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01103232, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.5962016582489, 'eval/sps': 6214.738140745249, 'num_steps': 445440}
{'eval/walltime': 1947.2282028198242, 'training/sps': 127.38866150655315, 'training/walltime': 3624.164179801941, 'training/entropy_loss': Array(0.04271094, dtype=float32), 'training/policy_loss': Array(-0.11403533, dtype=float32), 'training/total_loss': Array(-0.07132435, dtype=float32), 'training/v_loss': Array(4.6078473e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089544, dtype=float32), 'eval/episode_forward_reward': Array(-0.03907302, dtype=float32), 'eval/episode_reward': Array(-2.038665, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03907302, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99842, dtype=float32), 'eval/episode_train_reward': Array(-0.00117219, dtype=float32), 'eval/episode_x_position': Array(1.0070682, dtype=float32), 'eval/episode_x_velocity': Array(-0.03907302, dtype=float32), 'eval/episode_y_position': Array(0.00081975, dtype=float32), 'eval/episode_y_velocity': Array(0.00090317, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00556677, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0444119, dtype=float32), 'eval/episode_reward_std': Array(0.04603017, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0444119, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01013512, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133236, dtype=float32), 'eval/episode_x_position_std': Array(0.00554394, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0444119, dtype=float32), 'eval/episode_y_position_std': Array(0.00597144, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01406502, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67113208770752, 'eval/sps': 6192.210443864254, 'num_steps': 450560}
{'eval/walltime': 1967.8281552791595, 'training/sps': 127.19625767339849, 'training/walltime': 3664.4169363975525, 'training/entropy_loss': Array(0.04602588, dtype=float32), 'training/policy_loss': Array(-0.10898474, dtype=float32), 'training/total_loss': Array(-0.06295884, dtype=float32), 'training/v_loss': Array(2.4756138e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086844, dtype=float32), 'eval/episode_forward_reward': Array(-0.04059946, dtype=float32), 'eval/episode_reward': Array(-2.039596, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04059946, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977787, dtype=float32), 'eval/episode_train_reward': Array(-0.00121798, dtype=float32), 'eval/episode_x_position': Array(1.0068069, dtype=float32), 'eval/episode_x_velocity': Array(-0.04059946, dtype=float32), 'eval/episode_y_position': Array(0.00107673, dtype=float32), 'eval/episode_y_velocity': Array(0.00025567, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561681, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04318368, dtype=float32), 'eval/episode_reward_std': Array(0.04517155, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04318368, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01224859, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129551, dtype=float32), 'eval/episode_x_position_std': Array(0.00560998, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04318368, dtype=float32), 'eval/episode_y_position_std': Array(0.00586203, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01235629, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.599952459335327, 'eval/sps': 6213.6065727663345, 'num_steps': 455680}
{'eval/walltime': 1988.4836163520813, 'training/sps': 127.38587617102843, 'training/walltime': 3704.6097753047943, 'training/entropy_loss': Array(0.0623058, dtype=float32), 'training/policy_loss': Array(0.26419476, dtype=float32), 'training/total_loss': Array(0.32650056, dtype=float32), 'training/v_loss': Array(1.7942217e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009649, dtype=float32), 'eval/episode_forward_reward': Array(-0.03764608, dtype=float32), 'eval/episode_reward': Array(-2.0362806, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03764608, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975052, dtype=float32), 'eval/episode_train_reward': Array(-0.00112938, dtype=float32), 'eval/episode_x_position': Array(1.0077505, dtype=float32), 'eval/episode_x_velocity': Array(-0.03764608, dtype=float32), 'eval/episode_y_position': Array(0.0005395, dtype=float32), 'eval/episode_y_velocity': Array(-0.00278363, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571316, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04315905, dtype=float32), 'eval/episode_reward_std': Array(0.048034, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04315905, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01253838, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129477, dtype=float32), 'eval/episode_x_position_std': Array(0.00568165, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04315905, dtype=float32), 'eval/episode_y_position_std': Array(0.00584972, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01621404, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.655461072921753, 'eval/sps': 6196.908388929716, 'num_steps': 460800}
{'eval/walltime': 2009.110092163086, 'training/sps': 126.94354698564918, 'training/walltime': 3744.942664384842, 'training/entropy_loss': Array(0.04608006, dtype=float32), 'training/policy_loss': Array(0.2736632, dtype=float32), 'training/total_loss': Array(0.31974322, dtype=float32), 'training/v_loss': Array(1.1555147e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095744, dtype=float32), 'eval/episode_forward_reward': Array(-0.03683412, dtype=float32), 'eval/episode_reward': Array(-2.0356681, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03683412, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997729, dtype=float32), 'eval/episode_train_reward': Array(-0.00110502, dtype=float32), 'eval/episode_x_position': Array(1.0076685, dtype=float32), 'eval/episode_x_velocity': Array(-0.03683412, dtype=float32), 'eval/episode_y_position': Array(0.00089592, dtype=float32), 'eval/episode_y_velocity': Array(-0.00235606, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00556703, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0428221, dtype=float32), 'eval/episode_reward_std': Array(0.04650223, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0428221, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01142345, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128466, dtype=float32), 'eval/episode_x_position_std': Array(0.0055386, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0428221, dtype=float32), 'eval/episode_y_position_std': Array(0.00592336, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01372215, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62647581100464, 'eval/sps': 6205.616566437851, 'num_steps': 465920}
{'eval/walltime': 2029.7351734638214, 'training/sps': 127.2774048667943, 'training/walltime': 3785.1697573661804, 'training/entropy_loss': Array(0.04136003, dtype=float32), 'training/policy_loss': Array(-0.11223511, dtype=float32), 'training/total_loss': Array(-0.07087422, dtype=float32), 'training/v_loss': Array(8.705606e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008944, dtype=float32), 'eval/episode_forward_reward': Array(-0.03937516, dtype=float32), 'eval/episode_reward': Array(-2.0388412, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03937516, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982848, dtype=float32), 'eval/episode_train_reward': Array(-0.00118125, dtype=float32), 'eval/episode_x_position': Array(1.007085, dtype=float32), 'eval/episode_x_velocity': Array(-0.03937516, dtype=float32), 'eval/episode_y_position': Array(0.00026175, dtype=float32), 'eval/episode_y_velocity': Array(-0.000648, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00552217, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04283438, dtype=float32), 'eval/episode_reward_std': Array(0.04443561, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04283438, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01015503, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128503, dtype=float32), 'eval/episode_x_position_std': Array(0.00555979, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04283438, dtype=float32), 'eval/episode_y_position_std': Array(0.00615903, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01057466, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.625081300735474, 'eval/sps': 6206.036142773199, 'num_steps': 471040}
{'eval/walltime': 2050.3544659614563, 'training/sps': 127.22520642069243, 'training/walltime': 3825.413354873657, 'training/entropy_loss': Array(0.04147466, dtype=float32), 'training/policy_loss': Array(0.05537244, dtype=float32), 'training/total_loss': Array(0.09684728, dtype=float32), 'training/v_loss': Array(1.7816231e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009139, dtype=float32), 'eval/episode_forward_reward': Array(-0.04000194, dtype=float32), 'eval/episode_reward': Array(-2.038784, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04000194, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997582, dtype=float32), 'eval/episode_train_reward': Array(-0.00120006, dtype=float32), 'eval/episode_x_position': Array(1.0072923, dtype=float32), 'eval/episode_x_velocity': Array(-0.04000194, dtype=float32), 'eval/episode_y_position': Array(0.0006937, dtype=float32), 'eval/episode_y_velocity': Array(-0.00333492, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0060456, dtype=float32), 'eval/episode_forward_reward_std': Array(0.042354, dtype=float32), 'eval/episode_reward_std': Array(0.04405967, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.042354, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01299675, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127062, dtype=float32), 'eval/episode_x_position_std': Array(0.00599164, dtype=float32), 'eval/episode_x_velocity_std': Array(0.042354, dtype=float32), 'eval/episode_y_position_std': Array(0.00564068, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01009222, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.619292497634888, 'eval/sps': 6207.7784683777145, 'num_steps': 476160}
{'eval/walltime': 2070.987590789795, 'training/sps': 127.18618039816536, 'training/walltime': 3865.6693007946014, 'training/entropy_loss': Array(0.04457242, dtype=float32), 'training/policy_loss': Array(-0.10398671, dtype=float32), 'training/total_loss': Array(-0.05941415, dtype=float32), 'training/v_loss': Array(1.4818463e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087421, dtype=float32), 'eval/episode_forward_reward': Array(-0.0430181, dtype=float32), 'eval/episode_reward': Array(-2.0420694, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0430181, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977608, dtype=float32), 'eval/episode_train_reward': Array(-0.00129054, dtype=float32), 'eval/episode_x_position': Array(1.0068982, dtype=float32), 'eval/episode_x_velocity': Array(-0.0430181, dtype=float32), 'eval/episode_y_position': Array(-0.00042899, dtype=float32), 'eval/episode_y_velocity': Array(-0.0005375, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595772, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04291575, dtype=float32), 'eval/episode_reward_std': Array(0.04488896, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04291575, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01163521, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128747, dtype=float32), 'eval/episode_x_position_std': Array(0.00591365, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04291575, dtype=float32), 'eval/episode_y_position_std': Array(0.00577635, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00971269, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.633124828338623, 'eval/sps': 6203.616808647328, 'num_steps': 481280}
{'eval/walltime': 2091.621803998947, 'training/sps': 127.33771729450065, 'training/walltime': 3905.877340555191, 'training/entropy_loss': Array(0.04580741, dtype=float32), 'training/policy_loss': Array(-0.09504019, dtype=float32), 'training/total_loss': Array(-0.04923267, dtype=float32), 'training/v_loss': Array(1.1606012e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0102878, dtype=float32), 'eval/episode_forward_reward': Array(-0.04454019, dtype=float32), 'eval/episode_reward': Array(-2.0429657, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04454019, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970891, dtype=float32), 'eval/episode_train_reward': Array(-0.00133621, dtype=float32), 'eval/episode_x_position': Array(1.0084292, dtype=float32), 'eval/episode_x_velocity': Array(-0.04454019, dtype=float32), 'eval/episode_y_position': Array(0.00018059, dtype=float32), 'eval/episode_y_velocity': Array(-0.00132311, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559698, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04524157, dtype=float32), 'eval/episode_reward_std': Array(0.04828624, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04524157, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01212916, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135725, dtype=float32), 'eval/episode_x_position_std': Array(0.00558396, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04524157, dtype=float32), 'eval/episode_y_position_std': Array(0.00592529, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01433579, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63421320915222, 'eval/sps': 6203.289590088471, 'num_steps': 486400}
{'eval/walltime': 2112.2719979286194, 'training/sps': 127.38148758782071, 'training/walltime': 3946.0715641975403, 'training/entropy_loss': Array(0.04685923, dtype=float32), 'training/policy_loss': Array(-0.07096213, dtype=float32), 'training/total_loss': Array(-0.02410282, dtype=float32), 'training/v_loss': Array(8.931244e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101459, dtype=float32), 'eval/episode_forward_reward': Array(-0.04710381, dtype=float32), 'eval/episode_reward': Array(-2.0450244, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04710381, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965072, dtype=float32), 'eval/episode_train_reward': Array(-0.00141311, dtype=float32), 'eval/episode_x_position': Array(1.0083153, dtype=float32), 'eval/episode_x_velocity': Array(-0.04710381, dtype=float32), 'eval/episode_y_position': Array(-0.00014805, dtype=float32), 'eval/episode_y_velocity': Array(0.00016126, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581744, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04670815, dtype=float32), 'eval/episode_reward_std': Array(0.05038221, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04670815, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01399364, dtype=float32), 'eval/episode_train_reward_std': Array(0.00140124, dtype=float32), 'eval/episode_x_position_std': Array(0.00581353, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04670815, dtype=float32), 'eval/episode_y_position_std': Array(0.00605105, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01294502, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65019392967224, 'eval/sps': 6198.4890038285275, 'num_steps': 491520}
{'eval/walltime': 2132.888462781906, 'training/sps': 127.28742719251906, 'training/walltime': 3986.2954897880554, 'training/entropy_loss': Array(0.0475575, dtype=float32), 'training/policy_loss': Array(-0.12437391, dtype=float32), 'training/total_loss': Array(-0.07681634, dtype=float32), 'training/v_loss': Array(7.4183546e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085791, dtype=float32), 'eval/episode_forward_reward': Array(-0.03541277, dtype=float32), 'eval/episode_reward': Array(-2.0356007, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03541277, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9991255, dtype=float32), 'eval/episode_train_reward': Array(-0.00106238, dtype=float32), 'eval/episode_x_position': Array(1.0066923, dtype=float32), 'eval/episode_x_velocity': Array(-0.03541277, dtype=float32), 'eval/episode_y_position': Array(-5.5330704e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.0009909, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584974, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04218884, dtype=float32), 'eval/episode_reward_std': Array(0.04420511, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04218884, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00720413, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126567, dtype=float32), 'eval/episode_x_position_std': Array(0.00577724, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04218884, dtype=float32), 'eval/episode_y_position_std': Array(0.00549808, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01409328, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.616464853286743, 'eval/sps': 6208.629894159271, 'num_steps': 496640}
{'eval/walltime': 2153.520686864853, 'training/sps': 127.17359376883375, 'training/walltime': 4026.555419921875, 'training/entropy_loss': Array(0.04902328, dtype=float32), 'training/policy_loss': Array(-0.12135641, dtype=float32), 'training/total_loss': Array(-0.07233308, dtype=float32), 'training/v_loss': Array(5.5809057e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086882, dtype=float32), 'eval/episode_forward_reward': Array(-0.04292753, dtype=float32), 'eval/episode_reward': Array(-2.0407279, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04292753, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965127, dtype=float32), 'eval/episode_train_reward': Array(-0.00128783, dtype=float32), 'eval/episode_x_position': Array(1.006838, dtype=float32), 'eval/episode_x_velocity': Array(-0.04292753, dtype=float32), 'eval/episode_y_position': Array(0.00035089, dtype=float32), 'eval/episode_y_velocity': Array(-0.00104947, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558859, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04321358, dtype=float32), 'eval/episode_reward_std': Array(0.04937748, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04321358, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01549556, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129641, dtype=float32), 'eval/episode_x_position_std': Array(0.00559481, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04321358, dtype=float32), 'eval/episode_y_position_std': Array(0.00586273, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01239614, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.632224082946777, 'eval/sps': 6203.887641264825, 'num_steps': 501760}
{'eval/walltime': 2174.1191952228546, 'training/sps': 127.12017785097746, 'training/walltime': 4066.8322672843933, 'training/entropy_loss': Array(0.05117937, dtype=float32), 'training/policy_loss': Array(0.26053146, dtype=float32), 'training/total_loss': Array(0.31171086, dtype=float32), 'training/v_loss': Array(4.420761e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099767, dtype=float32), 'eval/episode_forward_reward': Array(-0.04163097, dtype=float32), 'eval/episode_reward': Array(-2.0407293, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04163097, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978495, dtype=float32), 'eval/episode_train_reward': Array(-0.00124893, dtype=float32), 'eval/episode_x_position': Array(1.0081009, dtype=float32), 'eval/episode_x_velocity': Array(-0.04163097, dtype=float32), 'eval/episode_y_position': Array(9.600082e-05, dtype=float32), 'eval/episode_y_velocity': Array(6.48289e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571664, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04475839, dtype=float32), 'eval/episode_reward_std': Array(0.0482987, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04475839, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01191237, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134275, dtype=float32), 'eval/episode_x_position_std': Array(0.00566197, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04475839, dtype=float32), 'eval/episode_y_position_std': Array(0.0054089, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01159695, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.59850835800171, 'eval/sps': 6214.0421905976045, 'num_steps': 506880}
{'eval/walltime': 2194.792800426483, 'training/sps': 127.4958942447256, 'training/walltime': 4106.990423202515, 'training/entropy_loss': Array(0.04986953, dtype=float32), 'training/policy_loss': Array(-0.14085294, dtype=float32), 'training/total_loss': Array(-0.09098336, dtype=float32), 'training/v_loss': Array(5.7036733e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084732, dtype=float32), 'eval/episode_forward_reward': Array(-0.04060078, dtype=float32), 'eval/episode_reward': Array(-2.0377328, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04060078, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995914, dtype=float32), 'eval/episode_train_reward': Array(-0.00121802, dtype=float32), 'eval/episode_x_position': Array(1.0066323, dtype=float32), 'eval/episode_x_velocity': Array(-0.04060078, dtype=float32), 'eval/episode_y_position': Array(0.000661, dtype=float32), 'eval/episode_y_velocity': Array(-5.020143e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0061197, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04427513, dtype=float32), 'eval/episode_reward_std': Array(0.04645695, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04427513, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01883514, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132825, dtype=float32), 'eval/episode_x_position_std': Array(0.00607318, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04427513, dtype=float32), 'eval/episode_y_position_std': Array(0.00537527, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01310695, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67360520362854, 'eval/sps': 6191.469689937487, 'num_steps': 512000}
{'eval/walltime': 2215.409003973007, 'training/sps': 127.11444942406061, 'training/walltime': 4147.269085645676, 'training/entropy_loss': Array(0.05684523, dtype=float32), 'training/policy_loss': Array(0.23325725, dtype=float32), 'training/total_loss': Array(0.29010248, dtype=float32), 'training/v_loss': Array(1.2988543e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171797, dtype=float32), 'eval/episode_forward_reward': Array(-0.04040264, dtype=float32), 'eval/episode_reward': Array(-2.054265, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04040264, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0204628, dtype=float32), 'eval/episode_train_reward': Array(-0.00121208, dtype=float32), 'eval/episode_x_position': Array(1.0153061, dtype=float32), 'eval/episode_x_velocity': Array(-0.04040264, dtype=float32), 'eval/episode_y_position': Array(8.8332126e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00215553, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08922614, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04194963, dtype=float32), 'eval/episode_reward_std': Array(0.17944828, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04194963, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26481637, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125849, dtype=float32), 'eval/episode_x_position_std': Array(0.08895127, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04194963, dtype=float32), 'eval/episode_y_position_std': Array(0.00616282, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01496206, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.616203546524048, 'eval/sps': 6208.708587453832, 'num_steps': 517120}
{'eval/walltime': 2236.03103017807, 'training/sps': 127.33308589514827, 'training/walltime': 4187.4785878658295, 'training/entropy_loss': Array(0.04253631, dtype=float32), 'training/policy_loss': Array(0.26853502, dtype=float32), 'training/total_loss': Array(0.31107277, dtype=float32), 'training/v_loss': Array(1.4708183e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0160742, dtype=float32), 'eval/episode_forward_reward': Array(-0.04447461, dtype=float32), 'eval/episode_reward': Array(-2.0595121, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04447461, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0215158, dtype=float32), 'eval/episode_train_reward': Array(-0.00133424, dtype=float32), 'eval/episode_x_position': Array(1.0142117, dtype=float32), 'eval/episode_x_velocity': Array(-0.04447461, dtype=float32), 'eval/episode_y_position': Array(0.00107199, dtype=float32), 'eval/episode_y_velocity': Array(0.00021683, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08890861, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04595328, dtype=float32), 'eval/episode_reward_std': Array(0.17931345, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04595328, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2645886, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013786, dtype=float32), 'eval/episode_x_position_std': Array(0.08863321, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04595328, dtype=float32), 'eval/episode_y_position_std': Array(0.00572128, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01309964, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.622026205062866, 'eval/sps': 6206.9555497206675, 'num_steps': 522240}
{'eval/walltime': 2256.6575694084167, 'training/sps': 127.1180987628429, 'training/walltime': 4227.756093978882, 'training/entropy_loss': Array(0.03947736, dtype=float32), 'training/policy_loss': Array(-0.19141926, dtype=float32), 'training/total_loss': Array(-0.15194133, dtype=float32), 'training/v_loss': Array(5.798043e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094001, dtype=float32), 'eval/episode_forward_reward': Array(-0.03348089, dtype=float32), 'eval/episode_reward': Array(-2.03083, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03348089, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963446, dtype=float32), 'eval/episode_train_reward': Array(-0.00100443, dtype=float32), 'eval/episode_x_position': Array(1.007489, dtype=float32), 'eval/episode_x_velocity': Array(-0.03348089, dtype=float32), 'eval/episode_y_position': Array(-0.00024933, dtype=float32), 'eval/episode_y_velocity': Array(-0.00103693, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602029, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04135522, dtype=float32), 'eval/episode_reward_std': Array(0.04608873, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04135522, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01620014, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124066, dtype=float32), 'eval/episode_x_position_std': Array(0.00602798, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04135522, dtype=float32), 'eval/episode_y_position_std': Array(0.00576331, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01023935, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62653923034668, 'eval/sps': 6205.597486352956, 'num_steps': 527360}
{'eval/walltime': 2277.280076980591, 'training/sps': 127.2286540803876, 'training/walltime': 4267.998600959778, 'training/entropy_loss': Array(0.0412829, dtype=float32), 'training/policy_loss': Array(-0.18780573, dtype=float32), 'training/total_loss': Array(-0.14652272, dtype=float32), 'training/v_loss': Array(1.0833717e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092648, dtype=float32), 'eval/episode_forward_reward': Array(-0.03967271, dtype=float32), 'eval/episode_reward': Array(-2.0394201, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03967271, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998557, dtype=float32), 'eval/episode_train_reward': Array(-0.00119018, dtype=float32), 'eval/episode_x_position': Array(1.0074, dtype=float32), 'eval/episode_x_velocity': Array(-0.03967271, dtype=float32), 'eval/episode_y_position': Array(-0.00014441, dtype=float32), 'eval/episode_y_velocity': Array(0.00039542, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576386, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04258078, dtype=float32), 'eval/episode_reward_std': Array(0.04465224, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04258078, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00912672, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127742, dtype=float32), 'eval/episode_x_position_std': Array(0.00575105, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04258078, dtype=float32), 'eval/episode_y_position_std': Array(0.00617832, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00961943, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.622507572174072, 'eval/sps': 6206.81066800578, 'num_steps': 532480}
{'eval/walltime': 2297.893798351288, 'training/sps': 127.22265735302439, 'training/walltime': 4308.243004798889, 'training/entropy_loss': Array(0.04233683, dtype=float32), 'training/policy_loss': Array(-0.17439637, dtype=float32), 'training/total_loss': Array(-0.13205947, dtype=float32), 'training/v_loss': Array(8.121738e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085115, dtype=float32), 'eval/episode_forward_reward': Array(-0.04165107, dtype=float32), 'eval/episode_reward': Array(-2.040924, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04165107, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980235, dtype=float32), 'eval/episode_train_reward': Array(-0.00124953, dtype=float32), 'eval/episode_x_position': Array(1.0066705, dtype=float32), 'eval/episode_x_velocity': Array(-0.04165107, dtype=float32), 'eval/episode_y_position': Array(0.00030295, dtype=float32), 'eval/episode_y_velocity': Array(-0.00156844, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00555664, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04344919, dtype=float32), 'eval/episode_reward_std': Array(0.04608624, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04344919, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01281915, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130348, dtype=float32), 'eval/episode_x_position_std': Array(0.00554315, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04344919, dtype=float32), 'eval/episode_y_position_std': Array(0.00602962, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01303608, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61372137069702, 'eval/sps': 6209.456201438502, 'num_steps': 537600}
{'eval/walltime': 2318.4878780841827, 'training/sps': 127.23742557605605, 'training/walltime': 4348.482737541199, 'training/entropy_loss': Array(0.04445589, dtype=float32), 'training/policy_loss': Array(-0.16869165, dtype=float32), 'training/total_loss': Array(-0.12423569, dtype=float32), 'training/v_loss': Array(6.485125e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097619, dtype=float32), 'eval/episode_forward_reward': Array(-0.03765857, dtype=float32), 'eval/episode_reward': Array(-2.0355873, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03765857, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9967988, dtype=float32), 'eval/episode_train_reward': Array(-0.00112976, dtype=float32), 'eval/episode_x_position': Array(1.0078555, dtype=float32), 'eval/episode_x_velocity': Array(-0.03765857, dtype=float32), 'eval/episode_y_position': Array(-0.00013811, dtype=float32), 'eval/episode_y_velocity': Array(-0.00021211, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600307, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0425154, dtype=float32), 'eval/episode_reward_std': Array(0.04829044, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0425154, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01552526, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127546, dtype=float32), 'eval/episode_x_position_std': Array(0.00595041, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0425154, dtype=float32), 'eval/episode_y_position_std': Array(0.0059823, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01024315, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.594079732894897, 'eval/sps': 6215.37848061964, 'num_steps': 542720}
{'eval/walltime': 2339.1179213523865, 'training/sps': 127.23201297708873, 'training/walltime': 4388.724182128906, 'training/entropy_loss': Array(0.0460891, dtype=float32), 'training/policy_loss': Array(-0.16878511, dtype=float32), 'training/total_loss': Array(-0.12269595, dtype=float32), 'training/v_loss': Array(5.3062372e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017307, dtype=float32), 'eval/episode_forward_reward': Array(-0.03645103, dtype=float32), 'eval/episode_reward': Array(-2.0525365, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03645103, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0228045, dtype=float32), 'eval/episode_train_reward': Array(-0.00109353, dtype=float32), 'eval/episode_x_position': Array(1.0154295, dtype=float32), 'eval/episode_x_velocity': Array(-0.03645103, dtype=float32), 'eval/episode_y_position': Array(-0.00024889, dtype=float32), 'eval/episode_y_velocity': Array(-0.00157615, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08924881, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04060705, dtype=float32), 'eval/episode_reward_std': Array(0.17938833, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04060705, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26421618, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121821, dtype=float32), 'eval/episode_x_position_std': Array(0.08898111, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04060705, dtype=float32), 'eval/episode_y_position_std': Array(0.00607718, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01365455, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.630043268203735, 'eval/sps': 6204.54345809741, 'num_steps': 547840}
{'eval/walltime': 2359.7634336948395, 'training/sps': 127.37958807790817, 'training/walltime': 4428.919005155563, 'training/entropy_loss': Array(0.048538, dtype=float32), 'training/policy_loss': Array(-0.14356121, dtype=float32), 'training/total_loss': Array(-0.09502319, dtype=float32), 'training/v_loss': Array(3.7296406e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008115, dtype=float32), 'eval/episode_forward_reward': Array(-0.03977586, dtype=float32), 'eval/episode_reward': Array(-2.038138, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03977586, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971688, dtype=float32), 'eval/episode_train_reward': Array(-0.00119328, dtype=float32), 'eval/episode_x_position': Array(1.0062307, dtype=float32), 'eval/episode_x_velocity': Array(-0.03977586, dtype=float32), 'eval/episode_y_position': Array(0.00061272, dtype=float32), 'eval/episode_y_velocity': Array(0.00118426, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0060585, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04245405, dtype=float32), 'eval/episode_reward_std': Array(0.04721852, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04245405, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01507705, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127362, dtype=float32), 'eval/episode_x_position_std': Array(0.00601845, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04245405, dtype=float32), 'eval/episode_y_position_std': Array(0.00598608, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01243215, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.645512342453003, 'eval/sps': 6199.894576449714, 'num_steps': 552960}
{'eval/walltime': 2380.400599718094, 'training/sps': 127.32535732762537, 'training/walltime': 4469.130948066711, 'training/entropy_loss': Array(0.05094399, dtype=float32), 'training/policy_loss': Array(-0.12395637, dtype=float32), 'training/total_loss': Array(-0.07301237, dtype=float32), 'training/v_loss': Array(2.2907502e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009238, dtype=float32), 'eval/episode_forward_reward': Array(-0.04196928, dtype=float32), 'eval/episode_reward': Array(-2.0425334, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04196928, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9993048, dtype=float32), 'eval/episode_train_reward': Array(-0.00125908, dtype=float32), 'eval/episode_x_position': Array(1.0074058, dtype=float32), 'eval/episode_x_velocity': Array(-0.04196928, dtype=float32), 'eval/episode_y_position': Array(-0.00071811, dtype=float32), 'eval/episode_y_velocity': Array(-0.00138846, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00554906, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04389254, dtype=float32), 'eval/episode_reward_std': Array(0.04535761, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04389254, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00438397, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131678, dtype=float32), 'eval/episode_x_position_std': Array(0.00556995, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04389254, dtype=float32), 'eval/episode_y_position_std': Array(0.00544668, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01216131, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.637166023254395, 'eval/sps': 6202.402008869188, 'num_steps': 558080}
{'eval/walltime': 2401.1043639183044, 'training/sps': 127.09026675198439, 'training/walltime': 4509.417274713516, 'training/entropy_loss': Array(0.05350242, dtype=float32), 'training/policy_loss': Array(-0.13492182, dtype=float32), 'training/total_loss': Array(-0.08141938, dtype=float32), 'training/v_loss': Array(1.6456747e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095675, dtype=float32), 'eval/episode_forward_reward': Array(-0.03910212, dtype=float32), 'eval/episode_reward': Array(-2.0390944, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03910212, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9988194, dtype=float32), 'eval/episode_train_reward': Array(-0.00117306, dtype=float32), 'eval/episode_x_position': Array(1.00769, dtype=float32), 'eval/episode_x_velocity': Array(-0.03910212, dtype=float32), 'eval/episode_y_position': Array(2.0585328e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00033103, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585534, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04290287, dtype=float32), 'eval/episode_reward_std': Array(0.04506901, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04290287, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00780887, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128709, dtype=float32), 'eval/episode_x_position_std': Array(0.00587415, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04290287, dtype=float32), 'eval/episode_y_position_std': Array(0.00575696, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0124085, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70376420021057, 'eval/sps': 6182.450628890864, 'num_steps': 563200}
{'eval/walltime': 2421.763335466385, 'training/sps': 127.11888132875197, 'training/walltime': 4549.694532871246, 'training/entropy_loss': Array(0.05535823, dtype=float32), 'training/policy_loss': Array(-0.09738556, dtype=float32), 'training/total_loss': Array(-0.04202731, dtype=float32), 'training/v_loss': Array(1.1719275e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009296, dtype=float32), 'eval/episode_forward_reward': Array(-0.03823265, dtype=float32), 'eval/episode_reward': Array(-2.0366101, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03823265, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972305, dtype=float32), 'eval/episode_train_reward': Array(-0.00114698, dtype=float32), 'eval/episode_x_position': Array(1.0073866, dtype=float32), 'eval/episode_x_velocity': Array(-0.03823265, dtype=float32), 'eval/episode_y_position': Array(-0.00027489, dtype=float32), 'eval/episode_y_velocity': Array(-0.00055264, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00623542, dtype=float32), 'eval/episode_forward_reward_std': Array(0.043076, dtype=float32), 'eval/episode_reward_std': Array(0.04468537, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.043076, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01480422, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129228, dtype=float32), 'eval/episode_x_position_std': Array(0.00624065, dtype=float32), 'eval/episode_x_velocity_std': Array(0.043076, dtype=float32), 'eval/episode_y_position_std': Array(0.00599996, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01042092, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.658971548080444, 'eval/sps': 6195.8553794461895, 'num_steps': 568320}
{'eval/walltime': 2442.416140794754, 'training/sps': 127.00931210978457, 'training/walltime': 4590.0065376758575, 'training/entropy_loss': Array(0.05853463, dtype=float32), 'training/policy_loss': Array(-0.04865309, dtype=float32), 'training/total_loss': Array(0.00988155, dtype=float32), 'training/v_loss': Array(9.19069e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.010292, dtype=float32), 'eval/episode_forward_reward': Array(-0.03051882, dtype=float32), 'eval/episode_reward': Array(-2.0266368, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03051882, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952025, dtype=float32), 'eval/episode_train_reward': Array(-0.00091556, dtype=float32), 'eval/episode_x_position': Array(1.0084132, dtype=float32), 'eval/episode_x_velocity': Array(-0.03051882, dtype=float32), 'eval/episode_y_position': Array(-0.00090845, dtype=float32), 'eval/episode_y_velocity': Array(-0.00085182, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574194, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04032948, dtype=float32), 'eval/episode_reward_std': Array(0.04597304, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04032948, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01751005, dtype=float32), 'eval/episode_train_reward_std': Array(0.00120988, dtype=float32), 'eval/episode_x_position_std': Array(0.00569417, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04032948, dtype=float32), 'eval/episode_y_position_std': Array(0.00539273, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00968847, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65280532836914, 'eval/sps': 6197.705249474096, 'num_steps': 573440}
{'eval/walltime': 2463.039202928543, 'training/sps': 127.33634460139596, 'training/walltime': 4630.215010881424, 'training/entropy_loss': Array(0.06219178, dtype=float32), 'training/policy_loss': Array(0.0543501, dtype=float32), 'training/total_loss': Array(0.11654189, dtype=float32), 'training/v_loss': Array(5.638755e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095551, dtype=float32), 'eval/episode_forward_reward': Array(-0.03777996, dtype=float32), 'eval/episode_reward': Array(-2.0367403, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03777996, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978268, dtype=float32), 'eval/episode_train_reward': Array(-0.0011334, dtype=float32), 'eval/episode_x_position': Array(1.0076699, dtype=float32), 'eval/episode_x_velocity': Array(-0.03777996, dtype=float32), 'eval/episode_y_position': Array(0.00057706, dtype=float32), 'eval/episode_y_velocity': Array(-0.00232284, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00618564, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04258532, dtype=float32), 'eval/episode_reward_std': Array(0.04628557, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04258532, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01204082, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127756, dtype=float32), 'eval/episode_x_position_std': Array(0.00610093, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04258532, dtype=float32), 'eval/episode_y_position_std': Array(0.00570104, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01363258, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.623062133789062, 'eval/sps': 6206.643764617444, 'num_steps': 578560}
{'eval/walltime': 2483.6857204437256, 'training/sps': 127.39765913872962, 'training/walltime': 4670.40413236618, 'training/entropy_loss': Array(0.06734186, dtype=float32), 'training/policy_loss': Array(0.16566357, dtype=float32), 'training/total_loss': Array(0.23300543, dtype=float32), 'training/v_loss': Array(3.2127108e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.010227, dtype=float32), 'eval/episode_forward_reward': Array(-0.0377337, dtype=float32), 'eval/episode_reward': Array(-2.038539, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0377337, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9996734, dtype=float32), 'eval/episode_train_reward': Array(-0.00113201, dtype=float32), 'eval/episode_x_position': Array(1.0083323, dtype=float32), 'eval/episode_x_velocity': Array(-0.0377337, dtype=float32), 'eval/episode_y_position': Array(0.00016322, dtype=float32), 'eval/episode_y_velocity': Array(-0.00093017, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00601929, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04471639, dtype=float32), 'eval/episode_reward_std': Array(0.04633531, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04471639, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00179144, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134149, dtype=float32), 'eval/episode_x_position_std': Array(0.00604473, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04471639, dtype=float32), 'eval/episode_y_position_std': Array(0.00624266, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01222885, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.646517515182495, 'eval/sps': 6199.592735475836, 'num_steps': 583680}
{'eval/walltime': 2504.3508999347687, 'training/sps': 127.23409277783989, 'training/walltime': 4710.644919157028, 'training/entropy_loss': Array(0.0669027, dtype=float32), 'training/policy_loss': Array(0.2708166, dtype=float32), 'training/total_loss': Array(0.33771935, dtype=float32), 'training/v_loss': Array(4.9233755e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089626, dtype=float32), 'eval/episode_forward_reward': Array(-0.04134429, dtype=float32), 'eval/episode_reward': Array(-2.0408103, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04134429, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982257, dtype=float32), 'eval/episode_train_reward': Array(-0.00124033, dtype=float32), 'eval/episode_x_position': Array(1.0071167, dtype=float32), 'eval/episode_x_velocity': Array(-0.04134429, dtype=float32), 'eval/episode_y_position': Array(0.00084204, dtype=float32), 'eval/episode_y_velocity': Array(-0.00132209, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00619904, dtype=float32), 'eval/episode_forward_reward_std': Array(0.042645, dtype=float32), 'eval/episode_reward_std': Array(0.04526372, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.042645, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01116451, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127935, dtype=float32), 'eval/episode_x_position_std': Array(0.00616902, dtype=float32), 'eval/episode_x_velocity_std': Array(0.042645, dtype=float32), 'eval/episode_y_position_std': Array(0.0056396, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01149036, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66517949104309, 'eval/sps': 6193.994107599165, 'num_steps': 588800}
{'eval/walltime': 2525.009757041931, 'training/sps': 127.1961265839903, 'training/walltime': 4750.8977172374725, 'training/entropy_loss': Array(0.06133877, dtype=float32), 'training/policy_loss': Array(0.26930463, dtype=float32), 'training/total_loss': Array(0.33064342, dtype=float32), 'training/v_loss': Array(2.4650927e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085754, dtype=float32), 'eval/episode_forward_reward': Array(-0.03880364, dtype=float32), 'eval/episode_reward': Array(-2.037441, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03880364, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974732, dtype=float32), 'eval/episode_train_reward': Array(-0.00116411, dtype=float32), 'eval/episode_x_position': Array(1.0066873, dtype=float32), 'eval/episode_x_velocity': Array(-0.03880364, dtype=float32), 'eval/episode_y_position': Array(0.00033857, dtype=float32), 'eval/episode_y_velocity': Array(0.00096303, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0055986, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04404037, dtype=float32), 'eval/episode_reward_std': Array(0.04823219, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04404037, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01326912, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132121, dtype=float32), 'eval/episode_x_position_std': Array(0.00555184, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04404037, dtype=float32), 'eval/episode_y_position_std': Array(0.00614298, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01446505, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.658857107162476, 'eval/sps': 6195.889701740669, 'num_steps': 593920}
{'eval/walltime': 2545.6667046546936, 'training/sps': 127.27193606601033, 'training/walltime': 4791.1265387535095, 'training/entropy_loss': Array(0.056843, dtype=float32), 'training/policy_loss': Array(-0.11681492, dtype=float32), 'training/total_loss': Array(-0.05997191, dtype=float32), 'training/v_loss': Array(1.3733607e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093133, dtype=float32), 'eval/episode_forward_reward': Array(-0.03878384, dtype=float32), 'eval/episode_reward': Array(-2.0358343, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03878384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958868, dtype=float32), 'eval/episode_train_reward': Array(-0.00116352, dtype=float32), 'eval/episode_x_position': Array(1.0074369, dtype=float32), 'eval/episode_x_velocity': Array(-0.03878384, dtype=float32), 'eval/episode_y_position': Array(0.00026319, dtype=float32), 'eval/episode_y_velocity': Array(-0.00179098, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00552996, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04313774, dtype=float32), 'eval/episode_reward_std': Array(0.04891961, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04313774, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0184023, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129413, dtype=float32), 'eval/episode_x_position_std': Array(0.00555123, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04313774, dtype=float32), 'eval/episode_y_position_std': Array(0.00601142, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01048225, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65694761276245, 'eval/sps': 6196.462439635465, 'num_steps': 599040}
{'eval/walltime': 2566.311560153961, 'training/sps': 127.45610363528468, 'training/walltime': 4831.297231674194, 'training/entropy_loss': Array(0.05858307, dtype=float32), 'training/policy_loss': Array(-0.01990217, dtype=float32), 'training/total_loss': Array(0.03868092, dtype=float32), 'training/v_loss': Array(1.00194795e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098095, dtype=float32), 'eval/episode_forward_reward': Array(-0.03586019, dtype=float32), 'eval/episode_reward': Array(-2.034604, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03586019, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976683, dtype=float32), 'eval/episode_train_reward': Array(-0.00107581, dtype=float32), 'eval/episode_x_position': Array(1.0079253, dtype=float32), 'eval/episode_x_velocity': Array(-0.03586019, dtype=float32), 'eval/episode_y_position': Array(-0.00033203, dtype=float32), 'eval/episode_y_velocity': Array(-0.00078955, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600834, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04077488, dtype=float32), 'eval/episode_reward_std': Array(0.04261641, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04077488, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01134013, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122325, dtype=float32), 'eval/episode_x_position_std': Array(0.00596355, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04077488, dtype=float32), 'eval/episode_y_position_std': Array(0.00592801, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01371116, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.644855499267578, 'eval/sps': 6200.091834236431, 'num_steps': 604160}
{'eval/walltime': 2586.970365524292, 'training/sps': 127.28308688285199, 'training/walltime': 4871.522528886795, 'training/entropy_loss': Array(0.06058636, dtype=float32), 'training/policy_loss': Array(0.22319934, dtype=float32), 'training/total_loss': Array(0.2837857, dtype=float32), 'training/v_loss': Array(6.447041e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085663, dtype=float32), 'eval/episode_forward_reward': Array(-0.04444458, dtype=float32), 'eval/episode_reward': Array(-2.0448189, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04444458, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.999041, dtype=float32), 'eval/episode_train_reward': Array(-0.00133334, dtype=float32), 'eval/episode_x_position': Array(1.0067415, dtype=float32), 'eval/episode_x_velocity': Array(-0.04444458, dtype=float32), 'eval/episode_y_position': Array(0.00077298, dtype=float32), 'eval/episode_y_velocity': Array(6.670444e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00605163, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0445405, dtype=float32), 'eval/episode_reward_std': Array(0.04696831, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0445405, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00480749, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133621, dtype=float32), 'eval/episode_x_position_std': Array(0.00601626, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0445405, dtype=float32), 'eval/episode_y_position_std': Array(0.00602593, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01368294, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65880537033081, 'eval/sps': 6195.905218402778, 'num_steps': 609280}
{'eval/walltime': 2607.6255238056183, 'training/sps': 127.29786536659473, 'training/walltime': 4911.743156194687, 'training/entropy_loss': Array(0.05955742, dtype=float32), 'training/policy_loss': Array(-0.11485086, dtype=float32), 'training/total_loss': Array(-0.0552934, dtype=float32), 'training/v_loss': Array(2.7534222e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090497, dtype=float32), 'eval/episode_forward_reward': Array(-0.03988335, dtype=float32), 'eval/episode_reward': Array(-2.040681, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03988335, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9996014, dtype=float32), 'eval/episode_train_reward': Array(-0.0011965, dtype=float32), 'eval/episode_x_position': Array(1.007148, dtype=float32), 'eval/episode_x_velocity': Array(-0.03988335, dtype=float32), 'eval/episode_y_position': Array(0.00039247, dtype=float32), 'eval/episode_y_velocity': Array(-0.00106636, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00608094, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04321638, dtype=float32), 'eval/episode_reward_std': Array(0.0446957, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04321638, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00299903, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129649, dtype=float32), 'eval/episode_x_position_std': Array(0.00610183, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04321638, dtype=float32), 'eval/episode_y_position_std': Array(0.0059141, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01333179, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.655158281326294, 'eval/sps': 6196.9992316989865, 'num_steps': 614400}
{'eval/walltime': 2628.2653896808624, 'training/sps': 127.35065437978989, 'training/walltime': 4951.947111368179, 'training/entropy_loss': Array(0.0613848, dtype=float32), 'training/policy_loss': Array(-0.08097154, dtype=float32), 'training/total_loss': Array(-0.01958673, dtype=float32), 'training/v_loss': Array(1.1449396e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094256, dtype=float32), 'eval/episode_forward_reward': Array(-0.03539981, dtype=float32), 'eval/episode_reward': Array(-2.0340698, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03539981, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976082, dtype=float32), 'eval/episode_train_reward': Array(-0.00106199, dtype=float32), 'eval/episode_x_position': Array(1.0075014, dtype=float32), 'eval/episode_x_velocity': Array(-0.03539981, dtype=float32), 'eval/episode_y_position': Array(-3.0873256e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0005009, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00621372, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04332885, dtype=float32), 'eval/episode_reward_std': Array(0.04565293, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04332885, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01144291, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129987, dtype=float32), 'eval/episode_x_position_std': Array(0.00624055, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04332885, dtype=float32), 'eval/episode_y_position_std': Array(0.00613003, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00997719, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63986587524414, 'eval/sps': 6201.590687346748, 'num_steps': 619520}
{'eval/walltime': 2648.897312402725, 'training/sps': 127.4906980505185, 'training/walltime': 4992.106904029846, 'training/entropy_loss': Array(0.06664291, dtype=float32), 'training/policy_loss': Array(0.26915166, dtype=float32), 'training/total_loss': Array(0.33579457, dtype=float32), 'training/v_loss': Array(8.35195e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093406, dtype=float32), 'eval/episode_forward_reward': Array(-0.04454764, dtype=float32), 'eval/episode_reward': Array(-2.0432367, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04454764, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973526, dtype=float32), 'eval/episode_train_reward': Array(-0.00133643, dtype=float32), 'eval/episode_x_position': Array(1.0074885, dtype=float32), 'eval/episode_x_velocity': Array(-0.04454764, dtype=float32), 'eval/episode_y_position': Array(0.00090017, dtype=float32), 'eval/episode_y_velocity': Array(-0.00149638, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574456, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04198216, dtype=float32), 'eval/episode_reward_std': Array(0.0450144, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04198216, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01315306, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125946, dtype=float32), 'eval/episode_x_position_std': Array(0.0056993, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04198216, dtype=float32), 'eval/episode_y_position_std': Array(0.00553862, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01078421, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.631922721862793, 'eval/sps': 6203.978258621709, 'num_steps': 624640}
{'eval/walltime': 2669.5445685386658, 'training/sps': 127.17690080354205, 'training/walltime': 5032.365787267685, 'training/entropy_loss': Array(0.06219012, dtype=float32), 'training/policy_loss': Array(0.26738948, dtype=float32), 'training/total_loss': Array(0.32957962, dtype=float32), 'training/v_loss': Array(6.0762595e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091987, dtype=float32), 'eval/episode_forward_reward': Array(-0.04056065, dtype=float32), 'eval/episode_reward': Array(-2.0395775, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04056065, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977999, dtype=float32), 'eval/episode_train_reward': Array(-0.00121682, dtype=float32), 'eval/episode_x_position': Array(1.0073333, dtype=float32), 'eval/episode_x_velocity': Array(-0.04056065, dtype=float32), 'eval/episode_y_position': Array(-0.00049195, dtype=float32), 'eval/episode_y_velocity': Array(-0.00066805, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0061306, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04343536, dtype=float32), 'eval/episode_reward_std': Array(0.04660217, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04343536, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01135047, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130306, dtype=float32), 'eval/episode_x_position_std': Array(0.00609232, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04343536, dtype=float32), 'eval/episode_y_position_std': Array(0.00560391, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01074661, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64725613594055, 'eval/sps': 6199.370955503922, 'num_steps': 629760}
{'eval/walltime': 2690.208327293396, 'training/sps': 127.46568201511774, 'training/walltime': 5072.53346157074, 'training/entropy_loss': Array(0.06174064, dtype=float32), 'training/policy_loss': Array(-0.10037558, dtype=float32), 'training/total_loss': Array(-0.03863494, dtype=float32), 'training/v_loss': Array(5.9060925e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088933, dtype=float32), 'eval/episode_forward_reward': Array(-0.03208018, dtype=float32), 'eval/episode_reward': Array(-2.0322104, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03208018, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.999168, dtype=float32), 'eval/episode_train_reward': Array(-0.00096241, dtype=float32), 'eval/episode_x_position': Array(1.0069684, dtype=float32), 'eval/episode_x_velocity': Array(-0.03208018, dtype=float32), 'eval/episode_y_position': Array(0.0006287, dtype=float32), 'eval/episode_y_velocity': Array(0.00020158, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563896, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04057497, dtype=float32), 'eval/episode_reward_std': Array(0.04161507, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04057497, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0061849, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121725, dtype=float32), 'eval/episode_x_position_std': Array(0.00562406, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04057497, dtype=float32), 'eval/episode_y_position_std': Array(0.00601032, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01244903, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.663758754730225, 'eval/sps': 6194.419975538042, 'num_steps': 634880}
{'eval/walltime': 2710.88205575943, 'training/sps': 127.38557391731003, 'training/walltime': 5112.726395845413, 'training/entropy_loss': Array(0.07904071, dtype=float32), 'training/policy_loss': Array(0.26910764, dtype=float32), 'training/total_loss': Array(0.34814835, dtype=float32), 'training/v_loss': Array(3.5072447e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0191368, dtype=float32), 'eval/episode_forward_reward': Array(-0.03183129, dtype=float32), 'eval/episode_reward': Array(-2.0459127, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03183129, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0209394, dtype=float32), 'eval/episode_train_reward': Array(-0.00095494, dtype=float32), 'eval/episode_x_position': Array(1.0171828, dtype=float32), 'eval/episode_x_velocity': Array(-0.03183129, dtype=float32), 'eval/episode_y_position': Array(-6.2940235e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00015985, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09016648, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04033403, dtype=float32), 'eval/episode_reward_std': Array(0.17885613, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04033403, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26460913, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121002, dtype=float32), 'eval/episode_x_position_std': Array(0.08991107, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04033403, dtype=float32), 'eval/episode_y_position_std': Array(0.00573727, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01220852, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.673728466033936, 'eval/sps': 6191.432774707214, 'num_steps': 640000}
{'eval/walltime': 2731.529855966568, 'training/sps': 127.35454160695068, 'training/walltime': 5152.929123878479, 'training/entropy_loss': Array(0.05076337, dtype=float32), 'training/policy_loss': Array(0.27458027, dtype=float32), 'training/total_loss': Array(0.3253436, dtype=float32), 'training/v_loss': Array(5.7176144e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087981, dtype=float32), 'eval/episode_forward_reward': Array(-0.03378241, dtype=float32), 'eval/episode_reward': Array(-2.032535, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03378241, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997739, dtype=float32), 'eval/episode_train_reward': Array(-0.00101347, dtype=float32), 'eval/episode_x_position': Array(1.006912, dtype=float32), 'eval/episode_x_velocity': Array(-0.03378241, dtype=float32), 'eval/episode_y_position': Array(-0.00016716, dtype=float32), 'eval/episode_y_velocity': Array(0.00043328, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576913, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04156187, dtype=float32), 'eval/episode_reward_std': Array(0.04331645, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04156187, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01179606, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124686, dtype=float32), 'eval/episode_x_position_std': Array(0.00574464, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04156187, dtype=float32), 'eval/episode_y_position_std': Array(0.00549642, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01322004, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64780020713806, 'eval/sps': 6199.207601580224, 'num_steps': 645120}
{'eval/walltime': 2752.157742500305, 'training/sps': 127.27581924334835, 'training/walltime': 5193.156718015671, 'training/entropy_loss': Array(0.04534322, dtype=float32), 'training/policy_loss': Array(-0.19092764, dtype=float32), 'training/total_loss': Array(-0.14558417, dtype=float32), 'training/v_loss': Array(2.701356e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097642, dtype=float32), 'eval/episode_forward_reward': Array(-0.04055398, dtype=float32), 'eval/episode_reward': Array(-2.0399191, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04055398, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981487, dtype=float32), 'eval/episode_train_reward': Array(-0.00121662, dtype=float32), 'eval/episode_x_position': Array(1.0079155, dtype=float32), 'eval/episode_x_velocity': Array(-0.04055398, dtype=float32), 'eval/episode_y_position': Array(-0.00020006, dtype=float32), 'eval/episode_y_velocity': Array(-0.00216714, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057394, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04331417, dtype=float32), 'eval/episode_reward_std': Array(0.04454353, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04331417, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00967224, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129943, dtype=float32), 'eval/episode_x_position_std': Array(0.00571923, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04331417, dtype=float32), 'eval/episode_y_position_std': Array(0.00612011, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01278222, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.627886533737183, 'eval/sps': 6205.192169864533, 'num_steps': 650240}
{'eval/walltime': 2772.8053908348083, 'training/sps': 127.26325182182954, 'training/walltime': 5233.3882846832275, 'training/entropy_loss': Array(0.04676891, dtype=float32), 'training/policy_loss': Array(-0.19142434, dtype=float32), 'training/total_loss': Array(-0.14465538, dtype=float32), 'training/v_loss': Array(7.1808444e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088226, dtype=float32), 'eval/episode_forward_reward': Array(-0.04551987, dtype=float32), 'eval/episode_reward': Array(-2.041782, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04551987, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9948964, dtype=float32), 'eval/episode_train_reward': Array(-0.0013656, dtype=float32), 'eval/episode_x_position': Array(1.0069828, dtype=float32), 'eval/episode_x_velocity': Array(-0.04551987, dtype=float32), 'eval/episode_y_position': Array(0.00055484, dtype=float32), 'eval/episode_y_velocity': Array(-0.00176848, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595896, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04299561, dtype=float32), 'eval/episode_reward_std': Array(0.04650779, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04299561, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01857398, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128987, dtype=float32), 'eval/episode_x_position_std': Array(0.00588132, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04299561, dtype=float32), 'eval/episode_y_position_std': Array(0.00551466, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01358153, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647648334503174, 'eval/sps': 6199.253199508735, 'num_steps': 655360}
{'eval/walltime': 2793.4559395313263, 'training/sps': 127.26199989201463, 'training/walltime': 5273.620247125626, 'training/entropy_loss': Array(0.04834677, dtype=float32), 'training/policy_loss': Array(-0.1838633, dtype=float32), 'training/total_loss': Array(-0.1355165, dtype=float32), 'training/v_loss': Array(5.3550245e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100508, dtype=float32), 'eval/episode_forward_reward': Array(-0.04462898, dtype=float32), 'eval/episode_reward': Array(-2.0444272, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04462898, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984593, dtype=float32), 'eval/episode_train_reward': Array(-0.00133887, dtype=float32), 'eval/episode_x_position': Array(1.0082304, dtype=float32), 'eval/episode_x_velocity': Array(-0.04462898, dtype=float32), 'eval/episode_y_position': Array(-0.00021411, dtype=float32), 'eval/episode_y_velocity': Array(0.00190891, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558004, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0431672, dtype=float32), 'eval/episode_reward_std': Array(0.04521481, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0431672, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00804164, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129502, dtype=float32), 'eval/episode_x_position_std': Array(0.00560639, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0431672, dtype=float32), 'eval/episode_y_position_std': Array(0.00560744, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01585687, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.650548696517944, 'eval/sps': 6198.382516663255, 'num_steps': 660480}
{'eval/walltime': 2814.1432435512543, 'training/sps': 127.29685346634699, 'training/walltime': 5313.841194152832, 'training/entropy_loss': Array(0.05036321, dtype=float32), 'training/policy_loss': Array(-0.16762066, dtype=float32), 'training/total_loss': Array(-0.11725742, dtype=float32), 'training/v_loss': Array(4.2144997e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090244, dtype=float32), 'eval/episode_forward_reward': Array(-0.03475805, dtype=float32), 'eval/episode_reward': Array(-2.0345187, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03475805, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987183, dtype=float32), 'eval/episode_train_reward': Array(-0.00104274, dtype=float32), 'eval/episode_x_position': Array(1.0071253, dtype=float32), 'eval/episode_x_velocity': Array(-0.03475805, dtype=float32), 'eval/episode_y_position': Array(-8.9794456e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00124345, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0055166, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04113498, dtype=float32), 'eval/episode_reward_std': Array(0.04315, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04113498, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0060169, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123405, dtype=float32), 'eval/episode_x_position_std': Array(0.00550289, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04113498, dtype=float32), 'eval/episode_y_position_std': Array(0.00604618, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0093188, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68730401992798, 'eval/sps': 6187.369793410404, 'num_steps': 665600}
{'eval/walltime': 2834.7672152519226, 'training/sps': 127.18223339210213, 'training/walltime': 5354.098389387131, 'training/entropy_loss': Array(0.05218092, dtype=float32), 'training/policy_loss': Array(-0.15426442, dtype=float32), 'training/total_loss': Array(-0.10208347, dtype=float32), 'training/v_loss': Array(3.331872e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097901, dtype=float32), 'eval/episode_forward_reward': Array(-0.03691196, dtype=float32), 'eval/episode_reward': Array(-2.0351284, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03691196, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997109, dtype=float32), 'eval/episode_train_reward': Array(-0.00110736, dtype=float32), 'eval/episode_x_position': Array(1.0078886, dtype=float32), 'eval/episode_x_velocity': Array(-0.03691196, dtype=float32), 'eval/episode_y_position': Array(-0.00015737, dtype=float32), 'eval/episode_y_velocity': Array(-0.00052942, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057021, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04365852, dtype=float32), 'eval/episode_reward_std': Array(0.04910051, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04365852, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01559769, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130976, dtype=float32), 'eval/episode_x_position_std': Array(0.00568218, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04365852, dtype=float32), 'eval/episode_y_position_std': Array(0.0058683, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01182653, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.623971700668335, 'eval/sps': 6206.37003666234, 'num_steps': 670720}
{'eval/walltime': 2855.445207595825, 'training/sps': 127.22574006458342, 'training/walltime': 5394.3418180942535, 'training/entropy_loss': Array(0.05358651, dtype=float32), 'training/policy_loss': Array(-0.16470173, dtype=float32), 'training/total_loss': Array(-0.11111522, dtype=float32), 'training/v_loss': Array(2.5053447e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008844, dtype=float32), 'eval/episode_forward_reward': Array(-0.04408586, dtype=float32), 'eval/episode_reward': Array(-2.044333, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04408586, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9989247, dtype=float32), 'eval/episode_train_reward': Array(-0.00132258, dtype=float32), 'eval/episode_x_position': Array(1.0070028, dtype=float32), 'eval/episode_x_velocity': Array(-0.04408586, dtype=float32), 'eval/episode_y_position': Array(-5.9283368e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00028526, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572464, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04556086, dtype=float32), 'eval/episode_reward_std': Array(0.04744862, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04556086, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00810979, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136683, dtype=float32), 'eval/episode_x_position_std': Array(0.00575336, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04556086, dtype=float32), 'eval/episode_y_position_std': Array(0.00605552, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01320789, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677992343902588, 'eval/sps': 6190.156078558755, 'num_steps': 675840}
{'eval/walltime': 2876.0794019699097, 'training/sps': 127.28666669274655, 'training/walltime': 5434.565984010696, 'training/entropy_loss': Array(0.05540614, dtype=float32), 'training/policy_loss': Array(-0.15948978, dtype=float32), 'training/total_loss': Array(-0.10408361, dtype=float32), 'training/v_loss': Array(1.7398934e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0081154, dtype=float32), 'eval/episode_forward_reward': Array(-0.03730708, dtype=float32), 'eval/episode_reward': Array(-2.0362866, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03730708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978604, dtype=float32), 'eval/episode_train_reward': Array(-0.00111921, dtype=float32), 'eval/episode_x_position': Array(1.0062183, dtype=float32), 'eval/episode_x_velocity': Array(-0.03730708, dtype=float32), 'eval/episode_y_position': Array(-0.00058955, dtype=float32), 'eval/episode_y_velocity': Array(-0.00015282, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00550546, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04155845, dtype=float32), 'eval/episode_reward_std': Array(0.04257783, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04155845, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01294311, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124675, dtype=float32), 'eval/episode_x_position_std': Array(0.00546902, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04155845, dtype=float32), 'eval/episode_y_position_std': Array(0.00581533, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00941488, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.634194374084473, 'eval/sps': 6203.295252503857, 'num_steps': 680960}
{'eval/walltime': 2896.7666277885437, 'training/sps': 127.27596482939148, 'training/walltime': 5474.793532133102, 'training/entropy_loss': Array(0.05757911, dtype=float32), 'training/policy_loss': Array(-0.10004914, dtype=float32), 'training/total_loss': Array(-0.04247002, dtype=float32), 'training/v_loss': Array(1.4735965e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086324, dtype=float32), 'eval/episode_forward_reward': Array(-0.03127948, dtype=float32), 'eval/episode_reward': Array(-2.0309763, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03127948, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987586, dtype=float32), 'eval/episode_train_reward': Array(-0.00093838, dtype=float32), 'eval/episode_x_position': Array(1.0067049, dtype=float32), 'eval/episode_x_velocity': Array(-0.03127948, dtype=float32), 'eval/episode_y_position': Array(-3.8058206e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00086144, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583927, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04071115, dtype=float32), 'eval/episode_reward_std': Array(0.04241426, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04071115, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00919344, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122133, dtype=float32), 'eval/episode_x_position_std': Array(0.00575073, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04071115, dtype=float32), 'eval/episode_y_position_std': Array(0.0058717, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01086298, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.687225818634033, 'eval/sps': 6187.393182739075, 'num_steps': 686080}
{'eval/walltime': 2917.477334499359, 'training/sps': 127.15153194190702, 'training/walltime': 5515.060447692871, 'training/entropy_loss': Array(0.06023218, dtype=float32), 'training/policy_loss': Array(-0.10329655, dtype=float32), 'training/total_loss': Array(-0.04306435, dtype=float32), 'training/v_loss': Array(9.8703445e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091873, dtype=float32), 'eval/episode_forward_reward': Array(-0.04022103, dtype=float32), 'eval/episode_reward': Array(-2.0392575, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04022103, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978297, dtype=float32), 'eval/episode_train_reward': Array(-0.00120663, dtype=float32), 'eval/episode_x_position': Array(1.007339, dtype=float32), 'eval/episode_x_velocity': Array(-0.04022103, dtype=float32), 'eval/episode_y_position': Array(0.00070212, dtype=float32), 'eval/episode_y_velocity': Array(-0.00091336, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00592927, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04282302, dtype=float32), 'eval/episode_reward_std': Array(0.04529313, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04282302, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01175006, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128469, dtype=float32), 'eval/episode_x_position_std': Array(0.00593652, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04282302, dtype=float32), 'eval/episode_y_position_std': Array(0.00592001, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01235095, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71070671081543, 'eval/sps': 6180.37818734387, 'num_steps': 691200}
{'eval/walltime': 2938.15505695343, 'training/sps': 127.13675279000546, 'training/walltime': 5555.332044124603, 'training/entropy_loss': Array(0.06225871, dtype=float32), 'training/policy_loss': Array(-0.09708106, dtype=float32), 'training/total_loss': Array(-0.03482234, dtype=float32), 'training/v_loss': Array(6.680577e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095994, dtype=float32), 'eval/episode_forward_reward': Array(-0.03570994, dtype=float32), 'eval/episode_reward': Array(-2.0347037, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03570994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979224, dtype=float32), 'eval/episode_train_reward': Array(-0.0010713, dtype=float32), 'eval/episode_x_position': Array(1.0077257, dtype=float32), 'eval/episode_x_velocity': Array(-0.03570994, dtype=float32), 'eval/episode_y_position': Array(-2.411368e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00017664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00603922, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04350041, dtype=float32), 'eval/episode_reward_std': Array(0.04639586, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04350041, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01089176, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130501, dtype=float32), 'eval/episode_x_position_std': Array(0.00598482, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04350041, dtype=float32), 'eval/episode_y_position_std': Array(0.00582057, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01425555, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677722454071045, 'eval/sps': 6190.236873732642, 'num_steps': 696320}
{'eval/walltime': 2958.8178639411926, 'training/sps': 126.90451655697571, 'training/walltime': 5595.677337884903, 'training/entropy_loss': Array(0.07064332, dtype=float32), 'training/policy_loss': Array(0.2624252, dtype=float32), 'training/total_loss': Array(0.33306855, dtype=float32), 'training/v_loss': Array(5.780303e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092036, dtype=float32), 'eval/episode_forward_reward': Array(-0.04031796, dtype=float32), 'eval/episode_reward': Array(-2.040113, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04031796, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985855, dtype=float32), 'eval/episode_train_reward': Array(-0.00120954, dtype=float32), 'eval/episode_x_position': Array(1.0073378, dtype=float32), 'eval/episode_x_velocity': Array(-0.04031796, dtype=float32), 'eval/episode_y_position': Array(-0.00028747, dtype=float32), 'eval/episode_y_velocity': Array(0.00050008, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570594, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04304627, dtype=float32), 'eval/episode_reward_std': Array(0.04562689, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04304627, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00889406, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129139, dtype=float32), 'eval/episode_x_position_std': Array(0.00571128, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04304627, dtype=float32), 'eval/episode_y_position_std': Array(0.0055804, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01102055, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66280698776245, 'eval/sps': 6194.705301937342, 'num_steps': 701440}
{'eval/walltime': 2979.4898359775543, 'training/sps': 127.30871053660026, 'training/walltime': 5635.8945388793945, 'training/entropy_loss': Array(0.07510744, dtype=float32), 'training/policy_loss': Array(0.26861963, dtype=float32), 'training/total_loss': Array(0.34372705, dtype=float32), 'training/v_loss': Array(3.9022607e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096399, dtype=float32), 'eval/episode_forward_reward': Array(-0.03911555, dtype=float32), 'eval/episode_reward': Array(-2.0380247, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03911555, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977357, dtype=float32), 'eval/episode_train_reward': Array(-0.00117347, dtype=float32), 'eval/episode_x_position': Array(1.0077703, dtype=float32), 'eval/episode_x_velocity': Array(-0.03911555, dtype=float32), 'eval/episode_y_position': Array(0.00061234, dtype=float32), 'eval/episode_y_velocity': Array(-0.00066355, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00601615, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04354629, dtype=float32), 'eval/episode_reward_std': Array(0.04567353, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04354629, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01187215, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130639, dtype=float32), 'eval/episode_x_position_std': Array(0.00599046, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04354629, dtype=float32), 'eval/episode_y_position_std': Array(0.00592822, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01811226, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.671972036361694, 'eval/sps': 6191.958840445889, 'num_steps': 706560}
{'eval/walltime': 3000.097368955612, 'training/sps': 127.09191319272752, 'training/walltime': 5676.18034362793, 'training/entropy_loss': Array(0.07363179, dtype=float32), 'training/policy_loss': Array(0.2712567, dtype=float32), 'training/total_loss': Array(0.3448885, dtype=float32), 'training/v_loss': Array(1.6181589e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086249, dtype=float32), 'eval/episode_forward_reward': Array(-0.0343353, dtype=float32), 'eval/episode_reward': Array(-2.0339017, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0343353, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998536, dtype=float32), 'eval/episode_train_reward': Array(-0.00103006, dtype=float32), 'eval/episode_x_position': Array(1.0067139, dtype=float32), 'eval/episode_x_velocity': Array(-0.0343353, dtype=float32), 'eval/episode_y_position': Array(9.180412e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00153909, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572778, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03993484, dtype=float32), 'eval/episode_reward_std': Array(0.04230335, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03993484, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00862846, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119805, dtype=float32), 'eval/episode_x_position_std': Array(0.0057314, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03993484, dtype=float32), 'eval/episode_y_position_std': Array(0.00591077, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01102629, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.60753297805786, 'eval/sps': 6211.320886216204, 'num_steps': 711680}
{'eval/walltime': 3020.7557830810547, 'training/sps': 127.2904753185238, 'training/walltime': 5716.403306007385, 'training/entropy_loss': Array(0.06887093, dtype=float32), 'training/policy_loss': Array(0.27015638, dtype=float32), 'training/total_loss': Array(0.33902735, dtype=float32), 'training/v_loss': Array(7.744555e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100291, dtype=float32), 'eval/episode_forward_reward': Array(-0.03535355, dtype=float32), 'eval/episode_reward': Array(-2.0343716, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03535355, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979575, dtype=float32), 'eval/episode_train_reward': Array(-0.00106061, dtype=float32), 'eval/episode_x_position': Array(1.0081637, dtype=float32), 'eval/episode_x_velocity': Array(-0.03535355, dtype=float32), 'eval/episode_y_position': Array(-0.00099389, dtype=float32), 'eval/episode_y_velocity': Array(-0.00117261, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571184, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04260666, dtype=float32), 'eval/episode_reward_std': Array(0.04550633, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04260666, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01160074, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012782, dtype=float32), 'eval/episode_x_position_std': Array(0.00566197, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04260666, dtype=float32), 'eval/episode_y_position_std': Array(0.00586214, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01107198, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.658414125442505, 'eval/sps': 6196.022561207042, 'num_steps': 716800}
{'eval/walltime': 3041.3984525203705, 'training/sps': 127.11498815862336, 'training/walltime': 5756.681797742844, 'training/entropy_loss': Array(0.06639179, dtype=float32), 'training/policy_loss': Array(0.26560593, dtype=float32), 'training/total_loss': Array(0.3319977, dtype=float32), 'training/v_loss': Array(4.867493e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088958, dtype=float32), 'eval/episode_forward_reward': Array(-0.04751096, dtype=float32), 'eval/episode_reward': Array(-2.0468202, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04751096, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978838, dtype=float32), 'eval/episode_train_reward': Array(-0.00142533, dtype=float32), 'eval/episode_x_position': Array(1.0070896, dtype=float32), 'eval/episode_x_velocity': Array(-0.04751096, dtype=float32), 'eval/episode_y_position': Array(-0.00037331, dtype=float32), 'eval/episode_y_velocity': Array(-0.00171582, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00547184, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04417825, dtype=float32), 'eval/episode_reward_std': Array(0.04707591, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04417825, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01365773, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132535, dtype=float32), 'eval/episode_x_position_std': Array(0.00547566, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04417825, dtype=float32), 'eval/episode_y_position_std': Array(0.00588392, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01246422, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.642669439315796, 'eval/sps': 6200.748424339569, 'num_steps': 721920}
{'eval/walltime': 3062.054773569107, 'training/sps': 127.21800341994218, 'training/walltime': 5796.927673816681, 'training/entropy_loss': Array(0.0652355, dtype=float32), 'training/policy_loss': Array(-0.08016457, dtype=float32), 'training/total_loss': Array(-0.01492907, dtype=float32), 'training/v_loss': Array(4.9387046e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009018, dtype=float32), 'eval/episode_forward_reward': Array(-0.04786082, dtype=float32), 'eval/episode_reward': Array(-2.046105, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04786082, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996808, dtype=float32), 'eval/episode_train_reward': Array(-0.00143582, dtype=float32), 'eval/episode_x_position': Array(1.0072114, dtype=float32), 'eval/episode_x_velocity': Array(-0.04786082, dtype=float32), 'eval/episode_y_position': Array(0.00012456, dtype=float32), 'eval/episode_y_velocity': Array(-0.00340579, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00587759, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0445371, dtype=float32), 'eval/episode_reward_std': Array(0.04793169, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0445371, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01331819, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133611, dtype=float32), 'eval/episode_x_position_std': Array(0.00583821, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0445371, dtype=float32), 'eval/episode_y_position_std': Array(0.00578555, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01148229, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.656321048736572, 'eval/sps': 6196.650395682585, 'num_steps': 727040}
{'eval/walltime': 3082.689687728882, 'training/sps': 127.36728645829595, 'training/walltime': 5837.1263790130615, 'training/entropy_loss': Array(0.06775888, dtype=float32), 'training/policy_loss': Array(0.02231739, dtype=float32), 'training/total_loss': Array(0.09007628, dtype=float32), 'training/v_loss': Array(5.236766e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087996, dtype=float32), 'eval/episode_forward_reward': Array(-0.04086426, dtype=float32), 'eval/episode_reward': Array(-2.0411055, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04086426, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9990153, dtype=float32), 'eval/episode_train_reward': Array(-0.00122593, dtype=float32), 'eval/episode_x_position': Array(1.0069256, dtype=float32), 'eval/episode_x_velocity': Array(-0.04086426, dtype=float32), 'eval/episode_y_position': Array(-0.00089335, dtype=float32), 'eval/episode_y_velocity': Array(-0.00179031, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586781, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04348433, dtype=float32), 'eval/episode_reward_std': Array(0.0447355, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04348433, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00500161, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130453, dtype=float32), 'eval/episode_x_position_std': Array(0.0058388, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04348433, dtype=float32), 'eval/episode_y_position_std': Array(0.00586025, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01231503, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63491415977478, 'eval/sps': 6203.078869575344, 'num_steps': 732160}
{'eval/walltime': 3103.340889930725, 'training/sps': 127.28740757633933, 'training/walltime': 5877.35031080246, 'training/entropy_loss': Array(0.07550333, dtype=float32), 'training/policy_loss': Array(0.26996425, dtype=float32), 'training/total_loss': Array(0.34546757, dtype=float32), 'training/v_loss': Array(2.3356805e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097275, dtype=float32), 'eval/episode_forward_reward': Array(-0.03534672, dtype=float32), 'eval/episode_reward': Array(-2.0351915, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03534672, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987843, dtype=float32), 'eval/episode_train_reward': Array(-0.0010604, dtype=float32), 'eval/episode_x_position': Array(1.0078316, dtype=float32), 'eval/episode_x_velocity': Array(-0.03534672, dtype=float32), 'eval/episode_y_position': Array(0.00020595, dtype=float32), 'eval/episode_y_velocity': Array(-0.00126138, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582962, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04333419, dtype=float32), 'eval/episode_reward_std': Array(0.04632232, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04333419, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00842608, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130003, dtype=float32), 'eval/episode_x_position_std': Array(0.00582677, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04333419, dtype=float32), 'eval/episode_y_position_std': Array(0.00546958, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01280153, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65120220184326, 'eval/sps': 6198.186369439311, 'num_steps': 737280}
{'eval/walltime': 3124.0301764011383, 'training/sps': 127.33572244441099, 'training/walltime': 5917.558980464935, 'training/entropy_loss': Array(0.07084523, dtype=float32), 'training/policy_loss': Array(0.275129, dtype=float32), 'training/total_loss': Array(0.34597424, dtype=float32), 'training/v_loss': Array(5.2530265e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095383, dtype=float32), 'eval/episode_forward_reward': Array(-0.03334857, dtype=float32), 'eval/episode_reward': Array(-2.0306885, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03334857, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963398, dtype=float32), 'eval/episode_train_reward': Array(-0.00100046, dtype=float32), 'eval/episode_x_position': Array(1.0076371, dtype=float32), 'eval/episode_x_velocity': Array(-0.03334857, dtype=float32), 'eval/episode_y_position': Array(-0.0003673, dtype=float32), 'eval/episode_y_velocity': Array(-0.00069973, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00611138, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03986505, dtype=float32), 'eval/episode_reward_std': Array(0.0436605, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03986505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01644669, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119595, dtype=float32), 'eval/episode_x_position_std': Array(0.00610308, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03986505, dtype=float32), 'eval/episode_y_position_std': Array(0.00596036, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01333571, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.689286470413208, 'eval/sps': 6186.776918722977, 'num_steps': 742400}
{'eval/walltime': 3144.708970308304, 'training/sps': 127.0013283700856, 'training/walltime': 5957.873519420624, 'training/entropy_loss': Array(0.06167547, dtype=float32), 'training/policy_loss': Array(0.26749346, dtype=float32), 'training/total_loss': Array(0.32916898, dtype=float32), 'training/v_loss': Array(3.3329798e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098667, dtype=float32), 'eval/episode_forward_reward': Array(-0.03076578, dtype=float32), 'eval/episode_reward': Array(-2.0276103, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03076578, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959214, dtype=float32), 'eval/episode_train_reward': Array(-0.00092297, dtype=float32), 'eval/episode_x_position': Array(1.0079399, dtype=float32), 'eval/episode_x_velocity': Array(-0.03076578, dtype=float32), 'eval/episode_y_position': Array(-0.00059515, dtype=float32), 'eval/episode_y_velocity': Array(0.00031494, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00625582, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03976456, dtype=float32), 'eval/episode_reward_std': Array(0.04330746, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03976456, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01750771, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119294, dtype=float32), 'eval/episode_x_position_std': Array(0.0062167, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03976456, dtype=float32), 'eval/episode_y_position_std': Array(0.00582358, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01273379, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.678793907165527, 'eval/sps': 6189.916132180513, 'num_steps': 747520}
{'eval/walltime': 3165.3884422779083, 'training/sps': 127.07485064523154, 'training/walltime': 5998.164733409882, 'training/entropy_loss': Array(0.06116353, dtype=float32), 'training/policy_loss': Array(-0.13639626, dtype=float32), 'training/total_loss': Array(-0.0752327, dtype=float32), 'training/v_loss': Array(3.1643673e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094872, dtype=float32), 'eval/episode_forward_reward': Array(-0.03684801, dtype=float32), 'eval/episode_reward': Array(-2.0357094, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03684801, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997756, dtype=float32), 'eval/episode_train_reward': Array(-0.00110544, dtype=float32), 'eval/episode_x_position': Array(1.0076178, dtype=float32), 'eval/episode_x_velocity': Array(-0.03684801, dtype=float32), 'eval/episode_y_position': Array(-0.00056501, dtype=float32), 'eval/episode_y_velocity': Array(-0.00253673, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057585, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04038809, dtype=float32), 'eval/episode_reward_std': Array(0.04361314, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04038809, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01094662, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121164, dtype=float32), 'eval/episode_x_position_std': Array(0.00569587, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04038809, dtype=float32), 'eval/episode_y_position_std': Array(0.00569202, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01552429, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.679471969604492, 'eval/sps': 6189.713170052865, 'num_steps': 752640}
{'eval/walltime': 3186.053435087204, 'training/sps': 127.27956083493396, 'training/walltime': 6038.391144990921, 'training/entropy_loss': Array(0.06514022, dtype=float32), 'training/policy_loss': Array(-0.06904373, dtype=float32), 'training/total_loss': Array(-0.00390351, dtype=float32), 'training/v_loss': Array(3.0545304e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085504, dtype=float32), 'eval/episode_forward_reward': Array(-0.03269393, dtype=float32), 'eval/episode_reward': Array(-2.0307665, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03269393, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970918, dtype=float32), 'eval/episode_train_reward': Array(-0.00098082, dtype=float32), 'eval/episode_x_position': Array(1.0066628, dtype=float32), 'eval/episode_x_velocity': Array(-0.03269393, dtype=float32), 'eval/episode_y_position': Array(-0.00027165, dtype=float32), 'eval/episode_y_velocity': Array(-0.00030834, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574767, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04270458, dtype=float32), 'eval/episode_reward_std': Array(0.0483042, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04270458, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01492037, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128114, dtype=float32), 'eval/episode_x_position_std': Array(0.0057064, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04270458, dtype=float32), 'eval/episode_y_position_std': Array(0.00559197, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01188354, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.664992809295654, 'eval/sps': 6194.050062404195, 'num_steps': 757760}
{'eval/walltime': 3206.719792842865, 'training/sps': 127.2322323367005, 'training/walltime': 6078.632520198822, 'training/entropy_loss': Array(0.06878479, dtype=float32), 'training/policy_loss': Array(-0.02171307, dtype=float32), 'training/total_loss': Array(0.04707172, dtype=float32), 'training/v_loss': Array(1.8360853e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0165505, dtype=float32), 'eval/episode_forward_reward': Array(-0.03455836, dtype=float32), 'eval/episode_reward': Array(-2.049223, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03455836, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0214403, dtype=float32), 'eval/episode_train_reward': Array(-0.00103675, dtype=float32), 'eval/episode_x_position': Array(1.0146297, dtype=float32), 'eval/episode_x_velocity': Array(-0.03455836, dtype=float32), 'eval/episode_y_position': Array(-0.00057407, dtype=float32), 'eval/episode_y_velocity': Array(0.00013496, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09092798, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04390597, dtype=float32), 'eval/episode_reward_std': Array(0.18041046, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04390597, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26458558, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131718, dtype=float32), 'eval/episode_x_position_std': Array(0.0906624, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04390597, dtype=float32), 'eval/episode_y_position_std': Array(0.00582231, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01061706, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.66635775566101, 'eval/sps': 6193.64096534803, 'num_steps': 762880}
{'eval/walltime': 3227.4193379879, 'training/sps': 127.19141507855254, 'training/walltime': 6118.88680934906, 'training/entropy_loss': Array(0.08674462, dtype=float32), 'training/policy_loss': Array(0.22473544, dtype=float32), 'training/total_loss': Array(0.31148005, dtype=float32), 'training/v_loss': Array(1.0425074e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100955, dtype=float32), 'eval/episode_forward_reward': Array(-0.04151541, dtype=float32), 'eval/episode_reward': Array(-2.0403123, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04151541, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975514, dtype=float32), 'eval/episode_train_reward': Array(-0.00124546, dtype=float32), 'eval/episode_x_position': Array(1.0082306, dtype=float32), 'eval/episode_x_velocity': Array(-0.04151541, dtype=float32), 'eval/episode_y_position': Array(-0.00019776, dtype=float32), 'eval/episode_y_velocity': Array(-0.00103745, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577856, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04494295, dtype=float32), 'eval/episode_reward_std': Array(0.04704676, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04494295, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01356431, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134829, dtype=float32), 'eval/episode_x_position_std': Array(0.00581079, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04494295, dtype=float32), 'eval/episode_y_position_std': Array(0.00582905, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01486983, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69954514503479, 'eval/sps': 6183.710758045494, 'num_steps': 768000}
{'eval/walltime': 3248.1273674964905, 'training/sps': 127.06154100865989, 'training/walltime': 6159.182243824005, 'training/entropy_loss': Array(0.07876794, dtype=float32), 'training/policy_loss': Array(0.2729988, dtype=float32), 'training/total_loss': Array(0.35176754, dtype=float32), 'training/v_loss': Array(7.6495303e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094252, dtype=float32), 'eval/episode_forward_reward': Array(-0.03659981, dtype=float32), 'eval/episode_reward': Array(-2.0353835, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03659981, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997686, dtype=float32), 'eval/episode_train_reward': Array(-0.00109799, dtype=float32), 'eval/episode_x_position': Array(1.0075376, dtype=float32), 'eval/episode_x_velocity': Array(-0.03659981, dtype=float32), 'eval/episode_y_position': Array(-0.00044941, dtype=float32), 'eval/episode_y_velocity': Array(-0.00136268, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00547171, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04149622, dtype=float32), 'eval/episode_reward_std': Array(0.04488897, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04149622, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0128412, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124489, dtype=float32), 'eval/episode_x_position_std': Array(0.00551232, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04149622, dtype=float32), 'eval/episode_y_position_std': Array(0.00644787, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01531975, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7080295085907, 'eval/sps': 6181.177206981445, 'num_steps': 773120}
{'eval/walltime': 3268.780425310135, 'training/sps': 126.9886333693213, 'training/walltime': 6199.500813007355, 'training/entropy_loss': Array(0.05945853, dtype=float32), 'training/policy_loss': Array(0.27072775, dtype=float32), 'training/total_loss': Array(0.33018658, dtype=float32), 'training/v_loss': Array(2.9704773e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090345, dtype=float32), 'eval/episode_forward_reward': Array(-0.03657917, dtype=float32), 'eval/episode_reward': Array(-2.03391, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03657917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962335, dtype=float32), 'eval/episode_train_reward': Array(-0.00109738, dtype=float32), 'eval/episode_x_position': Array(1.0071114, dtype=float32), 'eval/episode_x_velocity': Array(-0.03657917, dtype=float32), 'eval/episode_y_position': Array(0.00020339, dtype=float32), 'eval/episode_y_velocity': Array(0.0004692, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588995, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04330676, dtype=float32), 'eval/episode_reward_std': Array(0.04743246, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04330676, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01509554, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012992, dtype=float32), 'eval/episode_x_position_std': Array(0.005874, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04330676, dtype=float32), 'eval/episode_y_position_std': Array(0.0059613, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01313575, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65305781364441, 'eval/sps': 6197.62948203423, 'num_steps': 778240}
{'eval/walltime': 3289.457805633545, 'training/sps': 127.13421705005439, 'training/walltime': 6239.77321267128, 'training/entropy_loss': Array(0.05443442, dtype=float32), 'training/policy_loss': Array(-0.1788567, dtype=float32), 'training/total_loss': Array(-0.12442224, dtype=float32), 'training/v_loss': Array(2.6970337e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092335, dtype=float32), 'eval/episode_forward_reward': Array(-0.04560175, dtype=float32), 'eval/episode_reward': Array(-2.0446694, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04560175, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976995, dtype=float32), 'eval/episode_train_reward': Array(-0.00136805, dtype=float32), 'eval/episode_x_position': Array(1.0074337, dtype=float32), 'eval/episode_x_velocity': Array(-0.04560175, dtype=float32), 'eval/episode_y_position': Array(-0.00087493, dtype=float32), 'eval/episode_y_velocity': Array(-0.00076876, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00547047, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04272434, dtype=float32), 'eval/episode_reward_std': Array(0.04456235, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04272434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01141065, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128173, dtype=float32), 'eval/episode_x_position_std': Array(0.0055022, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04272434, dtype=float32), 'eval/episode_y_position_std': Array(0.00593784, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01351662, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677380323410034, 'eval/sps': 6190.339298208098, 'num_steps': 783360}
{'eval/walltime': 3310.1119174957275, 'training/sps': 127.18463847560821, 'training/walltime': 6280.0296466350555, 'training/entropy_loss': Array(0.0574149, dtype=float32), 'training/policy_loss': Array(-0.15560195, dtype=float32), 'training/total_loss': Array(-0.09818704, dtype=float32), 'training/v_loss': Array(5.7605867e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092537, dtype=float32), 'eval/episode_forward_reward': Array(-0.03335478, dtype=float32), 'eval/episode_reward': Array(-2.0325184, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03335478, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981632, dtype=float32), 'eval/episode_train_reward': Array(-0.00100064, dtype=float32), 'eval/episode_x_position': Array(1.007314, dtype=float32), 'eval/episode_x_velocity': Array(-0.03335478, dtype=float32), 'eval/episode_y_position': Array(0.00050081, dtype=float32), 'eval/episode_y_velocity': Array(-0.00016234, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00613893, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04229874, dtype=float32), 'eval/episode_reward_std': Array(0.04425491, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04229874, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00977335, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126896, dtype=float32), 'eval/episode_x_position_std': Array(0.0061296, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04229874, dtype=float32), 'eval/episode_y_position_std': Array(0.00586861, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00885616, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.654111862182617, 'eval/sps': 6197.3131962341195, 'num_steps': 788480}
{'eval/walltime': 3330.813069343567, 'training/sps': 127.16114064749218, 'training/walltime': 6320.293519496918, 'training/entropy_loss': Array(0.05995292, dtype=float32), 'training/policy_loss': Array(-0.15726268, dtype=float32), 'training/total_loss': Array(-0.09730974, dtype=float32), 'training/v_loss': Array(4.255017e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087099, dtype=float32), 'eval/episode_forward_reward': Array(-0.0405532, dtype=float32), 'eval/episode_reward': Array(-2.0387912, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0405532, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970212, dtype=float32), 'eval/episode_train_reward': Array(-0.0012166, dtype=float32), 'eval/episode_x_position': Array(1.006875, dtype=float32), 'eval/episode_x_velocity': Array(-0.0405532, dtype=float32), 'eval/episode_y_position': Array(0.00021186, dtype=float32), 'eval/episode_y_velocity': Array(-0.00205422, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00565008, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04298643, dtype=float32), 'eval/episode_reward_std': Array(0.04604904, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04298643, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01458738, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128959, dtype=float32), 'eval/episode_x_position_std': Array(0.00559846, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04298643, dtype=float32), 'eval/episode_y_position_std': Array(0.00576763, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01227825, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.701151847839355, 'eval/sps': 6183.230814441843, 'num_steps': 793600}
{'eval/walltime': 3351.5031323432922, 'training/sps': 127.109666474007, 'training/walltime': 6360.573697566986, 'training/entropy_loss': Array(0.06368394, dtype=float32), 'training/policy_loss': Array(-0.12211429, dtype=float32), 'training/total_loss': Array(-0.05843035, dtype=float32), 'training/v_loss': Array(2.8409524e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088012, dtype=float32), 'eval/episode_forward_reward': Array(-0.04392862, dtype=float32), 'eval/episode_reward': Array(-2.044467, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04392862, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9992204, dtype=float32), 'eval/episode_train_reward': Array(-0.00131786, dtype=float32), 'eval/episode_x_position': Array(1.0069757, dtype=float32), 'eval/episode_x_velocity': Array(-0.04392862, dtype=float32), 'eval/episode_y_position': Array(0.0008764, dtype=float32), 'eval/episode_y_velocity': Array(-0.00150583, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574733, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04542106, dtype=float32), 'eval/episode_reward_std': Array(0.04748672, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04542106, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00501413, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136263, dtype=float32), 'eval/episode_x_position_std': Array(0.00574403, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04542106, dtype=float32), 'eval/episode_y_position_std': Array(0.00533066, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01362523, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.690062999725342, 'eval/sps': 6186.544719641462, 'num_steps': 798720}
{'eval/walltime': 3372.1690142154694, 'training/sps': 127.16400577141269, 'training/walltime': 6400.836663246155, 'training/entropy_loss': Array(0.06770215, dtype=float32), 'training/policy_loss': Array(-0.07067955, dtype=float32), 'training/total_loss': Array(-0.00297739, dtype=float32), 'training/v_loss': Array(1.5963156e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092344, dtype=float32), 'eval/episode_forward_reward': Array(-0.04258938, dtype=float32), 'eval/episode_reward': Array(-2.040668, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04258938, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996801, dtype=float32), 'eval/episode_train_reward': Array(-0.00127768, dtype=float32), 'eval/episode_x_position': Array(1.0073858, dtype=float32), 'eval/episode_x_velocity': Array(-0.04258938, dtype=float32), 'eval/episode_y_position': Array(4.6960296e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0017383, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585485, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04373329, dtype=float32), 'eval/episode_reward_std': Array(0.04705406, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04373329, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0147786, dtype=float32), 'eval/episode_train_reward_std': Array(0.001312, dtype=float32), 'eval/episode_x_position_std': Array(0.00584599, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04373329, dtype=float32), 'eval/episode_y_position_std': Array(0.00521652, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01196891, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.665881872177124, 'eval/sps': 6193.783589382115, 'num_steps': 803840}
{'eval/walltime': 3392.810916185379, 'training/sps': 127.41842066207448, 'training/walltime': 6441.019236326218, 'training/entropy_loss': Array(0.07983135, dtype=float32), 'training/policy_loss': Array(0.2550577, dtype=float32), 'training/total_loss': Array(0.33488905, dtype=float32), 'training/v_loss': Array(1.0021429e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092151, dtype=float32), 'eval/episode_forward_reward': Array(-0.03436441, dtype=float32), 'eval/episode_reward': Array(-2.0310588, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03436441, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956632, dtype=float32), 'eval/episode_train_reward': Array(-0.00103093, dtype=float32), 'eval/episode_x_position': Array(1.0073152, dtype=float32), 'eval/episode_x_velocity': Array(-0.03436441, dtype=float32), 'eval/episode_y_position': Array(0.000404, dtype=float32), 'eval/episode_y_velocity': Array(-0.00156981, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00603462, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04148797, dtype=float32), 'eval/episode_reward_std': Array(0.04672253, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04148797, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01772008, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124464, dtype=float32), 'eval/episode_x_position_std': Array(0.00602417, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04148797, dtype=float32), 'eval/episode_y_position_std': Array(0.00591738, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01152711, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.641901969909668, 'eval/sps': 6200.978969214635, 'num_steps': 808960}
{'eval/walltime': 3413.463436603546, 'training/sps': 127.54089063358106, 'training/walltime': 6481.1632244586945, 'training/entropy_loss': Array(0.05825046, dtype=float32), 'training/policy_loss': Array(0.27531207, dtype=float32), 'training/total_loss': Array(0.33356258, dtype=float32), 'training/v_loss': Array(4.3213678e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009428, dtype=float32), 'eval/episode_forward_reward': Array(-0.03615332, dtype=float32), 'eval/episode_reward': Array(-2.0359612, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03615332, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987235, dtype=float32), 'eval/episode_train_reward': Array(-0.0010846, dtype=float32), 'eval/episode_x_position': Array(1.0075388, dtype=float32), 'eval/episode_x_velocity': Array(-0.03615332, dtype=float32), 'eval/episode_y_position': Array(0.00069262, dtype=float32), 'eval/episode_y_velocity': Array(-0.00226089, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00562223, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04554322, dtype=float32), 'eval/episode_reward_std': Array(0.04838807, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04554322, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00826212, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013663, dtype=float32), 'eval/episode_x_position_std': Array(0.00557014, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04554322, dtype=float32), 'eval/episode_y_position_std': Array(0.00525374, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01269793, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.652520418167114, 'eval/sps': 6197.790749423689, 'num_steps': 814080}
{'eval/walltime': 3434.0904955863953, 'training/sps': 127.17114994228754, 'training/walltime': 6521.423928260803, 'training/entropy_loss': Array(0.01789778, dtype=float32), 'training/policy_loss': Array(0.10906267, dtype=float32), 'training/total_loss': Array(0.12697653, dtype=float32), 'training/v_loss': Array(1.6081898e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099165, dtype=float32), 'eval/episode_forward_reward': Array(-0.0380131, dtype=float32), 'eval/episode_reward': Array(-2.0382292, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0380131, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.999076, dtype=float32), 'eval/episode_train_reward': Array(-0.00114039, dtype=float32), 'eval/episode_x_position': Array(1.0080119, dtype=float32), 'eval/episode_x_velocity': Array(-0.0380131, dtype=float32), 'eval/episode_y_position': Array(-0.00016767, dtype=float32), 'eval/episode_y_velocity': Array(-0.00027049, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00553006, dtype=float32), 'eval/episode_forward_reward_std': Array(0.044926, dtype=float32), 'eval/episode_reward_std': Array(0.04551615, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.044926, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00715968, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134778, dtype=float32), 'eval/episode_x_position_std': Array(0.00550952, dtype=float32), 'eval/episode_x_velocity_std': Array(0.044926, dtype=float32), 'eval/episode_y_position_std': Array(0.00603656, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01142144, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62705898284912, 'eval/sps': 6205.441120153328, 'num_steps': 819200}
{'eval/walltime': 3454.7484221458435, 'training/sps': 127.29921610116693, 'training/walltime': 6561.6441287994385, 'training/entropy_loss': Array(0.00252126, dtype=float32), 'training/policy_loss': Array(-0.15453503, dtype=float32), 'training/total_loss': Array(-0.15200788, dtype=float32), 'training/v_loss': Array(5.9039376e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171002, dtype=float32), 'eval/episode_forward_reward': Array(-0.03744103, dtype=float32), 'eval/episode_reward': Array(-2.0520833, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03744103, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0213315, dtype=float32), 'eval/episode_train_reward': Array(-0.00112323, dtype=float32), 'eval/episode_x_position': Array(1.0151663, dtype=float32), 'eval/episode_x_velocity': Array(-0.03744103, dtype=float32), 'eval/episode_y_position': Array(-0.00063833, dtype=float32), 'eval/episode_y_velocity': Array(-0.0015084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08924691, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04426836, dtype=float32), 'eval/episode_reward_std': Array(0.18006052, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04426836, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26452968, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132805, dtype=float32), 'eval/episode_x_position_std': Array(0.08898113, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04426836, dtype=float32), 'eval/episode_y_position_std': Array(0.00549506, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01255816, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.657926559448242, 'eval/sps': 6196.16879901517, 'num_steps': 824320}
{'eval/walltime': 3475.434746980667, 'training/sps': 126.92071574561547, 'training/walltime': 6601.984273195267, 'training/entropy_loss': Array(0.00275867, dtype=float32), 'training/policy_loss': Array(-0.19821247, dtype=float32), 'training/total_loss': Array(-0.19544922, dtype=float32), 'training/v_loss': Array(4.5785655e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097265, dtype=float32), 'eval/episode_forward_reward': Array(-0.03343665, dtype=float32), 'eval/episode_reward': Array(-2.0320778, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03343665, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997638, dtype=float32), 'eval/episode_train_reward': Array(-0.0010031, dtype=float32), 'eval/episode_x_position': Array(1.0078437, dtype=float32), 'eval/episode_x_velocity': Array(-0.03343665, dtype=float32), 'eval/episode_y_position': Array(0.00044733, dtype=float32), 'eval/episode_y_velocity': Array(-0.00021029, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566096, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04201355, dtype=float32), 'eval/episode_reward_std': Array(0.04481846, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04201355, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01225247, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126041, dtype=float32), 'eval/episode_x_position_std': Array(0.00565262, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04201355, dtype=float32), 'eval/episode_y_position_std': Array(0.00561399, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0106122, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68632483482361, 'eval/sps': 6187.662671936934, 'num_steps': 829440}
{'eval/walltime': 3496.0820455551147, 'training/sps': 127.23071115743154, 'training/walltime': 6642.22612953186, 'training/entropy_loss': Array(0.00467284, dtype=float32), 'training/policy_loss': Array(-0.19745168, dtype=float32), 'training/total_loss': Array(-0.19277517, dtype=float32), 'training/v_loss': Array(3.6523415e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096036, dtype=float32), 'eval/episode_forward_reward': Array(-0.03853526, dtype=float32), 'eval/episode_reward': Array(-2.036552, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03853526, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968607, dtype=float32), 'eval/episode_train_reward': Array(-0.00115606, dtype=float32), 'eval/episode_x_position': Array(1.0077083, dtype=float32), 'eval/episode_x_velocity': Array(-0.03853526, dtype=float32), 'eval/episode_y_position': Array(-0.00031912, dtype=float32), 'eval/episode_y_velocity': Array(0.00127215, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00607797, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04315393, dtype=float32), 'eval/episode_reward_std': Array(0.04656349, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04315393, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01481871, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129462, dtype=float32), 'eval/episode_x_position_std': Array(0.00604158, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04315393, dtype=float32), 'eval/episode_y_position_std': Array(0.00595552, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01255409, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647298574447632, 'eval/sps': 6199.358213301971, 'num_steps': 834560}
{'eval/walltime': 3516.7545647621155, 'training/sps': 127.10180627394682, 'training/walltime': 6682.508798599243, 'training/entropy_loss': Array(0.00662282, dtype=float32), 'training/policy_loss': Array(-0.20024095, dtype=float32), 'training/total_loss': Array(-0.19361532, dtype=float32), 'training/v_loss': Array(2.8258632e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095143, dtype=float32), 'eval/episode_forward_reward': Array(-0.03903996, dtype=float32), 'eval/episode_reward': Array(-2.0381718, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03903996, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979606, dtype=float32), 'eval/episode_train_reward': Array(-0.0011712, dtype=float32), 'eval/episode_x_position': Array(1.0075953, dtype=float32), 'eval/episode_x_velocity': Array(-0.03903996, dtype=float32), 'eval/episode_y_position': Array(-0.00048966, dtype=float32), 'eval/episode_y_velocity': Array(-0.00321609, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560783, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04236499, dtype=float32), 'eval/episode_reward_std': Array(0.0453833, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04236499, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00871042, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127095, dtype=float32), 'eval/episode_x_position_std': Array(0.00561925, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04236499, dtype=float32), 'eval/episode_y_position_std': Array(0.00570931, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01164065, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672519207000732, 'eval/sps': 6191.794948564029, 'num_steps': 839680}
{'eval/walltime': 3537.3864879608154, 'training/sps': 127.17728340941139, 'training/walltime': 6722.767560720444, 'training/entropy_loss': Array(0.00890052, dtype=float32), 'training/policy_loss': Array(-0.19958773, dtype=float32), 'training/total_loss': Array(-0.19068494, dtype=float32), 'training/v_loss': Array(2.2651484e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091565, dtype=float32), 'eval/episode_forward_reward': Array(-0.04361446, dtype=float32), 'eval/episode_reward': Array(-2.0395808, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04361446, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994658, dtype=float32), 'eval/episode_train_reward': Array(-0.00130843, dtype=float32), 'eval/episode_x_position': Array(1.0073047, dtype=float32), 'eval/episode_x_velocity': Array(-0.04361446, dtype=float32), 'eval/episode_y_position': Array(-8.3131585e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00127206, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00591566, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04360447, dtype=float32), 'eval/episode_reward_std': Array(0.05142392, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04360447, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02115768, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130813, dtype=float32), 'eval/episode_x_position_std': Array(0.0058697, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04360447, dtype=float32), 'eval/episode_y_position_std': Array(0.00568035, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01394394, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63192319869995, 'eval/sps': 6203.9781152377245, 'num_steps': 844800}
{'eval/walltime': 3558.098626613617, 'training/sps': 127.3892713344634, 'training/walltime': 6762.95932841301, 'training/entropy_loss': Array(0.01152475, dtype=float32), 'training/policy_loss': Array(-0.2019513, dtype=float32), 'training/total_loss': Array(-0.19042474, dtype=float32), 'training/v_loss': Array(1.7773873e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091538, dtype=float32), 'eval/episode_forward_reward': Array(-0.03515697, dtype=float32), 'eval/episode_reward': Array(-2.0331876, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03515697, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996976, dtype=float32), 'eval/episode_train_reward': Array(-0.00105471, dtype=float32), 'eval/episode_x_position': Array(1.0072932, dtype=float32), 'eval/episode_x_velocity': Array(-0.03515697, dtype=float32), 'eval/episode_y_position': Array(-0.00011061, dtype=float32), 'eval/episode_y_velocity': Array(-0.00053761, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00544396, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04245186, dtype=float32), 'eval/episode_reward_std': Array(0.04436099, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04245186, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01705336, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127356, dtype=float32), 'eval/episode_x_position_std': Array(0.00539371, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04245186, dtype=float32), 'eval/episode_y_position_std': Array(0.00577541, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01080101, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.712138652801514, 'eval/sps': 6179.95090442709, 'num_steps': 849920}
{'eval/walltime': 3578.7670073509216, 'training/sps': 127.22753398505846, 'training/walltime': 6803.202189683914, 'training/entropy_loss': Array(0.01335412, dtype=float32), 'training/policy_loss': Array(-0.20529974, dtype=float32), 'training/total_loss': Array(-0.19194439, dtype=float32), 'training/v_loss': Array(1.2206195e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099933, dtype=float32), 'eval/episode_forward_reward': Array(-0.04210409, dtype=float32), 'eval/episode_reward': Array(-2.040378, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04210409, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970107, dtype=float32), 'eval/episode_train_reward': Array(-0.00126312, dtype=float32), 'eval/episode_x_position': Array(1.0081482, dtype=float32), 'eval/episode_x_velocity': Array(-0.04210409, dtype=float32), 'eval/episode_y_position': Array(0.00031206, dtype=float32), 'eval/episode_y_velocity': Array(-0.00240507, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590676, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04455788, dtype=float32), 'eval/episode_reward_std': Array(0.04624983, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04455788, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0155425, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133674, dtype=float32), 'eval/episode_x_position_std': Array(0.00583435, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04455788, dtype=float32), 'eval/episode_y_position_std': Array(0.00569183, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01455525, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.668380737304688, 'eval/sps': 6193.034743596085, 'num_steps': 855040}
{'eval/walltime': 3599.42165184021, 'training/sps': 126.97398815609549, 'training/walltime': 6843.525409221649, 'training/entropy_loss': Array(0.01569717, dtype=float32), 'training/policy_loss': Array(-0.20078036, dtype=float32), 'training/total_loss': Array(-0.18508224, dtype=float32), 'training/v_loss': Array(9.446599e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094657, dtype=float32), 'eval/episode_forward_reward': Array(-0.03793556, dtype=float32), 'eval/episode_reward': Array(-2.0381608, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03793556, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9990873, dtype=float32), 'eval/episode_train_reward': Array(-0.00113807, dtype=float32), 'eval/episode_x_position': Array(1.0075928, dtype=float32), 'eval/episode_x_velocity': Array(-0.03793556, dtype=float32), 'eval/episode_y_position': Array(8.042148e-05, dtype=float32), 'eval/episode_y_velocity': Array(6.7989225e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586523, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04178922, dtype=float32), 'eval/episode_reward_std': Array(0.04310792, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04178922, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00565636, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125368, dtype=float32), 'eval/episode_x_position_std': Array(0.00584707, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04178922, dtype=float32), 'eval/episode_y_position_std': Array(0.00580132, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0107192, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65464448928833, 'eval/sps': 6197.153384381991, 'num_steps': 860160}
{'eval/walltime': 3620.0786480903625, 'training/sps': 127.02400604599833, 'training/walltime': 6883.832750797272, 'training/entropy_loss': Array(0.01802719, dtype=float32), 'training/policy_loss': Array(-0.20093104, dtype=float32), 'training/total_loss': Array(-0.18290317, dtype=float32), 'training/v_loss': Array(6.952355e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0104034, dtype=float32), 'eval/episode_forward_reward': Array(-0.03191666, dtype=float32), 'eval/episode_reward': Array(-2.0313878, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03191666, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985137, dtype=float32), 'eval/episode_train_reward': Array(-0.0009575, dtype=float32), 'eval/episode_x_position': Array(1.0084836, dtype=float32), 'eval/episode_x_velocity': Array(-0.03191666, dtype=float32), 'eval/episode_y_position': Array(-0.0003188, dtype=float32), 'eval/episode_y_velocity': Array(-0.00108703, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00604421, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04069597, dtype=float32), 'eval/episode_reward_std': Array(0.04242421, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04069597, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00783912, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122088, dtype=float32), 'eval/episode_x_position_std': Array(0.00604943, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04069597, dtype=float32), 'eval/episode_y_position_std': Array(0.00562294, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01368462, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.656996250152588, 'eval/sps': 6196.447849916925, 'num_steps': 865280}
{'eval/walltime': 3640.740854024887, 'training/sps': 127.30586228367257, 'training/walltime': 6924.050851583481, 'training/entropy_loss': Array(0.0201177, dtype=float32), 'training/policy_loss': Array(-0.20126311, dtype=float32), 'training/total_loss': Array(-0.18114492, dtype=float32), 'training/v_loss': Array(5.038705e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089797, dtype=float32), 'eval/episode_forward_reward': Array(-0.04624575, dtype=float32), 'eval/episode_reward': Array(-2.0454726, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04624575, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978392, dtype=float32), 'eval/episode_train_reward': Array(-0.00138737, dtype=float32), 'eval/episode_x_position': Array(1.0071733, dtype=float32), 'eval/episode_x_velocity': Array(-0.04624575, dtype=float32), 'eval/episode_y_position': Array(0.00026336, dtype=float32), 'eval/episode_y_velocity': Array(-0.00147838, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578119, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04351919, dtype=float32), 'eval/episode_reward_std': Array(0.0452344, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04351919, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01041319, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130558, dtype=float32), 'eval/episode_x_position_std': Array(0.00578463, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04351919, dtype=float32), 'eval/episode_y_position_std': Array(0.00617778, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01477437, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.662205934524536, 'eval/sps': 6194.885502816737, 'num_steps': 870400}
{'eval/walltime': 3661.405552148819, 'training/sps': 127.02501962396227, 'training/walltime': 6964.35787153244, 'training/entropy_loss': Array(0.02232036, dtype=float32), 'training/policy_loss': Array(-0.2021578, dtype=float32), 'training/total_loss': Array(-0.17983702, dtype=float32), 'training/v_loss': Array(3.9871856e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009562, dtype=float32), 'eval/episode_forward_reward': Array(-0.04288531, dtype=float32), 'eval/episode_reward': Array(-2.0379128, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04288531, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.993741, dtype=float32), 'eval/episode_train_reward': Array(-0.00128656, dtype=float32), 'eval/episode_x_position': Array(1.0077226, dtype=float32), 'eval/episode_x_velocity': Array(-0.04288531, dtype=float32), 'eval/episode_y_position': Array(-0.0003478, dtype=float32), 'eval/episode_y_velocity': Array(-0.00122373, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572032, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04307997, dtype=float32), 'eval/episode_reward_std': Array(0.05023484, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04307997, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02233408, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012924, dtype=float32), 'eval/episode_x_position_std': Array(0.00570379, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04307997, dtype=float32), 'eval/episode_y_position_std': Array(0.00556467, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01539017, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.664698123931885, 'eval/sps': 6194.138391586886, 'num_steps': 875520}
{'eval/walltime': 3682.09015083313, 'training/sps': 127.06751203053004, 'training/walltime': 7004.65141248703, 'training/entropy_loss': Array(0.02446388, dtype=float32), 'training/policy_loss': Array(-0.19838437, dtype=float32), 'training/total_loss': Array(-0.17392018, dtype=float32), 'training/v_loss': Array(2.979186e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009285, dtype=float32), 'eval/episode_forward_reward': Array(-0.03781721, dtype=float32), 'eval/episode_reward': Array(-2.0374374, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03781721, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998486, dtype=float32), 'eval/episode_train_reward': Array(-0.00113452, dtype=float32), 'eval/episode_x_position': Array(1.0074034, dtype=float32), 'eval/episode_x_velocity': Array(-0.03781721, dtype=float32), 'eval/episode_y_position': Array(-0.00041819, dtype=float32), 'eval/episode_y_velocity': Array(-0.00082121, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.005641, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04566948, dtype=float32), 'eval/episode_reward_std': Array(0.04847038, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04566948, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00909085, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137008, dtype=float32), 'eval/episode_x_position_std': Array(0.00563189, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04566948, dtype=float32), 'eval/episode_y_position_std': Array(0.00572423, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01312994, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.684598684310913, 'eval/sps': 6188.179038594879, 'num_steps': 880640}
{'eval/walltime': 3702.74928855896, 'training/sps': 127.17777070801515, 'training/walltime': 7044.91002035141, 'training/entropy_loss': Array(0.02647223, dtype=float32), 'training/policy_loss': Array(-0.20251149, dtype=float32), 'training/total_loss': Array(-0.17603904, dtype=float32), 'training/v_loss': Array(2.1585191e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086296, dtype=float32), 'eval/episode_forward_reward': Array(-0.03656637, dtype=float32), 'eval/episode_reward': Array(-2.0347939, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03656637, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971306, dtype=float32), 'eval/episode_train_reward': Array(-0.00109699, dtype=float32), 'eval/episode_x_position': Array(1.006712, dtype=float32), 'eval/episode_x_velocity': Array(-0.03656637, dtype=float32), 'eval/episode_y_position': Array(-0.0002118, dtype=float32), 'eval/episode_y_velocity': Array(-0.0003089, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563162, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04374681, dtype=float32), 'eval/episode_reward_std': Array(0.04782486, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04374681, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01421078, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013124, dtype=float32), 'eval/episode_x_position_std': Array(0.00559468, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04374681, dtype=float32), 'eval/episode_y_position_std': Array(0.00573299, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01340913, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.659137725830078, 'eval/sps': 6195.80554129139, 'num_steps': 885760}
{'eval/walltime': 3723.424262046814, 'training/sps': 127.16951199093567, 'training/walltime': 7085.171242713928, 'training/entropy_loss': Array(0.02906684, dtype=float32), 'training/policy_loss': Array(-0.20395541, dtype=float32), 'training/total_loss': Array(-0.1748884, dtype=float32), 'training/v_loss': Array(1.6506544e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085568, dtype=float32), 'eval/episode_forward_reward': Array(-0.04225946, dtype=float32), 'eval/episode_reward': Array(-2.0419476, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04225946, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984202, dtype=float32), 'eval/episode_train_reward': Array(-0.00126778, dtype=float32), 'eval/episode_x_position': Array(1.0067174, dtype=float32), 'eval/episode_x_velocity': Array(-0.04225946, dtype=float32), 'eval/episode_y_position': Array(-1.4872057e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00149379, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566163, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04375311, dtype=float32), 'eval/episode_reward_std': Array(0.04546814, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04375311, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00848333, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131259, dtype=float32), 'eval/episode_x_position_std': Array(0.00565332, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04375311, dtype=float32), 'eval/episode_y_position_std': Array(0.0055681, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01293996, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.674973487854004, 'eval/sps': 6191.059934137114, 'num_steps': 890880}
{'eval/walltime': 3744.0547473430634, 'training/sps': 127.39726613648158, 'training/walltime': 7125.360488176346, 'training/entropy_loss': Array(0.03112077, dtype=float32), 'training/policy_loss': Array(-0.20063329, dtype=float32), 'training/total_loss': Array(-0.1695124, dtype=float32), 'training/v_loss': Array(1.2144996e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094295, dtype=float32), 'eval/episode_forward_reward': Array(-0.03652112, dtype=float32), 'eval/episode_reward': Array(-2.0341513, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03652112, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965343, dtype=float32), 'eval/episode_train_reward': Array(-0.00109563, dtype=float32), 'eval/episode_x_position': Array(1.0075346, dtype=float32), 'eval/episode_x_velocity': Array(-0.03652112, dtype=float32), 'eval/episode_y_position': Array(-1.1590149e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00106015, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00613528, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0446683, dtype=float32), 'eval/episode_reward_std': Array(0.05118293, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0446683, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01696793, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134005, dtype=float32), 'eval/episode_x_position_std': Array(0.00610774, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0446683, dtype=float32), 'eval/episode_y_position_std': Array(0.00581657, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01139345, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63048529624939, 'eval/sps': 6204.410519769514, 'num_steps': 896000}
{'eval/walltime': 3764.7317900657654, 'training/sps': 127.20004054795008, 'training/walltime': 7165.612047672272, 'training/entropy_loss': Array(0.03384938, dtype=float32), 'training/policy_loss': Array(-0.19626644, dtype=float32), 'training/total_loss': Array(-0.16241696, dtype=float32), 'training/v_loss': Array(8.782504e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083641, dtype=float32), 'eval/episode_forward_reward': Array(-0.04791507, dtype=float32), 'eval/episode_reward': Array(-2.0471773, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04791507, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978247, dtype=float32), 'eval/episode_train_reward': Array(-0.00143745, dtype=float32), 'eval/episode_x_position': Array(1.0065346, dtype=float32), 'eval/episode_x_velocity': Array(-0.04791507, dtype=float32), 'eval/episode_y_position': Array(-0.00076737, dtype=float32), 'eval/episode_y_velocity': Array(0.00043331, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00625122, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04314627, dtype=float32), 'eval/episode_reward_std': Array(0.04556641, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04314627, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01088393, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129439, dtype=float32), 'eval/episode_x_position_std': Array(0.0062393, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04314627, dtype=float32), 'eval/episode_y_position_std': Array(0.00520989, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01437338, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677042722702026, 'eval/sps': 6190.440369863165, 'num_steps': 901120}
{'eval/walltime': 3785.3878269195557, 'training/sps': 127.29577895304669, 'training/walltime': 7205.833334207535, 'training/entropy_loss': Array(0.03663886, dtype=float32), 'training/policy_loss': Array(-0.19474852, dtype=float32), 'training/total_loss': Array(-0.1581096, dtype=float32), 'training/v_loss': Array(6.331106e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169156, dtype=float32), 'eval/episode_forward_reward': Array(-0.03338978, dtype=float32), 'eval/episode_reward': Array(-2.0486221, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03338978, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.022043, dtype=float32), 'eval/episode_train_reward': Array(-0.00100169, dtype=float32), 'eval/episode_x_position': Array(1.014996, dtype=float32), 'eval/episode_x_velocity': Array(-0.03338978, dtype=float32), 'eval/episode_y_position': Array(0.0010027, dtype=float32), 'eval/episode_y_velocity': Array(-0.00170101, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08989921, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04074526, dtype=float32), 'eval/episode_reward_std': Array(0.17873156, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04074526, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26438212, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122236, dtype=float32), 'eval/episode_x_position_std': Array(0.08963265, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04074526, dtype=float32), 'eval/episode_y_position_std': Array(0.00579757, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01098848, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.656036853790283, 'eval/sps': 6196.735651956034, 'num_steps': 906240}
{'eval/walltime': 3806.058597803116, 'training/sps': 127.09802246991778, 'training/walltime': 7246.1172025203705, 'training/entropy_loss': Array(0.03951427, dtype=float32), 'training/policy_loss': Array(-0.19447671, dtype=float32), 'training/total_loss': Array(-0.15496239, dtype=float32), 'training/v_loss': Array(4.2801247e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095378, dtype=float32), 'eval/episode_forward_reward': Array(-0.0430413, dtype=float32), 'eval/episode_reward': Array(-2.0405936, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0430413, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962611, dtype=float32), 'eval/episode_train_reward': Array(-0.00129124, dtype=float32), 'eval/episode_x_position': Array(1.0077038, dtype=float32), 'eval/episode_x_velocity': Array(-0.0430413, dtype=float32), 'eval/episode_y_position': Array(0.00019553, dtype=float32), 'eval/episode_y_velocity': Array(-0.00024348, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00539461, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04480434, dtype=float32), 'eval/episode_reward_std': Array(0.04755934, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04480434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01676114, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134413, dtype=float32), 'eval/episode_x_position_std': Array(0.00538473, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04480434, dtype=float32), 'eval/episode_y_position_std': Array(0.00590324, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00970034, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67077088356018, 'eval/sps': 6192.318647477275, 'num_steps': 911360}
{'eval/walltime': 3826.705240726471, 'training/sps': 127.04284140260884, 'training/walltime': 7286.418568134308, 'training/entropy_loss': Array(0.04205507, dtype=float32), 'training/policy_loss': Array(-0.1920659, dtype=float32), 'training/total_loss': Array(-0.1500108, dtype=float32), 'training/v_loss': Array(3.1498768e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090985, dtype=float32), 'eval/episode_forward_reward': Array(-0.03283107, dtype=float32), 'eval/episode_reward': Array(-2.0323849, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03283107, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998569, dtype=float32), 'eval/episode_train_reward': Array(-0.00098493, dtype=float32), 'eval/episode_x_position': Array(1.0071882, dtype=float32), 'eval/episode_x_velocity': Array(-0.03283107, dtype=float32), 'eval/episode_y_position': Array(-9.408442e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00053696, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00565153, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0409334, dtype=float32), 'eval/episode_reward_std': Array(0.04155533, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0409334, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01013118, dtype=float32), 'eval/episode_train_reward_std': Array(0.001228, dtype=float32), 'eval/episode_x_position_std': Array(0.0056683, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0409334, dtype=float32), 'eval/episode_y_position_std': Array(0.0060739, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01116838, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.646642923355103, 'eval/sps': 6199.555079010387, 'num_steps': 916480}
{'eval/walltime': 3847.380959749222, 'training/sps': 127.28660709046983, 'training/walltime': 7326.6427528858185, 'training/entropy_loss': Array(0.04481076, dtype=float32), 'training/policy_loss': Array(-0.18673733, dtype=float32), 'training/total_loss': Array(-0.14192654, dtype=float32), 'training/v_loss': Array(2.1230932e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096127, dtype=float32), 'eval/episode_forward_reward': Array(-0.03540633, dtype=float32), 'eval/episode_reward': Array(-2.0348651, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03540633, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983969, dtype=float32), 'eval/episode_train_reward': Array(-0.00106219, dtype=float32), 'eval/episode_x_position': Array(1.007708, dtype=float32), 'eval/episode_x_velocity': Array(-0.03540633, dtype=float32), 'eval/episode_y_position': Array(-0.00011399, dtype=float32), 'eval/episode_y_velocity': Array(-0.00227559, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563122, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04236614, dtype=float32), 'eval/episode_reward_std': Array(0.04616331, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04236614, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01117494, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127098, dtype=float32), 'eval/episode_x_position_std': Array(0.00561361, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04236614, dtype=float32), 'eval/episode_y_position_std': Array(0.00601113, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00950145, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.675719022750854, 'eval/sps': 6190.836693957447, 'num_steps': 921600}
{'eval/walltime': 3868.0428462028503, 'training/sps': 127.12564114285206, 'training/walltime': 7366.9178693294525, 'training/entropy_loss': Array(0.04731961, dtype=float32), 'training/policy_loss': Array(-0.18155846, dtype=float32), 'training/total_loss': Array(-0.13423884, dtype=float32), 'training/v_loss': Array(1.4698935e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090165, dtype=float32), 'eval/episode_forward_reward': Array(-0.04225481, dtype=float32), 'eval/episode_reward': Array(-2.0421624, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04225481, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99864, dtype=float32), 'eval/episode_train_reward': Array(-0.00126764, dtype=float32), 'eval/episode_x_position': Array(1.007185, dtype=float32), 'eval/episode_x_velocity': Array(-0.04225481, dtype=float32), 'eval/episode_y_position': Array(0.0004071, dtype=float32), 'eval/episode_y_velocity': Array(-0.00128123, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593707, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04515511, dtype=float32), 'eval/episode_reward_std': Array(0.04703706, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04515511, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00613323, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135465, dtype=float32), 'eval/episode_x_position_std': Array(0.00591095, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04515511, dtype=float32), 'eval/episode_y_position_std': Array(0.0057611, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01164149, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66188645362854, 'eval/sps': 6194.981290177464, 'num_steps': 926720}
{'eval/walltime': 3888.7194080352783, 'training/sps': 127.08778100062088, 'training/walltime': 7407.204983949661, 'training/entropy_loss': Array(0.05033065, dtype=float32), 'training/policy_loss': Array(-0.17460734, dtype=float32), 'training/total_loss': Array(-0.12427668, dtype=float32), 'training/v_loss': Array(9.994601e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096397, dtype=float32), 'eval/episode_forward_reward': Array(-0.03192597, dtype=float32), 'eval/episode_reward': Array(-2.0308166, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03192597, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997933, dtype=float32), 'eval/episode_train_reward': Array(-0.00095778, dtype=float32), 'eval/episode_x_position': Array(1.0077301, dtype=float32), 'eval/episode_x_velocity': Array(-0.03192597, dtype=float32), 'eval/episode_y_position': Array(-0.0002428, dtype=float32), 'eval/episode_y_velocity': Array(-0.00150838, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576937, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04037098, dtype=float32), 'eval/episode_reward_std': Array(0.04303185, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04037098, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01067231, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121113, dtype=float32), 'eval/episode_x_position_std': Array(0.00577837, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04037098, dtype=float32), 'eval/episode_y_position_std': Array(0.00571268, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01248614, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67656183242798, 'eval/sps': 6190.584345568123, 'num_steps': 931840}
{'eval/walltime': 3909.3876099586487, 'training/sps': 127.29876786539924, 'training/walltime': 7447.4253261089325, 'training/entropy_loss': Array(0.05349228, dtype=float32), 'training/policy_loss': Array(-0.17080408, dtype=float32), 'training/total_loss': Array(-0.11731179, dtype=float32), 'training/v_loss': Array(7.3820656e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176206, dtype=float32), 'eval/episode_forward_reward': Array(-0.04307352, dtype=float32), 'eval/episode_reward': Array(-2.0564523, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04307352, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0198991, dtype=float32), 'eval/episode_train_reward': Array(-0.00129221, dtype=float32), 'eval/episode_x_position': Array(1.0157826, dtype=float32), 'eval/episode_x_velocity': Array(-0.04307352, dtype=float32), 'eval/episode_y_position': Array(0.0006838, dtype=float32), 'eval/episode_y_velocity': Array(-0.00178969, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09017503, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04245741, dtype=float32), 'eval/episode_reward_std': Array(0.17894642, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04245741, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26489857, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127372, dtype=float32), 'eval/episode_x_position_std': Array(0.08989868, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04245741, dtype=float32), 'eval/episode_y_position_std': Array(0.00610955, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01178846, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.66820192337036, 'eval/sps': 6193.088323530713, 'num_steps': 936960}
{'eval/walltime': 3930.040987968445, 'training/sps': 127.24254836929003, 'training/walltime': 7487.663438796997, 'training/entropy_loss': Array(0.05690399, dtype=float32), 'training/policy_loss': Array(-0.16046384, dtype=float32), 'training/total_loss': Array(-0.10355984, dtype=float32), 'training/v_loss': Array(4.9364552e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095024, dtype=float32), 'eval/episode_forward_reward': Array(-0.03577637, dtype=float32), 'eval/episode_reward': Array(-2.033442, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03577637, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996592, dtype=float32), 'eval/episode_train_reward': Array(-0.00107329, dtype=float32), 'eval/episode_x_position': Array(1.0076287, dtype=float32), 'eval/episode_x_velocity': Array(-0.03577637, dtype=float32), 'eval/episode_y_position': Array(-0.00075077, dtype=float32), 'eval/episode_y_velocity': Array(-0.00104037, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583634, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04304038, dtype=float32), 'eval/episode_reward_std': Array(0.04591563, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04304038, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01224935, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129121, dtype=float32), 'eval/episode_x_position_std': Array(0.00585744, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04304038, dtype=float32), 'eval/episode_y_position_std': Array(0.00585774, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01141649, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.653378009796143, 'eval/sps': 6197.533398134101, 'num_steps': 942080}
{'eval/walltime': 3950.7163348197937, 'training/sps': 127.60698967899084, 'training/walltime': 7527.78663277626, 'training/entropy_loss': Array(0.06074271, dtype=float32), 'training/policy_loss': Array(-0.13779972, dtype=float32), 'training/total_loss': Array(-0.07705702, dtype=float32), 'training/v_loss': Array(3.0833953e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088577, dtype=float32), 'eval/episode_forward_reward': Array(-0.04080451, dtype=float32), 'eval/episode_reward': Array(-2.037419, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04080451, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9953904, dtype=float32), 'eval/episode_train_reward': Array(-0.00122414, dtype=float32), 'eval/episode_x_position': Array(1.007, dtype=float32), 'eval/episode_x_velocity': Array(-0.04080451, dtype=float32), 'eval/episode_y_position': Array(-0.0008227, dtype=float32), 'eval/episode_y_velocity': Array(-0.00144105, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00607564, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04452028, dtype=float32), 'eval/episode_reward_std': Array(0.05116358, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04452028, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01714977, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133561, dtype=float32), 'eval/episode_x_position_std': Array(0.00610833, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04452028, dtype=float32), 'eval/episode_y_position_std': Array(0.00599175, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01115356, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.675346851348877, 'eval/sps': 6190.948133556907, 'num_steps': 947200}
{'eval/walltime': 3971.3837933540344, 'training/sps': 127.21556768334113, 'training/walltime': 7568.033279418945, 'training/entropy_loss': Array(0.06543171, dtype=float32), 'training/policy_loss': Array(-0.09885654, dtype=float32), 'training/total_loss': Array(-0.03342482, dtype=float32), 'training/v_loss': Array(2.020113e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091205, dtype=float32), 'eval/episode_forward_reward': Array(-0.04325015, dtype=float32), 'eval/episode_reward': Array(-2.0400798, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04325015, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955323, dtype=float32), 'eval/episode_train_reward': Array(-0.0012975, dtype=float32), 'eval/episode_x_position': Array(1.0072684, dtype=float32), 'eval/episode_x_velocity': Array(-0.04325015, dtype=float32), 'eval/episode_y_position': Array(-0.00029978, dtype=float32), 'eval/episode_y_velocity': Array(-0.00161302, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576585, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0431168, dtype=float32), 'eval/episode_reward_std': Array(0.04763342, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0431168, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01786471, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012935, dtype=float32), 'eval/episode_x_position_std': Array(0.00576902, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0431168, dtype=float32), 'eval/episode_y_position_std': Array(0.00548938, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01194825, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.667458534240723, 'eval/sps': 6193.311083118253, 'num_steps': 952320}
{'eval/walltime': 3992.0532829761505, 'training/sps': 127.26164995941078, 'training/walltime': 7608.265352487564, 'training/entropy_loss': Array(0.07738639, dtype=float32), 'training/policy_loss': Array(0.25861216, dtype=float32), 'training/total_loss': Array(0.33599854, dtype=float32), 'training/v_loss': Array(1.0812184e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094259, dtype=float32), 'eval/episode_forward_reward': Array(-0.0432247, dtype=float32), 'eval/episode_reward': Array(-2.0414324, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0432247, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996911, dtype=float32), 'eval/episode_train_reward': Array(-0.00129674, dtype=float32), 'eval/episode_x_position': Array(1.007577, dtype=float32), 'eval/episode_x_velocity': Array(-0.0432247, dtype=float32), 'eval/episode_y_position': Array(-0.00012175, dtype=float32), 'eval/episode_y_velocity': Array(-0.00084164, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0055325, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0430819, dtype=float32), 'eval/episode_reward_std': Array(0.04529306, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0430819, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01415922, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129246, dtype=float32), 'eval/episode_x_position_std': Array(0.00551288, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0430819, dtype=float32), 'eval/episode_y_position_std': Array(0.00565647, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01451954, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66948962211609, 'eval/sps': 6192.70249726155, 'num_steps': 957440}
{'eval/walltime': 4012.7264585494995, 'training/sps': 127.05347853862858, 'training/walltime': 7648.56334400177, 'training/entropy_loss': Array(0.08200358, dtype=float32), 'training/policy_loss': Array(0.27406424, dtype=float32), 'training/total_loss': Array(0.35606787, dtype=float32), 'training/v_loss': Array(5.4043085e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090429, dtype=float32), 'eval/episode_forward_reward': Array(-0.03722504, dtype=float32), 'eval/episode_reward': Array(-2.0355992, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03722504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972575, dtype=float32), 'eval/episode_train_reward': Array(-0.00111675, dtype=float32), 'eval/episode_x_position': Array(1.0071352, dtype=float32), 'eval/episode_x_velocity': Array(-0.03722504, dtype=float32), 'eval/episode_y_position': Array(-0.0001943, dtype=float32), 'eval/episode_y_velocity': Array(-0.00125687, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574077, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04342298, dtype=float32), 'eval/episode_reward_std': Array(0.04731544, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04342298, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01383319, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130269, dtype=float32), 'eval/episode_x_position_std': Array(0.00576332, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04342298, dtype=float32), 'eval/episode_y_position_std': Array(0.00606575, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01181551, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.673175573349, 'eval/sps': 6191.59836116384, 'num_steps': 962560}
{'eval/walltime': 4033.35555768013, 'training/sps': 127.03906862373829, 'training/walltime': 7688.8659064769745, 'training/entropy_loss': Array(0.07182983, dtype=float32), 'training/policy_loss': Array(0.2740392, dtype=float32), 'training/total_loss': Array(0.34586906, dtype=float32), 'training/v_loss': Array(8.10588e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086408, dtype=float32), 'eval/episode_forward_reward': Array(-0.03623737, dtype=float32), 'eval/episode_reward': Array(-2.0338354, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03623737, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996511, dtype=float32), 'eval/episode_train_reward': Array(-0.00108712, dtype=float32), 'eval/episode_x_position': Array(1.0067383, dtype=float32), 'eval/episode_x_velocity': Array(-0.03623737, dtype=float32), 'eval/episode_y_position': Array(-0.00073346, dtype=float32), 'eval/episode_y_velocity': Array(-0.00192983, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586778, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04277963, dtype=float32), 'eval/episode_reward_std': Array(0.04609732, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04277963, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01501961, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128339, dtype=float32), 'eval/episode_x_position_std': Array(0.0058457, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04277963, dtype=float32), 'eval/episode_y_position_std': Array(0.00564363, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01270152, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.629099130630493, 'eval/sps': 6204.827423120144, 'num_steps': 967680}
{'eval/walltime': 4054.008684158325, 'training/sps': 127.15957222566522, 'training/walltime': 7729.130275964737, 'training/entropy_loss': Array(0.06399208, dtype=float32), 'training/policy_loss': Array(0.2684899, dtype=float32), 'training/total_loss': Array(0.332482, dtype=float32), 'training/v_loss': Array(1.3205465e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090058, dtype=float32), 'eval/episode_forward_reward': Array(-0.04339017, dtype=float32), 'eval/episode_reward': Array(-2.0428038, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04339017, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998112, dtype=float32), 'eval/episode_train_reward': Array(-0.0013017, dtype=float32), 'eval/episode_x_position': Array(1.0071795, dtype=float32), 'eval/episode_x_velocity': Array(-0.04339017, dtype=float32), 'eval/episode_y_position': Array(0.00019167, dtype=float32), 'eval/episode_y_velocity': Array(-0.00073812, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570894, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04392132, dtype=float32), 'eval/episode_reward_std': Array(0.0459612, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04392132, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01203118, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131764, dtype=float32), 'eval/episode_x_position_std': Array(0.00565431, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04392132, dtype=float32), 'eval/episode_y_position_std': Array(0.00577997, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01694237, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65312647819519, 'eval/sps': 6197.608877045211, 'num_steps': 972800}
{'eval/walltime': 4074.6539611816406, 'training/sps': 127.4652651391485, 'training/walltime': 7769.298081636429, 'training/entropy_loss': Array(0.06474757, dtype=float32), 'training/policy_loss': Array(-0.12241618, dtype=float32), 'training/total_loss': Array(-0.05766858, dtype=float32), 'training/v_loss': Array(3.601479e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0168599, dtype=float32), 'eval/episode_forward_reward': Array(-0.03210967, dtype=float32), 'eval/episode_reward': Array(-2.0464106, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03210967, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.02115, dtype=float32), 'eval/episode_train_reward': Array(-0.00096329, dtype=float32), 'eval/episode_x_position': Array(1.014905, dtype=float32), 'eval/episode_x_velocity': Array(-0.03210967, dtype=float32), 'eval/episode_y_position': Array(0.00059447, dtype=float32), 'eval/episode_y_velocity': Array(-0.00145392, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08846702, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04183906, dtype=float32), 'eval/episode_reward_std': Array(0.18106212, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04183906, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26463717, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125517, dtype=float32), 'eval/episode_x_position_std': Array(0.08819441, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04183906, dtype=float32), 'eval/episode_y_position_std': Array(0.0061706, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01033199, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.64527702331543, 'eval/sps': 6199.96524413042, 'num_steps': 977920}
{'eval/walltime': 4095.3500146865845, 'training/sps': 127.2481292530863, 'training/walltime': 7809.534429550171, 'training/entropy_loss': Array(0.06793876, dtype=float32), 'training/policy_loss': Array(-0.11613484, dtype=float32), 'training/total_loss': Array(-0.04819608, dtype=float32), 'training/v_loss': Array(2.4740814e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0178657, dtype=float32), 'eval/episode_forward_reward': Array(-0.04179512, dtype=float32), 'eval/episode_reward': Array(-2.057574, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04179512, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0223374, dtype=float32), 'eval/episode_train_reward': Array(-0.00125385, dtype=float32), 'eval/episode_x_position': Array(1.0159645, dtype=float32), 'eval/episode_x_velocity': Array(-0.04179512, dtype=float32), 'eval/episode_y_position': Array(0.00047615, dtype=float32), 'eval/episode_y_velocity': Array(-0.00216685, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08916419, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04509147, dtype=float32), 'eval/episode_reward_std': Array(0.17728946, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04509147, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26431608, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135274, dtype=float32), 'eval/episode_x_position_std': Array(0.08890233, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04509147, dtype=float32), 'eval/episode_y_position_std': Array(0.00577845, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01258464, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.696053504943848, 'eval/sps': 6184.75401454792, 'num_steps': 983040}
{'eval/walltime': 4115.981020689011, 'training/sps': 127.28737211633745, 'training/walltime': 7849.758372545242, 'training/entropy_loss': Array(0.0788836, dtype=float32), 'training/policy_loss': Array(0.23811552, dtype=float32), 'training/total_loss': Array(0.3169991, dtype=float32), 'training/v_loss': Array(1.2848657e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095057, dtype=float32), 'eval/episode_forward_reward': Array(-0.02902723, dtype=float32), 'eval/episode_reward': Array(-2.0270967, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.02902723, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971986, dtype=float32), 'eval/episode_train_reward': Array(-0.00087082, dtype=float32), 'eval/episode_x_position': Array(1.0075643, dtype=float32), 'eval/episode_x_velocity': Array(-0.02902723, dtype=float32), 'eval/episode_y_position': Array(0.00013029, dtype=float32), 'eval/episode_y_velocity': Array(-0.0034114, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600413, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04105956, dtype=float32), 'eval/episode_reward_std': Array(0.04540733, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04105956, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01390331, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123179, dtype=float32), 'eval/episode_x_position_std': Array(0.00598551, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04105956, dtype=float32), 'eval/episode_y_position_std': Array(0.00581307, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01321786, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.631006002426147, 'eval/sps': 6204.253926587368, 'num_steps': 988160}
{'eval/walltime': 4136.665716648102, 'training/sps': 127.04062956503051, 'training/walltime': 7890.060439825058, 'training/entropy_loss': Array(0.07768725, dtype=float32), 'training/policy_loss': Array(0.2716077, dtype=float32), 'training/total_loss': Array(0.34929508, dtype=float32), 'training/v_loss': Array(1.0663531e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009285, dtype=float32), 'eval/episode_forward_reward': Array(-0.03235143, dtype=float32), 'eval/episode_reward': Array(-2.0312397, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03235143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979177, dtype=float32), 'eval/episode_train_reward': Array(-0.00097054, dtype=float32), 'eval/episode_x_position': Array(1.0073569, dtype=float32), 'eval/episode_x_velocity': Array(-0.03235143, dtype=float32), 'eval/episode_y_position': Array(-0.00024043, dtype=float32), 'eval/episode_y_velocity': Array(-0.00053027, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00565261, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04139452, dtype=float32), 'eval/episode_reward_std': Array(0.04440583, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04139452, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01258321, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124184, dtype=float32), 'eval/episode_x_position_std': Array(0.00562457, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04139452, dtype=float32), 'eval/episode_y_position_std': Array(0.00598468, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01237969, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.684695959091187, 'eval/sps': 6188.149937187854, 'num_steps': 993280}
{'eval/walltime': 4157.288057804108, 'training/sps': 127.33881214795072, 'training/walltime': 7930.268133878708, 'training/entropy_loss': Array(0.0701378, dtype=float32), 'training/policy_loss': Array(0.26928303, dtype=float32), 'training/total_loss': Array(0.33942088, dtype=float32), 'training/v_loss': Array(6.8878386e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095433, dtype=float32), 'eval/episode_forward_reward': Array(-0.04058036, dtype=float32), 'eval/episode_reward': Array(-2.0392323, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04058036, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974346, dtype=float32), 'eval/episode_train_reward': Array(-0.00121741, dtype=float32), 'eval/episode_x_position': Array(1.007672, dtype=float32), 'eval/episode_x_velocity': Array(-0.04058036, dtype=float32), 'eval/episode_y_position': Array(0.00050484, dtype=float32), 'eval/episode_y_velocity': Array(-0.00367276, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563104, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04512198, dtype=float32), 'eval/episode_reward_std': Array(0.04791531, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04512198, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01190424, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135366, dtype=float32), 'eval/episode_x_position_std': Array(0.00565895, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04512198, dtype=float32), 'eval/episode_y_position_std': Array(0.00533709, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01322285, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62234115600586, 'eval/sps': 6206.860755124423, 'num_steps': 998400}
{'eval/walltime': 4178.006482601166, 'training/sps': 127.3112011642741, 'training/walltime': 7970.484548091888, 'training/entropy_loss': Array(0.07024959, dtype=float32), 'training/policy_loss': Array(-0.05523333, dtype=float32), 'training/total_loss': Array(0.01501626, dtype=float32), 'training/v_loss': Array(3.368339e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095675, dtype=float32), 'eval/episode_forward_reward': Array(-0.04057897, dtype=float32), 'eval/episode_reward': Array(-2.0376463, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04057897, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99585, dtype=float32), 'eval/episode_train_reward': Array(-0.00121737, dtype=float32), 'eval/episode_x_position': Array(1.0077189, dtype=float32), 'eval/episode_x_velocity': Array(-0.04057897, dtype=float32), 'eval/episode_y_position': Array(0.00039534, dtype=float32), 'eval/episode_y_velocity': Array(-0.0010038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057773, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0435008, dtype=float32), 'eval/episode_reward_std': Array(0.04722005, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0435008, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01578066, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130502, dtype=float32), 'eval/episode_x_position_std': Array(0.00579555, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0435008, dtype=float32), 'eval/episode_y_position_std': Array(0.00545478, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0138989, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.718424797058105, 'eval/sps': 6178.075855369818, 'num_steps': 1003520}
{'eval/walltime': 4198.64905166626, 'training/sps': 127.03662921310428, 'training/walltime': 8010.787884473801, 'training/entropy_loss': Array(0.07333234, dtype=float32), 'training/policy_loss': Array(0.1057885, dtype=float32), 'training/total_loss': Array(0.17912084, dtype=float32), 'training/v_loss': Array(1.5950883e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0174267, dtype=float32), 'eval/episode_forward_reward': Array(-0.03402137, dtype=float32), 'eval/episode_reward': Array(-2.0488172, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03402137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0215876, dtype=float32), 'eval/episode_train_reward': Array(-0.00102064, dtype=float32), 'eval/episode_x_position': Array(1.0154886, dtype=float32), 'eval/episode_x_velocity': Array(-0.03402137, dtype=float32), 'eval/episode_y_position': Array(0.0002323, dtype=float32), 'eval/episode_y_velocity': Array(0.0007511, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08857261, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0443633, dtype=float32), 'eval/episode_reward_std': Array(0.17908576, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0443633, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26448667, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013309, dtype=float32), 'eval/episode_x_position_std': Array(0.08830708, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0443633, dtype=float32), 'eval/episode_y_position_std': Array(0.00579956, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01333663, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.642569065093994, 'eval/sps': 6200.778575397595, 'num_steps': 1008640}
{'eval/walltime': 4219.335914373398, 'training/sps': 127.09350777627623, 'training/walltime': 8051.073183774948, 'training/entropy_loss': Array(0.07546365, dtype=float32), 'training/policy_loss': Array(-0.03080483, dtype=float32), 'training/total_loss': Array(0.04465882, dtype=float32), 'training/v_loss': Array(1.1652949e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091453, dtype=float32), 'eval/episode_forward_reward': Array(-0.04074924, dtype=float32), 'eval/episode_reward': Array(-2.038961, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04074924, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969893, dtype=float32), 'eval/episode_train_reward': Array(-0.00122248, dtype=float32), 'eval/episode_x_position': Array(1.0073155, dtype=float32), 'eval/episode_x_velocity': Array(-0.04074924, dtype=float32), 'eval/episode_y_position': Array(0.00084281, dtype=float32), 'eval/episode_y_velocity': Array(-0.00096639, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563231, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04312932, dtype=float32), 'eval/episode_reward_std': Array(0.05006303, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04312932, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01981204, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129388, dtype=float32), 'eval/episode_x_position_std': Array(0.00563931, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04312932, dtype=float32), 'eval/episode_y_position_std': Array(0.00543649, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01250349, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68686270713806, 'eval/sps': 6187.501788554589, 'num_steps': 1013760}
{'eval/walltime': 4239.942763090134, 'training/sps': 127.48459864497354, 'training/walltime': 8091.234897851944, 'training/entropy_loss': Array(0.08701907, dtype=float32), 'training/policy_loss': Array(0.27058184, dtype=float32), 'training/total_loss': Array(0.3576009, dtype=float32), 'training/v_loss': Array(6.826417e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0080717, dtype=float32), 'eval/episode_forward_reward': Array(-0.03551195, dtype=float32), 'eval/episode_reward': Array(-2.0313096, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03551195, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947324, dtype=float32), 'eval/episode_train_reward': Array(-0.00106536, dtype=float32), 'eval/episode_x_position': Array(1.0061929, dtype=float32), 'eval/episode_x_velocity': Array(-0.03551195, dtype=float32), 'eval/episode_y_position': Array(0.00089636, dtype=float32), 'eval/episode_y_velocity': Array(-0.00144871, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583422, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04395592, dtype=float32), 'eval/episode_reward_std': Array(0.05073547, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04395592, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01965397, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131868, dtype=float32), 'eval/episode_x_position_std': Array(0.00585505, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04395592, dtype=float32), 'eval/episode_y_position_std': Array(0.00543716, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01112181, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.60684871673584, 'eval/sps': 6211.52713641484, 'num_steps': 1018880}
{'eval/walltime': 4260.577144861221, 'training/sps': 127.38274564764693, 'training/walltime': 8131.428724527359, 'training/entropy_loss': Array(0.05378082, dtype=float32), 'training/policy_loss': Array(0.2770346, dtype=float32), 'training/total_loss': Array(0.33081543, dtype=float32), 'training/v_loss': Array(3.6263717e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094148, dtype=float32), 'eval/episode_forward_reward': Array(-0.04587703, dtype=float32), 'eval/episode_reward': Array(-2.0439, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04587703, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996647, dtype=float32), 'eval/episode_train_reward': Array(-0.00137631, dtype=float32), 'eval/episode_x_position': Array(1.0076056, dtype=float32), 'eval/episode_x_velocity': Array(-0.04587703, dtype=float32), 'eval/episode_y_position': Array(-0.00026283, dtype=float32), 'eval/episode_y_velocity': Array(-0.00233908, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595892, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04445587, dtype=float32), 'eval/episode_reward_std': Array(0.04863195, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04445587, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01554093, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133368, dtype=float32), 'eval/episode_x_position_std': Array(0.00596344, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04445587, dtype=float32), 'eval/episode_y_position_std': Array(0.00576624, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01305181, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.634381771087646, 'eval/sps': 6203.238915514796, 'num_steps': 1024000}
{'eval/walltime': 4281.256526470184, 'training/sps': 127.29848111690042, 'training/walltime': 8171.64915728569, 'training/entropy_loss': Array(-0.01060693, dtype=float32), 'training/policy_loss': Array(0.11695576, dtype=float32), 'training/total_loss': Array(0.10653724, dtype=float32), 'training/v_loss': Array(0.00018842, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008892, dtype=float32), 'eval/episode_forward_reward': Array(-0.03996461, dtype=float32), 'eval/episode_reward': Array(-2.035862, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03996461, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946985, dtype=float32), 'eval/episode_train_reward': Array(-0.00119894, dtype=float32), 'eval/episode_x_position': Array(1.0070174, dtype=float32), 'eval/episode_x_velocity': Array(-0.03996461, dtype=float32), 'eval/episode_y_position': Array(-0.0002742, dtype=float32), 'eval/episode_y_velocity': Array(0.00115022, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00526573, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04365816, dtype=float32), 'eval/episode_reward_std': Array(0.04857963, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04365816, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01857209, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130974, dtype=float32), 'eval/episode_x_position_std': Array(0.00529189, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04365816, dtype=float32), 'eval/episode_y_position_std': Array(0.00557229, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0135463, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.679381608963013, 'eval/sps': 6189.740216628204, 'num_steps': 1029120}
{'eval/walltime': 4301.92641544342, 'training/sps': 127.0920357937219, 'training/walltime': 8211.934923171997, 'training/entropy_loss': Array(-0.0199479, dtype=float32), 'training/policy_loss': Array(-0.1640986, dtype=float32), 'training/total_loss': Array(-0.1839847, dtype=float32), 'training/v_loss': Array(6.180827e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100272, dtype=float32), 'eval/episode_forward_reward': Array(-0.04048195, dtype=float32), 'eval/episode_reward': Array(-2.038856, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04048195, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99716, dtype=float32), 'eval/episode_train_reward': Array(-0.00121446, dtype=float32), 'eval/episode_x_position': Array(1.0081351, dtype=float32), 'eval/episode_x_velocity': Array(-0.04048195, dtype=float32), 'eval/episode_y_position': Array(-0.00054192, dtype=float32), 'eval/episode_y_velocity': Array(-0.00177116, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561053, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04546199, dtype=float32), 'eval/episode_reward_std': Array(0.04950604, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04546199, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01362609, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136386, dtype=float32), 'eval/episode_x_position_std': Array(0.00558755, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04546199, dtype=float32), 'eval/episode_y_position_std': Array(0.00586069, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01243136, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.669888973236084, 'eval/sps': 6192.582851593338, 'num_steps': 1034240}
{'eval/walltime': 4322.607061624527, 'training/sps': 127.20786241680453, 'training/walltime': 8252.184007644653, 'training/entropy_loss': Array(-0.01955768, dtype=float32), 'training/policy_loss': Array(-0.17633091, dtype=float32), 'training/total_loss': Array(-0.19582985, dtype=float32), 'training/v_loss': Array(5.8731108e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087163, dtype=float32), 'eval/episode_forward_reward': Array(-0.03781193, dtype=float32), 'eval/episode_reward': Array(-2.0369081, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03781193, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979618, dtype=float32), 'eval/episode_train_reward': Array(-0.00113436, dtype=float32), 'eval/episode_x_position': Array(1.006819, dtype=float32), 'eval/episode_x_velocity': Array(-0.03781193, dtype=float32), 'eval/episode_y_position': Array(0.00012732, dtype=float32), 'eval/episode_y_velocity': Array(-0.00187777, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00613484, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0448933, dtype=float32), 'eval/episode_reward_std': Array(0.04833727, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0448933, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01049003, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013468, dtype=float32), 'eval/episode_x_position_std': Array(0.00611795, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0448933, dtype=float32), 'eval/episode_y_position_std': Array(0.00553247, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01013934, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680646181106567, 'eval/sps': 6189.361728790577, 'num_steps': 1039360}
{'eval/walltime': 4343.268659114838, 'training/sps': 127.07172110362029, 'training/walltime': 8292.476213932037, 'training/entropy_loss': Array(-0.0189775, dtype=float32), 'training/policy_loss': Array(-0.18682635, dtype=float32), 'training/total_loss': Array(-0.20574985, dtype=float32), 'training/v_loss': Array(5.3978136e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0172702, dtype=float32), 'eval/episode_forward_reward': Array(-0.03315081, dtype=float32), 'eval/episode_reward': Array(-2.0451293, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03315081, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0187962, dtype=float32), 'eval/episode_train_reward': Array(-0.00099452, dtype=float32), 'eval/episode_x_position': Array(1.0153495, dtype=float32), 'eval/episode_x_velocity': Array(-0.03315081, dtype=float32), 'eval/episode_y_position': Array(0.00018754, dtype=float32), 'eval/episode_y_velocity': Array(-0.00168304, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09069053, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04231153, dtype=float32), 'eval/episode_reward_std': Array(0.17953297, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04231153, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26513407, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126935, dtype=float32), 'eval/episode_x_position_std': Array(0.09042943, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04231153, dtype=float32), 'eval/episode_y_position_std': Array(0.00597293, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00908987, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.66159749031067, 'eval/sps': 6195.067930252057, 'num_steps': 1044480}
{'eval/walltime': 4363.9857006073, 'training/sps': 127.15764921108958, 'training/walltime': 8332.74119234085, 'training/entropy_loss': Array(-0.01812189, dtype=float32), 'training/policy_loss': Array(-0.191228, dtype=float32), 'training/total_loss': Array(-0.20930153, dtype=float32), 'training/v_loss': Array(4.8372054e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.010432, dtype=float32), 'eval/episode_forward_reward': Array(-0.03610831, dtype=float32), 'eval/episode_reward': Array(-2.0334554, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03610831, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962635, dtype=float32), 'eval/episode_train_reward': Array(-0.00108325, dtype=float32), 'eval/episode_x_position': Array(1.0085108, dtype=float32), 'eval/episode_x_velocity': Array(-0.03610831, dtype=float32), 'eval/episode_y_position': Array(0.00045452, dtype=float32), 'eval/episode_y_velocity': Array(-0.00106858, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571541, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04372444, dtype=float32), 'eval/episode_reward_std': Array(0.05015248, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04372444, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0155836, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131173, dtype=float32), 'eval/episode_x_position_std': Array(0.0057055, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04372444, dtype=float32), 'eval/episode_y_position_std': Array(0.00603752, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00916641, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.717041492462158, 'eval/sps': 6178.488373765746, 'num_steps': 1049600}
{'eval/walltime': 4384.624861955643, 'training/sps': 127.11712132145703, 'training/walltime': 8373.019008159637, 'training/entropy_loss': Array(-0.0170781, dtype=float32), 'training/policy_loss': Array(-0.19275689, dtype=float32), 'training/total_loss': Array(-0.20979357, dtype=float32), 'training/v_loss': Array(4.1412633e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093782, dtype=float32), 'eval/episode_forward_reward': Array(-0.03661503, dtype=float32), 'eval/episode_reward': Array(-2.03537, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03661503, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976563, dtype=float32), 'eval/episode_train_reward': Array(-0.00109845, dtype=float32), 'eval/episode_x_position': Array(1.0075016, dtype=float32), 'eval/episode_x_velocity': Array(-0.03661503, dtype=float32), 'eval/episode_y_position': Array(0.00015616, dtype=float32), 'eval/episode_y_velocity': Array(-0.00269538, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00592967, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04211035, dtype=float32), 'eval/episode_reward_std': Array(0.04596721, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04211035, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01255106, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126331, dtype=float32), 'eval/episode_x_position_std': Array(0.00589376, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04211035, dtype=float32), 'eval/episode_y_position_std': Array(0.00556286, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01447036, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.639161348342896, 'eval/sps': 6201.8023813878, 'num_steps': 1054720}
{'eval/walltime': 4405.280514717102, 'training/sps': 127.13089116159541, 'training/walltime': 8413.292461395264, 'training/entropy_loss': Array(-0.01590424, dtype=float32), 'training/policy_loss': Array(-0.19573376, dtype=float32), 'training/total_loss': Array(-0.21160054, dtype=float32), 'training/v_loss': Array(3.74612e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101669, dtype=float32), 'eval/episode_forward_reward': Array(-0.03268275, dtype=float32), 'eval/episode_reward': Array(-2.0320175, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03268275, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983542, dtype=float32), 'eval/episode_train_reward': Array(-0.00098048, dtype=float32), 'eval/episode_x_position': Array(1.0082686, dtype=float32), 'eval/episode_x_velocity': Array(-0.03268275, dtype=float32), 'eval/episode_y_position': Array(-0.00023797, dtype=float32), 'eval/episode_y_velocity': Array(-0.00168333, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00612054, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04177834, dtype=float32), 'eval/episode_reward_std': Array(0.04318381, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04177834, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00775058, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125335, dtype=float32), 'eval/episode_x_position_std': Array(0.0061541, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04177834, dtype=float32), 'eval/episode_y_position_std': Array(0.00561613, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01221876, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65565276145935, 'eval/sps': 6196.850880395833, 'num_steps': 1059840}
{'eval/walltime': 4425.9113211631775, 'training/sps': 127.01594082600761, 'training/walltime': 8453.602362394333, 'training/entropy_loss': Array(-0.01471093, dtype=float32), 'training/policy_loss': Array(-0.2008682, dtype=float32), 'training/total_loss': Array(-0.21554813, dtype=float32), 'training/v_loss': Array(3.1002575e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097222, dtype=float32), 'eval/episode_forward_reward': Array(-0.03358303, dtype=float32), 'eval/episode_reward': Array(-2.028336, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03358303, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9937453, dtype=float32), 'eval/episode_train_reward': Array(-0.00100749, dtype=float32), 'eval/episode_x_position': Array(1.0078185, dtype=float32), 'eval/episode_x_velocity': Array(-0.03358303, dtype=float32), 'eval/episode_y_position': Array(-0.00026577, dtype=float32), 'eval/episode_y_velocity': Array(-0.00141739, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577661, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04280862, dtype=float32), 'eval/episode_reward_std': Array(0.04961787, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04280862, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02323652, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128426, dtype=float32), 'eval/episode_x_position_std': Array(0.00582907, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04280862, dtype=float32), 'eval/episode_y_position_std': Array(0.00576266, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01162611, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63080644607544, 'eval/sps': 6204.313938699629, 'num_steps': 1064960}
{'eval/walltime': 4446.575867891312, 'training/sps': 127.37495287683993, 'training/walltime': 8493.798648118973, 'training/entropy_loss': Array(-0.01337662, dtype=float32), 'training/policy_loss': Array(-0.19773453, dtype=float32), 'training/total_loss': Array(-0.21108502, dtype=float32), 'training/v_loss': Array(2.6115677e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094346, dtype=float32), 'eval/episode_forward_reward': Array(-0.03936476, dtype=float32), 'eval/episode_reward': Array(-2.0365422, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03936476, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959965, dtype=float32), 'eval/episode_train_reward': Array(-0.00118094, dtype=float32), 'eval/episode_x_position': Array(1.0075338, dtype=float32), 'eval/episode_x_velocity': Array(-0.03936476, dtype=float32), 'eval/episode_y_position': Array(-0.00057165, dtype=float32), 'eval/episode_y_velocity': Array(-0.00041727, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566446, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04310359, dtype=float32), 'eval/episode_reward_std': Array(0.04724945, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04310359, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01737289, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129311, dtype=float32), 'eval/episode_x_position_std': Array(0.00567826, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04310359, dtype=float32), 'eval/episode_y_position_std': Array(0.00591842, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01014351, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.664546728134155, 'eval/sps': 6194.18377204141, 'num_steps': 1070080}
{'eval/walltime': 4467.201198101044, 'training/sps': 127.31544375778624, 'training/walltime': 8534.01372218132, 'training/entropy_loss': Array(-0.01175089, dtype=float32), 'training/policy_loss': Array(-0.20203051, dtype=float32), 'training/total_loss': Array(-0.21375863, dtype=float32), 'training/v_loss': Array(2.2768763e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094142, dtype=float32), 'eval/episode_forward_reward': Array(-0.04407042, dtype=float32), 'eval/episode_reward': Array(-2.0415626, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04407042, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99617, dtype=float32), 'eval/episode_train_reward': Array(-0.00132211, dtype=float32), 'eval/episode_x_position': Array(1.0075703, dtype=float32), 'eval/episode_x_velocity': Array(-0.04407042, dtype=float32), 'eval/episode_y_position': Array(-0.0001528, dtype=float32), 'eval/episode_y_velocity': Array(-0.00078318, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602771, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04453574, dtype=float32), 'eval/episode_reward_std': Array(0.04635677, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04453574, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01585521, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133607, dtype=float32), 'eval/episode_x_position_std': Array(0.00602421, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04453574, dtype=float32), 'eval/episode_y_position_std': Array(0.00576618, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01529983, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.625330209732056, 'eval/sps': 6205.961247573299, 'num_steps': 1075200}
{'eval/walltime': 4487.866874933243, 'training/sps': 127.34877089324455, 'training/walltime': 8574.218271970749, 'training/entropy_loss': Array(-0.00997147, dtype=float32), 'training/policy_loss': Array(-0.20384657, dtype=float32), 'training/total_loss': Array(-0.21379796, dtype=float32), 'training/v_loss': Array(2.0085277e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092264, dtype=float32), 'eval/episode_forward_reward': Array(-0.03921722, dtype=float32), 'eval/episode_reward': Array(-2.0372767, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03921722, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996883, dtype=float32), 'eval/episode_train_reward': Array(-0.00117652, dtype=float32), 'eval/episode_x_position': Array(1.0073603, dtype=float32), 'eval/episode_x_velocity': Array(-0.03921722, dtype=float32), 'eval/episode_y_position': Array(-0.00052437, dtype=float32), 'eval/episode_y_velocity': Array(-0.00111077, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558687, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04421749, dtype=float32), 'eval/episode_reward_std': Array(0.04497348, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04421749, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01261075, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132652, dtype=float32), 'eval/episode_x_position_std': Array(0.00556219, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04421749, dtype=float32), 'eval/episode_y_position_std': Array(0.00561733, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01267598, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.665676832199097, 'eval/sps': 6193.845042644032, 'num_steps': 1080320}
{'eval/walltime': 4508.496829986572, 'training/sps': 127.38986227612507, 'training/walltime': 8614.409853219986, 'training/entropy_loss': Array(-0.00836921, dtype=float32), 'training/policy_loss': Array(-0.2026679, dtype=float32), 'training/total_loss': Array(-0.21102147, dtype=float32), 'training/v_loss': Array(1.565088e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093594, dtype=float32), 'eval/episode_forward_reward': Array(-0.03501222, dtype=float32), 'eval/episode_reward': Array(-2.032298, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03501222, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962358, dtype=float32), 'eval/episode_train_reward': Array(-0.00105037, dtype=float32), 'eval/episode_x_position': Array(1.0074648, dtype=float32), 'eval/episode_x_velocity': Array(-0.03501222, dtype=float32), 'eval/episode_y_position': Array(-0.00035583, dtype=float32), 'eval/episode_y_velocity': Array(-0.00105104, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00546276, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04312364, dtype=float32), 'eval/episode_reward_std': Array(0.04619562, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04312364, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01624998, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129371, dtype=float32), 'eval/episode_x_position_std': Array(0.00549926, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04312364, dtype=float32), 'eval/episode_y_position_std': Array(0.00616669, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01403729, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.629955053329468, 'eval/sps': 6204.56998908207, 'num_steps': 1085440}
{'eval/walltime': 4529.147841691971, 'training/sps': 127.32541696619742, 'training/walltime': 8654.621777296066, 'training/entropy_loss': Array(-0.00652261, dtype=float32), 'training/policy_loss': Array(-0.19993813, dtype=float32), 'training/total_loss': Array(-0.2064473, dtype=float32), 'training/v_loss': Array(1.345248e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093639, dtype=float32), 'eval/episode_forward_reward': Array(-0.03733261, dtype=float32), 'eval/episode_reward': Array(-2.0343595, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03733261, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959073, dtype=float32), 'eval/episode_train_reward': Array(-0.00111998, dtype=float32), 'eval/episode_x_position': Array(1.0074797, dtype=float32), 'eval/episode_x_velocity': Array(-0.03733261, dtype=float32), 'eval/episode_y_position': Array(-0.00024331, dtype=float32), 'eval/episode_y_velocity': Array(-0.0019388, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0055428, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04277674, dtype=float32), 'eval/episode_reward_std': Array(0.04685585, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04277674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01633177, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012833, dtype=float32), 'eval/episode_x_position_std': Array(0.00552415, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04277674, dtype=float32), 'eval/episode_y_position_std': Array(0.00581645, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01205179, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65101170539856, 'eval/sps': 6198.24354496581, 'num_steps': 1090560}
{'eval/walltime': 4549.828208446503, 'training/sps': 126.87705234057094, 'training/walltime': 8694.975804328918, 'training/entropy_loss': Array(-0.00494261, dtype=float32), 'training/policy_loss': Array(-0.20325655, dtype=float32), 'training/total_loss': Array(-0.20818846, dtype=float32), 'training/v_loss': Array(1.0704773e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096619, dtype=float32), 'eval/episode_forward_reward': Array(-0.04582627, dtype=float32), 'eval/episode_reward': Array(-2.0444722, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04582627, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972713, dtype=float32), 'eval/episode_train_reward': Array(-0.00137479, dtype=float32), 'eval/episode_x_position': Array(1.0078, dtype=float32), 'eval/episode_x_velocity': Array(-0.04582627, dtype=float32), 'eval/episode_y_position': Array(0.00037973, dtype=float32), 'eval/episode_y_velocity': Array(-0.00321702, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00548383, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04530235, dtype=float32), 'eval/episode_reward_std': Array(0.0486985, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04530235, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01277746, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135907, dtype=float32), 'eval/episode_x_position_std': Array(0.00542836, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04530235, dtype=float32), 'eval/episode_y_position_std': Array(0.00611302, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01125141, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68036675453186, 'eval/sps': 6189.4453574886575, 'num_steps': 1095680}
{'eval/walltime': 4570.504503488541, 'training/sps': 127.25080526522629, 'training/walltime': 8735.211306095123, 'training/entropy_loss': Array(-0.00289002, dtype=float32), 'training/policy_loss': Array(-0.20303106, dtype=float32), 'training/total_loss': Array(-0.20591256, dtype=float32), 'training/v_loss': Array(8.521036e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171962, dtype=float32), 'eval/episode_forward_reward': Array(-0.03570962, dtype=float32), 'eval/episode_reward': Array(-2.0463786, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03570962, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0174103, dtype=float32), 'eval/episode_train_reward': Array(-0.00107129, dtype=float32), 'eval/episode_x_position': Array(1.0152664, dtype=float32), 'eval/episode_x_velocity': Array(-0.03570962, dtype=float32), 'eval/episode_y_position': Array(-0.00043264, dtype=float32), 'eval/episode_y_velocity': Array(-0.00058889, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09078623, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04295724, dtype=float32), 'eval/episode_reward_std': Array(0.18065025, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04295724, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2653739, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128872, dtype=float32), 'eval/episode_x_position_std': Array(0.09051877, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04295724, dtype=float32), 'eval/episode_y_position_std': Array(0.0058084, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01292946, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.676295042037964, 'eval/sps': 6190.664223921988, 'num_steps': 1100800}
{'eval/walltime': 4591.184517621994, 'training/sps': 127.07845033505265, 'training/walltime': 8775.501378774643, 'training/entropy_loss': Array(-0.00068516, dtype=float32), 'training/policy_loss': Array(-0.20468937, dtype=float32), 'training/total_loss': Array(-0.20536792, dtype=float32), 'training/v_loss': Array(6.594383e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101615, dtype=float32), 'eval/episode_forward_reward': Array(-0.04276533, dtype=float32), 'eval/episode_reward': Array(-2.0429406, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04276533, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9988923, dtype=float32), 'eval/episode_train_reward': Array(-0.00128296, dtype=float32), 'eval/episode_x_position': Array(1.0083328, dtype=float32), 'eval/episode_x_velocity': Array(-0.04276533, dtype=float32), 'eval/episode_y_position': Array(-0.00055109, dtype=float32), 'eval/episode_y_velocity': Array(-0.00264554, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560442, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04693571, dtype=float32), 'eval/episode_reward_std': Array(0.04815254, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04693571, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00484452, dtype=float32), 'eval/episode_train_reward_std': Array(0.00140807, dtype=float32), 'eval/episode_x_position_std': Array(0.00560725, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04693571, dtype=float32), 'eval/episode_y_position_std': Array(0.00546599, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01290236, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68001413345337, 'eval/sps': 6189.550895564364, 'num_steps': 1105920}
{'eval/walltime': 4611.8423635959625, 'training/sps': 127.17773154322893, 'training/walltime': 8815.759999036789, 'training/entropy_loss': Array(0.00141771, dtype=float32), 'training/policy_loss': Array(-0.20409328, dtype=float32), 'training/total_loss': Array(-0.20267045, dtype=float32), 'training/v_loss': Array(5.09368e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0177563, dtype=float32), 'eval/episode_forward_reward': Array(-0.04086868, dtype=float32), 'eval/episode_reward': Array(-2.0537708, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04086868, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0194886, dtype=float32), 'eval/episode_train_reward': Array(-0.00122606, dtype=float32), 'eval/episode_x_position': Array(1.0158844, dtype=float32), 'eval/episode_x_velocity': Array(-0.04086868, dtype=float32), 'eval/episode_y_position': Array(0.0003361, dtype=float32), 'eval/episode_y_velocity': Array(-0.00071923, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08808652, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04385906, dtype=float32), 'eval/episode_reward_std': Array(0.18017395, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04385906, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26501325, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131577, dtype=float32), 'eval/episode_x_position_std': Array(0.08781113, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04385906, dtype=float32), 'eval/episode_y_position_std': Array(0.00544589, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01827547, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.657845973968506, 'eval/sps': 6196.192970036477, 'num_steps': 1111040}
{'eval/walltime': 4632.483024358749, 'training/sps': 126.95432360887536, 'training/walltime': 8856.08946442604, 'training/entropy_loss': Array(0.00362769, dtype=float32), 'training/policy_loss': Array(-0.20497082, dtype=float32), 'training/total_loss': Array(-0.20133917, dtype=float32), 'training/v_loss': Array(3.9636016e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099413, dtype=float32), 'eval/episode_forward_reward': Array(-0.04136011, dtype=float32), 'eval/episode_reward': Array(-2.0390687, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04136011, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996468, dtype=float32), 'eval/episode_train_reward': Array(-0.0012408, dtype=float32), 'eval/episode_x_position': Array(1.0080807, dtype=float32), 'eval/episode_x_velocity': Array(-0.04136011, dtype=float32), 'eval/episode_y_position': Array(0.00095545, dtype=float32), 'eval/episode_y_velocity': Array(-0.0016234, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.005423, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04320797, dtype=float32), 'eval/episode_reward_std': Array(0.0485666, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04320797, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01598436, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129624, dtype=float32), 'eval/episode_x_position_std': Array(0.00532463, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04320797, dtype=float32), 'eval/episode_y_position_std': Array(0.00585011, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00883117, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.640660762786865, 'eval/sps': 6201.351859373211, 'num_steps': 1116160}
{'eval/walltime': 4653.140127658844, 'training/sps': 127.1770536949814, 'training/walltime': 8896.348299264908, 'training/entropy_loss': Array(0.00572598, dtype=float32), 'training/policy_loss': Array(-0.20553869, dtype=float32), 'training/total_loss': Array(-0.19980958, dtype=float32), 'training/v_loss': Array(3.1248587e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095127, dtype=float32), 'eval/episode_forward_reward': Array(-0.03693688, dtype=float32), 'eval/episode_reward': Array(-2.0357559, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03693688, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997711, dtype=float32), 'eval/episode_train_reward': Array(-0.00110811, dtype=float32), 'eval/episode_x_position': Array(1.0076212, dtype=float32), 'eval/episode_x_velocity': Array(-0.03693688, dtype=float32), 'eval/episode_y_position': Array(-0.00059599, dtype=float32), 'eval/episode_y_velocity': Array(-0.00250402, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614034, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04359259, dtype=float32), 'eval/episode_reward_std': Array(0.04638318, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04359259, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0121676, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130778, dtype=float32), 'eval/episode_x_position_std': Array(0.0061163, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04359259, dtype=float32), 'eval/episode_y_position_std': Array(0.00584209, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01380994, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.657103300094604, 'eval/sps': 6196.415738474512, 'num_steps': 1121280}
{'eval/walltime': 4673.804116487503, 'training/sps': 126.95272651190261, 'training/walltime': 8936.678272008896, 'training/entropy_loss': Array(0.00782733, dtype=float32), 'training/policy_loss': Array(-0.2045884, dtype=float32), 'training/total_loss': Array(-0.19675866, dtype=float32), 'training/v_loss': Array(2.418493e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094335, dtype=float32), 'eval/episode_forward_reward': Array(-0.03965579, dtype=float32), 'eval/episode_reward': Array(-2.0389447, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03965579, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980993, dtype=float32), 'eval/episode_train_reward': Array(-0.00118967, dtype=float32), 'eval/episode_x_position': Array(1.0075448, dtype=float32), 'eval/episode_x_velocity': Array(-0.03965579, dtype=float32), 'eval/episode_y_position': Array(-0.00083032, dtype=float32), 'eval/episode_y_velocity': Array(-0.00181016, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580579, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04749062, dtype=float32), 'eval/episode_reward_std': Array(0.05033027, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04749062, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00914871, dtype=float32), 'eval/episode_train_reward_std': Array(0.00142472, dtype=float32), 'eval/episode_x_position_std': Array(0.00578196, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04749062, dtype=float32), 'eval/episode_y_position_std': Array(0.00584468, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01085173, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.663988828659058, 'eval/sps': 6194.351006543119, 'num_steps': 1126400}
{'eval/walltime': 4694.461482524872, 'training/sps': 127.22813473360036, 'training/walltime': 8976.920943260193, 'training/entropy_loss': Array(0.01005593, dtype=float32), 'training/policy_loss': Array(-0.20614842, dtype=float32), 'training/total_loss': Array(-0.1960906, dtype=float32), 'training/v_loss': Array(1.9061958e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008854, dtype=float32), 'eval/episode_forward_reward': Array(-0.03683443, dtype=float32), 'eval/episode_reward': Array(-2.0328097, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03683443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9948702, dtype=float32), 'eval/episode_train_reward': Array(-0.00110503, dtype=float32), 'eval/episode_x_position': Array(1.0069761, dtype=float32), 'eval/episode_x_velocity': Array(-0.03683443, dtype=float32), 'eval/episode_y_position': Array(-9.545188e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0001175, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596641, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04267752, dtype=float32), 'eval/episode_reward_std': Array(0.04908453, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04267752, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01743958, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128033, dtype=float32), 'eval/episode_x_position_std': Array(0.00597034, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04267752, dtype=float32), 'eval/episode_y_position_std': Array(0.00589049, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01446679, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.657366037368774, 'eval/sps': 6196.336927391928, 'num_steps': 1131520}
{'eval/walltime': 4715.1110463142395, 'training/sps': 127.11656977725521, 'training/walltime': 9017.198933839798, 'training/entropy_loss': Array(0.01216408, dtype=float32), 'training/policy_loss': Array(-0.20307232, dtype=float32), 'training/total_loss': Array(-0.19090688, dtype=float32), 'training/v_loss': Array(1.3673457e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098239, dtype=float32), 'eval/episode_forward_reward': Array(-0.03551094, dtype=float32), 'eval/episode_reward': Array(-2.0326471, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03551094, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960709, dtype=float32), 'eval/episode_train_reward': Array(-0.00106533, dtype=float32), 'eval/episode_x_position': Array(1.0079195, dtype=float32), 'eval/episode_x_velocity': Array(-0.03551094, dtype=float32), 'eval/episode_y_position': Array(0.00041645, dtype=float32), 'eval/episode_y_velocity': Array(-0.00461197, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00601316, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04422532, dtype=float32), 'eval/episode_reward_std': Array(0.04985445, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04422532, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01642178, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132676, dtype=float32), 'eval/episode_x_position_std': Array(0.00599821, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04422532, dtype=float32), 'eval/episode_y_position_std': Array(0.00598749, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01629855, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.649563789367676, 'eval/sps': 6198.678156383447, 'num_steps': 1136640}
{'eval/walltime': 4735.788021326065, 'training/sps': 127.15069928591565, 'training/walltime': 9057.466113090515, 'training/entropy_loss': Array(0.01409414, dtype=float32), 'training/policy_loss': Array(-0.20356181, dtype=float32), 'training/total_loss': Array(-0.18946654, dtype=float32), 'training/v_loss': Array(1.1302851e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095783, dtype=float32), 'eval/episode_forward_reward': Array(-0.0281677, dtype=float32), 'eval/episode_reward': Array(-2.0277705, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0281677, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987578, dtype=float32), 'eval/episode_train_reward': Array(-0.00084503, dtype=float32), 'eval/episode_x_position': Array(1.0076575, dtype=float32), 'eval/episode_x_velocity': Array(-0.0281677, dtype=float32), 'eval/episode_y_position': Array(-0.00031499, dtype=float32), 'eval/episode_y_velocity': Array(-0.00164947, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595593, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04046035, dtype=float32), 'eval/episode_reward_std': Array(0.04214885, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04046035, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00490013, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121381, dtype=float32), 'eval/episode_x_position_std': Array(0.00592011, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04046035, dtype=float32), 'eval/episode_y_position_std': Array(0.00581652, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01063721, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67697501182556, 'eval/sps': 6190.460641694171, 'num_steps': 1141760}
{'eval/walltime': 4756.41416144371, 'training/sps': 126.94882400039262, 'training/walltime': 9097.797325611115, 'training/entropy_loss': Array(0.01632193, dtype=float32), 'training/policy_loss': Array(-0.20555693, dtype=float32), 'training/total_loss': Array(-0.18923415, dtype=float32), 'training/v_loss': Array(8.4959885e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086212, dtype=float32), 'eval/episode_forward_reward': Array(-0.03972106, dtype=float32), 'eval/episode_reward': Array(-2.038405, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03972106, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974923, dtype=float32), 'eval/episode_train_reward': Array(-0.00119163, dtype=float32), 'eval/episode_x_position': Array(1.0067221, dtype=float32), 'eval/episode_x_velocity': Array(-0.03972106, dtype=float32), 'eval/episode_y_position': Array(-0.00109345, dtype=float32), 'eval/episode_y_velocity': Array(-0.00163939, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576696, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04335039, dtype=float32), 'eval/episode_reward_std': Array(0.04593192, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04335039, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01215712, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130051, dtype=float32), 'eval/episode_x_position_std': Array(0.00574012, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04335039, dtype=float32), 'eval/episode_y_position_std': Array(0.00591484, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01420609, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.626140117645264, 'eval/sps': 6205.717563728682, 'num_steps': 1146880}
{'eval/walltime': 4777.080474853516, 'training/sps': 127.07232188545305, 'training/walltime': 9138.089341402054, 'training/entropy_loss': Array(0.01847726, dtype=float32), 'training/policy_loss': Array(-0.20231494, dtype=float32), 'training/total_loss': Array(-0.18383706, dtype=float32), 'training/v_loss': Array(6.300545e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0185021, dtype=float32), 'eval/episode_forward_reward': Array(-0.03900115, dtype=float32), 'eval/episode_reward': Array(-2.0507884, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03900115, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0184298, dtype=float32), 'eval/episode_train_reward': Array(-0.00117003, dtype=float32), 'eval/episode_x_position': Array(1.01659, dtype=float32), 'eval/episode_x_velocity': Array(-0.03900115, dtype=float32), 'eval/episode_y_position': Array(0.00087709, dtype=float32), 'eval/episode_y_velocity': Array(-0.00395746, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09066115, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04223331, dtype=float32), 'eval/episode_reward_std': Array(0.17860182, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04223331, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26540607, dtype=float32), 'eval/episode_train_reward_std': Array(0.001267, dtype=float32), 'eval/episode_x_position_std': Array(0.09039057, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04223331, dtype=float32), 'eval/episode_y_position_std': Array(0.00601352, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01238128, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.666313409805298, 'eval/sps': 6193.654255686908, 'num_steps': 1152000}
{'eval/walltime': 4797.714536190033, 'training/sps': 127.04238595167318, 'training/walltime': 9178.39085149765, 'training/entropy_loss': Array(0.02073224, dtype=float32), 'training/policy_loss': Array(-0.20425706, dtype=float32), 'training/total_loss': Array(-0.18352434, dtype=float32), 'training/v_loss': Array(4.783316e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098637, dtype=float32), 'eval/episode_forward_reward': Array(-0.03656621, dtype=float32), 'eval/episode_reward': Array(-2.0361323, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03656621, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984694, dtype=float32), 'eval/episode_train_reward': Array(-0.00109699, dtype=float32), 'eval/episode_x_position': Array(1.0079993, dtype=float32), 'eval/episode_x_velocity': Array(-0.03656621, dtype=float32), 'eval/episode_y_position': Array(0.00027329, dtype=float32), 'eval/episode_y_velocity': Array(-0.00372641, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578472, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04213864, dtype=float32), 'eval/episode_reward_std': Array(0.04445197, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04213864, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00710943, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126416, dtype=float32), 'eval/episode_x_position_std': Array(0.00574103, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04213864, dtype=float32), 'eval/episode_y_position_std': Array(0.00573621, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01442558, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.634061336517334, 'eval/sps': 6203.335248086654, 'num_steps': 1157120}
{'eval/walltime': 4818.398590564728, 'training/sps': 127.07319562336345, 'training/walltime': 9218.6825902462, 'training/entropy_loss': Array(0.02285869, dtype=float32), 'training/policy_loss': Array(-0.20346963, dtype=float32), 'training/total_loss': Array(-0.18061057, dtype=float32), 'training/v_loss': Array(3.807592e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098581, dtype=float32), 'eval/episode_forward_reward': Array(-0.03136524, dtype=float32), 'eval/episode_reward': Array(-2.0266476, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03136524, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9943416, dtype=float32), 'eval/episode_train_reward': Array(-0.00094096, dtype=float32), 'eval/episode_x_position': Array(1.0079378, dtype=float32), 'eval/episode_x_velocity': Array(-0.03136524, dtype=float32), 'eval/episode_y_position': Array(-0.00070159, dtype=float32), 'eval/episode_y_velocity': Array(-0.00027439, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00591663, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03991536, dtype=float32), 'eval/episode_reward_std': Array(0.04638301, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03991536, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01911079, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119746, dtype=float32), 'eval/episode_x_position_std': Array(0.00591083, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03991536, dtype=float32), 'eval/episode_y_position_std': Array(0.00588731, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00970319, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.684054374694824, 'eval/sps': 6188.341883136658, 'num_steps': 1162240}
{'eval/walltime': 4839.053277015686, 'training/sps': 127.1238839584935, 'training/walltime': 9258.958263397217, 'training/entropy_loss': Array(0.02521149, dtype=float32), 'training/policy_loss': Array(-0.19676314, dtype=float32), 'training/total_loss': Array(-0.17155138, dtype=float32), 'training/v_loss': Array(2.7977526e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088965, dtype=float32), 'eval/episode_forward_reward': Array(-0.03604413, dtype=float32), 'eval/episode_reward': Array(-2.0352867, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03604413, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981613, dtype=float32), 'eval/episode_train_reward': Array(-0.00108132, dtype=float32), 'eval/episode_x_position': Array(1.0070105, dtype=float32), 'eval/episode_x_velocity': Array(-0.03604413, dtype=float32), 'eval/episode_y_position': Array(-0.00028945, dtype=float32), 'eval/episode_y_velocity': Array(-0.00124312, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589253, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04059799, dtype=float32), 'eval/episode_reward_std': Array(0.04373139, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04059799, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01115393, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121794, dtype=float32), 'eval/episode_x_position_std': Array(0.00594826, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04059799, dtype=float32), 'eval/episode_y_position_std': Array(0.00555777, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00963341, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.654686450958252, 'eval/sps': 6197.14079436251, 'num_steps': 1167360}
{'eval/walltime': 4859.674031019211, 'training/sps': 127.14765785037139, 'training/walltime': 9299.226405858994, 'training/entropy_loss': Array(0.02754186, dtype=float32), 'training/policy_loss': Array(-0.20088536, dtype=float32), 'training/total_loss': Array(-0.17334329, dtype=float32), 'training/v_loss': Array(2.0735068e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092666, dtype=float32), 'eval/episode_forward_reward': Array(-0.04089795, dtype=float32), 'eval/episode_reward': Array(-2.0397613, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04089795, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976363, dtype=float32), 'eval/episode_train_reward': Array(-0.00122694, dtype=float32), 'eval/episode_x_position': Array(1.007434, dtype=float32), 'eval/episode_x_velocity': Array(-0.04089795, dtype=float32), 'eval/episode_y_position': Array(-0.00024667, dtype=float32), 'eval/episode_y_velocity': Array(-0.00228726, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0054882, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04250226, dtype=float32), 'eval/episode_reward_std': Array(0.04579199, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04250226, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01308913, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127507, dtype=float32), 'eval/episode_x_position_std': Array(0.00548848, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04250226, dtype=float32), 'eval/episode_y_position_std': Array(0.00575508, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01558355, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62075400352478, 'eval/sps': 6207.338489083401, 'num_steps': 1172480}
{'eval/walltime': 4880.304088592529, 'training/sps': 127.19686114019353, 'training/walltime': 9339.478971481323, 'training/entropy_loss': Array(0.03008454, dtype=float32), 'training/policy_loss': Array(-0.20340806, dtype=float32), 'training/total_loss': Array(-0.17332338, dtype=float32), 'training/v_loss': Array(1.5014484e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090587, dtype=float32), 'eval/episode_forward_reward': Array(-0.04288283, dtype=float32), 'eval/episode_reward': Array(-2.041788, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04288283, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997619, dtype=float32), 'eval/episode_train_reward': Array(-0.00128648, dtype=float32), 'eval/episode_x_position': Array(1.0071843, dtype=float32), 'eval/episode_x_velocity': Array(-0.04288283, dtype=float32), 'eval/episode_y_position': Array(-3.900146e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00246076, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0062399, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04594805, dtype=float32), 'eval/episode_reward_std': Array(0.04689612, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04594805, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01197697, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137844, dtype=float32), 'eval/episode_x_position_std': Array(0.00617862, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04594805, dtype=float32), 'eval/episode_y_position_std': Array(0.00586248, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01222745, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63005757331848, 'eval/sps': 6204.539155796953, 'num_steps': 1177600}
{'eval/walltime': 4900.981666326523, 'training/sps': 126.90945282875641, 'training/walltime': 9379.822695970535, 'training/entropy_loss': Array(0.03260501, dtype=float32), 'training/policy_loss': Array(-0.19794452, dtype=float32), 'training/total_loss': Array(-0.16533941, dtype=float32), 'training/v_loss': Array(1.1086349e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092359, dtype=float32), 'eval/episode_forward_reward': Array(-0.04641922, dtype=float32), 'eval/episode_reward': Array(-2.0438614, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04641922, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99605, dtype=float32), 'eval/episode_train_reward': Array(-0.00139258, dtype=float32), 'eval/episode_x_position': Array(1.0073982, dtype=float32), 'eval/episode_x_velocity': Array(-0.04641922, dtype=float32), 'eval/episode_y_position': Array(-0.00016959, dtype=float32), 'eval/episode_y_velocity': Array(-0.00123473, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580458, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04327133, dtype=float32), 'eval/episode_reward_std': Array(0.04435705, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04327133, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01430569, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129814, dtype=float32), 'eval/episode_x_position_std': Array(0.0057455, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04327133, dtype=float32), 'eval/episode_y_position_std': Array(0.00586444, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01126239, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67757773399353, 'eval/sps': 6190.280198515251, 'num_steps': 1182720}
{'eval/walltime': 4921.609881877899, 'training/sps': 126.97291157902734, 'training/walltime': 9420.146257400513, 'training/entropy_loss': Array(0.0355466, dtype=float32), 'training/policy_loss': Array(-0.19428411, dtype=float32), 'training/total_loss': Array(-0.15873742, dtype=float32), 'training/v_loss': Array(8.334548e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087568, dtype=float32), 'eval/episode_forward_reward': Array(-0.0370394, dtype=float32), 'eval/episode_reward': Array(-2.0338016, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0370394, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956512, dtype=float32), 'eval/episode_train_reward': Array(-0.00111118, dtype=float32), 'eval/episode_x_position': Array(1.0068743, dtype=float32), 'eval/episode_x_velocity': Array(-0.0370394, dtype=float32), 'eval/episode_y_position': Array(0.00073613, dtype=float32), 'eval/episode_y_velocity': Array(-0.00325952, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569023, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04227459, dtype=float32), 'eval/episode_reward_std': Array(0.04469295, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04227459, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0166224, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126824, dtype=float32), 'eval/episode_x_position_std': Array(0.00567222, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04227459, dtype=float32), 'eval/episode_y_position_std': Array(0.00567805, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01307109, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.628215551376343, 'eval/sps': 6205.093197771033, 'num_steps': 1187840}
{'eval/walltime': 4942.232939958572, 'training/sps': 127.36668439493933, 'training/walltime': 9460.3451526165, 'training/entropy_loss': Array(0.03815465, dtype=float32), 'training/policy_loss': Array(-0.19370905, dtype=float32), 'training/total_loss': Array(-0.15555434, dtype=float32), 'training/v_loss': Array(5.292744e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099299, dtype=float32), 'eval/episode_forward_reward': Array(-0.035091, dtype=float32), 'eval/episode_reward': Array(-2.0287366, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.035091, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.992593, dtype=float32), 'eval/episode_train_reward': Array(-0.00105273, dtype=float32), 'eval/episode_x_position': Array(1.0080254, dtype=float32), 'eval/episode_x_velocity': Array(-0.035091, dtype=float32), 'eval/episode_y_position': Array(-0.00055757, dtype=float32), 'eval/episode_y_velocity': Array(-0.00360729, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00607821, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04217092, dtype=float32), 'eval/episode_reward_std': Array(0.04890047, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04217092, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02262214, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126513, dtype=float32), 'eval/episode_x_position_std': Array(0.00603725, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04217092, dtype=float32), 'eval/episode_y_position_std': Array(0.00572163, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01220207, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.623058080673218, 'eval/sps': 6206.644984429078, 'num_steps': 1192960}
{'eval/walltime': 4962.905727624893, 'training/sps': 127.01503557181486, 'training/walltime': 9500.655340909958, 'training/entropy_loss': Array(0.04097832, dtype=float32), 'training/policy_loss': Array(-0.19219564, dtype=float32), 'training/total_loss': Array(-0.15121728, dtype=float32), 'training/v_loss': Array(3.5349267e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0168979, dtype=float32), 'eval/episode_forward_reward': Array(-0.04014901, dtype=float32), 'eval/episode_reward': Array(-2.055038, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04014901, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.021497, dtype=float32), 'eval/episode_train_reward': Array(-0.00120447, dtype=float32), 'eval/episode_x_position': Array(1.0150164, dtype=float32), 'eval/episode_x_velocity': Array(-0.04014901, dtype=float32), 'eval/episode_y_position': Array(-5.5464086e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00250357, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08915102, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04383424, dtype=float32), 'eval/episode_reward_std': Array(0.17879659, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04383424, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26448974, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131503, dtype=float32), 'eval/episode_x_position_std': Array(0.08887728, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04383424, dtype=float32), 'eval/episode_y_position_std': Array(0.00571237, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01518705, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.6727876663208, 'eval/sps': 6191.71454116621, 'num_steps': 1198080}
{'eval/walltime': 4983.565354347229, 'training/sps': 127.2574154749514, 'training/walltime': 9540.888752698898, 'training/entropy_loss': Array(0.04402758, dtype=float32), 'training/policy_loss': Array(-0.1816401, dtype=float32), 'training/total_loss': Array(-0.1376125, dtype=float32), 'training/v_loss': Array(2.5415423e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095465, dtype=float32), 'eval/episode_forward_reward': Array(-0.03598755, dtype=float32), 'eval/episode_reward': Array(-2.0325968, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03598755, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955297, dtype=float32), 'eval/episode_train_reward': Array(-0.00107963, dtype=float32), 'eval/episode_x_position': Array(1.0076805, dtype=float32), 'eval/episode_x_velocity': Array(-0.03598755, dtype=float32), 'eval/episode_y_position': Array(0.00054009, dtype=float32), 'eval/episode_y_velocity': Array(-0.00228731, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600399, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04295088, dtype=float32), 'eval/episode_reward_std': Array(0.04812098, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04295088, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01768097, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128853, dtype=float32), 'eval/episode_x_position_std': Array(0.00600734, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04295088, dtype=float32), 'eval/episode_y_position_std': Array(0.00600467, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0114322, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.659626722335815, 'eval/sps': 6195.6588916301625, 'num_steps': 1203200}
{'eval/walltime': 5004.219663143158, 'training/sps': 127.07852027046539, 'training/walltime': 9581.17880320549, 'training/entropy_loss': Array(0.04687672, dtype=float32), 'training/policy_loss': Array(-0.1864834, dtype=float32), 'training/total_loss': Array(-0.13960667, dtype=float32), 'training/v_loss': Array(1.5985766e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094873, dtype=float32), 'eval/episode_forward_reward': Array(-0.03334694, dtype=float32), 'eval/episode_reward': Array(-2.0306783, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03334694, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963312, dtype=float32), 'eval/episode_train_reward': Array(-0.00100041, dtype=float32), 'eval/episode_x_position': Array(1.0075898, dtype=float32), 'eval/episode_x_velocity': Array(-0.03334694, dtype=float32), 'eval/episode_y_position': Array(0.00110836, dtype=float32), 'eval/episode_y_velocity': Array(-0.00335164, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00612912, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04035171, dtype=float32), 'eval/episode_reward_std': Array(0.04531289, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04035171, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01585362, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121055, dtype=float32), 'eval/episode_x_position_std': Array(0.00617994, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04035171, dtype=float32), 'eval/episode_y_position_std': Array(0.00603483, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01275375, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.654308795928955, 'eval/sps': 6197.254106379454, 'num_steps': 1208320}
{'eval/walltime': 5024.866702795029, 'training/sps': 127.31002376450135, 'training/walltime': 9621.395589351654, 'training/entropy_loss': Array(0.04992475, dtype=float32), 'training/policy_loss': Array(-0.17867449, dtype=float32), 'training/total_loss': Array(-0.12874973, dtype=float32), 'training/v_loss': Array(1.2391686e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009208, dtype=float32), 'eval/episode_forward_reward': Array(-0.03439599, dtype=float32), 'eval/episode_reward': Array(-2.0324135, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03439599, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969854, dtype=float32), 'eval/episode_train_reward': Array(-0.00103188, dtype=float32), 'eval/episode_x_position': Array(1.007284, dtype=float32), 'eval/episode_x_velocity': Array(-0.03439599, dtype=float32), 'eval/episode_y_position': Array(0.0004435, dtype=float32), 'eval/episode_y_velocity': Array(-0.00200631, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582395, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04204588, dtype=float32), 'eval/episode_reward_std': Array(0.04451676, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04204588, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0143028, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126138, dtype=float32), 'eval/episode_x_position_std': Array(0.00583917, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04204588, dtype=float32), 'eval/episode_y_position_std': Array(0.00617305, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01111874, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647039651870728, 'eval/sps': 6199.435955866077, 'num_steps': 1213440}
{'eval/walltime': 5045.521363258362, 'training/sps': 127.04851752715237, 'training/walltime': 9661.695154428482, 'training/entropy_loss': Array(0.05292499, dtype=float32), 'training/policy_loss': Array(-0.172889, dtype=float32), 'training/total_loss': Array(-0.11996399, dtype=float32), 'training/v_loss': Array(7.916812e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092369, dtype=float32), 'eval/episode_forward_reward': Array(-0.03550303, dtype=float32), 'eval/episode_reward': Array(-2.0306962, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03550303, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9941278, dtype=float32), 'eval/episode_train_reward': Array(-0.00106509, dtype=float32), 'eval/episode_x_position': Array(1.0073513, dtype=float32), 'eval/episode_x_velocity': Array(-0.03550303, dtype=float32), 'eval/episode_y_position': Array(0.00135573, dtype=float32), 'eval/episode_y_velocity': Array(-0.00165058, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057706, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04088071, dtype=float32), 'eval/episode_reward_std': Array(0.04704309, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04088071, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01921662, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122642, dtype=float32), 'eval/episode_x_position_std': Array(0.00578504, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04088071, dtype=float32), 'eval/episode_y_position_std': Array(0.00575481, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0119954, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65466046333313, 'eval/sps': 6197.148591584453, 'num_steps': 1218560}
{'eval/walltime': 5066.1468777656555, 'training/sps': 127.36668666116462, 'training/walltime': 9701.894048929214, 'training/entropy_loss': Array(0.05600009, dtype=float32), 'training/policy_loss': Array(-0.16447029, dtype=float32), 'training/total_loss': Array(-0.10847019, dtype=float32), 'training/v_loss': Array(5.8593788e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098288, dtype=float32), 'eval/episode_forward_reward': Array(-0.04174475, dtype=float32), 'eval/episode_reward': Array(-2.0389297, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04174475, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959326, dtype=float32), 'eval/episode_train_reward': Array(-0.00125234, dtype=float32), 'eval/episode_x_position': Array(1.0079988, dtype=float32), 'eval/episode_x_velocity': Array(-0.04174475, dtype=float32), 'eval/episode_y_position': Array(0.00039274, dtype=float32), 'eval/episode_y_velocity': Array(-0.00357367, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00624433, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04280775, dtype=float32), 'eval/episode_reward_std': Array(0.04806372, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04280775, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01467931, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128423, dtype=float32), 'eval/episode_x_position_std': Array(0.00622148, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04280775, dtype=float32), 'eval/episode_y_position_std': Array(0.00570868, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01195399, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6255145072937, 'eval/sps': 6205.905794725071, 'num_steps': 1223680}
{'eval/walltime': 5086.788662910461, 'training/sps': 127.21685336684261, 'training/walltime': 9742.140288829803, 'training/entropy_loss': Array(0.05921043, dtype=float32), 'training/policy_loss': Array(-0.14472303, dtype=float32), 'training/total_loss': Array(-0.08551259, dtype=float32), 'training/v_loss': Array(3.4070053e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089004, dtype=float32), 'eval/episode_forward_reward': Array(-0.03209703, dtype=float32), 'eval/episode_reward': Array(-2.0293546, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03209703, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962945, dtype=float32), 'eval/episode_train_reward': Array(-0.00096291, dtype=float32), 'eval/episode_x_position': Array(1.0070007, dtype=float32), 'eval/episode_x_velocity': Array(-0.03209703, dtype=float32), 'eval/episode_y_position': Array(0.00070186, dtype=float32), 'eval/episode_y_velocity': Array(-0.00203788, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00539145, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0423034, dtype=float32), 'eval/episode_reward_std': Array(0.04529458, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0423034, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01505911, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012691, dtype=float32), 'eval/episode_x_position_std': Array(0.00540401, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0423034, dtype=float32), 'eval/episode_y_position_std': Array(0.00593984, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01351116, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.641785144805908, 'eval/sps': 6201.014064532526, 'num_steps': 1228800}
{'eval/walltime': 5107.400775909424, 'training/sps': 127.39531174208297, 'training/walltime': 9782.330150842667, 'training/entropy_loss': Array(0.06227427, dtype=float32), 'training/policy_loss': Array(-0.135697, dtype=float32), 'training/total_loss': Array(-0.07342274, dtype=float32), 'training/v_loss': Array(2.4872542e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095013, dtype=float32), 'eval/episode_forward_reward': Array(-0.02852222, dtype=float32), 'eval/episode_reward': Array(-2.0254345, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.02852222, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960566, dtype=float32), 'eval/episode_train_reward': Array(-0.00085567, dtype=float32), 'eval/episode_x_position': Array(1.0075705, dtype=float32), 'eval/episode_x_velocity': Array(-0.02852222, dtype=float32), 'eval/episode_y_position': Array(-6.582955e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00137106, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596221, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03983473, dtype=float32), 'eval/episode_reward_std': Array(0.04538498, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03983473, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01586201, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119504, dtype=float32), 'eval/episode_x_position_std': Array(0.00596835, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03983473, dtype=float32), 'eval/episode_y_position_std': Array(0.00591857, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01116425, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.612112998962402, 'eval/sps': 6209.940727883813, 'num_steps': 1233920}
{'eval/walltime': 5128.063813686371, 'training/sps': 127.32347458927521, 'training/walltime': 9822.542688369751, 'training/entropy_loss': Array(0.06631791, dtype=float32), 'training/policy_loss': Array(-0.11808108, dtype=float32), 'training/total_loss': Array(-0.05176316, dtype=float32), 'training/v_loss': Array(1.5632262e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095322, dtype=float32), 'eval/episode_forward_reward': Array(-0.04050788, dtype=float32), 'eval/episode_reward': Array(-2.0391867, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04050788, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974637, dtype=float32), 'eval/episode_train_reward': Array(-0.00121524, dtype=float32), 'eval/episode_x_position': Array(1.0076818, dtype=float32), 'eval/episode_x_velocity': Array(-0.04050788, dtype=float32), 'eval/episode_y_position': Array(0.0009927, dtype=float32), 'eval/episode_y_velocity': Array(-0.00267689, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574156, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04326318, dtype=float32), 'eval/episode_reward_std': Array(0.04629461, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04326318, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01199259, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012979, dtype=float32), 'eval/episode_x_position_std': Array(0.0057413, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04326318, dtype=float32), 'eval/episode_y_position_std': Array(0.00540675, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01067306, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66303777694702, 'eval/sps': 6194.636112159888, 'num_steps': 1239040}
{'eval/walltime': 5148.665860652924, 'training/sps': 127.18328941819335, 'training/walltime': 9862.799549341202, 'training/entropy_loss': Array(0.0710768, dtype=float32), 'training/policy_loss': Array(-0.04430055, dtype=float32), 'training/total_loss': Array(0.02677625, dtype=float32), 'training/v_loss': Array(9.942742e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090723, dtype=float32), 'eval/episode_forward_reward': Array(-0.04447477, dtype=float32), 'eval/episode_reward': Array(-2.042626, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04447477, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968166, dtype=float32), 'eval/episode_train_reward': Array(-0.00133424, dtype=float32), 'eval/episode_x_position': Array(1.0072398, dtype=float32), 'eval/episode_x_velocity': Array(-0.04447477, dtype=float32), 'eval/episode_y_position': Array(8.7615335e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00389347, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00646061, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0466453, dtype=float32), 'eval/episode_reward_std': Array(0.05193637, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0466453, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01606781, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139936, dtype=float32), 'eval/episode_x_position_std': Array(0.00647221, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0466453, dtype=float32), 'eval/episode_y_position_std': Array(0.00608209, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01415081, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.602046966552734, 'eval/sps': 6212.974866420168, 'num_steps': 1244160}
{'eval/walltime': 5169.294855117798, 'training/sps': 127.4036270246704, 'training/walltime': 9902.986788272858, 'training/entropy_loss': Array(0.07601079, dtype=float32), 'training/policy_loss': Array(0.09563747, dtype=float32), 'training/total_loss': Array(0.17164826, dtype=float32), 'training/v_loss': Array(5.841436e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094328, dtype=float32), 'eval/episode_forward_reward': Array(-0.04300405, dtype=float32), 'eval/episode_reward': Array(-2.042057, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04300405, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997763, dtype=float32), 'eval/episode_train_reward': Array(-0.00129012, dtype=float32), 'eval/episode_x_position': Array(1.0075717, dtype=float32), 'eval/episode_x_velocity': Array(-0.04300405, dtype=float32), 'eval/episode_y_position': Array(-1.26745435e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00089261, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581868, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04378715, dtype=float32), 'eval/episode_reward_std': Array(0.0449571, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04378715, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00916565, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131361, dtype=float32), 'eval/episode_x_position_std': Array(0.00580625, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04378715, dtype=float32), 'eval/episode_y_position_std': Array(0.00558928, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01089653, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.628994464874268, 'eval/sps': 6204.858904681477, 'num_steps': 1249280}
{'eval/walltime': 5189.984894037247, 'training/sps': 127.34636110858179, 'training/walltime': 9943.192098855972, 'training/entropy_loss': Array(0.07560556, dtype=float32), 'training/policy_loss': Array(0.2729121, dtype=float32), 'training/total_loss': Array(0.34851772, dtype=float32), 'training/v_loss': Array(4.2947946e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100172, dtype=float32), 'eval/episode_forward_reward': Array(-0.03813898, dtype=float32), 'eval/episode_reward': Array(-2.035658, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03813898, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963746, dtype=float32), 'eval/episode_train_reward': Array(-0.00114417, dtype=float32), 'eval/episode_x_position': Array(1.0081251, dtype=float32), 'eval/episode_x_velocity': Array(-0.03813898, dtype=float32), 'eval/episode_y_position': Array(-7.515575e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00231458, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589805, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04321072, dtype=float32), 'eval/episode_reward_std': Array(0.04674177, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04321072, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01509527, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129632, dtype=float32), 'eval/episode_x_position_std': Array(0.00593173, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04321072, dtype=float32), 'eval/episode_y_position_std': Array(0.0059432, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01364616, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.690038919448853, 'eval/sps': 6186.551919903769, 'num_steps': 1254400}
{'eval/walltime': 5210.574292421341, 'training/sps': 127.03948797733203, 'training/walltime': 9983.49452829361, 'training/entropy_loss': Array(0.07498883, dtype=float32), 'training/policy_loss': Array(-0.06769483, dtype=float32), 'training/total_loss': Array(0.00729402, dtype=float32), 'training/v_loss': Array(2.7849413e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008781, dtype=float32), 'eval/episode_forward_reward': Array(-0.03953061, dtype=float32), 'eval/episode_reward': Array(-2.0347545, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03953061, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994038, dtype=float32), 'eval/episode_train_reward': Array(-0.00118592, dtype=float32), 'eval/episode_x_position': Array(1.0069062, dtype=float32), 'eval/episode_x_velocity': Array(-0.03953061, dtype=float32), 'eval/episode_y_position': Array(0.00052775, dtype=float32), 'eval/episode_y_velocity': Array(-0.00118348, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00523938, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04354081, dtype=float32), 'eval/episode_reward_std': Array(0.04863692, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04354081, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02082016, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130622, dtype=float32), 'eval/episode_x_position_std': Array(0.0052338, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04354081, dtype=float32), 'eval/episode_y_position_std': Array(0.00571012, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01385208, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.58939838409424, 'eval/sps': 6216.791652294358, 'num_steps': 1259520}
{'eval/walltime': 5231.241991996765, 'training/sps': 127.40728316005217, 'training/walltime': 10023.680613994598, 'training/entropy_loss': Array(0.0802553, dtype=float32), 'training/policy_loss': Array(0.26501358, dtype=float32), 'training/total_loss': Array(0.34526888, dtype=float32), 'training/v_loss': Array(1.3451191e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0081542, dtype=float32), 'eval/episode_forward_reward': Array(-0.03210339, dtype=float32), 'eval/episode_reward': Array(-2.0317082, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03210339, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986417, dtype=float32), 'eval/episode_train_reward': Array(-0.0009631, dtype=float32), 'eval/episode_x_position': Array(1.0062675, dtype=float32), 'eval/episode_x_velocity': Array(-0.03210339, dtype=float32), 'eval/episode_y_position': Array(-0.00015316, dtype=float32), 'eval/episode_y_velocity': Array(-0.00342057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00542487, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04116337, dtype=float32), 'eval/episode_reward_std': Array(0.04180598, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04116337, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00821377, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012349, dtype=float32), 'eval/episode_x_position_std': Array(0.00539307, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04116337, dtype=float32), 'eval/episode_y_position_std': Array(0.00607276, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01249751, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.667699575424194, 'eval/sps': 6193.238852387995, 'num_steps': 1264640}
{'eval/walltime': 5251.849109172821, 'training/sps': 126.93363200724201, 'training/walltime': 10064.01665353775, 'training/entropy_loss': Array(0.08102132, dtype=float32), 'training/policy_loss': Array(0.26343134, dtype=float32), 'training/total_loss': Array(0.34445268, dtype=float32), 'training/v_loss': Array(1.4357668e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090766, dtype=float32), 'eval/episode_forward_reward': Array(-0.03193125, dtype=float32), 'eval/episode_reward': Array(-2.0275345, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03193125, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946454, dtype=float32), 'eval/episode_train_reward': Array(-0.00095794, dtype=float32), 'eval/episode_x_position': Array(1.0071601, dtype=float32), 'eval/episode_x_velocity': Array(-0.03193125, dtype=float32), 'eval/episode_y_position': Array(0.00023966, dtype=float32), 'eval/episode_y_velocity': Array(-0.00219784, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567016, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04103462, dtype=float32), 'eval/episode_reward_std': Array(0.04489828, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04103462, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01962977, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123104, dtype=float32), 'eval/episode_x_position_std': Array(0.0056692, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04103462, dtype=float32), 'eval/episode_y_position_std': Array(0.00573594, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01081813, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.607117176055908, 'eval/sps': 6211.446215714609, 'num_steps': 1269760}
{'eval/walltime': 5272.558786869049, 'training/sps': 126.96115825687286, 'training/walltime': 10104.34394788742, 'training/entropy_loss': Array(0.08825926, dtype=float32), 'training/policy_loss': Array(0.27270117, dtype=float32), 'training/total_loss': Array(0.36096042, dtype=float32), 'training/v_loss': Array(8.780382e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009547, dtype=float32), 'eval/episode_forward_reward': Array(-0.03834084, dtype=float32), 'eval/episode_reward': Array(-2.0372326, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03834084, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977417, dtype=float32), 'eval/episode_train_reward': Array(-0.00115023, dtype=float32), 'eval/episode_x_position': Array(1.0076678, dtype=float32), 'eval/episode_x_velocity': Array(-0.03834084, dtype=float32), 'eval/episode_y_position': Array(0.00091822, dtype=float32), 'eval/episode_y_velocity': Array(-0.00188329, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00592017, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04312931, dtype=float32), 'eval/episode_reward_std': Array(0.0461214, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04312931, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01128082, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129388, dtype=float32), 'eval/episode_x_position_std': Array(0.0059076, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04312931, dtype=float32), 'eval/episode_y_position_std': Array(0.00551694, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01065791, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.709677696228027, 'eval/sps': 6180.685275624225, 'num_steps': 1274880}
{'eval/walltime': 5293.174797296524, 'training/sps': 127.16866102596869, 'training/walltime': 10144.605439662933, 'training/entropy_loss': Array(0.07213363, dtype=float32), 'training/policy_loss': Array(0.27288783, dtype=float32), 'training/total_loss': Array(0.3450215, dtype=float32), 'training/v_loss': Array(1.6233904e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094907, dtype=float32), 'eval/episode_forward_reward': Array(-0.04289664, dtype=float32), 'eval/episode_reward': Array(-2.042406, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04289664, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982228, dtype=float32), 'eval/episode_train_reward': Array(-0.0012869, dtype=float32), 'eval/episode_x_position': Array(1.0076402, dtype=float32), 'eval/episode_x_velocity': Array(-0.04289664, dtype=float32), 'eval/episode_y_position': Array(-0.00045996, dtype=float32), 'eval/episode_y_velocity': Array(-0.00232776, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582053, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04271071, dtype=float32), 'eval/episode_reward_std': Array(0.04439043, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04271071, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00973111, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128132, dtype=float32), 'eval/episode_x_position_std': Array(0.00582098, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04271071, dtype=float32), 'eval/episode_y_position_std': Array(0.00604583, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01310018, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.616010427474976, 'eval/sps': 6208.7667471012865, 'num_steps': 1280000}
{'eval/walltime': 5313.820820808411, 'training/sps': 127.18572391890586, 'training/walltime': 10184.861530065536, 'training/entropy_loss': Array(0.06954663, dtype=float32), 'training/policy_loss': Array(-0.0837368, dtype=float32), 'training/total_loss': Array(-0.01419012, dtype=float32), 'training/v_loss': Array(4.4777828e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091441, dtype=float32), 'eval/episode_forward_reward': Array(-0.03775543, dtype=float32), 'eval/episode_reward': Array(-2.033734, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03775543, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9948459, dtype=float32), 'eval/episode_train_reward': Array(-0.00113266, dtype=float32), 'eval/episode_x_position': Array(1.0072653, dtype=float32), 'eval/episode_x_velocity': Array(-0.03775543, dtype=float32), 'eval/episode_y_position': Array(0.0007419, dtype=float32), 'eval/episode_y_velocity': Array(-0.00154261, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599065, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04120737, dtype=float32), 'eval/episode_reward_std': Array(0.0457368, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04120737, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01695089, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123622, dtype=float32), 'eval/episode_x_position_std': Array(0.00603788, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04120737, dtype=float32), 'eval/episode_y_position_std': Array(0.00603782, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01156185, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.646023511886597, 'eval/sps': 6199.741074900267, 'num_steps': 1285120}
{'eval/walltime': 5334.417229890823, 'training/sps': 127.25649772625128, 'training/walltime': 10225.095232009888, 'training/entropy_loss': Array(0.07053374, dtype=float32), 'training/policy_loss': Array(-0.1206661, dtype=float32), 'training/total_loss': Array(-0.05013236, dtype=float32), 'training/v_loss': Array(9.280605e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084405, dtype=float32), 'eval/episode_forward_reward': Array(-0.03630614, dtype=float32), 'eval/episode_reward': Array(-2.0321631, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03630614, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947677, dtype=float32), 'eval/episode_train_reward': Array(-0.00108918, dtype=float32), 'eval/episode_x_position': Array(1.0065757, dtype=float32), 'eval/episode_x_velocity': Array(-0.03630614, dtype=float32), 'eval/episode_y_position': Array(0.00059722, dtype=float32), 'eval/episode_y_velocity': Array(-0.00354237, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00549522, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04065293, dtype=float32), 'eval/episode_reward_std': Array(0.05012241, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04065293, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02200112, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121959, dtype=float32), 'eval/episode_x_position_std': Array(0.00548225, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04065293, dtype=float32), 'eval/episode_y_position_std': Array(0.00573338, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01285275, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.59640908241272, 'eval/sps': 6214.675552803, 'num_steps': 1290240}
{'eval/walltime': 5355.089567661285, 'training/sps': 127.15723133581865, 'training/walltime': 10265.360342741013, 'training/entropy_loss': Array(0.07148471, dtype=float32), 'training/policy_loss': Array(-0.08644077, dtype=float32), 'training/total_loss': Array(-0.01495606, dtype=float32), 'training/v_loss': Array(6.988212e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093377, dtype=float32), 'eval/episode_forward_reward': Array(-0.04416138, dtype=float32), 'eval/episode_reward': Array(-2.037972, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04416138, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.992486, dtype=float32), 'eval/episode_train_reward': Array(-0.00132484, dtype=float32), 'eval/episode_x_position': Array(1.007473, dtype=float32), 'eval/episode_x_velocity': Array(-0.04416138, dtype=float32), 'eval/episode_y_position': Array(0.00080283, dtype=float32), 'eval/episode_y_velocity': Array(-0.00237558, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579642, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04578389, dtype=float32), 'eval/episode_reward_std': Array(0.050494, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04578389, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02234221, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137352, dtype=float32), 'eval/episode_x_position_std': Array(0.00575447, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04578389, dtype=float32), 'eval/episode_y_position_std': Array(0.00581424, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01563523, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672337770462036, 'eval/sps': 6191.849292579508, 'num_steps': 1295360}
{'eval/walltime': 5375.738169670105, 'training/sps': 127.01345422511743, 'training/walltime': 10305.671032905579, 'training/entropy_loss': Array(0.07263237, dtype=float32), 'training/policy_loss': Array(-0.06149941, dtype=float32), 'training/total_loss': Array(0.01113296, dtype=float32), 'training/v_loss': Array(5.5393374e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087152, dtype=float32), 'eval/episode_forward_reward': Array(-0.04203292, dtype=float32), 'eval/episode_reward': Array(-2.0365682, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04203292, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9932742, dtype=float32), 'eval/episode_train_reward': Array(-0.00126099, dtype=float32), 'eval/episode_x_position': Array(1.0068316, dtype=float32), 'eval/episode_x_velocity': Array(-0.04203292, dtype=float32), 'eval/episode_y_position': Array(0.00066531, dtype=float32), 'eval/episode_y_velocity': Array(-0.00500418, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00550073, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04386154, dtype=float32), 'eval/episode_reward_std': Array(0.05316374, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04386154, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02096871, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131585, dtype=float32), 'eval/episode_x_position_std': Array(0.00547492, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04386154, dtype=float32), 'eval/episode_y_position_std': Array(0.00602172, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01591097, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64860200881958, 'eval/sps': 6198.96688140571, 'num_steps': 1300480}
{'eval/walltime': 5396.445907592773, 'training/sps': 127.34005954875676, 'training/walltime': 10345.878333091736, 'training/entropy_loss': Array(0.07367049, dtype=float32), 'training/policy_loss': Array(-0.07449197, dtype=float32), 'training/total_loss': Array(-0.00082147, dtype=float32), 'training/v_loss': Array(4.7257895e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0255201, dtype=float32), 'eval/episode_forward_reward': Array(-0.0306489, dtype=float32), 'eval/episode_reward': Array(-2.0607495, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0306489, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.044806, dtype=float32), 'eval/episode_train_reward': Array(-0.00091947, dtype=float32), 'eval/episode_x_position': Array(1.0235345, dtype=float32), 'eval/episode_x_velocity': Array(-0.0306489, dtype=float32), 'eval/episode_y_position': Array(0.00030602, dtype=float32), 'eval/episode_y_velocity': Array(-0.00129557, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12555037, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03961717, dtype=float32), 'eval/episode_reward_std': Array(0.24724878, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03961717, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37246177, dtype=float32), 'eval/episode_train_reward_std': Array(0.00118852, dtype=float32), 'eval/episode_x_position_std': Array(0.12518005, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03961717, dtype=float32), 'eval/episode_y_position_std': Array(0.00584166, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01276569, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.707737922668457, 'eval/sps': 6181.264244216664, 'num_steps': 1305600}
{'eval/walltime': 5417.086916208267, 'training/sps': 127.09274357463909, 'training/walltime': 10386.16387462616, 'training/entropy_loss': Array(0.07477334, dtype=float32), 'training/policy_loss': Array(-0.03337532, dtype=float32), 'training/total_loss': Array(0.04139803, dtype=float32), 'training/v_loss': Array(4.4140336e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094842, dtype=float32), 'eval/episode_forward_reward': Array(-0.03365575, dtype=float32), 'eval/episode_reward': Array(-2.0301137, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03365575, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995448, dtype=float32), 'eval/episode_train_reward': Array(-0.00100967, dtype=float32), 'eval/episode_x_position': Array(1.0075936, dtype=float32), 'eval/episode_x_velocity': Array(-0.03365575, dtype=float32), 'eval/episode_y_position': Array(0.00027179, dtype=float32), 'eval/episode_y_velocity': Array(-0.0022365, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00613666, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0414863, dtype=float32), 'eval/episode_reward_std': Array(0.04546662, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0414863, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01626467, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124459, dtype=float32), 'eval/episode_x_position_std': Array(0.00611134, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0414863, dtype=float32), 'eval/episode_y_position_std': Array(0.00586683, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01237422, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.641008615493774, 'eval/sps': 6201.247351058188, 'num_steps': 1310720}
{'eval/walltime': 5437.761664867401, 'training/sps': 127.11067239098179, 'training/walltime': 10426.443733930588, 'training/entropy_loss': Array(0.07580251, dtype=float32), 'training/policy_loss': Array(0.05899899, dtype=float32), 'training/total_loss': Array(0.1348015, dtype=float32), 'training/v_loss': Array(3.3559782e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089962, dtype=float32), 'eval/episode_forward_reward': Array(-0.03500135, dtype=float32), 'eval/episode_reward': Array(-2.0323067, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03500135, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962552, dtype=float32), 'eval/episode_train_reward': Array(-0.00105004, dtype=float32), 'eval/episode_x_position': Array(1.0070901, dtype=float32), 'eval/episode_x_velocity': Array(-0.03500135, dtype=float32), 'eval/episode_y_position': Array(-0.00044766, dtype=float32), 'eval/episode_y_velocity': Array(-0.00117352, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595008, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04095332, dtype=float32), 'eval/episode_reward_std': Array(0.04546947, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04095332, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01680245, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012286, dtype=float32), 'eval/episode_x_position_std': Array(0.00590726, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04095332, dtype=float32), 'eval/episode_y_position_std': Array(0.00579995, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0140421, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67474865913391, 'eval/sps': 6191.127259167467, 'num_steps': 1315840}
{'eval/walltime': 5458.398666858673, 'training/sps': 127.07844507109996, 'training/walltime': 10466.733808279037, 'training/entropy_loss': Array(0.07741871, dtype=float32), 'training/policy_loss': Array(-0.0550618, dtype=float32), 'training/total_loss': Array(0.02235691, dtype=float32), 'training/v_loss': Array(2.436992e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0165336, dtype=float32), 'eval/episode_forward_reward': Array(-0.04210743, dtype=float32), 'eval/episode_reward': Array(-2.05369, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04210743, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0181317, dtype=float32), 'eval/episode_train_reward': Array(-0.00126322, dtype=float32), 'eval/episode_x_position': Array(1.0146518, dtype=float32), 'eval/episode_x_velocity': Array(-0.04210743, dtype=float32), 'eval/episode_y_position': Array(0.00015273, dtype=float32), 'eval/episode_y_velocity': Array(-0.00067606, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08815084, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04311581, dtype=float32), 'eval/episode_reward_std': Array(0.17937088, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04311581, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26533464, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129347, dtype=float32), 'eval/episode_x_position_std': Array(0.08787865, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04311581, dtype=float32), 'eval/episode_y_position_std': Array(0.00593673, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01405778, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.637001991271973, 'eval/sps': 6202.4513082925105, 'num_steps': 1320960}
{'eval/walltime': 5479.060088396072, 'training/sps': 127.49557632992969, 'training/walltime': 10506.892064332962, 'training/entropy_loss': Array(0.07858017, dtype=float32), 'training/policy_loss': Array(0.17176601, dtype=float32), 'training/total_loss': Array(0.25034618, dtype=float32), 'training/v_loss': Array(1.9784974e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095553, dtype=float32), 'eval/episode_forward_reward': Array(-0.03375921, dtype=float32), 'eval/episode_reward': Array(-2.0311124, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03375921, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963405, dtype=float32), 'eval/episode_train_reward': Array(-0.00101278, dtype=float32), 'eval/episode_x_position': Array(1.0076559, dtype=float32), 'eval/episode_x_velocity': Array(-0.03375921, dtype=float32), 'eval/episode_y_position': Array(-0.00097381, dtype=float32), 'eval/episode_y_velocity': Array(-0.00122427, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567562, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0419502, dtype=float32), 'eval/episode_reward_std': Array(0.04509984, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0419502, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01497346, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125851, dtype=float32), 'eval/episode_x_position_std': Array(0.00566252, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0419502, dtype=float32), 'eval/episode_y_position_std': Array(0.00547324, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01394395, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.661421537399292, 'eval/sps': 6195.12068752418, 'num_steps': 1326080}
{'eval/walltime': 5499.664448022842, 'training/sps': 127.17294307672036, 'training/walltime': 10547.152200460434, 'training/entropy_loss': Array(0.08298471, dtype=float32), 'training/policy_loss': Array(0.26625323, dtype=float32), 'training/total_loss': Array(0.34923798, dtype=float32), 'training/v_loss': Array(1.4761143e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087087, dtype=float32), 'eval/episode_forward_reward': Array(-0.03581013, dtype=float32), 'eval/episode_reward': Array(-2.03287, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03581013, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959857, dtype=float32), 'eval/episode_train_reward': Array(-0.0010743, dtype=float32), 'eval/episode_x_position': Array(1.0068455, dtype=float32), 'eval/episode_x_velocity': Array(-0.03581013, dtype=float32), 'eval/episode_y_position': Array(0.00054445, dtype=float32), 'eval/episode_y_velocity': Array(-0.0032223, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00620823, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04267631, dtype=float32), 'eval/episode_reward_std': Array(0.0479616, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04267631, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01539924, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128029, dtype=float32), 'eval/episode_x_position_std': Array(0.00619343, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04267631, dtype=float32), 'eval/episode_y_position_std': Array(0.00560696, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01244785, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.60435962677002, 'eval/sps': 6212.277514011997, 'num_steps': 1331200}
{'eval/walltime': 5520.316150426865, 'training/sps': 127.18174078678534, 'training/walltime': 10587.409551620483, 'training/entropy_loss': Array(0.08580453, dtype=float32), 'training/policy_loss': Array(0.27035236, dtype=float32), 'training/total_loss': Array(0.35615692, dtype=float32), 'training/v_loss': Array(5.2164455e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090504, dtype=float32), 'eval/episode_forward_reward': Array(-0.0419893, dtype=float32), 'eval/episode_reward': Array(-2.0413084, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0419893, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980593, dtype=float32), 'eval/episode_train_reward': Array(-0.00125968, dtype=float32), 'eval/episode_x_position': Array(1.0071819, dtype=float32), 'eval/episode_x_velocity': Array(-0.0419893, dtype=float32), 'eval/episode_y_position': Array(-0.00056575, dtype=float32), 'eval/episode_y_velocity': Array(-0.00298361, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570117, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04357339, dtype=float32), 'eval/episode_reward_std': Array(0.04571105, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04357339, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01062096, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013072, dtype=float32), 'eval/episode_x_position_std': Array(0.00569695, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04357339, dtype=float32), 'eval/episode_y_position_std': Array(0.00566087, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01073941, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.651702404022217, 'eval/sps': 6198.0362439791, 'num_steps': 1336320}
{'eval/walltime': 5540.954279184341, 'training/sps': 127.08301058589123, 'training/walltime': 10627.69817852974, 'training/entropy_loss': Array(0.08281811, dtype=float32), 'training/policy_loss': Array(0.26924834, dtype=float32), 'training/total_loss': Array(0.3520665, dtype=float32), 'training/v_loss': Array(1.9741545e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0259361, dtype=float32), 'eval/episode_forward_reward': Array(-0.03726392, dtype=float32), 'eval/episode_reward': Array(-2.0636463, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03726392, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0408895, dtype=float32), 'eval/episode_train_reward': Array(-0.00111792, dtype=float32), 'eval/episode_x_position': Array(1.023998, dtype=float32), 'eval/episode_x_velocity': Array(-0.03726392, dtype=float32), 'eval/episode_y_position': Array(0.00048662, dtype=float32), 'eval/episode_y_velocity': Array(-0.0019768, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12768054, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04361706, dtype=float32), 'eval/episode_reward_std': Array(0.2501353, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04361706, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3733739, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130851, dtype=float32), 'eval/episode_x_position_std': Array(0.12731043, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04361706, dtype=float32), 'eval/episode_y_position_std': Array(0.00574831, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01581072, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.638128757476807, 'eval/sps': 6202.11267717903, 'num_steps': 1341440}
{'eval/walltime': 5561.596085071564, 'training/sps': 127.15940055246162, 'training/walltime': 10667.962602376938, 'training/entropy_loss': Array(0.08399524, dtype=float32), 'training/policy_loss': Array(0.26371872, dtype=float32), 'training/total_loss': Array(0.34771395, dtype=float32), 'training/v_loss': Array(1.674512e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087347, dtype=float32), 'eval/episode_forward_reward': Array(-0.0459021, dtype=float32), 'eval/episode_reward': Array(-2.0431185, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0459021, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995839, dtype=float32), 'eval/episode_train_reward': Array(-0.00137706, dtype=float32), 'eval/episode_x_position': Array(1.0068989, dtype=float32), 'eval/episode_x_velocity': Array(-0.0459021, dtype=float32), 'eval/episode_y_position': Array(-0.0004089, dtype=float32), 'eval/episode_y_velocity': Array(-0.00218558, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557774, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04302268, dtype=float32), 'eval/episode_reward_std': Array(0.04781837, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04302268, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01833037, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129068, dtype=float32), 'eval/episode_x_position_std': Array(0.00557457, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04302268, dtype=float32), 'eval/episode_y_position_std': Array(0.00596597, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01456764, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64180588722229, 'eval/sps': 6201.007833294018, 'num_steps': 1346560}
{'eval/walltime': 5582.240668296814, 'training/sps': 126.83583634663516, 'training/walltime': 10708.32974267006, 'training/entropy_loss': Array(0.08710226, dtype=float32), 'training/policy_loss': Array(0.2696676, dtype=float32), 'training/total_loss': Array(0.35676986, dtype=float32), 'training/v_loss': Array(2.8504393e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0164326, dtype=float32), 'eval/episode_forward_reward': Array(-0.04346118, dtype=float32), 'eval/episode_reward': Array(-2.0531716, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04346118, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0162191, dtype=float32), 'eval/episode_train_reward': Array(-0.00130384, dtype=float32), 'eval/episode_x_position': Array(1.0145526, dtype=float32), 'eval/episode_x_velocity': Array(-0.04346118, dtype=float32), 'eval/episode_y_position': Array(-0.00049616, dtype=float32), 'eval/episode_y_velocity': Array(-0.00146845, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0882091, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04494429, dtype=float32), 'eval/episode_reward_std': Array(0.18047263, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04494429, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.265799, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134833, dtype=float32), 'eval/episode_x_position_std': Array(0.0879344, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04494429, dtype=float32), 'eval/episode_y_position_std': Array(0.00610879, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01358037, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.644583225250244, 'eval/sps': 6200.1736050279815, 'num_steps': 1351680}
{'eval/walltime': 5602.942820072174, 'training/sps': 127.16433332994029, 'training/walltime': 10748.592604637146, 'training/entropy_loss': Array(0.08547383, dtype=float32), 'training/policy_loss': Array(0.26916644, dtype=float32), 'training/total_loss': Array(0.35464028, dtype=float32), 'training/v_loss': Array(1.4137729e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097637, dtype=float32), 'eval/episode_forward_reward': Array(-0.03431062, dtype=float32), 'eval/episode_reward': Array(-2.0335898, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03431062, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99825, dtype=float32), 'eval/episode_train_reward': Array(-0.00102932, dtype=float32), 'eval/episode_x_position': Array(1.0078852, dtype=float32), 'eval/episode_x_velocity': Array(-0.03431062, dtype=float32), 'eval/episode_y_position': Array(-0.00065262, dtype=float32), 'eval/episode_y_velocity': Array(-0.00231774, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600305, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04150314, dtype=float32), 'eval/episode_reward_std': Array(0.043313, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04150314, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00936662, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124509, dtype=float32), 'eval/episode_x_position_std': Array(0.00599671, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04150314, dtype=float32), 'eval/episode_y_position_std': Array(0.00557816, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01433293, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.702151775360107, 'eval/sps': 6182.9321603345015, 'num_steps': 1356800}
{'eval/walltime': 5623.55836725235, 'training/sps': 127.22558931726788, 'training/walltime': 10788.836081027985, 'training/entropy_loss': Array(0.08657623, dtype=float32), 'training/policy_loss': Array(0.26930285, dtype=float32), 'training/total_loss': Array(0.35587907, dtype=float32), 'training/v_loss': Array(9.319421e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090954, dtype=float32), 'eval/episode_forward_reward': Array(-0.0421765, dtype=float32), 'eval/episode_reward': Array(-2.0384393, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0421765, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9949975, dtype=float32), 'eval/episode_train_reward': Array(-0.00126529, dtype=float32), 'eval/episode_x_position': Array(1.0072124, dtype=float32), 'eval/episode_x_velocity': Array(-0.0421765, dtype=float32), 'eval/episode_y_position': Array(0.00010064, dtype=float32), 'eval/episode_y_velocity': Array(-0.00343664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575381, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04438737, dtype=float32), 'eval/episode_reward_std': Array(0.04938948, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04438737, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02049853, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133162, dtype=float32), 'eval/episode_x_position_std': Array(0.00570556, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04438737, dtype=float32), 'eval/episode_y_position_std': Array(0.00555451, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01520476, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61554718017578, 'eval/sps': 6208.906262894963, 'num_steps': 1361920}
{'eval/walltime': 5644.226792812347, 'training/sps': 127.21446665851381, 'training/walltime': 10829.083076000214, 'training/entropy_loss': Array(0.08732043, dtype=float32), 'training/policy_loss': Array(0.26945084, dtype=float32), 'training/total_loss': Array(0.35677126, dtype=float32), 'training/v_loss': Array(4.1838216e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097256, dtype=float32), 'eval/episode_forward_reward': Array(-0.0376394, dtype=float32), 'eval/episode_reward': Array(-2.0344481, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0376394, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956794, dtype=float32), 'eval/episode_train_reward': Array(-0.00112918, dtype=float32), 'eval/episode_x_position': Array(1.0078549, dtype=float32), 'eval/episode_x_velocity': Array(-0.0376394, dtype=float32), 'eval/episode_y_position': Array(-0.00025043, dtype=float32), 'eval/episode_y_velocity': Array(-0.00220592, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572843, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0436406, dtype=float32), 'eval/episode_reward_std': Array(0.05031135, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0436406, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01812577, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130922, dtype=float32), 'eval/episode_x_position_std': Array(0.0057565, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0436406, dtype=float32), 'eval/episode_y_position_std': Array(0.00598908, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01471181, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66842555999756, 'eval/sps': 6193.021313037795, 'num_steps': 1367040}
{'eval/walltime': 5664.835998058319, 'training/sps': 127.29428417222852, 'training/walltime': 10869.304834842682, 'training/entropy_loss': Array(0.08695353, dtype=float32), 'training/policy_loss': Array(0.26867512, dtype=float32), 'training/total_loss': Array(0.35562864, dtype=float32), 'training/v_loss': Array(3.8105724e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.010235, dtype=float32), 'eval/episode_forward_reward': Array(-0.03656629, dtype=float32), 'eval/episode_reward': Array(-2.030826, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03656629, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9931626, dtype=float32), 'eval/episode_train_reward': Array(-0.00109699, dtype=float32), 'eval/episode_x_position': Array(1.008356, dtype=float32), 'eval/episode_x_velocity': Array(-0.03656629, dtype=float32), 'eval/episode_y_position': Array(-0.00065382, dtype=float32), 'eval/episode_y_velocity': Array(-0.00219567, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576836, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04319228, dtype=float32), 'eval/episode_reward_std': Array(0.05095058, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04319228, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02119934, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129577, dtype=float32), 'eval/episode_x_position_std': Array(0.00574504, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04319228, dtype=float32), 'eval/episode_y_position_std': Array(0.00593189, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01204509, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.60920524597168, 'eval/sps': 6210.816888488175, 'num_steps': 1372160}
{'eval/walltime': 5685.499162197113, 'training/sps': 127.20684365827562, 'training/walltime': 10909.554241657257, 'training/entropy_loss': Array(0.09050206, dtype=float32), 'training/policy_loss': Array(0.27009416, dtype=float32), 'training/total_loss': Array(0.3605962, dtype=float32), 'training/v_loss': Array(6.4825967e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093728, dtype=float32), 'eval/episode_forward_reward': Array(-0.04067699, dtype=float32), 'eval/episode_reward': Array(-2.0377705, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04067699, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958735, dtype=float32), 'eval/episode_train_reward': Array(-0.00122031, dtype=float32), 'eval/episode_x_position': Array(1.0075331, dtype=float32), 'eval/episode_x_velocity': Array(-0.04067699, dtype=float32), 'eval/episode_y_position': Array(0.00044792, dtype=float32), 'eval/episode_y_velocity': Array(-0.00345164, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588744, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0435692, dtype=float32), 'eval/episode_reward_std': Array(0.04712769, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0435692, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01580262, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130708, dtype=float32), 'eval/episode_x_position_std': Array(0.00589313, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0435692, dtype=float32), 'eval/episode_y_position_std': Array(0.00600049, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01510147, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.663164138793945, 'eval/sps': 6194.598229981975, 'num_steps': 1377280}
{'eval/walltime': 5706.089504957199, 'training/sps': 127.15687143823712, 'training/walltime': 10949.819466352463, 'training/entropy_loss': Array(0.0826975, dtype=float32), 'training/policy_loss': Array(0.27331054, dtype=float32), 'training/total_loss': Array(0.35600805, dtype=float32), 'training/v_loss': Array(3.2637506e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083623, dtype=float32), 'eval/episode_forward_reward': Array(-0.04219978, dtype=float32), 'eval/episode_reward': Array(-2.0369473, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04219978, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9934816, dtype=float32), 'eval/episode_train_reward': Array(-0.00126599, dtype=float32), 'eval/episode_x_position': Array(1.0065194, dtype=float32), 'eval/episode_x_velocity': Array(-0.04219978, dtype=float32), 'eval/episode_y_position': Array(-8.6633634e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00198286, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00556826, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04499609, dtype=float32), 'eval/episode_reward_std': Array(0.05015922, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04499609, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02043506, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134988, dtype=float32), 'eval/episode_x_position_std': Array(0.00555101, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04499609, dtype=float32), 'eval/episode_y_position_std': Array(0.00536278, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01206517, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.59034276008606, 'eval/sps': 6216.506519169038, 'num_steps': 1382400}
{'eval/walltime': 5726.787335634232, 'training/sps': 127.59535673188365, 'training/walltime': 10989.946318387985, 'training/entropy_loss': Array(0.07983503, dtype=float32), 'training/policy_loss': Array(0.26524788, dtype=float32), 'training/total_loss': Array(0.34508288, dtype=float32), 'training/v_loss': Array(6.490013e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094613, dtype=float32), 'eval/episode_forward_reward': Array(-0.03995087, dtype=float32), 'eval/episode_reward': Array(-2.0367744, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03995087, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995625, dtype=float32), 'eval/episode_train_reward': Array(-0.00119853, dtype=float32), 'eval/episode_x_position': Array(1.007618, dtype=float32), 'eval/episode_x_velocity': Array(-0.03995087, dtype=float32), 'eval/episode_y_position': Array(-0.000446, dtype=float32), 'eval/episode_y_velocity': Array(-0.00218654, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567736, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04313422, dtype=float32), 'eval/episode_reward_std': Array(0.04822776, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04313422, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01710322, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129403, dtype=float32), 'eval/episode_x_position_std': Array(0.00571135, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04313422, dtype=float32), 'eval/episode_y_position_std': Array(0.00571578, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01527632, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69783067703247, 'eval/sps': 6184.222974731179, 'num_steps': 1387520}
{'eval/walltime': 5747.388637304306, 'training/sps': 127.2487460303496, 'training/walltime': 11030.18247127533, 'training/entropy_loss': Array(0.08107807, dtype=float32), 'training/policy_loss': Array(-0.02332959, dtype=float32), 'training/total_loss': Array(0.0577485, dtype=float32), 'training/v_loss': Array(1.1779685e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095037, dtype=float32), 'eval/episode_forward_reward': Array(-0.04272023, dtype=float32), 'eval/episode_reward': Array(-2.0405638, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04272023, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965618, dtype=float32), 'eval/episode_train_reward': Array(-0.00128161, dtype=float32), 'eval/episode_x_position': Array(1.0076396, dtype=float32), 'eval/episode_x_velocity': Array(-0.04272023, dtype=float32), 'eval/episode_y_position': Array(-0.00062599, dtype=float32), 'eval/episode_y_velocity': Array(-0.00331188, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582719, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04397948, dtype=float32), 'eval/episode_reward_std': Array(0.05110097, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04397948, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01863625, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131938, dtype=float32), 'eval/episode_x_position_std': Array(0.00586006, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04397948, dtype=float32), 'eval/episode_y_position_std': Array(0.00586571, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01412189, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.601301670074463, 'eval/sps': 6213.199634173278, 'num_steps': 1392640}
{'eval/walltime': 5768.054446220398, 'training/sps': 127.33393604200421, 'training/walltime': 11070.391705036163, 'training/entropy_loss': Array(0.0831608, dtype=float32), 'training/policy_loss': Array(0.04807881, dtype=float32), 'training/total_loss': Array(0.13123961, dtype=float32), 'training/v_loss': Array(6.6171757e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086648, dtype=float32), 'eval/episode_forward_reward': Array(-0.03263556, dtype=float32), 'eval/episode_reward': Array(-2.0289974, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03263556, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9953828, dtype=float32), 'eval/episode_train_reward': Array(-0.00097907, dtype=float32), 'eval/episode_x_position': Array(1.0067528, dtype=float32), 'eval/episode_x_velocity': Array(-0.03263556, dtype=float32), 'eval/episode_y_position': Array(-0.00037041, dtype=float32), 'eval/episode_y_velocity': Array(-0.00196614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00555856, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04097086, dtype=float32), 'eval/episode_reward_std': Array(0.04405511, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04097086, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01640132, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122913, dtype=float32), 'eval/episode_x_position_std': Array(0.00559644, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04097086, dtype=float32), 'eval/episode_y_position_std': Array(0.00559992, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01013823, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66580891609192, 'eval/sps': 6193.805455170438, 'num_steps': 1397760}
{'eval/walltime': 5788.698612689972, 'training/sps': 127.11915522909648, 'training/walltime': 11110.66887640953, 'training/entropy_loss': Array(0.08719942, dtype=float32), 'training/policy_loss': Array(0.2693761, dtype=float32), 'training/total_loss': Array(0.35657555, dtype=float32), 'training/v_loss': Array(4.416461e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096251, dtype=float32), 'eval/episode_forward_reward': Array(-0.04056958, dtype=float32), 'eval/episode_reward': Array(-2.0358748, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04056958, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9940882, dtype=float32), 'eval/episode_train_reward': Array(-0.00121709, dtype=float32), 'eval/episode_x_position': Array(1.00774, dtype=float32), 'eval/episode_x_velocity': Array(-0.04056958, dtype=float32), 'eval/episode_y_position': Array(-7.208361e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00306173, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00535822, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04514745, dtype=float32), 'eval/episode_reward_std': Array(0.04800052, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04514745, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01996295, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135442, dtype=float32), 'eval/episode_x_position_std': Array(0.00531434, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04514745, dtype=float32), 'eval/episode_y_position_std': Array(0.00583734, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01518037, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.644166469573975, 'eval/sps': 6200.298771502858, 'num_steps': 1402880}
{'eval/walltime': 5809.373358011246, 'training/sps': 127.53625050284408, 'training/walltime': 11150.814325094223, 'training/entropy_loss': Array(0.0880411, dtype=float32), 'training/policy_loss': Array(0.26891732, dtype=float32), 'training/total_loss': Array(0.3569584, dtype=float32), 'training/v_loss': Array(4.5798743e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093546, dtype=float32), 'eval/episode_forward_reward': Array(-0.04266769, dtype=float32), 'eval/episode_reward': Array(-2.0380964, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04266769, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9941487, dtype=float32), 'eval/episode_train_reward': Array(-0.00128003, dtype=float32), 'eval/episode_x_position': Array(1.0074887, dtype=float32), 'eval/episode_x_velocity': Array(-0.04266769, dtype=float32), 'eval/episode_y_position': Array(-8.970268e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00198921, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576403, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0451789, dtype=float32), 'eval/episode_reward_std': Array(0.04748261, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0451789, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02017474, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135537, dtype=float32), 'eval/episode_x_position_std': Array(0.00577821, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0451789, dtype=float32), 'eval/episode_y_position_std': Array(0.00557267, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01085926, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.674745321273804, 'eval/sps': 6191.128258701749, 'num_steps': 1408000}
{'eval/walltime': 5829.961318254471, 'training/sps': 127.18424377354799, 'training/walltime': 11191.070883989334, 'training/entropy_loss': Array(0.09286162, dtype=float32), 'training/policy_loss': Array(0.27254272, dtype=float32), 'training/total_loss': Array(0.36540434, dtype=float32), 'training/v_loss': Array(4.7529075e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097016, dtype=float32), 'eval/episode_forward_reward': Array(-0.03310014, dtype=float32), 'eval/episode_reward': Array(-2.030582, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03310014, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964886, dtype=float32), 'eval/episode_train_reward': Array(-0.000993, dtype=float32), 'eval/episode_x_position': Array(1.0078092, dtype=float32), 'eval/episode_x_velocity': Array(-0.03310014, dtype=float32), 'eval/episode_y_position': Array(0.0002147, dtype=float32), 'eval/episode_y_velocity': Array(-0.00100982, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058305, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03968795, dtype=float32), 'eval/episode_reward_std': Array(0.04419942, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03968795, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01480423, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119064, dtype=float32), 'eval/episode_x_position_std': Array(0.00585461, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03968795, dtype=float32), 'eval/episode_y_position_std': Array(0.00593759, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01297004, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.587960243225098, 'eval/sps': 6217.225916886113, 'num_steps': 1413120}
{'eval/walltime': 5850.608334064484, 'training/sps': 127.4309741359497, 'training/walltime': 11231.249498605728, 'training/entropy_loss': Array(0.08503392, dtype=float32), 'training/policy_loss': Array(0.27316433, dtype=float32), 'training/total_loss': Array(0.35819826, dtype=float32), 'training/v_loss': Array(2.3121132e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091712, dtype=float32), 'eval/episode_forward_reward': Array(-0.03723956, dtype=float32), 'eval/episode_reward': Array(-2.0342731, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03723956, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959164, dtype=float32), 'eval/episode_train_reward': Array(-0.00111719, dtype=float32), 'eval/episode_x_position': Array(1.0073066, dtype=float32), 'eval/episode_x_velocity': Array(-0.03723956, dtype=float32), 'eval/episode_y_position': Array(-0.00067194, dtype=float32), 'eval/episode_y_velocity': Array(-0.0007597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590335, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04229745, dtype=float32), 'eval/episode_reward_std': Array(0.0471704, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04229745, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01675675, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126892, dtype=float32), 'eval/episode_x_position_std': Array(0.00589621, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04229745, dtype=float32), 'eval/episode_y_position_std': Array(0.00580829, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01306321, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647015810012817, 'eval/sps': 6199.443114579595, 'num_steps': 1418240}
{'eval/walltime': 5871.208808898926, 'training/sps': 127.32806829688865, 'training/walltime': 11271.460585355759, 'training/entropy_loss': Array(0.08299071, dtype=float32), 'training/policy_loss': Array(0.26643145, dtype=float32), 'training/total_loss': Array(0.3494222, dtype=float32), 'training/v_loss': Array(8.68296e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094081, dtype=float32), 'eval/episode_forward_reward': Array(-0.03888559, dtype=float32), 'eval/episode_reward': Array(-2.0375495, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03888559, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997497, dtype=float32), 'eval/episode_train_reward': Array(-0.00116657, dtype=float32), 'eval/episode_x_position': Array(1.0075445, dtype=float32), 'eval/episode_x_velocity': Array(-0.03888559, dtype=float32), 'eval/episode_y_position': Array(0.00092445, dtype=float32), 'eval/episode_y_velocity': Array(-0.00362018, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00539299, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04236202, dtype=float32), 'eval/episode_reward_std': Array(0.04539563, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04236202, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01262407, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127086, dtype=float32), 'eval/episode_x_position_std': Array(0.00543267, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04236202, dtype=float32), 'eval/episode_y_position_std': Array(0.00578234, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0122152, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.60047483444214, 'eval/sps': 6213.449011670135, 'num_steps': 1423360}
{'eval/walltime': 5891.9177668094635, 'training/sps': 127.40054551222926, 'training/walltime': 11311.648796319962, 'training/entropy_loss': Array(0.08591737, dtype=float32), 'training/policy_loss': Array(0.26299164, dtype=float32), 'training/total_loss': Array(0.34890902, dtype=float32), 'training/v_loss': Array(1.1727362e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096507, dtype=float32), 'eval/episode_forward_reward': Array(-0.03479708, dtype=float32), 'eval/episode_reward': Array(-2.0311613, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03479708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9953203, dtype=float32), 'eval/episode_train_reward': Array(-0.00104391, dtype=float32), 'eval/episode_x_position': Array(1.0077245, dtype=float32), 'eval/episode_x_velocity': Array(-0.03479708, dtype=float32), 'eval/episode_y_position': Array(-0.00021331, dtype=float32), 'eval/episode_y_velocity': Array(-0.00156522, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.005412, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04422883, dtype=float32), 'eval/episode_reward_std': Array(0.04755404, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04422883, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01762029, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132687, dtype=float32), 'eval/episode_x_position_std': Array(0.00542593, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04422883, dtype=float32), 'eval/episode_y_position_std': Array(0.00551983, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01194571, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70895791053772, 'eval/sps': 6180.900099027552, 'num_steps': 1428480}
{'eval/walltime': 5912.536294221878, 'training/sps': 127.04750282253188, 'training/walltime': 11351.948683261871, 'training/entropy_loss': Array(0.08996276, dtype=float32), 'training/policy_loss': Array(0.26764148, dtype=float32), 'training/total_loss': Array(0.35760427, dtype=float32), 'training/v_loss': Array(3.202746e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0080109, dtype=float32), 'eval/episode_forward_reward': Array(-0.04118254, dtype=float32), 'eval/episode_reward': Array(-2.0386515, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04118254, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962335, dtype=float32), 'eval/episode_train_reward': Array(-0.00123548, dtype=float32), 'eval/episode_x_position': Array(1.0061557, dtype=float32), 'eval/episode_x_velocity': Array(-0.04118254, dtype=float32), 'eval/episode_y_position': Array(0.00040084, dtype=float32), 'eval/episode_y_velocity': Array(-0.0017829, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590976, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0441973, dtype=float32), 'eval/episode_reward_std': Array(0.05074422, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0441973, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01833487, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132592, dtype=float32), 'eval/episode_x_position_std': Array(0.00589348, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0441973, dtype=float32), 'eval/episode_y_position_std': Array(0.00574671, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01616024, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61852741241455, 'eval/sps': 6208.008818463454, 'num_steps': 1433600}
{'eval/walltime': 5933.221647024155, 'training/sps': 127.33226595964534, 'training/walltime': 11392.158444404602, 'training/entropy_loss': Array(0.08629474, dtype=float32), 'training/policy_loss': Array(0.27338544, dtype=float32), 'training/total_loss': Array(0.35968018, dtype=float32), 'training/v_loss': Array(2.6962363e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.00883, dtype=float32), 'eval/episode_forward_reward': Array(-0.03832959, dtype=float32), 'eval/episode_reward': Array(-2.0366359, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03832959, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971566, dtype=float32), 'eval/episode_train_reward': Array(-0.00114989, dtype=float32), 'eval/episode_x_position': Array(1.0069436, dtype=float32), 'eval/episode_x_velocity': Array(-0.03832959, dtype=float32), 'eval/episode_y_position': Array(-0.00054468, dtype=float32), 'eval/episode_y_velocity': Array(-0.00207341, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568835, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04361989, dtype=float32), 'eval/episode_reward_std': Array(0.0474711, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04361989, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01280293, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013086, dtype=float32), 'eval/episode_x_position_std': Array(0.00568755, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04361989, dtype=float32), 'eval/episode_y_position_std': Array(0.00557335, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01409162, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68535280227661, 'eval/sps': 6187.953438527403, 'num_steps': 1438720}
{'eval/walltime': 5953.845712184906, 'training/sps': 127.27519239740222, 'training/walltime': 11432.386236667633, 'training/entropy_loss': Array(0.08601866, dtype=float32), 'training/policy_loss': Array(0.27090138, dtype=float32), 'training/total_loss': Array(0.35692006, dtype=float32), 'training/v_loss': Array(2.562055e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090132, dtype=float32), 'eval/episode_forward_reward': Array(-0.03465459, dtype=float32), 'eval/episode_reward': Array(-2.03414, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03465459, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984457, dtype=float32), 'eval/episode_train_reward': Array(-0.00103964, dtype=float32), 'eval/episode_x_position': Array(1.0070946, dtype=float32), 'eval/episode_x_velocity': Array(-0.03465459, dtype=float32), 'eval/episode_y_position': Array(-0.0001615, dtype=float32), 'eval/episode_y_velocity': Array(-0.00108589, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00598805, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04391211, dtype=float32), 'eval/episode_reward_std': Array(0.04440186, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04391211, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00946789, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131736, dtype=float32), 'eval/episode_x_position_std': Array(0.00595023, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04391211, dtype=float32), 'eval/episode_y_position_std': Array(0.00542902, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00848857, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.624065160751343, 'eval/sps': 6206.34191185502, 'num_steps': 1443840}
{'eval/walltime': 5974.534617185593, 'training/sps': 127.23519866551509, 'training/walltime': 11472.626673698425, 'training/entropy_loss': Array(0.08797097, dtype=float32), 'training/policy_loss': Array(0.2696553, dtype=float32), 'training/total_loss': Array(0.35762626, dtype=float32), 'training/v_loss': Array(5.352581e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091199, dtype=float32), 'eval/episode_forward_reward': Array(-0.04690932, dtype=float32), 'eval/episode_reward': Array(-2.0431619, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04690932, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994845, dtype=float32), 'eval/episode_train_reward': Array(-0.00140728, dtype=float32), 'eval/episode_x_position': Array(1.0072749, dtype=float32), 'eval/episode_x_velocity': Array(-0.04690932, dtype=float32), 'eval/episode_y_position': Array(-0.0010165, dtype=float32), 'eval/episode_y_velocity': Array(-0.00234915, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588984, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0459746, dtype=float32), 'eval/episode_reward_std': Array(0.05260087, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0459746, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01777283, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137924, dtype=float32), 'eval/episode_x_position_std': Array(0.00587496, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0459746, dtype=float32), 'eval/episode_y_position_std': Array(0.00597887, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01615073, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.688905000686646, 'eval/sps': 6186.890992817252, 'num_steps': 1448960}
{'eval/walltime': 5995.150408506393, 'training/sps': 127.18486972394572, 'training/walltime': 11512.883034467697, 'training/entropy_loss': Array(0.08622228, dtype=float32), 'training/policy_loss': Array(0.26708823, dtype=float32), 'training/total_loss': Array(0.35331053, dtype=float32), 'training/v_loss': Array(9.692442e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096724, dtype=float32), 'eval/episode_forward_reward': Array(-0.03877577, dtype=float32), 'eval/episode_reward': Array(-2.037044, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03877577, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971051, dtype=float32), 'eval/episode_train_reward': Array(-0.00116327, dtype=float32), 'eval/episode_x_position': Array(1.007781, dtype=float32), 'eval/episode_x_velocity': Array(-0.03877577, dtype=float32), 'eval/episode_y_position': Array(5.0020157e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00334532, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0056554, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04316926, dtype=float32), 'eval/episode_reward_std': Array(0.04819699, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04316926, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01406173, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129508, dtype=float32), 'eval/episode_x_position_std': Array(0.00561736, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04316926, dtype=float32), 'eval/episode_y_position_std': Array(0.00605868, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01529897, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61579132080078, 'eval/sps': 6208.832734489868, 'num_steps': 1454080}
{'eval/walltime': 6015.830483198166, 'training/sps': 127.256017365118, 'training/walltime': 11553.116888284683, 'training/entropy_loss': Array(0.09110768, dtype=float32), 'training/policy_loss': Array(0.26828033, dtype=float32), 'training/total_loss': Array(0.359388, dtype=float32), 'training/v_loss': Array(5.229724e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093215, dtype=float32), 'eval/episode_forward_reward': Array(-0.04819168, dtype=float32), 'eval/episode_reward': Array(-2.043459, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04819168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9938216, dtype=float32), 'eval/episode_train_reward': Array(-0.00144575, dtype=float32), 'eval/episode_x_position': Array(1.0075173, dtype=float32), 'eval/episode_x_velocity': Array(-0.04819168, dtype=float32), 'eval/episode_y_position': Array(0.00024034, dtype=float32), 'eval/episode_y_velocity': Array(-0.0045685, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558073, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04471165, dtype=float32), 'eval/episode_reward_std': Array(0.05218611, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04471165, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01867287, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134135, dtype=float32), 'eval/episode_x_position_std': Array(0.00556778, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04471165, dtype=float32), 'eval/episode_y_position_std': Array(0.00589128, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01581479, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68007469177246, 'eval/sps': 6189.532770446164, 'num_steps': 1459200}
{'eval/walltime': 6036.43933391571, 'training/sps': 127.13252360241412, 'training/walltime': 11593.389824390411, 'training/entropy_loss': Array(0.08669271, dtype=float32), 'training/policy_loss': Array(0.2680002, dtype=float32), 'training/total_loss': Array(0.3546929, dtype=float32), 'training/v_loss': Array(8.704679e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093545, dtype=float32), 'eval/episode_forward_reward': Array(-0.03957042, dtype=float32), 'eval/episode_reward': Array(-2.0377865, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03957042, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970288, dtype=float32), 'eval/episode_train_reward': Array(-0.00118711, dtype=float32), 'eval/episode_x_position': Array(1.0075104, dtype=float32), 'eval/episode_x_velocity': Array(-0.03957042, dtype=float32), 'eval/episode_y_position': Array(0.00093359, dtype=float32), 'eval/episode_y_velocity': Array(-0.00240977, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595157, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04284799, dtype=float32), 'eval/episode_reward_std': Array(0.04568731, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04284799, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01369237, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128544, dtype=float32), 'eval/episode_x_position_std': Array(0.00593515, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04284799, dtype=float32), 'eval/episode_y_position_std': Array(0.00558743, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01210408, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.608850717544556, 'eval/sps': 6210.923731473881, 'num_steps': 1464320}
{'eval/walltime': 6057.152623653412, 'training/sps': 127.43344837620127, 'training/walltime': 11633.567658901215, 'training/entropy_loss': Array(0.08681032, dtype=float32), 'training/policy_loss': Array(0.17083555, dtype=float32), 'training/total_loss': Array(0.2576459, dtype=float32), 'training/v_loss': Array(5.269063e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0170257, dtype=float32), 'eval/episode_forward_reward': Array(-0.03434268, dtype=float32), 'eval/episode_reward': Array(-2.0425353, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03434268, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.014975, dtype=float32), 'eval/episode_train_reward': Array(-0.00103028, dtype=float32), 'eval/episode_x_position': Array(1.0151078, dtype=float32), 'eval/episode_x_velocity': Array(-0.03434268, dtype=float32), 'eval/episode_y_position': Array(-8.633081e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00176579, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09001967, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03958508, dtype=float32), 'eval/episode_reward_std': Array(0.18199643, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03958508, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26604345, dtype=float32), 'eval/episode_train_reward_std': Array(0.00118755, dtype=float32), 'eval/episode_x_position_std': Array(0.08975916, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03958508, dtype=float32), 'eval/episode_y_position_std': Array(0.00527287, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0117112, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.713289737701416, 'eval/sps': 6179.607470416447, 'num_steps': 1469440}
{'eval/walltime': 6077.758426904678, 'training/sps': 127.254197756852, 'training/walltime': 11673.802088022232, 'training/entropy_loss': Array(0.08956061, dtype=float32), 'training/policy_loss': Array(0.26513347, dtype=float32), 'training/total_loss': Array(0.3546941, dtype=float32), 'training/v_loss': Array(1.1705181e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0082712, dtype=float32), 'eval/episode_forward_reward': Array(-0.04575083, dtype=float32), 'eval/episode_reward': Array(-2.0432796, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04575083, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961562, dtype=float32), 'eval/episode_train_reward': Array(-0.00137253, dtype=float32), 'eval/episode_x_position': Array(1.0064578, dtype=float32), 'eval/episode_x_velocity': Array(-0.04575083, dtype=float32), 'eval/episode_y_position': Array(0.00061293, dtype=float32), 'eval/episode_y_velocity': Array(-0.00533133, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576943, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04095043, dtype=float32), 'eval/episode_reward_std': Array(0.04568487, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04095043, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01589996, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122851, dtype=float32), 'eval/episode_x_position_std': Array(0.00575489, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04095043, dtype=float32), 'eval/episode_y_position_std': Array(0.0057675, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01055227, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.60580325126648, 'eval/sps': 6211.8422872999545, 'num_steps': 1474560}
{'eval/walltime': 6098.440272808075, 'training/sps': 127.04745847655147, 'training/walltime': 11714.101989030838, 'training/entropy_loss': Array(0.09301263, dtype=float32), 'training/policy_loss': Array(0.26104033, dtype=float32), 'training/total_loss': Array(0.354053, dtype=float32), 'training/v_loss': Array(1.8087202e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085595, dtype=float32), 'eval/episode_forward_reward': Array(-0.03858128, dtype=float32), 'eval/episode_reward': Array(-2.035355, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03858128, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956164, dtype=float32), 'eval/episode_train_reward': Array(-0.00115744, dtype=float32), 'eval/episode_x_position': Array(1.0067059, dtype=float32), 'eval/episode_x_velocity': Array(-0.03858128, dtype=float32), 'eval/episode_y_position': Array(-1.2725854e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00299047, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578475, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04358893, dtype=float32), 'eval/episode_reward_std': Array(0.04969632, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04358893, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01757017, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130767, dtype=float32), 'eval/episode_x_position_std': Array(0.00574345, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04358893, dtype=float32), 'eval/episode_y_position_std': Array(0.00562615, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01422175, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.681845903396606, 'eval/sps': 6189.00269337073, 'num_steps': 1479680}
{'eval/walltime': 6119.064455270767, 'training/sps': 127.15155528052321, 'training/walltime': 11754.36889719963, 'training/entropy_loss': Array(0.09573492, dtype=float32), 'training/policy_loss': Array(0.2717957, dtype=float32), 'training/total_loss': Array(0.36753058, dtype=float32), 'training/v_loss': Array(1.2476942e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092499, dtype=float32), 'eval/episode_forward_reward': Array(-0.03688907, dtype=float32), 'eval/episode_reward': Array(-2.0338113, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03688907, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958158, dtype=float32), 'eval/episode_train_reward': Array(-0.00110667, dtype=float32), 'eval/episode_x_position': Array(1.0073762, dtype=float32), 'eval/episode_x_velocity': Array(-0.03688907, dtype=float32), 'eval/episode_y_position': Array(0.00022765, dtype=float32), 'eval/episode_y_velocity': Array(-0.00311214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599238, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04424825, dtype=float32), 'eval/episode_reward_std': Array(0.04832248, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04424825, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01684828, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132745, dtype=float32), 'eval/episode_x_position_std': Array(0.00591678, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04424825, dtype=float32), 'eval/episode_y_position_std': Array(0.00619225, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01365741, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62418246269226, 'eval/sps': 6206.306612712687, 'num_steps': 1484800}
{'eval/walltime': 6139.736035585403, 'training/sps': 127.0600043620224, 'training/walltime': 11794.664819002151, 'training/entropy_loss': Array(0.09325029, dtype=float32), 'training/policy_loss': Array(0.27040237, dtype=float32), 'training/total_loss': Array(0.3636527, dtype=float32), 'training/v_loss': Array(1.8858803e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0186734, dtype=float32), 'eval/episode_forward_reward': Array(-0.03444225, dtype=float32), 'eval/episode_reward': Array(-2.048191, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03444225, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0205283, dtype=float32), 'eval/episode_train_reward': Array(-0.00103327, dtype=float32), 'eval/episode_x_position': Array(1.0167773, dtype=float32), 'eval/episode_x_velocity': Array(-0.03444225, dtype=float32), 'eval/episode_y_position': Array(-0.00084125, dtype=float32), 'eval/episode_y_velocity': Array(0.0003917, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08821583, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04253049, dtype=float32), 'eval/episode_reward_std': Array(0.17840964, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04253049, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26462528, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127591, dtype=float32), 'eval/episode_x_position_std': Array(0.08794389, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04253049, dtype=float32), 'eval/episode_y_position_std': Array(0.00581125, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01424523, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.67158031463623, 'eval/sps': 6192.076176651639, 'num_steps': 1489920}
{'eval/walltime': 6160.358560562134, 'training/sps': 127.18355757026373, 'training/walltime': 11834.921595096588, 'training/entropy_loss': Array(0.08936362, dtype=float32), 'training/policy_loss': Array(0.26848346, dtype=float32), 'training/total_loss': Array(0.35784703, dtype=float32), 'training/v_loss': Array(7.2916935e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009172, dtype=float32), 'eval/episode_forward_reward': Array(-0.04229159, dtype=float32), 'eval/episode_reward': Array(-2.038045, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04229159, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9944847, dtype=float32), 'eval/episode_train_reward': Array(-0.00126875, dtype=float32), 'eval/episode_x_position': Array(1.0073127, dtype=float32), 'eval/episode_x_velocity': Array(-0.04229159, dtype=float32), 'eval/episode_y_position': Array(-0.00058735, dtype=float32), 'eval/episode_y_velocity': Array(-0.00127102, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594506, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04492815, dtype=float32), 'eval/episode_reward_std': Array(0.04994098, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04492815, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01894888, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134784, dtype=float32), 'eval/episode_x_position_std': Array(0.00597058, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04492815, dtype=float32), 'eval/episode_y_position_std': Array(0.00561527, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01578026, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.622524976730347, 'eval/sps': 6206.805429714848, 'num_steps': 1495040}
{'eval/walltime': 6181.052371501923, 'training/sps': 127.26752063517068, 'training/walltime': 11875.151812314987, 'training/entropy_loss': Array(0.08622615, dtype=float32), 'training/policy_loss': Array(0.2703386, dtype=float32), 'training/total_loss': Array(0.35656476, dtype=float32), 'training/v_loss': Array(1.1332127e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0162513, dtype=float32), 'eval/episode_forward_reward': Array(-0.0431748, dtype=float32), 'eval/episode_reward': Array(-2.057285, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0431748, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0206275, dtype=float32), 'eval/episode_train_reward': Array(-0.00129524, dtype=float32), 'eval/episode_x_position': Array(1.0143628, dtype=float32), 'eval/episode_x_velocity': Array(-0.0431748, dtype=float32), 'eval/episode_y_position': Array(0.00023677, dtype=float32), 'eval/episode_y_velocity': Array(-0.00373158, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09084688, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0449683, dtype=float32), 'eval/episode_reward_std': Array(0.17984222, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0449683, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26466405, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134905, dtype=float32), 'eval/episode_x_position_std': Array(0.09058241, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0449683, dtype=float32), 'eval/episode_y_position_std': Array(0.0058792, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01400891, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.69381093978882, 'eval/sps': 6185.424249425671, 'num_steps': 1500160}
{'eval/walltime': 6201.721942186356, 'training/sps': 127.02017728662015, 'training/walltime': 11915.460368871689, 'training/entropy_loss': Array(0.08978933, dtype=float32), 'training/policy_loss': Array(0.27017924, dtype=float32), 'training/total_loss': Array(0.3599686, dtype=float32), 'training/v_loss': Array(5.5047416e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009757, dtype=float32), 'eval/episode_forward_reward': Array(-0.03878392, dtype=float32), 'eval/episode_reward': Array(-2.035511, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03878392, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955635, dtype=float32), 'eval/episode_train_reward': Array(-0.00116352, dtype=float32), 'eval/episode_x_position': Array(1.0078549, dtype=float32), 'eval/episode_x_velocity': Array(-0.03878392, dtype=float32), 'eval/episode_y_position': Array(0.00043101, dtype=float32), 'eval/episode_y_velocity': Array(-0.00325237, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614447, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04360426, dtype=float32), 'eval/episode_reward_std': Array(0.04601257, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04360426, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01547631, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130813, dtype=float32), 'eval/episode_x_position_std': Array(0.00615279, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04360426, dtype=float32), 'eval/episode_y_position_std': Array(0.00567278, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0112485, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.669570684432983, 'eval/sps': 6192.678210602677, 'num_steps': 1505280}
{'eval/walltime': 6222.427640914917, 'training/sps': 127.04131046910717, 'training/walltime': 11955.762220144272, 'training/entropy_loss': Array(0.08479442, dtype=float32), 'training/policy_loss': Array(0.27236384, dtype=float32), 'training/total_loss': Array(0.35715827, dtype=float32), 'training/v_loss': Array(1.7418076e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0103068, dtype=float32), 'eval/episode_forward_reward': Array(-0.03808737, dtype=float32), 'eval/episode_reward': Array(-2.0355163, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03808737, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962864, dtype=float32), 'eval/episode_train_reward': Array(-0.00114262, dtype=float32), 'eval/episode_x_position': Array(1.0084249, dtype=float32), 'eval/episode_x_velocity': Array(-0.03808737, dtype=float32), 'eval/episode_y_position': Array(0.00048112, dtype=float32), 'eval/episode_y_velocity': Array(-0.00322691, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00543524, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04420902, dtype=float32), 'eval/episode_reward_std': Array(0.04659913, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04420902, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01577698, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132627, dtype=float32), 'eval/episode_x_position_std': Array(0.00539671, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04420902, dtype=float32), 'eval/episode_y_position_std': Array(0.00608521, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00979372, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7056987285614, 'eval/sps': 6181.87300404584, 'num_steps': 1510400}
{'eval/walltime': 6243.061376571655, 'training/sps': 127.23125916975553, 'training/walltime': 11996.003903150558, 'training/entropy_loss': Array(0.08439457, dtype=float32), 'training/policy_loss': Array(0.26430058, dtype=float32), 'training/total_loss': Array(0.3486952, dtype=float32), 'training/v_loss': Array(1.8039747e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093929, dtype=float32), 'eval/episode_forward_reward': Array(-0.03485964, dtype=float32), 'eval/episode_reward': Array(-2.0310183, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03485964, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9951124, dtype=float32), 'eval/episode_train_reward': Array(-0.00104579, dtype=float32), 'eval/episode_x_position': Array(1.0074983, dtype=float32), 'eval/episode_x_velocity': Array(-0.03485964, dtype=float32), 'eval/episode_y_position': Array(5.8702775e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.0017567, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00510419, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04108085, dtype=float32), 'eval/episode_reward_std': Array(0.04363958, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04108085, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02014572, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123243, dtype=float32), 'eval/episode_x_position_std': Array(0.0051437, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04108085, dtype=float32), 'eval/episode_y_position_std': Array(0.00627041, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01806947, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63373565673828, 'eval/sps': 6203.433160596856, 'num_steps': 1515520}
{'eval/walltime': 6263.7540011405945, 'training/sps': 127.37729876773699, 'training/walltime': 12036.19944858551, 'training/entropy_loss': Array(0.09371906, dtype=float32), 'training/policy_loss': Array(0.27085853, dtype=float32), 'training/total_loss': Array(0.36457762, dtype=float32), 'training/v_loss': Array(2.2695188e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090399, dtype=float32), 'eval/episode_forward_reward': Array(-0.0379476, dtype=float32), 'eval/episode_reward': Array(-2.036916, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0379476, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99783, dtype=float32), 'eval/episode_train_reward': Array(-0.00113843, dtype=float32), 'eval/episode_x_position': Array(1.0071999, dtype=float32), 'eval/episode_x_velocity': Array(-0.0379476, dtype=float32), 'eval/episode_y_position': Array(0.00115147, dtype=float32), 'eval/episode_y_velocity': Array(-0.00222804, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558981, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04111462, dtype=float32), 'eval/episode_reward_std': Array(0.04412397, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04111462, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01177389, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123344, dtype=float32), 'eval/episode_x_position_std': Array(0.00556682, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04111462, dtype=float32), 'eval/episode_y_position_std': Array(0.00582363, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01421703, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69262456893921, 'eval/sps': 6185.778878535069, 'num_steps': 1520640}
{'eval/walltime': 6284.368572473526, 'training/sps': 127.10491247151711, 'training/walltime': 12076.48113322258, 'training/entropy_loss': Array(0.08688629, dtype=float32), 'training/policy_loss': Array(0.2727082, dtype=float32), 'training/total_loss': Array(0.35959452, dtype=float32), 'training/v_loss': Array(3.3817578e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096328, dtype=float32), 'eval/episode_forward_reward': Array(-0.03434555, dtype=float32), 'eval/episode_reward': Array(-2.0279727, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03434555, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9925969, dtype=float32), 'eval/episode_train_reward': Array(-0.00103037, dtype=float32), 'eval/episode_x_position': Array(1.0077589, dtype=float32), 'eval/episode_x_velocity': Array(-0.03434555, dtype=float32), 'eval/episode_y_position': Array(-0.00047292, dtype=float32), 'eval/episode_y_velocity': Array(-0.00035221, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566587, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04226308, dtype=float32), 'eval/episode_reward_std': Array(0.05006279, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04226308, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02609043, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126789, dtype=float32), 'eval/episode_x_position_std': Array(0.00562239, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04226308, dtype=float32), 'eval/episode_y_position_std': Array(0.00582497, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01686003, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61457133293152, 'eval/sps': 6209.200178493239, 'num_steps': 1525760}
{'eval/walltime': 6305.069710493088, 'training/sps': 127.19026927270487, 'training/walltime': 12116.735785007477, 'training/entropy_loss': Array(0.0848835, dtype=float32), 'training/policy_loss': Array(0.267982, dtype=float32), 'training/total_loss': Array(0.35286552, dtype=float32), 'training/v_loss': Array(6.4778085e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098839, dtype=float32), 'eval/episode_forward_reward': Array(-0.04340429, dtype=float32), 'eval/episode_reward': Array(-2.0415597, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04340429, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968529, dtype=float32), 'eval/episode_train_reward': Array(-0.00130213, dtype=float32), 'eval/episode_x_position': Array(1.0080556, dtype=float32), 'eval/episode_x_velocity': Array(-0.04340429, dtype=float32), 'eval/episode_y_position': Array(0.00057535, dtype=float32), 'eval/episode_y_velocity': Array(-0.00122247, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0054165, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04449312, dtype=float32), 'eval/episode_reward_std': Array(0.04643258, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04449312, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01408243, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133479, dtype=float32), 'eval/episode_x_position_std': Array(0.00539465, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04449312, dtype=float32), 'eval/episode_y_position_std': Array(0.00588712, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01160046, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.701138019561768, 'eval/sps': 6183.234944815353, 'num_steps': 1530880}
{'eval/walltime': 6325.668098211288, 'training/sps': 127.41549341122199, 'training/walltime': 12156.919281244278, 'training/entropy_loss': Array(0.08740862, dtype=float32), 'training/policy_loss': Array(0.06708413, dtype=float32), 'training/total_loss': Array(0.15449277, dtype=float32), 'training/v_loss': Array(1.1316141e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100036, dtype=float32), 'eval/episode_forward_reward': Array(-0.03498855, dtype=float32), 'eval/episode_reward': Array(-2.0336745, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03498855, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976363, dtype=float32), 'eval/episode_train_reward': Array(-0.00104966, dtype=float32), 'eval/episode_x_position': Array(1.0081125, dtype=float32), 'eval/episode_x_velocity': Array(-0.03498855, dtype=float32), 'eval/episode_y_position': Array(-9.608251e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00075154, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058187, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04237799, dtype=float32), 'eval/episode_reward_std': Array(0.0449733, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04237799, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01091056, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127134, dtype=float32), 'eval/episode_x_position_std': Array(0.00584034, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04237799, dtype=float32), 'eval/episode_y_position_std': Array(0.00636871, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01087033, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.598387718200684, 'eval/sps': 6214.078584747655, 'num_steps': 1536000}
{'eval/walltime': 6346.346937894821, 'training/sps': 127.22819503489654, 'training/walltime': 12197.161933422089, 'training/entropy_loss': Array(0.0912719, dtype=float32), 'training/policy_loss': Array(0.26745707, dtype=float32), 'training/total_loss': Array(0.35872898, dtype=float32), 'training/v_loss': Array(4.4805873e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009846, dtype=float32), 'eval/episode_forward_reward': Array(-0.03985595, dtype=float32), 'eval/episode_reward': Array(-2.037361, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03985595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963093, dtype=float32), 'eval/episode_train_reward': Array(-0.00119568, dtype=float32), 'eval/episode_x_position': Array(1.0079422, dtype=float32), 'eval/episode_x_velocity': Array(-0.03985595, dtype=float32), 'eval/episode_y_position': Array(0.00045757, dtype=float32), 'eval/episode_y_velocity': Array(-0.00176799, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00623623, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04264504, dtype=float32), 'eval/episode_reward_std': Array(0.04687773, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04264504, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01569487, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127935, dtype=float32), 'eval/episode_x_position_std': Array(0.0062156, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04264504, dtype=float32), 'eval/episode_y_position_std': Array(0.00595439, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01358732, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.678839683532715, 'eval/sps': 6189.902429676985, 'num_steps': 1541120}
{'eval/walltime': 6366.95893907547, 'training/sps': 127.25140246334756, 'training/walltime': 12237.397246360779, 'training/entropy_loss': Array(0.09355085, dtype=float32), 'training/policy_loss': Array(0.26888505, dtype=float32), 'training/total_loss': Array(0.3624359, dtype=float32), 'training/v_loss': Array(7.009211e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097389, dtype=float32), 'eval/episode_forward_reward': Array(-0.04339288, dtype=float32), 'eval/episode_reward': Array(-2.0411913, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04339288, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964967, dtype=float32), 'eval/episode_train_reward': Array(-0.00130179, dtype=float32), 'eval/episode_x_position': Array(1.007895, dtype=float32), 'eval/episode_x_velocity': Array(-0.04339288, dtype=float32), 'eval/episode_y_position': Array(0.00052937, dtype=float32), 'eval/episode_y_velocity': Array(-0.00242951, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581402, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04339877, dtype=float32), 'eval/episode_reward_std': Array(0.04479734, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04339877, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01535412, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130196, dtype=float32), 'eval/episode_x_position_std': Array(0.00579342, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04339877, dtype=float32), 'eval/episode_y_position_std': Array(0.0062397, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01453158, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.612001180648804, 'eval/sps': 6209.97441627213, 'num_steps': 1546240}
{'eval/walltime': 6387.66903758049, 'training/sps': 127.21728369227166, 'training/walltime': 12277.64335012436, 'training/entropy_loss': Array(0.09104881, dtype=float32), 'training/policy_loss': Array(0.27360058, dtype=float32), 'training/total_loss': Array(0.36464936, dtype=float32), 'training/v_loss': Array(5.1368136e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.018081, dtype=float32), 'eval/episode_forward_reward': Array(-0.03371931, dtype=float32), 'eval/episode_reward': Array(-2.0470762, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03371931, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0201578, dtype=float32), 'eval/episode_train_reward': Array(-0.00101158, dtype=float32), 'eval/episode_x_position': Array(1.0161314, dtype=float32), 'eval/episode_x_velocity': Array(-0.03371931, dtype=float32), 'eval/episode_y_position': Array(-0.00041826, dtype=float32), 'eval/episode_y_velocity': Array(-0.00079456, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0881232, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04243718, dtype=float32), 'eval/episode_reward_std': Array(0.17867048, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04243718, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26462883, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127312, dtype=float32), 'eval/episode_x_position_std': Array(0.08785382, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04243718, dtype=float32), 'eval/episode_y_position_std': Array(0.0058096, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01054808, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.71009850502014, 'eval/sps': 6180.559690190402, 'num_steps': 1551360}
{'eval/walltime': 6408.305729627609, 'training/sps': 127.14115237698662, 'training/walltime': 12317.913552999496, 'training/entropy_loss': Array(0.08834251, dtype=float32), 'training/policy_loss': Array(0.26710522, dtype=float32), 'training/total_loss': Array(0.3554477, dtype=float32), 'training/v_loss': Array(8.087429e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090824, dtype=float32), 'eval/episode_forward_reward': Array(-0.03634021, dtype=float32), 'eval/episode_reward': Array(-2.0351365, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03634021, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997706, dtype=float32), 'eval/episode_train_reward': Array(-0.00109021, dtype=float32), 'eval/episode_x_position': Array(1.0071667, dtype=float32), 'eval/episode_x_velocity': Array(-0.03634021, dtype=float32), 'eval/episode_y_position': Array(-3.2216936e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00344592, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590424, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04219477, dtype=float32), 'eval/episode_reward_std': Array(0.04415125, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04219477, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01171194, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126584, dtype=float32), 'eval/episode_x_position_std': Array(0.0058943, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04219477, dtype=float32), 'eval/episode_y_position_std': Array(0.00582583, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00993091, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63669204711914, 'eval/sps': 6202.544463412132, 'num_steps': 1556480}
{'eval/walltime': 6428.986472129822, 'training/sps': 127.23416213083053, 'training/walltime': 12358.154317855835, 'training/entropy_loss': Array(0.09207054, dtype=float32), 'training/policy_loss': Array(0.20275058, dtype=float32), 'training/total_loss': Array(0.29482114, dtype=float32), 'training/v_loss': Array(3.1249186e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089648, dtype=float32), 'eval/episode_forward_reward': Array(-0.03651134, dtype=float32), 'eval/episode_reward': Array(-2.0344415, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03651134, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968348, dtype=float32), 'eval/episode_train_reward': Array(-0.00109534, dtype=float32), 'eval/episode_x_position': Array(1.0070682, dtype=float32), 'eval/episode_x_velocity': Array(-0.03651134, dtype=float32), 'eval/episode_y_position': Array(0.00049381, dtype=float32), 'eval/episode_y_velocity': Array(0.00076845, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580379, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04274424, dtype=float32), 'eval/episode_reward_std': Array(0.04725772, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04274424, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01316899, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128233, dtype=float32), 'eval/episode_x_position_std': Array(0.00583727, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04274424, dtype=float32), 'eval/episode_y_position_std': Array(0.00607888, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01647561, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680742502212524, 'eval/sps': 6189.332901674394, 'num_steps': 1561600}
{'eval/walltime': 6449.584616422653, 'training/sps': 127.26885036114226, 'training/walltime': 12398.384114742279, 'training/entropy_loss': Array(0.08477019, dtype=float32), 'training/policy_loss': Array(0.2739926, dtype=float32), 'training/total_loss': Array(0.3587628, dtype=float32), 'training/v_loss': Array(2.7947468e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009522, dtype=float32), 'eval/episode_forward_reward': Array(-0.03319591, dtype=float32), 'eval/episode_reward': Array(-2.0271091, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03319591, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.992917, dtype=float32), 'eval/episode_train_reward': Array(-0.00099588, dtype=float32), 'eval/episode_x_position': Array(1.0076007, dtype=float32), 'eval/episode_x_velocity': Array(-0.03319591, dtype=float32), 'eval/episode_y_position': Array(0.00068268, dtype=float32), 'eval/episode_y_velocity': Array(-0.00298224, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00555879, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04120494, dtype=float32), 'eval/episode_reward_std': Array(0.0487965, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04120494, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02150938, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123615, dtype=float32), 'eval/episode_x_position_std': Array(0.00559568, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04120494, dtype=float32), 'eval/episode_y_position_std': Array(0.00533105, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01024324, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.59814429283142, 'eval/sps': 6214.152021672488, 'num_steps': 1566720}
{'eval/walltime': 6470.246999025345, 'training/sps': 127.34600542574611, 'training/walltime': 12438.589537620544, 'training/entropy_loss': Array(0.07948603, dtype=float32), 'training/policy_loss': Array(-0.10092333, dtype=float32), 'training/total_loss': Array(-0.0214373, dtype=float32), 'training/v_loss': Array(6.225928e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086386, dtype=float32), 'eval/episode_forward_reward': Array(-0.03416573, dtype=float32), 'eval/episode_reward': Array(-2.0294666, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03416573, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994276, dtype=float32), 'eval/episode_train_reward': Array(-0.00102497, dtype=float32), 'eval/episode_x_position': Array(1.0067209, dtype=float32), 'eval/episode_x_velocity': Array(-0.03416573, dtype=float32), 'eval/episode_y_position': Array(-0.00031228, dtype=float32), 'eval/episode_y_velocity': Array(-0.00289734, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568981, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04279183, dtype=float32), 'eval/episode_reward_std': Array(0.05019225, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04279183, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01931495, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128375, dtype=float32), 'eval/episode_x_position_std': Array(0.00570387, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04279183, dtype=float32), 'eval/episode_y_position_std': Array(0.00606564, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01312181, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66238260269165, 'eval/sps': 6194.832535107818, 'num_steps': 1571840}
{'eval/walltime': 6490.891232728958, 'training/sps': 127.15060819130171, 'training/walltime': 12478.85674571991, 'training/entropy_loss': Array(0.08126013, dtype=float32), 'training/policy_loss': Array(-0.10924153, dtype=float32), 'training/total_loss': Array(-0.0279814, dtype=float32), 'training/v_loss': Array(1.3938566e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097501, dtype=float32), 'eval/episode_forward_reward': Array(-0.04660974, dtype=float32), 'eval/episode_reward': Array(-2.045094, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04660974, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997086, dtype=float32), 'eval/episode_train_reward': Array(-0.00139829, dtype=float32), 'eval/episode_x_position': Array(1.0079379, dtype=float32), 'eval/episode_x_velocity': Array(-0.04660974, dtype=float32), 'eval/episode_y_position': Array(-0.00032353, dtype=float32), 'eval/episode_y_velocity': Array(-0.0019094, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059461, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04648551, dtype=float32), 'eval/episode_reward_std': Array(0.05099467, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04648551, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01508016, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139457, dtype=float32), 'eval/episode_x_position_std': Array(0.00591998, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04648551, dtype=float32), 'eval/episode_y_position_std': Array(0.00549014, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01145043, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64423370361328, 'eval/sps': 6200.278578400159, 'num_steps': 1576960}
{'eval/walltime': 6511.571283578873, 'training/sps': 127.2245725359554, 'training/walltime': 12519.100543737411, 'training/entropy_loss': Array(0.08323964, dtype=float32), 'training/policy_loss': Array(-0.08475718, dtype=float32), 'training/total_loss': Array(-0.00151753, dtype=float32), 'training/v_loss': Array(1.1233732e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0102932, dtype=float32), 'eval/episode_forward_reward': Array(-0.03894294, dtype=float32), 'eval/episode_reward': Array(-2.0342689, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03894294, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9941576, dtype=float32), 'eval/episode_train_reward': Array(-0.00116829, dtype=float32), 'eval/episode_x_position': Array(1.0084306, dtype=float32), 'eval/episode_x_velocity': Array(-0.03894294, dtype=float32), 'eval/episode_y_position': Array(0.00024393, dtype=float32), 'eval/episode_y_velocity': Array(-0.00232802, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590246, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04406438, dtype=float32), 'eval/episode_reward_std': Array(0.05212121, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04406438, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02046506, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132193, dtype=float32), 'eval/episode_x_position_std': Array(0.00589707, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04406438, dtype=float32), 'eval/episode_y_position_std': Array(0.00547285, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01113778, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68005084991455, 'eval/sps': 6189.539906306802, 'num_steps': 1582080}
{'eval/walltime': 6532.249819278717, 'training/sps': 127.18457294284464, 'training/walltime': 12559.356998443604, 'training/entropy_loss': Array(0.08542234, dtype=float32), 'training/policy_loss': Array(-0.0515838, dtype=float32), 'training/total_loss': Array(0.03383854, dtype=float32), 'training/v_loss': Array(1.3500959e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008654, dtype=float32), 'eval/episode_forward_reward': Array(-0.04190129, dtype=float32), 'eval/episode_reward': Array(-2.0399995, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04190129, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968412, dtype=float32), 'eval/episode_train_reward': Array(-0.00125704, dtype=float32), 'eval/episode_x_position': Array(1.0067785, dtype=float32), 'eval/episode_x_velocity': Array(-0.04190129, dtype=float32), 'eval/episode_y_position': Array(-0.00038442, dtype=float32), 'eval/episode_y_velocity': Array(-0.00133775, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00603462, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04387364, dtype=float32), 'eval/episode_reward_std': Array(0.04684777, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04387364, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01346716, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131621, dtype=float32), 'eval/episode_x_position_std': Array(0.00599884, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04387364, dtype=float32), 'eval/episode_y_position_std': Array(0.00614891, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01397179, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67853569984436, 'eval/sps': 6189.993424000685, 'num_steps': 1587200}
{'eval/walltime': 6552.955743789673, 'training/sps': 127.20600801719675, 'training/walltime': 12599.606669664383, 'training/entropy_loss': Array(0.08740861, dtype=float32), 'training/policy_loss': Array(0.0983571, dtype=float32), 'training/total_loss': Array(0.18576571, dtype=float32), 'training/v_loss': Array(9.702482e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089118, dtype=float32), 'eval/episode_forward_reward': Array(-0.03805679, dtype=float32), 'eval/episode_reward': Array(-2.0363412, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03805679, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971428, dtype=float32), 'eval/episode_train_reward': Array(-0.0011417, dtype=float32), 'eval/episode_x_position': Array(1.0070174, dtype=float32), 'eval/episode_x_velocity': Array(-0.03805679, dtype=float32), 'eval/episode_y_position': Array(0.00081933, dtype=float32), 'eval/episode_y_velocity': Array(-0.00200218, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059953, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0459106, dtype=float32), 'eval/episode_reward_std': Array(0.04826919, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0459106, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01079785, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137732, dtype=float32), 'eval/episode_x_position_std': Array(0.00594291, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0459106, dtype=float32), 'eval/episode_y_position_std': Array(0.00598698, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0110567, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70592451095581, 'eval/sps': 6181.8055954117535, 'num_steps': 1592320}
{'eval/walltime': 6573.64306306839, 'training/sps': 127.06667521160816, 'training/walltime': 12639.900475978851, 'training/entropy_loss': Array(0.09258261, dtype=float32), 'training/policy_loss': Array(0.2264975, dtype=float32), 'training/total_loss': Array(0.3190801, dtype=float32), 'training/v_loss': Array(1.8064781e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009321, dtype=float32), 'eval/episode_forward_reward': Array(-0.03954729, dtype=float32), 'eval/episode_reward': Array(-2.0339003, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03954729, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9931667, dtype=float32), 'eval/episode_train_reward': Array(-0.00118642, dtype=float32), 'eval/episode_x_position': Array(1.0074499, dtype=float32), 'eval/episode_x_velocity': Array(-0.03954729, dtype=float32), 'eval/episode_y_position': Array(0.00017401, dtype=float32), 'eval/episode_y_velocity': Array(-0.00251887, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593365, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04327254, dtype=float32), 'eval/episode_reward_std': Array(0.04914577, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04327254, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0229145, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129818, dtype=float32), 'eval/episode_x_position_std': Array(0.00591443, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04327254, dtype=float32), 'eval/episode_y_position_std': Array(0.0062111, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01026547, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68731927871704, 'eval/sps': 6187.365229659574, 'num_steps': 1597440}
{'eval/walltime': 6594.327538490295, 'training/sps': 127.3317699264427, 'training/walltime': 12680.110393762589, 'training/entropy_loss': Array(0.09205127, dtype=float32), 'training/policy_loss': Array(0.26932812, dtype=float32), 'training/total_loss': Array(0.36137968, dtype=float32), 'training/v_loss': Array(3.035852e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098946, dtype=float32), 'eval/episode_forward_reward': Array(-0.02613284, dtype=float32), 'eval/episode_reward': Array(-2.0254788, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.02613284, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998562, dtype=float32), 'eval/episode_train_reward': Array(-0.00078399, dtype=float32), 'eval/episode_x_position': Array(1.0079373, dtype=float32), 'eval/episode_x_velocity': Array(-0.02613284, dtype=float32), 'eval/episode_y_position': Array(0.00062396, dtype=float32), 'eval/episode_y_velocity': Array(-0.00135362, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.005864, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03842556, dtype=float32), 'eval/episode_reward_std': Array(0.0410647, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03842556, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0096674, dtype=float32), 'eval/episode_train_reward_std': Array(0.00115277, dtype=float32), 'eval/episode_x_position_std': Array(0.0058433, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03842556, dtype=float32), 'eval/episode_y_position_std': Array(0.00575902, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01237202, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.684475421905518, 'eval/sps': 6188.215915035676, 'num_steps': 1602560}
{'eval/walltime': 6615.0186886787415, 'training/sps': 127.21513435507383, 'training/walltime': 12720.357177495956, 'training/entropy_loss': Array(0.08929874, dtype=float32), 'training/policy_loss': Array(0.26622546, dtype=float32), 'training/total_loss': Array(0.35552424, dtype=float32), 'training/v_loss': Array(3.6661156e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089614, dtype=float32), 'eval/episode_forward_reward': Array(-0.03728465, dtype=float32), 'eval/episode_reward': Array(-2.0355725, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03728465, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971695, dtype=float32), 'eval/episode_train_reward': Array(-0.00111854, dtype=float32), 'eval/episode_x_position': Array(1.0070591, dtype=float32), 'eval/episode_x_velocity': Array(-0.03728465, dtype=float32), 'eval/episode_y_position': Array(-0.00071427, dtype=float32), 'eval/episode_y_velocity': Array(-0.00147759, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00551776, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04299754, dtype=float32), 'eval/episode_reward_std': Array(0.04669401, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04299754, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01169762, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128993, dtype=float32), 'eval/episode_x_position_std': Array(0.00549501, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04299754, dtype=float32), 'eval/episode_y_position_std': Array(0.00582732, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01123402, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.691150188446045, 'eval/sps': 6186.21965595104, 'num_steps': 1607680}
{'eval/walltime': 6635.718163490295, 'training/sps': 127.18608849943715, 'training/walltime': 12760.613152503967, 'training/entropy_loss': Array(0.08885446, dtype=float32), 'training/policy_loss': Array(0.03264559, dtype=float32), 'training/total_loss': Array(0.12150007, dtype=float32), 'training/v_loss': Array(9.491e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008183, dtype=float32), 'eval/episode_forward_reward': Array(-0.03598739, dtype=float32), 'eval/episode_reward': Array(-2.0322986, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03598739, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952316, dtype=float32), 'eval/episode_train_reward': Array(-0.00107962, dtype=float32), 'eval/episode_x_position': Array(1.006298, dtype=float32), 'eval/episode_x_velocity': Array(-0.03598739, dtype=float32), 'eval/episode_y_position': Array(-0.00022526, dtype=float32), 'eval/episode_y_velocity': Array(-0.00252708, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571809, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04155583, dtype=float32), 'eval/episode_reward_std': Array(0.04691813, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04155583, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01813545, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124667, dtype=float32), 'eval/episode_x_position_std': Array(0.00566302, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04155583, dtype=float32), 'eval/episode_y_position_std': Array(0.00600393, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0148781, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.699474811553955, 'eval/sps': 6183.731769298487, 'num_steps': 1612800}
{'eval/walltime': 6656.394271612167, 'training/sps': 127.14679287460987, 'training/walltime': 12800.881568908691, 'training/entropy_loss': Array(0.08958992, dtype=float32), 'training/policy_loss': Array(0.2637772, dtype=float32), 'training/total_loss': Array(0.3533671, dtype=float32), 'training/v_loss': Array(4.732518e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086788, dtype=float32), 'eval/episode_forward_reward': Array(-0.03933449, dtype=float32), 'eval/episode_reward': Array(-2.036161, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03933449, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956465, dtype=float32), 'eval/episode_train_reward': Array(-0.00118003, dtype=float32), 'eval/episode_x_position': Array(1.0067879, dtype=float32), 'eval/episode_x_velocity': Array(-0.03933449, dtype=float32), 'eval/episode_y_position': Array(-0.00023843, dtype=float32), 'eval/episode_y_velocity': Array(-0.0006209, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579612, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04305593, dtype=float32), 'eval/episode_reward_std': Array(0.04887982, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04305593, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01622682, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129168, dtype=float32), 'eval/episode_x_position_std': Array(0.00581615, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04305593, dtype=float32), 'eval/episode_y_position_std': Array(0.00561462, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01166197, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67610812187195, 'eval/sps': 6190.720189966355, 'num_steps': 1617920}
{'eval/walltime': 6677.10143327713, 'training/sps': 126.96873156999354, 'training/walltime': 12841.206457853317, 'training/entropy_loss': Array(0.09222451, dtype=float32), 'training/policy_loss': Array(0.14251474, dtype=float32), 'training/total_loss': Array(0.23473924, dtype=float32), 'training/v_loss': Array(1.6801657e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091631, dtype=float32), 'eval/episode_forward_reward': Array(-0.04115344, dtype=float32), 'eval/episode_reward': Array(-2.0411994, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04115344, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9988115, dtype=float32), 'eval/episode_train_reward': Array(-0.0012346, dtype=float32), 'eval/episode_x_position': Array(1.0072926, dtype=float32), 'eval/episode_x_velocity': Array(-0.04115344, dtype=float32), 'eval/episode_y_position': Array(0.0001502, dtype=float32), 'eval/episode_y_velocity': Array(-0.00174377, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572808, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0449561, dtype=float32), 'eval/episode_reward_std': Array(0.04658578, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0449561, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00758555, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134868, dtype=float32), 'eval/episode_x_position_std': Array(0.00570496, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0449561, dtype=float32), 'eval/episode_y_position_std': Array(0.00540517, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0129852, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70716166496277, 'eval/sps': 6181.436262053259, 'num_steps': 1623040}
{'eval/walltime': 6697.761998653412, 'training/sps': 127.21472815960472, 'training/walltime': 12881.4533700943, 'training/entropy_loss': Array(0.10983355, dtype=float32), 'training/policy_loss': Array(0.27369192, dtype=float32), 'training/total_loss': Array(0.38352555, dtype=float32), 'training/v_loss': Array(8.9280164e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095106, dtype=float32), 'eval/episode_forward_reward': Array(-0.04397193, dtype=float32), 'eval/episode_reward': Array(-2.0408232, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04397193, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955323, dtype=float32), 'eval/episode_train_reward': Array(-0.00131916, dtype=float32), 'eval/episode_x_position': Array(1.0076563, dtype=float32), 'eval/episode_x_velocity': Array(-0.04397193, dtype=float32), 'eval/episode_y_position': Array(0.00036678, dtype=float32), 'eval/episode_y_velocity': Array(-0.00133724, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00587365, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04277442, dtype=float32), 'eval/episode_reward_std': Array(0.04547506, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04277442, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01701204, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128323, dtype=float32), 'eval/episode_x_position_std': Array(0.00580286, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04277442, dtype=float32), 'eval/episode_y_position_std': Array(0.00564353, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01293227, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66056537628174, 'eval/sps': 6195.377409513855, 'num_steps': 1628160}
{'eval/walltime': 6718.453572034836, 'training/sps': 127.18391008650354, 'training/walltime': 12921.710034608841, 'training/entropy_loss': Array(0.10966948, dtype=float32), 'training/policy_loss': Array(0.2470253, dtype=float32), 'training/total_loss': Array(0.35669577, dtype=float32), 'training/v_loss': Array(9.717311e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094931, dtype=float32), 'eval/episode_forward_reward': Array(-0.03512522, dtype=float32), 'eval/episode_reward': Array(-2.031919, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03512522, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99574, dtype=float32), 'eval/episode_train_reward': Array(-0.00105376, dtype=float32), 'eval/episode_x_position': Array(1.007596, dtype=float32), 'eval/episode_x_velocity': Array(-0.03512522, dtype=float32), 'eval/episode_y_position': Array(-0.00038476, dtype=float32), 'eval/episode_y_velocity': Array(-0.00335768, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00607931, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04316514, dtype=float32), 'eval/episode_reward_std': Array(0.04529117, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04316514, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01702896, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129495, dtype=float32), 'eval/episode_x_position_std': Array(0.00611733, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04316514, dtype=float32), 'eval/episode_y_position_std': Array(0.00571552, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01001498, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69157338142395, 'eval/sps': 6186.093132720065, 'num_steps': 1633280}
{'eval/walltime': 6739.112950325012, 'training/sps': 127.06932329629316, 'training/walltime': 12962.003001213074, 'training/entropy_loss': Array(0.10791136, dtype=float32), 'training/policy_loss': Array(0.24078673, dtype=float32), 'training/total_loss': Array(0.34869808, dtype=float32), 'training/v_loss': Array(1.0764243e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088718, dtype=float32), 'eval/episode_forward_reward': Array(-0.03935606, dtype=float32), 'eval/episode_reward': Array(-2.0374813, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03935606, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996945, dtype=float32), 'eval/episode_train_reward': Array(-0.00118068, dtype=float32), 'eval/episode_x_position': Array(1.0070087, dtype=float32), 'eval/episode_x_velocity': Array(-0.03935606, dtype=float32), 'eval/episode_y_position': Array(0.00077612, dtype=float32), 'eval/episode_y_velocity': Array(-0.00094917, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00597179, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04205394, dtype=float32), 'eval/episode_reward_std': Array(0.04238191, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04205394, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0137495, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126162, dtype=float32), 'eval/episode_x_position_std': Array(0.00595614, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04205394, dtype=float32), 'eval/episode_y_position_std': Array(0.00559811, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01500726, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65937829017639, 'eval/sps': 6195.733395368652, 'num_steps': 1638400}
{'eval/walltime': 6759.8132445812225, 'training/sps': 127.33272500142513, 'training/walltime': 13002.212617397308, 'training/entropy_loss': Array(0.1004917, dtype=float32), 'training/policy_loss': Array(0.24338743, dtype=float32), 'training/total_loss': Array(0.34387913, dtype=float32), 'training/v_loss': Array(3.758517e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092764, dtype=float32), 'eval/episode_forward_reward': Array(-0.03909568, dtype=float32), 'eval/episode_reward': Array(-2.038029, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03909568, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977605, dtype=float32), 'eval/episode_train_reward': Array(-0.00117287, dtype=float32), 'eval/episode_x_position': Array(1.0073706, dtype=float32), 'eval/episode_x_velocity': Array(-0.03909568, dtype=float32), 'eval/episode_y_position': Array(-0.00064643, dtype=float32), 'eval/episode_y_velocity': Array(-0.00330946, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571954, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04332735, dtype=float32), 'eval/episode_reward_std': Array(0.04669969, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04332735, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01115427, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129982, dtype=float32), 'eval/episode_x_position_std': Array(0.00574289, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04332735, dtype=float32), 'eval/episode_y_position_std': Array(0.00585793, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00991749, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.700294256210327, 'eval/sps': 6183.486979253858, 'num_steps': 1643520}
{'eval/walltime': 6780.4865481853485, 'training/sps': 127.18998150616935, 'training/walltime': 13042.467360258102, 'training/entropy_loss': Array(0.09287067, dtype=float32), 'training/policy_loss': Array(0.24034628, dtype=float32), 'training/total_loss': Array(0.333217, dtype=float32), 'training/v_loss': Array(5.836495e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089663, dtype=float32), 'eval/episode_forward_reward': Array(-0.04171549, dtype=float32), 'eval/episode_reward': Array(-2.0391264, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04171549, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961596, dtype=float32), 'eval/episode_train_reward': Array(-0.00125146, dtype=float32), 'eval/episode_x_position': Array(1.0071013, dtype=float32), 'eval/episode_x_velocity': Array(-0.04171549, dtype=float32), 'eval/episode_y_position': Array(0.00020616, dtype=float32), 'eval/episode_y_velocity': Array(-0.00188579, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00565434, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04696911, dtype=float32), 'eval/episode_reward_std': Array(0.05278603, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04696911, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01659968, dtype=float32), 'eval/episode_train_reward_std': Array(0.00140907, dtype=float32), 'eval/episode_x_position_std': Array(0.00566258, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04696911, dtype=float32), 'eval/episode_y_position_std': Array(0.00590376, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01838625, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.673303604125977, 'eval/sps': 6191.560016293369, 'num_steps': 1648640}
{'eval/walltime': 6801.179527997971, 'training/sps': 127.2081464966115, 'training/walltime': 13082.716354846954, 'training/entropy_loss': Array(0.09024133, dtype=float32), 'training/policy_loss': Array(-0.08453999, dtype=float32), 'training/total_loss': Array(0.00570135, dtype=float32), 'training/v_loss': Array(1.1785522e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088977, dtype=float32), 'eval/episode_forward_reward': Array(-0.04426289, dtype=float32), 'eval/episode_reward': Array(-2.0408998, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04426289, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9953089, dtype=float32), 'eval/episode_train_reward': Array(-0.00132789, dtype=float32), 'eval/episode_x_position': Array(1.0070767, dtype=float32), 'eval/episode_x_velocity': Array(-0.04426289, dtype=float32), 'eval/episode_y_position': Array(0.00026488, dtype=float32), 'eval/episode_y_velocity': Array(-0.00278096, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0060038, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04344193, dtype=float32), 'eval/episode_reward_std': Array(0.04821169, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04344193, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01635007, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130326, dtype=float32), 'eval/episode_x_position_std': Array(0.00598563, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04344193, dtype=float32), 'eval/episode_y_position_std': Array(0.00585273, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01342348, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69297981262207, 'eval/sps': 6185.672685087336, 'num_steps': 1653760}
{'eval/walltime': 6821.8656969070435, 'training/sps': 127.1086282218746, 'training/walltime': 13122.996861934662, 'training/entropy_loss': Array(0.09079126, dtype=float32), 'training/policy_loss': Array(-0.11130519, dtype=float32), 'training/total_loss': Array(-0.02051393, dtype=float32), 'training/v_loss': Array(6.2425896e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098841, dtype=float32), 'eval/episode_forward_reward': Array(-0.03614789, dtype=float32), 'eval/episode_reward': Array(-2.0340686, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03614789, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968362, dtype=float32), 'eval/episode_train_reward': Array(-0.00108444, dtype=float32), 'eval/episode_x_position': Array(1.0079801, dtype=float32), 'eval/episode_x_velocity': Array(-0.03614789, dtype=float32), 'eval/episode_y_position': Array(0.00073513, dtype=float32), 'eval/episode_y_velocity': Array(-0.0038556, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00554273, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04244965, dtype=float32), 'eval/episode_reward_std': Array(0.04578907, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04244965, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01282567, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127349, dtype=float32), 'eval/episode_x_position_std': Array(0.00562887, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04244965, dtype=float32), 'eval/episode_y_position_std': Array(0.00654755, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0123903, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.686168909072876, 'eval/sps': 6187.709312566798, 'num_steps': 1658880}
{'eval/walltime': 6842.544524908066, 'training/sps': 127.18385509986742, 'training/walltime': 13163.25354385376, 'training/entropy_loss': Array(0.09141925, dtype=float32), 'training/policy_loss': Array(-0.11072081, dtype=float32), 'training/total_loss': Array(-0.01930155, dtype=float32), 'training/v_loss': Array(5.7204708e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008862, dtype=float32), 'eval/episode_forward_reward': Array(-0.0365957, dtype=float32), 'eval/episode_reward': Array(-2.034936, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0365957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972425, dtype=float32), 'eval/episode_train_reward': Array(-0.00109787, dtype=float32), 'eval/episode_x_position': Array(1.0069747, dtype=float32), 'eval/episode_x_velocity': Array(-0.0365957, dtype=float32), 'eval/episode_y_position': Array(-9.9707846e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00327492, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0055049, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04493125, dtype=float32), 'eval/episode_reward_std': Array(0.04699172, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04493125, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01445414, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134794, dtype=float32), 'eval/episode_x_position_std': Array(0.00554401, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04493125, dtype=float32), 'eval/episode_y_position_std': Array(0.00523372, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01286297, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67882800102234, 'eval/sps': 6189.905926664307, 'num_steps': 1664000}
{'eval/walltime': 6863.202750682831, 'training/sps': 127.10948590720037, 'training/walltime': 13203.533779144287, 'training/entropy_loss': Array(0.09157584, dtype=float32), 'training/policy_loss': Array(-0.04757798, dtype=float32), 'training/total_loss': Array(0.04399787, dtype=float32), 'training/v_loss': Array(5.586785e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089574, dtype=float32), 'eval/episode_forward_reward': Array(-0.03662046, dtype=float32), 'eval/episode_reward': Array(-2.033061, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03662046, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995342, dtype=float32), 'eval/episode_train_reward': Array(-0.00109861, dtype=float32), 'eval/episode_x_position': Array(1.0070429, dtype=float32), 'eval/episode_x_velocity': Array(-0.03662046, dtype=float32), 'eval/episode_y_position': Array(0.00047121, dtype=float32), 'eval/episode_y_velocity': Array(-0.00328505, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561685, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04271002, dtype=float32), 'eval/episode_reward_std': Array(0.04750694, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04271002, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01921852, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012813, dtype=float32), 'eval/episode_x_position_std': Array(0.00564537, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04271002, dtype=float32), 'eval/episode_y_position_std': Array(0.00587223, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01264278, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.658225774765015, 'eval/sps': 6196.079053233989, 'num_steps': 1669120}
{'eval/walltime': 6883.915375471115, 'training/sps': 127.1498508312182, 'training/walltime': 13243.801227092743, 'training/entropy_loss': Array(0.0920308, dtype=float32), 'training/policy_loss': Array(-0.03977278, dtype=float32), 'training/total_loss': Array(0.05225803, dtype=float32), 'training/v_loss': Array(4.88626e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008414, dtype=float32), 'eval/episode_forward_reward': Array(-0.0464938, dtype=float32), 'eval/episode_reward': Array(-2.0456507, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0464938, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977622, dtype=float32), 'eval/episode_train_reward': Array(-0.00139481, dtype=float32), 'eval/episode_x_position': Array(1.0066164, dtype=float32), 'eval/episode_x_velocity': Array(-0.0464938, dtype=float32), 'eval/episode_y_position': Array(0.00025541, dtype=float32), 'eval/episode_y_velocity': Array(-0.00272608, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568508, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04450269, dtype=float32), 'eval/episode_reward_std': Array(0.04682003, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04450269, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0097559, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133508, dtype=float32), 'eval/episode_x_position_std': Array(0.00565113, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04450269, dtype=float32), 'eval/episode_y_position_std': Array(0.00548737, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01357844, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7126247882843, 'eval/sps': 6179.80585794229, 'num_steps': 1674240}
{'eval/walltime': 6904.559983730316, 'training/sps': 127.07967083185417, 'training/walltime': 13284.090912818909, 'training/entropy_loss': Array(0.09246364, dtype=float32), 'training/policy_loss': Array(-0.02420272, dtype=float32), 'training/total_loss': Array(0.06826093, dtype=float32), 'training/v_loss': Array(4.5575597e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167022, dtype=float32), 'eval/episode_forward_reward': Array(-0.03988203, dtype=float32), 'eval/episode_reward': Array(-2.0525022, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03988203, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.019236, dtype=float32), 'eval/episode_train_reward': Array(-0.00119646, dtype=float32), 'eval/episode_x_position': Array(1.0148227, dtype=float32), 'eval/episode_x_velocity': Array(-0.03988203, dtype=float32), 'eval/episode_y_position': Array(-0.00020314, dtype=float32), 'eval/episode_y_velocity': Array(-0.00233116, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08779372, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0447798, dtype=float32), 'eval/episode_reward_std': Array(0.1795585, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0447798, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26498324, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134339, dtype=float32), 'eval/episode_x_position_std': Array(0.08752184, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0447798, dtype=float32), 'eval/episode_y_position_std': Array(0.00576583, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01577108, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.64460825920105, 'eval/sps': 6200.166086607721, 'num_steps': 1679360}
{'eval/walltime': 6925.241256952286, 'training/sps': 127.3652430919843, 'training/walltime': 13324.290262937546, 'training/entropy_loss': Array(0.09211693, dtype=float32), 'training/policy_loss': Array(0.03174266, dtype=float32), 'training/total_loss': Array(0.12385958, dtype=float32), 'training/v_loss': Array(5.715659e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091519, dtype=float32), 'eval/episode_forward_reward': Array(-0.03658095, dtype=float32), 'eval/episode_reward': Array(-2.0315866, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03658095, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9939084, dtype=float32), 'eval/episode_train_reward': Array(-0.00109743, dtype=float32), 'eval/episode_x_position': Array(1.0072815, dtype=float32), 'eval/episode_x_velocity': Array(-0.03658095, dtype=float32), 'eval/episode_y_position': Array(0.00041311, dtype=float32), 'eval/episode_y_velocity': Array(-0.0044666, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00564368, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04431602, dtype=float32), 'eval/episode_reward_std': Array(0.04998647, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04431602, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02216663, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132948, dtype=float32), 'eval/episode_x_position_std': Array(0.00563505, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04431602, dtype=float32), 'eval/episode_y_position_std': Array(0.00605999, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01357301, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.681273221969604, 'eval/sps': 6189.174071934135, 'num_steps': 1684480}
{'eval/walltime': 6945.8755922317505, 'training/sps': 127.36675011550577, 'training/walltime': 13364.489137411118, 'training/entropy_loss': Array(0.09289287, dtype=float32), 'training/policy_loss': Array(0.01424078, dtype=float32), 'training/total_loss': Array(0.10713366, dtype=float32), 'training/v_loss': Array(3.8651486e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009554, dtype=float32), 'eval/episode_forward_reward': Array(-0.04030221, dtype=float32), 'eval/episode_reward': Array(-2.0371985, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04030221, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956872, dtype=float32), 'eval/episode_train_reward': Array(-0.00120907, dtype=float32), 'eval/episode_x_position': Array(1.0077021, dtype=float32), 'eval/episode_x_velocity': Array(-0.04030221, dtype=float32), 'eval/episode_y_position': Array(0.00062798, dtype=float32), 'eval/episode_y_velocity': Array(-0.00216144, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563775, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04091605, dtype=float32), 'eval/episode_reward_std': Array(0.04543477, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04091605, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01745101, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122748, dtype=float32), 'eval/episode_x_position_std': Array(0.00567507, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04091605, dtype=float32), 'eval/episode_y_position_std': Array(0.00572257, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01269833, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63433527946472, 'eval/sps': 6203.25289215328, 'num_steps': 1689600}
{'eval/walltime': 6966.550406217575, 'training/sps': 126.96369010055062, 'training/walltime': 13404.81562757492, 'training/entropy_loss': Array(0.09383562, dtype=float32), 'training/policy_loss': Array(-0.0873121, dtype=float32), 'training/total_loss': Array(0.00652353, dtype=float32), 'training/v_loss': Array(3.990862e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0166421, dtype=float32), 'eval/episode_forward_reward': Array(-0.04497667, dtype=float32), 'eval/episode_reward': Array(-2.0602822, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04497667, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0217686, dtype=float32), 'eval/episode_train_reward': Array(-0.0013493, dtype=float32), 'eval/episode_x_position': Array(1.0147768, dtype=float32), 'eval/episode_x_velocity': Array(-0.04497667, dtype=float32), 'eval/episode_y_position': Array(2.1805317e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00014612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08761251, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04455414, dtype=float32), 'eval/episode_reward_std': Array(0.17696165, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04455414, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2643918, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133662, dtype=float32), 'eval/episode_x_position_std': Array(0.08734059, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04455414, dtype=float32), 'eval/episode_y_position_std': Array(0.00574019, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01373808, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.674813985824585, 'eval/sps': 6191.107696918652, 'num_steps': 1694720}
{'eval/walltime': 6987.20893406868, 'training/sps': 127.19034535779186, 'training/walltime': 13445.070255279541, 'training/entropy_loss': Array(0.09312732, dtype=float32), 'training/policy_loss': Array(0.09088022, dtype=float32), 'training/total_loss': Array(0.18400754, dtype=float32), 'training/v_loss': Array(3.9436765e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0170903, dtype=float32), 'eval/episode_forward_reward': Array(-0.03801783, dtype=float32), 'eval/episode_reward': Array(-2.0539737, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03801783, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0226278, dtype=float32), 'eval/episode_train_reward': Array(-0.00114053, dtype=float32), 'eval/episode_x_position': Array(1.0152256, dtype=float32), 'eval/episode_x_velocity': Array(-0.03801783, dtype=float32), 'eval/episode_y_position': Array(0.00018572, dtype=float32), 'eval/episode_y_velocity': Array(-0.00339182, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08956519, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0415384, dtype=float32), 'eval/episode_reward_std': Array(0.17710572, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0415384, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26426327, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124615, dtype=float32), 'eval/episode_x_position_std': Array(0.08929287, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0415384, dtype=float32), 'eval/episode_y_position_std': Array(0.00585861, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01689062, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.658527851104736, 'eval/sps': 6195.988451962954, 'num_steps': 1699840}
{'eval/walltime': 7007.912873983383, 'training/sps': 127.33158872806301, 'training/walltime': 13485.280230283737, 'training/entropy_loss': Array(0.09430286, dtype=float32), 'training/policy_loss': Array(-0.08715288, dtype=float32), 'training/total_loss': Array(0.00714998, dtype=float32), 'training/v_loss': Array(3.4358991e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098207, dtype=float32), 'eval/episode_forward_reward': Array(-0.03948614, dtype=float32), 'eval/episode_reward': Array(-2.032639, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03948614, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9919682, dtype=float32), 'eval/episode_train_reward': Array(-0.00118458, dtype=float32), 'eval/episode_x_position': Array(1.007933, dtype=float32), 'eval/episode_x_velocity': Array(-0.03948614, dtype=float32), 'eval/episode_y_position': Array(-0.00054797, dtype=float32), 'eval/episode_y_velocity': Array(-0.00119025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586974, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04484392, dtype=float32), 'eval/episode_reward_std': Array(0.05160355, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04484392, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02296085, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134532, dtype=float32), 'eval/episode_x_position_std': Array(0.00590696, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04484392, dtype=float32), 'eval/episode_y_position_std': Array(0.00608041, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01077556, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70393991470337, 'eval/sps': 6182.398158386169, 'num_steps': 1704960}
{'eval/walltime': 7028.587495803833, 'training/sps': 127.21608617391244, 'training/walltime': 13525.52671289444, 'training/entropy_loss': Array(0.09453431, dtype=float32), 'training/policy_loss': Array(-0.03234217, dtype=float32), 'training/total_loss': Array(0.06219214, dtype=float32), 'training/v_loss': Array(3.8412087e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093114, dtype=float32), 'eval/episode_forward_reward': Array(-0.0405196, dtype=float32), 'eval/episode_reward': Array(-2.0375507, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0405196, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958155, dtype=float32), 'eval/episode_train_reward': Array(-0.00121559, dtype=float32), 'eval/episode_x_position': Array(1.0074668, dtype=float32), 'eval/episode_x_velocity': Array(-0.0405196, dtype=float32), 'eval/episode_y_position': Array(-0.00026057, dtype=float32), 'eval/episode_y_velocity': Array(-0.00287497, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585889, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04312412, dtype=float32), 'eval/episode_reward_std': Array(0.04514139, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04312412, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01684178, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129372, dtype=float32), 'eval/episode_x_position_std': Array(0.00588028, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04312412, dtype=float32), 'eval/episode_y_position_std': Array(0.00609674, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01415834, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67462182044983, 'eval/sps': 6191.165241697032, 'num_steps': 1710080}
{'eval/walltime': 7049.269768238068, 'training/sps': 127.29830152244593, 'training/walltime': 13565.747202396393, 'training/entropy_loss': Array(0.09515378, dtype=float32), 'training/policy_loss': Array(-0.02132466, dtype=float32), 'training/total_loss': Array(0.07382911, dtype=float32), 'training/v_loss': Array(3.3389211e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171808, dtype=float32), 'eval/episode_forward_reward': Array(-0.03637878, dtype=float32), 'eval/episode_reward': Array(-2.0510626, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03637878, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0214047, dtype=float32), 'eval/episode_train_reward': Array(-0.00109136, dtype=float32), 'eval/episode_x_position': Array(1.0152758, dtype=float32), 'eval/episode_x_velocity': Array(-0.03637878, dtype=float32), 'eval/episode_y_position': Array(-0.00046427, dtype=float32), 'eval/episode_y_velocity': Array(-0.002559, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09090123, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04299161, dtype=float32), 'eval/episode_reward_std': Array(0.17963706, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04299161, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26447043, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128975, dtype=float32), 'eval/episode_x_position_std': Array(0.09064244, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04299161, dtype=float32), 'eval/episode_y_position_std': Array(0.00571717, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01066832, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.68227243423462, 'eval/sps': 6188.875057468357, 'num_steps': 1715200}
{'eval/walltime': 7069.922137260437, 'training/sps': 127.06311377942066, 'training/walltime': 13606.04213809967, 'training/entropy_loss': Array(0.09294543, dtype=float32), 'training/policy_loss': Array(0.26681733, dtype=float32), 'training/total_loss': Array(0.35976276, dtype=float32), 'training/v_loss': Array(3.4550656e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0082061, dtype=float32), 'eval/episode_forward_reward': Array(-0.03477504, dtype=float32), 'eval/episode_reward': Array(-2.032125, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03477504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996307, dtype=float32), 'eval/episode_train_reward': Array(-0.00104325, dtype=float32), 'eval/episode_x_position': Array(1.0063251, dtype=float32), 'eval/episode_x_velocity': Array(-0.03477504, dtype=float32), 'eval/episode_y_position': Array(0.00066747, dtype=float32), 'eval/episode_y_velocity': Array(-0.00301942, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596646, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04108422, dtype=float32), 'eval/episode_reward_std': Array(0.04748074, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04108422, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01536866, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123253, dtype=float32), 'eval/episode_x_position_std': Array(0.00594428, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04108422, dtype=float32), 'eval/episode_y_position_std': Array(0.00546266, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01108511, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.652369022369385, 'eval/sps': 6197.836183411125, 'num_steps': 1720320}
{'eval/walltime': 7090.604425907135, 'training/sps': 127.24571875186352, 'training/walltime': 13646.27924823761, 'training/entropy_loss': Array(0.09242495, dtype=float32), 'training/policy_loss': Array(-0.09461353, dtype=float32), 'training/total_loss': Array(-0.00218855, dtype=float32), 'training/v_loss': Array(3.4877203e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008527, dtype=float32), 'eval/episode_forward_reward': Array(-0.03855357, dtype=float32), 'eval/episode_reward': Array(-2.0365653, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03855357, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968553, dtype=float32), 'eval/episode_train_reward': Array(-0.00115661, dtype=float32), 'eval/episode_x_position': Array(1.0066519, dtype=float32), 'eval/episode_x_velocity': Array(-0.03855357, dtype=float32), 'eval/episode_y_position': Array(-0.00041003, dtype=float32), 'eval/episode_y_velocity': Array(-0.00183293, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058195, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04174511, dtype=float32), 'eval/episode_reward_std': Array(0.04552761, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04174511, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01301055, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125235, dtype=float32), 'eval/episode_x_position_std': Array(0.00582574, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04174511, dtype=float32), 'eval/episode_y_position_std': Array(0.00556694, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01264629, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.682288646697998, 'eval/sps': 6188.8702061237145, 'num_steps': 1725440}
{'eval/walltime': 7111.258410215378, 'training/sps': 127.42457346813624, 'training/walltime': 13686.459881067276, 'training/entropy_loss': Array(0.09289061, dtype=float32), 'training/policy_loss': Array(-0.10736649, dtype=float32), 'training/total_loss': Array(-0.01447587, dtype=float32), 'training/v_loss': Array(2.8796197e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090998, dtype=float32), 'eval/episode_forward_reward': Array(-0.03577156, dtype=float32), 'eval/episode_reward': Array(-2.0340436, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03577156, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971988, dtype=float32), 'eval/episode_train_reward': Array(-0.00107315, dtype=float32), 'eval/episode_x_position': Array(1.0072068, dtype=float32), 'eval/episode_x_velocity': Array(-0.03577156, dtype=float32), 'eval/episode_y_position': Array(-0.00054654, dtype=float32), 'eval/episode_y_velocity': Array(-0.00346613, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00592118, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04355368, dtype=float32), 'eval/episode_reward_std': Array(0.04332281, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04355368, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01137192, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130661, dtype=float32), 'eval/episode_x_position_std': Array(0.00589886, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04355368, dtype=float32), 'eval/episode_y_position_std': Array(0.00618828, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01577817, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.653984308242798, 'eval/sps': 6197.351469319965, 'num_steps': 1730560}
{'eval/walltime': 7131.924869775772, 'training/sps': 126.98082191826182, 'training/walltime': 13726.780930519104, 'training/entropy_loss': Array(0.09331893, dtype=float32), 'training/policy_loss': Array(-0.08050108, dtype=float32), 'training/total_loss': Array(0.01281785, dtype=float32), 'training/v_loss': Array(2.0821007e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087992, dtype=float32), 'eval/episode_forward_reward': Array(-0.03922622, dtype=float32), 'eval/episode_reward': Array(-2.0389895, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03922622, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985867, dtype=float32), 'eval/episode_train_reward': Array(-0.00117679, dtype=float32), 'eval/episode_x_position': Array(1.0069373, dtype=float32), 'eval/episode_x_velocity': Array(-0.03922622, dtype=float32), 'eval/episode_y_position': Array(0.00045349, dtype=float32), 'eval/episode_y_velocity': Array(-0.00412371, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00601341, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04156337, dtype=float32), 'eval/episode_reward_std': Array(0.04395625, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04156337, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00921236, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012469, dtype=float32), 'eval/episode_x_position_std': Array(0.00603948, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04156337, dtype=float32), 'eval/episode_y_position_std': Array(0.00598593, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01405006, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666459560394287, 'eval/sps': 6193.610454947124, 'num_steps': 1735680}
{'eval/walltime': 7152.575577735901, 'training/sps': 127.07408441211966, 'training/walltime': 13767.072387456894, 'training/entropy_loss': Array(0.09371211, dtype=float32), 'training/policy_loss': Array(-0.09225887, dtype=float32), 'training/total_loss': Array(0.00145324, dtype=float32), 'training/v_loss': Array(1.8658577e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101318, dtype=float32), 'eval/episode_forward_reward': Array(-0.04206512, dtype=float32), 'eval/episode_reward': Array(-2.041676, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04206512, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998349, dtype=float32), 'eval/episode_train_reward': Array(-0.00126195, dtype=float32), 'eval/episode_x_position': Array(1.008257, dtype=float32), 'eval/episode_x_velocity': Array(-0.04206512, dtype=float32), 'eval/episode_y_position': Array(0.00023412, dtype=float32), 'eval/episode_y_velocity': Array(-0.00147474, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585922, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04287302, dtype=float32), 'eval/episode_reward_std': Array(0.04512518, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04287302, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00794172, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128619, dtype=float32), 'eval/episode_x_position_std': Array(0.00581854, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04287302, dtype=float32), 'eval/episode_y_position_std': Array(0.00595022, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01245388, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.650707960128784, 'eval/sps': 6198.33471313115, 'num_steps': 1740800}
{'eval/walltime': 7173.2417623996735, 'training/sps': 127.4753034530411, 'training/walltime': 13807.237030029297, 'training/entropy_loss': Array(0.09409775, dtype=float32), 'training/policy_loss': Array(-0.04490017, dtype=float32), 'training/total_loss': Array(0.04919758, dtype=float32), 'training/v_loss': Array(2.163836e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100307, dtype=float32), 'eval/episode_forward_reward': Array(-0.04630381, dtype=float32), 'eval/episode_reward': Array(-2.0449111, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04630381, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972181, dtype=float32), 'eval/episode_train_reward': Array(-0.00138911, dtype=float32), 'eval/episode_x_position': Array(1.0081943, dtype=float32), 'eval/episode_x_velocity': Array(-0.04630381, dtype=float32), 'eval/episode_y_position': Array(-0.00051948, dtype=float32), 'eval/episode_y_velocity': Array(-0.00485166, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00523903, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04597104, dtype=float32), 'eval/episode_reward_std': Array(0.04780747, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04597104, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01391364, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137913, dtype=float32), 'eval/episode_x_position_std': Array(0.0052842, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04597104, dtype=float32), 'eval/episode_y_position_std': Array(0.00577763, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01523308, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666184663772583, 'eval/sps': 6193.692840864888, 'num_steps': 1745920}
{'eval/walltime': 7193.870198249817, 'training/sps': 127.097659898537, 'training/walltime': 13847.521013259888, 'training/entropy_loss': Array(0.09450567, dtype=float32), 'training/policy_loss': Array(-0.02785355, dtype=float32), 'training/total_loss': Array(0.06665212, dtype=float32), 'training/v_loss': Array(1.7120192e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091126, dtype=float32), 'eval/episode_forward_reward': Array(-0.03745057, dtype=float32), 'eval/episode_reward': Array(-2.033856, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03745057, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952822, dtype=float32), 'eval/episode_train_reward': Array(-0.00112352, dtype=float32), 'eval/episode_x_position': Array(1.0072272, dtype=float32), 'eval/episode_x_velocity': Array(-0.03745057, dtype=float32), 'eval/episode_y_position': Array(-0.00030571, dtype=float32), 'eval/episode_y_velocity': Array(-0.00277084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578435, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04183053, dtype=float32), 'eval/episode_reward_std': Array(0.04769111, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04183053, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01718129, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125492, dtype=float32), 'eval/episode_x_position_std': Array(0.00581981, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04183053, dtype=float32), 'eval/episode_y_position_std': Array(0.00659866, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01296666, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.628435850143433, 'eval/sps': 6205.026931264398, 'num_steps': 1751040}
{'eval/walltime': 7214.5475461483, 'training/sps': 127.55932799820623, 'training/walltime': 13887.659198999405, 'training/entropy_loss': Array(0.09560722, dtype=float32), 'training/policy_loss': Array(-0.06153791, dtype=float32), 'training/total_loss': Array(0.03406931, dtype=float32), 'training/v_loss': Array(1.6811375e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009317, dtype=float32), 'eval/episode_forward_reward': Array(-0.03520337, dtype=float32), 'eval/episode_reward': Array(-2.033199, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03520337, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969397, dtype=float32), 'eval/episode_train_reward': Array(-0.0010561, dtype=float32), 'eval/episode_x_position': Array(1.0074167, dtype=float32), 'eval/episode_x_velocity': Array(-0.03520337, dtype=float32), 'eval/episode_y_position': Array(-0.0003456, dtype=float32), 'eval/episode_y_velocity': Array(-0.00194208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614274, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04166328, dtype=float32), 'eval/episode_reward_std': Array(0.04650202, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04166328, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0144453, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012499, dtype=float32), 'eval/episode_x_position_std': Array(0.00613823, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04166328, dtype=float32), 'eval/episode_y_position_std': Array(0.0058581, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01106881, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677347898483276, 'eval/sps': 6190.349005511923, 'num_steps': 1756160}
{'eval/walltime': 7235.1565408706665, 'training/sps': 127.1730944524163, 'training/walltime': 13927.919287204742, 'training/entropy_loss': Array(0.09572131, dtype=float32), 'training/policy_loss': Array(-0.01774683, dtype=float32), 'training/total_loss': Array(0.07797448, dtype=float32), 'training/v_loss': Array(1.4071417e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087091, dtype=float32), 'eval/episode_forward_reward': Array(-0.03943375, dtype=float32), 'eval/episode_reward': Array(-2.0376425, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03943375, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970255, dtype=float32), 'eval/episode_train_reward': Array(-0.00118301, dtype=float32), 'eval/episode_x_position': Array(1.0068636, dtype=float32), 'eval/episode_x_velocity': Array(-0.03943375, dtype=float32), 'eval/episode_y_position': Array(-8.155975e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00440667, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575233, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04274254, dtype=float32), 'eval/episode_reward_std': Array(0.04766238, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04274254, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01367671, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128228, dtype=float32), 'eval/episode_x_position_std': Array(0.00575122, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04274254, dtype=float32), 'eval/episode_y_position_std': Array(0.00584453, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01707353, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.608994722366333, 'eval/sps': 6210.880332803685, 'num_steps': 1761280}
{'eval/walltime': 7255.812652349472, 'training/sps': 127.56298701365046, 'training/walltime': 13968.056321620941, 'training/entropy_loss': Array(0.09413745, dtype=float32), 'training/policy_loss': Array(0.2614218, dtype=float32), 'training/total_loss': Array(0.35555926, dtype=float32), 'training/v_loss': Array(1.2240577e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088717, dtype=float32), 'eval/episode_forward_reward': Array(-0.03346832, dtype=float32), 'eval/episode_reward': Array(-2.0299878, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03346832, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955156, dtype=float32), 'eval/episode_train_reward': Array(-0.00100405, dtype=float32), 'eval/episode_x_position': Array(1.0069726, dtype=float32), 'eval/episode_x_velocity': Array(-0.03346832, dtype=float32), 'eval/episode_y_position': Array(-0.00032171, dtype=float32), 'eval/episode_y_velocity': Array(-0.00101034, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00615025, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04020171, dtype=float32), 'eval/episode_reward_std': Array(0.0473033, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04020171, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01723801, dtype=float32), 'eval/episode_train_reward_std': Array(0.00120605, dtype=float32), 'eval/episode_x_position_std': Array(0.0060785, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04020171, dtype=float32), 'eval/episode_y_position_std': Array(0.00576828, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01201348, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.656111478805542, 'eval/sps': 6196.713264804752, 'num_steps': 1766400}
{'eval/walltime': 7276.426953077316, 'training/sps': 127.2600179715625, 'training/walltime': 14008.288910627365, 'training/entropy_loss': Array(0.09380123, dtype=float32), 'training/policy_loss': Array(0.00033878, dtype=float32), 'training/total_loss': Array(0.09414002, dtype=float32), 'training/v_loss': Array(1.3261836e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097594, dtype=float32), 'eval/episode_forward_reward': Array(-0.03853083, dtype=float32), 'eval/episode_reward': Array(-2.036127, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03853083, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964402, dtype=float32), 'eval/episode_train_reward': Array(-0.00115592, dtype=float32), 'eval/episode_x_position': Array(1.0078752, dtype=float32), 'eval/episode_x_velocity': Array(-0.03853083, dtype=float32), 'eval/episode_y_position': Array(-2.345565e-06, dtype=float32), 'eval/episode_y_velocity': Array(0.00031571, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584569, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04422373, dtype=float32), 'eval/episode_reward_std': Array(0.04955828, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04422373, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01491003, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132671, dtype=float32), 'eval/episode_x_position_std': Array(0.00587341, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04422373, dtype=float32), 'eval/episode_y_position_std': Array(0.00545144, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01362007, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61430072784424, 'eval/sps': 6209.281687013874, 'num_steps': 1771520}
{'eval/walltime': 7297.099619626999, 'training/sps': 127.40599362463266, 'training/walltime': 14048.47540307045, 'training/entropy_loss': Array(0.09457424, dtype=float32), 'training/policy_loss': Array(0.02983252, dtype=float32), 'training/total_loss': Array(0.12440677, dtype=float32), 'training/v_loss': Array(9.2953156e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096737, dtype=float32), 'eval/episode_forward_reward': Array(-0.03268717, dtype=float32), 'eval/episode_reward': Array(-2.0293353, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03268717, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956675, dtype=float32), 'eval/episode_train_reward': Array(-0.00098062, dtype=float32), 'eval/episode_x_position': Array(1.0077617, dtype=float32), 'eval/episode_x_velocity': Array(-0.03268717, dtype=float32), 'eval/episode_y_position': Array(0.00019684, dtype=float32), 'eval/episode_y_velocity': Array(-0.00358089, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563025, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04083487, dtype=float32), 'eval/episode_reward_std': Array(0.04774776, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04083487, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01699886, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122505, dtype=float32), 'eval/episode_x_position_std': Array(0.00562691, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04083487, dtype=float32), 'eval/episode_y_position_std': Array(0.00574924, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01649348, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672666549682617, 'eval/sps': 6191.750817069371, 'num_steps': 1776640}
{'eval/walltime': 7317.692420005798, 'training/sps': 126.98039394188868, 'training/walltime': 14088.796588420868, 'training/entropy_loss': Array(0.09502988, dtype=float32), 'training/policy_loss': Array(-0.05912694, dtype=float32), 'training/total_loss': Array(0.03590294, dtype=float32), 'training/v_loss': Array(6.286903e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091027, dtype=float32), 'eval/episode_forward_reward': Array(-0.04275399, dtype=float32), 'eval/episode_reward': Array(-2.0398626, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04275399, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995826, dtype=float32), 'eval/episode_train_reward': Array(-0.00128262, dtype=float32), 'eval/episode_x_position': Array(1.0072763, dtype=float32), 'eval/episode_x_velocity': Array(-0.04275399, dtype=float32), 'eval/episode_y_position': Array(0.00075473, dtype=float32), 'eval/episode_y_velocity': Array(-0.00279598, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059862, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0429828, dtype=float32), 'eval/episode_reward_std': Array(0.04997236, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0429828, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01641618, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128948, dtype=float32), 'eval/episode_x_position_std': Array(0.00598214, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0429828, dtype=float32), 'eval/episode_y_position_std': Array(0.00602977, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01454164, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.59280037879944, 'eval/sps': 6215.764618967399, 'num_steps': 1781760}
{'eval/walltime': 7338.348088264465, 'training/sps': 127.34396198706054, 'training/walltime': 14129.002656459808, 'training/entropy_loss': Array(0.09495925, dtype=float32), 'training/policy_loss': Array(0.14872473, dtype=float32), 'training/total_loss': Array(0.243684, dtype=float32), 'training/v_loss': Array(7.0986816e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089655, dtype=float32), 'eval/episode_forward_reward': Array(-0.04479507, dtype=float32), 'eval/episode_reward': Array(-2.042346, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04479507, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962068, dtype=float32), 'eval/episode_train_reward': Array(-0.00134385, dtype=float32), 'eval/episode_x_position': Array(1.0071173, dtype=float32), 'eval/episode_x_velocity': Array(-0.04479507, dtype=float32), 'eval/episode_y_position': Array(-0.00073347, dtype=float32), 'eval/episode_y_velocity': Array(-0.00207944, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579561, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0438211, dtype=float32), 'eval/episode_reward_std': Array(0.04798585, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0438211, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01603868, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131463, dtype=float32), 'eval/episode_x_position_std': Array(0.00578372, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0438211, dtype=float32), 'eval/episode_y_position_std': Array(0.00567565, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01339254, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.655668258666992, 'eval/sps': 6196.846231120699, 'num_steps': 1786880}
{'eval/walltime': 7358.954451560974, 'training/sps': 127.12482839201431, 'training/walltime': 14169.278030395508, 'training/entropy_loss': Array(0.09316934, dtype=float32), 'training/policy_loss': Array(0.27129263, dtype=float32), 'training/total_loss': Array(0.364462, dtype=float32), 'training/v_loss': Array(7.400709e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089519, dtype=float32), 'eval/episode_forward_reward': Array(-0.03840347, dtype=float32), 'eval/episode_reward': Array(-2.0371928, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03840347, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976373, dtype=float32), 'eval/episode_train_reward': Array(-0.0011521, dtype=float32), 'eval/episode_x_position': Array(1.007073, dtype=float32), 'eval/episode_x_velocity': Array(-0.03840347, dtype=float32), 'eval/episode_y_position': Array(-4.424015e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00144531, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590531, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04555069, dtype=float32), 'eval/episode_reward_std': Array(0.04906929, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04555069, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01076497, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136652, dtype=float32), 'eval/episode_x_position_std': Array(0.00588869, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04555069, dtype=float32), 'eval/episode_y_position_std': Array(0.00557629, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01476615, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.60636329650879, 'eval/sps': 6211.673460192089, 'num_steps': 1792000}
{'eval/walltime': 7379.64492225647, 'training/sps': 127.34658992470465, 'training/walltime': 14209.483268737793, 'training/entropy_loss': Array(0.09379996, dtype=float32), 'training/policy_loss': Array(-0.08799282, dtype=float32), 'training/total_loss': Array(0.00580714, dtype=float32), 'training/v_loss': Array(9.913428e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100842, dtype=float32), 'eval/episode_forward_reward': Array(-0.0380304, dtype=float32), 'eval/episode_reward': Array(-2.0350566, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0380304, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958854, dtype=float32), 'eval/episode_train_reward': Array(-0.00114091, dtype=float32), 'eval/episode_x_position': Array(1.0081971, dtype=float32), 'eval/episode_x_velocity': Array(-0.0380304, dtype=float32), 'eval/episode_y_position': Array(-5.03209e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00330322, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00621529, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04286307, dtype=float32), 'eval/episode_reward_std': Array(0.04758304, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04286307, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01583627, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128589, dtype=float32), 'eval/episode_x_position_std': Array(0.00620872, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04286307, dtype=float32), 'eval/episode_y_position_std': Array(0.00565149, dtype=float32), 'eval/episode_y_velocity_std': Array(0.008313, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.690470695495605, 'eval/sps': 6186.422816754289, 'num_steps': 1797120}
{'eval/walltime': 7400.272928476334, 'training/sps': 127.19973239460262, 'training/walltime': 14249.734925746918, 'training/entropy_loss': Array(0.09700042, dtype=float32), 'training/policy_loss': Array(0.12779011, dtype=float32), 'training/total_loss': Array(0.22479053, dtype=float32), 'training/v_loss': Array(2.728609e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096976, dtype=float32), 'eval/episode_forward_reward': Array(-0.03392024, dtype=float32), 'eval/episode_reward': Array(-2.0318048, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03392024, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996867, dtype=float32), 'eval/episode_train_reward': Array(-0.00101761, dtype=float32), 'eval/episode_x_position': Array(1.0077995, dtype=float32), 'eval/episode_x_velocity': Array(-0.03392024, dtype=float32), 'eval/episode_y_position': Array(0.00018029, dtype=float32), 'eval/episode_y_velocity': Array(-0.00117304, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558702, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04221234, dtype=float32), 'eval/episode_reward_std': Array(0.04627832, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04221234, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01468222, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126637, dtype=float32), 'eval/episode_x_position_std': Array(0.00558293, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04221234, dtype=float32), 'eval/episode_y_position_std': Array(0.0054843, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01190335, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62800621986389, 'eval/sps': 6205.156166607195, 'num_steps': 1802240}
{'eval/walltime': 7420.94166302681, 'training/sps': 127.21991846275604, 'training/walltime': 14289.980195999146, 'training/entropy_loss': Array(0.0966049, dtype=float32), 'training/policy_loss': Array(0.270073, dtype=float32), 'training/total_loss': Array(0.36667788, dtype=float32), 'training/v_loss': Array(1.0090382e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091008, dtype=float32), 'eval/episode_forward_reward': Array(-0.04340421, dtype=float32), 'eval/episode_reward': Array(-2.0421932, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04340421, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997487, dtype=float32), 'eval/episode_train_reward': Array(-0.00130213, dtype=float32), 'eval/episode_x_position': Array(1.007264, dtype=float32), 'eval/episode_x_velocity': Array(-0.04340421, dtype=float32), 'eval/episode_y_position': Array(-0.00062869, dtype=float32), 'eval/episode_y_velocity': Array(-0.00259226, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589884, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04199717, dtype=float32), 'eval/episode_reward_std': Array(0.04646, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04199717, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01255298, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125992, dtype=float32), 'eval/episode_x_position_std': Array(0.00589846, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04199717, dtype=float32), 'eval/episode_y_position_std': Array(0.00610844, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0134838, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.668734550476074, 'eval/sps': 6192.928729497457, 'num_steps': 1807360}
{'eval/walltime': 7441.563438177109, 'training/sps': 127.10122176306487, 'training/walltime': 14330.263050317764, 'training/entropy_loss': Array(0.09812307, dtype=float32), 'training/policy_loss': Array(0.0846483, dtype=float32), 'training/total_loss': Array(0.18277135, dtype=float32), 'training/v_loss': Array(2.3661801e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098054, dtype=float32), 'eval/episode_forward_reward': Array(-0.03342913, dtype=float32), 'eval/episode_reward': Array(-2.0314293, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03342913, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969974, dtype=float32), 'eval/episode_train_reward': Array(-0.00100287, dtype=float32), 'eval/episode_x_position': Array(1.0078709, dtype=float32), 'eval/episode_x_velocity': Array(-0.03342913, dtype=float32), 'eval/episode_y_position': Array(0.00070466, dtype=float32), 'eval/episode_y_velocity': Array(-6.810622e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057859, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0411879, dtype=float32), 'eval/episode_reward_std': Array(0.04662558, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0411879, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01368852, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123564, dtype=float32), 'eval/episode_x_position_std': Array(0.00575809, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0411879, dtype=float32), 'eval/episode_y_position_std': Array(0.00543284, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00914725, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.621775150299072, 'eval/sps': 6207.031114784687, 'num_steps': 1812480}
{'eval/walltime': 7462.25145149231, 'training/sps': 127.23512554215093, 'training/walltime': 14370.503510475159, 'training/entropy_loss': Array(0.10179422, dtype=float32), 'training/policy_loss': Array(0.2686539, dtype=float32), 'training/total_loss': Array(0.3704481, dtype=float32), 'training/v_loss': Array(9.805037e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0173144, dtype=float32), 'eval/episode_forward_reward': Array(-0.04192791, dtype=float32), 'eval/episode_reward': Array(-2.054538, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04192791, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0191646, dtype=float32), 'eval/episode_train_reward': Array(-0.00125784, dtype=float32), 'eval/episode_x_position': Array(1.0154107, dtype=float32), 'eval/episode_x_velocity': Array(-0.04192791, dtype=float32), 'eval/episode_y_position': Array(-0.00052947, dtype=float32), 'eval/episode_y_velocity': Array(-0.00237558, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08730946, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04368811, dtype=float32), 'eval/episode_reward_std': Array(0.18063614, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04368811, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26493204, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131064, dtype=float32), 'eval/episode_x_position_std': Array(0.08703652, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04368811, dtype=float32), 'eval/episode_y_position_std': Array(0.00610011, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01128231, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.688013315200806, 'eval/sps': 6187.15765742234, 'num_steps': 1817600}
{'eval/walltime': 7482.895161628723, 'training/sps': 127.04287447178085, 'training/walltime': 14410.804865598679, 'training/entropy_loss': Array(0.10171305, dtype=float32), 'training/policy_loss': Array(0.26746228, dtype=float32), 'training/total_loss': Array(0.36917531, dtype=float32), 'training/v_loss': Array(2.1451887e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092568, dtype=float32), 'eval/episode_forward_reward': Array(-0.03502704, dtype=float32), 'eval/episode_reward': Array(-2.0313656, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03502704, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995288, dtype=float32), 'eval/episode_train_reward': Array(-0.00105081, dtype=float32), 'eval/episode_x_position': Array(1.0073651, dtype=float32), 'eval/episode_x_velocity': Array(-0.03502704, dtype=float32), 'eval/episode_y_position': Array(-0.0001305, dtype=float32), 'eval/episode_y_velocity': Array(-0.00129236, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569104, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04043199, dtype=float32), 'eval/episode_reward_std': Array(0.04439001, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04043199, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01607546, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121296, dtype=float32), 'eval/episode_x_position_std': Array(0.00568314, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04043199, dtype=float32), 'eval/episode_y_position_std': Array(0.00552849, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01360636, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.643710136413574, 'eval/sps': 6200.435830292927, 'num_steps': 1822720}
{'eval/walltime': 7503.574239492416, 'training/sps': 127.25923065043331, 'training/walltime': 14451.0377035141, 'training/entropy_loss': Array(0.10270205, dtype=float32), 'training/policy_loss': Array(0.26599294, dtype=float32), 'training/total_loss': Array(0.36869496, dtype=float32), 'training/v_loss': Array(2.1301085e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095413, dtype=float32), 'eval/episode_forward_reward': Array(-0.03580268, dtype=float32), 'eval/episode_reward': Array(-2.0347893, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03580268, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979126, dtype=float32), 'eval/episode_train_reward': Array(-0.00107408, dtype=float32), 'eval/episode_x_position': Array(1.0076344, dtype=float32), 'eval/episode_x_velocity': Array(-0.03580268, dtype=float32), 'eval/episode_y_position': Array(0.00141341, dtype=float32), 'eval/episode_y_velocity': Array(-0.00159262, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00555986, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04290457, dtype=float32), 'eval/episode_reward_std': Array(0.0459733, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04290457, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01160404, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128714, dtype=float32), 'eval/episode_x_position_std': Array(0.00554319, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04290457, dtype=float32), 'eval/episode_y_position_std': Array(0.00555894, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01134732, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.679077863693237, 'eval/sps': 6189.831134817318, 'num_steps': 1827840}
{'eval/walltime': 7524.19778752327, 'training/sps': 127.28053851285638, 'training/walltime': 14491.26380610466, 'training/entropy_loss': Array(0.10327191, dtype=float32), 'training/policy_loss': Array(0.26896527, dtype=float32), 'training/total_loss': Array(0.37223718, dtype=float32), 'training/v_loss': Array(1.0633535e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009361, dtype=float32), 'eval/episode_forward_reward': Array(-0.04526057, dtype=float32), 'eval/episode_reward': Array(-2.0445254, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04526057, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979072, dtype=float32), 'eval/episode_train_reward': Array(-0.00135782, dtype=float32), 'eval/episode_x_position': Array(1.0075282, dtype=float32), 'eval/episode_x_velocity': Array(-0.04526057, dtype=float32), 'eval/episode_y_position': Array(0.00118804, dtype=float32), 'eval/episode_y_velocity': Array(-0.00249757, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602937, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04329593, dtype=float32), 'eval/episode_reward_std': Array(0.04600709, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04329593, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01229569, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129888, dtype=float32), 'eval/episode_x_position_std': Array(0.00602025, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04329593, dtype=float32), 'eval/episode_y_position_std': Array(0.0059304, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01797889, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62354803085327, 'eval/sps': 6206.497534202614, 'num_steps': 1832960}
{'eval/walltime': 7544.8863842487335, 'training/sps': 127.00461293137755, 'training/walltime': 14531.577302455902, 'training/entropy_loss': Array(0.10090733, dtype=float32), 'training/policy_loss': Array(0.27086508, dtype=float32), 'training/total_loss': Array(0.37177244, dtype=float32), 'training/v_loss': Array(2.5327092e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0251565, dtype=float32), 'eval/episode_forward_reward': Array(-0.03883002, dtype=float32), 'eval/episode_reward': Array(-2.067316, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03883002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.042946, dtype=float32), 'eval/episode_train_reward': Array(-0.0011649, dtype=float32), 'eval/episode_x_position': Array(1.0232592, dtype=float32), 'eval/episode_x_velocity': Array(-0.03883002, dtype=float32), 'eval/episode_y_position': Array(0.0005306, dtype=float32), 'eval/episode_y_velocity': Array(-0.00262612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12733491, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04214943, dtype=float32), 'eval/episode_reward_std': Array(0.24782237, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04214943, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37290013, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126448, dtype=float32), 'eval/episode_x_position_std': Array(0.12695335, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04214943, dtype=float32), 'eval/episode_y_position_std': Array(0.00600218, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01040625, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.688596725463867, 'eval/sps': 6186.983182018115, 'num_steps': 1838080}
{'eval/walltime': 7565.511691093445, 'training/sps': 127.14791907687078, 'training/walltime': 14571.845362186432, 'training/entropy_loss': Array(0.09971347, dtype=float32), 'training/policy_loss': Array(0.2711715, dtype=float32), 'training/total_loss': Array(0.37088498, dtype=float32), 'training/v_loss': Array(7.003676e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0082494, dtype=float32), 'eval/episode_forward_reward': Array(-0.03443185, dtype=float32), 'eval/episode_reward': Array(-2.0337338, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03443185, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998269, dtype=float32), 'eval/episode_train_reward': Array(-0.00103296, dtype=float32), 'eval/episode_x_position': Array(1.0063523, dtype=float32), 'eval/episode_x_velocity': Array(-0.03443185, dtype=float32), 'eval/episode_y_position': Array(-0.00038194, dtype=float32), 'eval/episode_y_velocity': Array(-0.00199854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579547, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04256808, dtype=float32), 'eval/episode_reward_std': Array(0.04467256, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04256808, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00985235, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127704, dtype=float32), 'eval/episode_x_position_std': Array(0.00575212, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04256808, dtype=float32), 'eval/episode_y_position_std': Array(0.00574151, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00952429, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.625306844711304, 'eval/sps': 6205.968277888747, 'num_steps': 1843200}
{'eval/walltime': 7586.184492111206, 'training/sps': 127.32647386155243, 'training/walltime': 14612.056952476501, 'training/entropy_loss': Array(0.09878854, dtype=float32), 'training/policy_loss': Array(0.27073824, dtype=float32), 'training/total_loss': Array(0.36952677, dtype=float32), 'training/v_loss': Array(2.5659224e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094678, dtype=float32), 'eval/episode_forward_reward': Array(-0.03547004, dtype=float32), 'eval/episode_reward': Array(-2.0310864, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03547004, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9945521, dtype=float32), 'eval/episode_train_reward': Array(-0.0010641, dtype=float32), 'eval/episode_x_position': Array(1.0075572, dtype=float32), 'eval/episode_x_velocity': Array(-0.03547004, dtype=float32), 'eval/episode_y_position': Array(-0.00034434, dtype=float32), 'eval/episode_y_velocity': Array(-0.00196076, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00626979, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04111211, dtype=float32), 'eval/episode_reward_std': Array(0.04695542, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04111211, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01875261, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123336, dtype=float32), 'eval/episode_x_position_std': Array(0.00623432, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04111211, dtype=float32), 'eval/episode_y_position_std': Array(0.00597743, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00940601, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67280101776123, 'eval/sps': 6191.710542273763, 'num_steps': 1848320}
{'eval/walltime': 7606.7636477947235, 'training/sps': 127.32768100849746, 'training/walltime': 14652.268161535263, 'training/entropy_loss': Array(0.09889442, dtype=float32), 'training/policy_loss': Array(0.2696866, dtype=float32), 'training/total_loss': Array(0.36858103, dtype=float32), 'training/v_loss': Array(1.1063954e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0259182, dtype=float32), 'eval/episode_forward_reward': Array(-0.03961512, dtype=float32), 'eval/episode_reward': Array(-2.066125, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03961512, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0409462, dtype=float32), 'eval/episode_train_reward': Array(-0.00118845, dtype=float32), 'eval/episode_x_position': Array(1.024003, dtype=float32), 'eval/episode_x_velocity': Array(-0.03961512, dtype=float32), 'eval/episode_y_position': Array(-0.00035089, dtype=float32), 'eval/episode_y_velocity': Array(-0.00155429, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12749673, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04335073, dtype=float32), 'eval/episode_reward_std': Array(0.24911287, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04335073, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3733031, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130052, dtype=float32), 'eval/episode_x_position_std': Array(0.1271133, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04335073, dtype=float32), 'eval/episode_y_position_std': Array(0.00636081, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01044273, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.579155683517456, 'eval/sps': 6219.885886888914, 'num_steps': 1853440}
{'eval/walltime': 7627.41804432869, 'training/sps': 127.32931926203693, 'training/walltime': 14692.478853225708, 'training/entropy_loss': Array(0.09802307, dtype=float32), 'training/policy_loss': Array(0.28416318, dtype=float32), 'training/total_loss': Array(0.38218623, dtype=float32), 'training/v_loss': Array(6.9608257e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0165746, dtype=float32), 'eval/episode_forward_reward': Array(-0.03570093, dtype=float32), 'eval/episode_reward': Array(-2.0465813, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03570093, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.017622, dtype=float32), 'eval/episode_train_reward': Array(-0.00107103, dtype=float32), 'eval/episode_x_position': Array(1.0146207, dtype=float32), 'eval/episode_x_velocity': Array(-0.03570093, dtype=float32), 'eval/episode_y_position': Array(-0.00055356, dtype=float32), 'eval/episode_y_velocity': Array(-0.00320181, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09077957, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0430512, dtype=float32), 'eval/episode_reward_std': Array(0.17239976, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0430512, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25591677, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129154, dtype=float32), 'eval/episode_x_position_std': Array(0.0905037, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0430512, dtype=float32), 'eval/episode_y_position_std': Array(0.00597731, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00988347, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.654396533966064, 'eval/sps': 6197.227780995904, 'num_steps': 1858560}
{'eval/walltime': 7648.0350024700165, 'training/sps': 127.4389098908361, 'training/walltime': 14732.654965877533, 'training/entropy_loss': Array(0.09657679, dtype=float32), 'training/policy_loss': Array(-0.03599155, dtype=float32), 'training/total_loss': Array(0.06058637, dtype=float32), 'training/v_loss': Array(1.1247512e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085341, dtype=float32), 'eval/episode_forward_reward': Array(-0.03859898, dtype=float32), 'eval/episode_reward': Array(-2.0343666, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03859898, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946094, dtype=float32), 'eval/episode_train_reward': Array(-0.00115797, dtype=float32), 'eval/episode_x_position': Array(1.0066552, dtype=float32), 'eval/episode_x_velocity': Array(-0.03859898, dtype=float32), 'eval/episode_y_position': Array(0.00046439, dtype=float32), 'eval/episode_y_velocity': Array(-0.00209581, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00564095, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04118281, dtype=float32), 'eval/episode_reward_std': Array(0.04570261, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04118281, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0186471, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123548, dtype=float32), 'eval/episode_x_position_std': Array(0.00568979, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04118281, dtype=float32), 'eval/episode_y_position_std': Array(0.00614989, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01376382, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.616958141326904, 'eval/sps': 6208.481344462872, 'num_steps': 1863680}
{'eval/walltime': 7668.668837547302, 'training/sps': 127.47024361835473, 'training/walltime': 14772.821202754974, 'training/entropy_loss': Array(0.09724414, dtype=float32), 'training/policy_loss': Array(0.0178385, dtype=float32), 'training/total_loss': Array(0.11508264, dtype=float32), 'training/v_loss': Array(3.1569556e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0160446, dtype=float32), 'eval/episode_forward_reward': Array(-0.04381586, dtype=float32), 'eval/episode_reward': Array(-2.0571468, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04381586, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0198288, dtype=float32), 'eval/episode_train_reward': Array(-0.00131448, dtype=float32), 'eval/episode_x_position': Array(1.0141842, dtype=float32), 'eval/episode_x_velocity': Array(-0.04381586, dtype=float32), 'eval/episode_y_position': Array(-0.00105565, dtype=float32), 'eval/episode_y_velocity': Array(-0.00015487, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08872364, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04517019, dtype=float32), 'eval/episode_reward_std': Array(0.17830233, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04517019, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26480997, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135511, dtype=float32), 'eval/episode_x_position_std': Array(0.08843481, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04517019, dtype=float32), 'eval/episode_y_position_std': Array(0.00579437, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01568259, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.633835077285767, 'eval/sps': 6203.403270432531, 'num_steps': 1868800}
{'eval/walltime': 7689.290401935577, 'training/sps': 127.26388005854218, 'training/walltime': 14813.052570819855, 'training/entropy_loss': Array(0.0972093, dtype=float32), 'training/policy_loss': Array(0.01194287, dtype=float32), 'training/total_loss': Array(0.10915218, dtype=float32), 'training/v_loss': Array(2.8697404e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009589, dtype=float32), 'eval/episode_forward_reward': Array(-0.03108848, dtype=float32), 'eval/episode_reward': Array(-2.0273504, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03108848, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9953294, dtype=float32), 'eval/episode_train_reward': Array(-0.00093265, dtype=float32), 'eval/episode_x_position': Array(1.0076709, dtype=float32), 'eval/episode_x_velocity': Array(-0.03108848, dtype=float32), 'eval/episode_y_position': Array(0.00084983, dtype=float32), 'eval/episode_y_velocity': Array(0.00014777, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568241, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04101353, dtype=float32), 'eval/episode_reward_std': Array(0.04387031, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04101353, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01467933, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123041, dtype=float32), 'eval/episode_x_position_std': Array(0.00566627, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04101353, dtype=float32), 'eval/episode_y_position_std': Array(0.00586464, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01223367, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.621564388275146, 'eval/sps': 6207.094553543051, 'num_steps': 1873920}
{'eval/walltime': 7709.967631101608, 'training/sps': 127.58956265820818, 'training/walltime': 14853.181245088577, 'training/entropy_loss': Array(0.09789519, dtype=float32), 'training/policy_loss': Array(-0.04282311, dtype=float32), 'training/total_loss': Array(0.05507208, dtype=float32), 'training/v_loss': Array(3.048404e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009005, dtype=float32), 'eval/episode_forward_reward': Array(-0.04102903, dtype=float32), 'eval/episode_reward': Array(-2.0380132, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04102903, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957533, dtype=float32), 'eval/episode_train_reward': Array(-0.00123087, dtype=float32), 'eval/episode_x_position': Array(1.0071303, dtype=float32), 'eval/episode_x_velocity': Array(-0.04102903, dtype=float32), 'eval/episode_y_position': Array(0.00049677, dtype=float32), 'eval/episode_y_velocity': Array(-0.00030512, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00544759, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0431112, dtype=float32), 'eval/episode_reward_std': Array(0.04640481, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0431112, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0148459, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129334, dtype=float32), 'eval/episode_x_position_std': Array(0.00542186, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0431112, dtype=float32), 'eval/episode_y_position_std': Array(0.00575743, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01144285, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677229166030884, 'eval/sps': 6190.384551634312, 'num_steps': 1879040}
{'eval/walltime': 7730.5488402843475, 'training/sps': 127.22006316727135, 'training/walltime': 14893.426469564438, 'training/entropy_loss': Array(0.09760448, dtype=float32), 'training/policy_loss': Array(0.06957974, dtype=float32), 'training/total_loss': Array(0.1671842, dtype=float32), 'training/v_loss': Array(2.5540956e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0180302, dtype=float32), 'eval/episode_forward_reward': Array(-0.03948583, dtype=float32), 'eval/episode_reward': Array(-2.0544474, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03948583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0215895, dtype=float32), 'eval/episode_train_reward': Array(-0.00118457, dtype=float32), 'eval/episode_x_position': Array(1.0161269, dtype=float32), 'eval/episode_x_velocity': Array(-0.03948583, dtype=float32), 'eval/episode_y_position': Array(-0.0002483, dtype=float32), 'eval/episode_y_velocity': Array(-0.00353439, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08961932, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04323541, dtype=float32), 'eval/episode_reward_std': Array(0.18010703, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04323541, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26444754, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129706, dtype=float32), 'eval/episode_x_position_std': Array(0.08935451, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04323541, dtype=float32), 'eval/episode_y_position_std': Array(0.00551944, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01399761, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.581209182739258, 'eval/sps': 6219.265295031797, 'num_steps': 1884160}
{'eval/walltime': 7751.205201387405, 'training/sps': 127.40370336523235, 'training/walltime': 14933.613684415817, 'training/entropy_loss': Array(0.09896626, dtype=float32), 'training/policy_loss': Array(-0.0891632, dtype=float32), 'training/total_loss': Array(0.00980306, dtype=float32), 'training/v_loss': Array(2.4022566e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091357, dtype=float32), 'eval/episode_forward_reward': Array(-0.0386294, dtype=float32), 'eval/episode_reward': Array(-2.0356832, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0386294, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995895, dtype=float32), 'eval/episode_train_reward': Array(-0.00115888, dtype=float32), 'eval/episode_x_position': Array(1.0072808, dtype=float32), 'eval/episode_x_velocity': Array(-0.0386294, dtype=float32), 'eval/episode_y_position': Array(0.00024059, dtype=float32), 'eval/episode_y_velocity': Array(-0.00126553, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588709, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04246451, dtype=float32), 'eval/episode_reward_std': Array(0.04560671, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04246451, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01600381, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127394, dtype=float32), 'eval/episode_x_position_std': Array(0.00590838, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04246451, dtype=float32), 'eval/episode_y_position_std': Array(0.00540643, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01115832, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65636110305786, 'eval/sps': 6196.638379886355, 'num_steps': 1889280}
{'eval/walltime': 7771.809072494507, 'training/sps': 127.31600231277578, 'training/walltime': 14973.828582048416, 'training/entropy_loss': Array(0.09914201, dtype=float32), 'training/policy_loss': Array(-0.05394074, dtype=float32), 'training/total_loss': Array(0.04520127, dtype=float32), 'training/v_loss': Array(2.104549e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087409, dtype=float32), 'eval/episode_forward_reward': Array(-0.03925603, dtype=float32), 'eval/episode_reward': Array(-2.0377603, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03925603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973269, dtype=float32), 'eval/episode_train_reward': Array(-0.00117768, dtype=float32), 'eval/episode_x_position': Array(1.006893, dtype=float32), 'eval/episode_x_velocity': Array(-0.03925603, dtype=float32), 'eval/episode_y_position': Array(0.0007457, dtype=float32), 'eval/episode_y_velocity': Array(-0.0032416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578725, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04105455, dtype=float32), 'eval/episode_reward_std': Array(0.04515809, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04105455, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01075416, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123164, dtype=float32), 'eval/episode_x_position_std': Array(0.00577528, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04105455, dtype=float32), 'eval/episode_y_position_std': Array(0.00585976, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0163402, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.60387110710144, 'eval/sps': 6212.424807680089, 'num_steps': 1894400}
{'eval/walltime': 7792.478448867798, 'training/sps': 127.42139567903904, 'training/walltime': 15014.01021695137, 'training/entropy_loss': Array(0.09543005, dtype=float32), 'training/policy_loss': Array(0.26666996, dtype=float32), 'training/total_loss': Array(0.3621, dtype=float32), 'training/v_loss': Array(2.492954e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176101, dtype=float32), 'eval/episode_forward_reward': Array(-0.04126993, dtype=float32), 'eval/episode_reward': Array(-2.052376, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04126993, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0176804, dtype=float32), 'eval/episode_train_reward': Array(-0.0012381, dtype=float32), 'eval/episode_x_position': Array(1.0157244, dtype=float32), 'eval/episode_x_velocity': Array(-0.04126993, dtype=float32), 'eval/episode_y_position': Array(0.00031563, dtype=float32), 'eval/episode_y_velocity': Array(-0.00235447, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0880039, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04485096, dtype=float32), 'eval/episode_reward_std': Array(0.17951232, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04485096, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2649673, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134553, dtype=float32), 'eval/episode_x_position_std': Array(0.08773261, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04485096, dtype=float32), 'eval/episode_y_position_std': Array(0.00580319, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01097665, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.669376373291016, 'eval/sps': 6192.736427471596, 'num_steps': 1899520}
{'eval/walltime': 7813.0880925655365, 'training/sps': 127.49866925404748, 'training/walltime': 15054.16749882698, 'training/entropy_loss': Array(0.09456546, dtype=float32), 'training/policy_loss': Array(-0.09041888, dtype=float32), 'training/total_loss': Array(0.00414661, dtype=float32), 'training/v_loss': Array(2.9222232e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086787, dtype=float32), 'eval/episode_forward_reward': Array(-0.03522472, dtype=float32), 'eval/episode_reward': Array(-2.0302613, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03522472, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99398, dtype=float32), 'eval/episode_train_reward': Array(-0.00105674, dtype=float32), 'eval/episode_x_position': Array(1.0068021, dtype=float32), 'eval/episode_x_velocity': Array(-0.03522472, dtype=float32), 'eval/episode_y_position': Array(0.00038338, dtype=float32), 'eval/episode_y_velocity': Array(-0.00046308, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00592993, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04139641, dtype=float32), 'eval/episode_reward_std': Array(0.04895777, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04139641, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02466686, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124189, dtype=float32), 'eval/episode_x_position_std': Array(0.00598474, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04139641, dtype=float32), 'eval/episode_y_position_std': Array(0.00587795, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01234088, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.609643697738647, 'eval/sps': 6210.6847589046165, 'num_steps': 1904640}
{'eval/walltime': 7833.741387844086, 'training/sps': 126.90298895541433, 'training/walltime': 15094.513278245926, 'training/entropy_loss': Array(0.09463707, dtype=float32), 'training/policy_loss': Array(0.00531659, dtype=float32), 'training/total_loss': Array(0.09995367, dtype=float32), 'training/v_loss': Array(2.674055e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086477, dtype=float32), 'eval/episode_forward_reward': Array(-0.04041071, dtype=float32), 'eval/episode_reward': Array(-2.0374947, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04041071, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958715, dtype=float32), 'eval/episode_train_reward': Array(-0.00121232, dtype=float32), 'eval/episode_x_position': Array(1.0067748, dtype=float32), 'eval/episode_x_velocity': Array(-0.04041071, dtype=float32), 'eval/episode_y_position': Array(-0.00034068, dtype=float32), 'eval/episode_y_velocity': Array(-0.00215491, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00530649, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04443613, dtype=float32), 'eval/episode_reward_std': Array(0.04934768, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04443613, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01539553, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133308, dtype=float32), 'eval/episode_x_position_std': Array(0.00529993, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04443613, dtype=float32), 'eval/episode_y_position_std': Array(0.00606663, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01214425, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.653295278549194, 'eval/sps': 6197.558223696275, 'num_steps': 1909760}
{'eval/walltime': 7854.326389312744, 'training/sps': 127.17348381344893, 'training/walltime': 15134.773243188858, 'training/entropy_loss': Array(0.09539065, dtype=float32), 'training/policy_loss': Array(-0.02167866, dtype=float32), 'training/total_loss': Array(0.07371198, dtype=float32), 'training/v_loss': Array(1.6547785e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088627, dtype=float32), 'eval/episode_forward_reward': Array(-0.04965673, dtype=float32), 'eval/episode_reward': Array(-2.0494783, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04965673, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983318, dtype=float32), 'eval/episode_train_reward': Array(-0.0014897, dtype=float32), 'eval/episode_x_position': Array(1.0070554, dtype=float32), 'eval/episode_x_velocity': Array(-0.04965673, dtype=float32), 'eval/episode_y_position': Array(0.00042014, dtype=float32), 'eval/episode_y_velocity': Array(-0.00319614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568548, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0480341, dtype=float32), 'eval/episode_reward_std': Array(0.05018641, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0480341, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00958395, dtype=float32), 'eval/episode_train_reward_std': Array(0.00144102, dtype=float32), 'eval/episode_x_position_std': Array(0.00562703, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0480341, dtype=float32), 'eval/episode_y_position_std': Array(0.00525346, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01495345, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.585001468658447, 'eval/sps': 6218.119546645917, 'num_steps': 1914880}
{'eval/walltime': 7874.991805076599, 'training/sps': 127.29931042727766, 'training/walltime': 15174.99341392517, 'training/entropy_loss': Array(0.09598011, dtype=float32), 'training/policy_loss': Array(-0.07330165, dtype=float32), 'training/total_loss': Array(0.02267845, dtype=float32), 'training/v_loss': Array(1.4871947e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094066, dtype=float32), 'eval/episode_forward_reward': Array(-0.04111448, dtype=float32), 'eval/episode_reward': Array(-2.0363941, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04111448, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9940462, dtype=float32), 'eval/episode_train_reward': Array(-0.00123343, dtype=float32), 'eval/episode_x_position': Array(1.0075651, dtype=float32), 'eval/episode_x_velocity': Array(-0.04111448, dtype=float32), 'eval/episode_y_position': Array(-6.343857e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00369734, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599177, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04252322, dtype=float32), 'eval/episode_reward_std': Array(0.04647031, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04252322, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02000354, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012757, dtype=float32), 'eval/episode_x_position_std': Array(0.00601234, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04252322, dtype=float32), 'eval/episode_y_position_std': Array(0.00566461, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0148458, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66541576385498, 'eval/sps': 6193.9232901318865, 'num_steps': 1920000}
{'eval/walltime': 7895.627548217773, 'training/sps': 127.25243626273951, 'training/walltime': 15215.22839999199, 'training/entropy_loss': Array(0.0961512, dtype=float32), 'training/policy_loss': Array(-0.04295979, dtype=float32), 'training/total_loss': Array(0.05319142, dtype=float32), 'training/v_loss': Array(1.5475575e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176256, dtype=float32), 'eval/episode_forward_reward': Array(-0.03444605, dtype=float32), 'eval/episode_reward': Array(-2.0445716, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03444605, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0169048, dtype=float32), 'eval/episode_train_reward': Array(-0.00103338, dtype=float32), 'eval/episode_x_position': Array(1.0157017, dtype=float32), 'eval/episode_x_velocity': Array(-0.03444605, dtype=float32), 'eval/episode_y_position': Array(-8.594601e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00094937, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0891693, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04228307, dtype=float32), 'eval/episode_reward_std': Array(0.18110569, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04228307, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26557553, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126849, dtype=float32), 'eval/episode_x_position_std': Array(0.08889786, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04228307, dtype=float32), 'eval/episode_y_position_std': Array(0.00581809, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0150373, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.635743141174316, 'eval/sps': 6202.829678791782, 'num_steps': 1925120}
{'eval/walltime': 7916.287136316299, 'training/sps': 127.23197000983068, 'training/walltime': 15255.469858169556, 'training/entropy_loss': Array(0.09656765, dtype=float32), 'training/policy_loss': Array(-0.0320562, dtype=float32), 'training/total_loss': Array(0.06451144, dtype=float32), 'training/v_loss': Array(1.7463332e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093056, dtype=float32), 'eval/episode_forward_reward': Array(-0.03968211, dtype=float32), 'eval/episode_reward': Array(-2.038338, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03968211, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974654, dtype=float32), 'eval/episode_train_reward': Array(-0.00119046, dtype=float32), 'eval/episode_x_position': Array(1.0074382, dtype=float32), 'eval/episode_x_velocity': Array(-0.03968211, dtype=float32), 'eval/episode_y_position': Array(-0.00045357, dtype=float32), 'eval/episode_y_velocity': Array(-0.00152223, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583383, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04310278, dtype=float32), 'eval/episode_reward_std': Array(0.04600339, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04310278, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01401749, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129308, dtype=float32), 'eval/episode_x_position_std': Array(0.00581364, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04310278, dtype=float32), 'eval/episode_y_position_std': Array(0.0059725, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00916684, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.659588098526, 'eval/sps': 6195.6704746273435, 'num_steps': 1930240}
{'eval/walltime': 7936.9376220703125, 'training/sps': 127.15994644473744, 'training/walltime': 15295.734109163284, 'training/entropy_loss': Array(0.09728785, dtype=float32), 'training/policy_loss': Array(-0.02558836, dtype=float32), 'training/total_loss': Array(0.07169949, dtype=float32), 'training/v_loss': Array(1.7505e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101411, dtype=float32), 'eval/episode_forward_reward': Array(-0.03264417, dtype=float32), 'eval/episode_reward': Array(-2.0289884, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03264417, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995365, dtype=float32), 'eval/episode_train_reward': Array(-0.00097933, dtype=float32), 'eval/episode_x_position': Array(1.0082139, dtype=float32), 'eval/episode_x_velocity': Array(-0.03264417, dtype=float32), 'eval/episode_y_position': Array(-0.00095736, dtype=float32), 'eval/episode_y_velocity': Array(-0.00188895, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574725, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04277018, dtype=float32), 'eval/episode_reward_std': Array(0.04765258, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04277018, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0175281, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128311, dtype=float32), 'eval/episode_x_position_std': Array(0.00572423, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04277018, dtype=float32), 'eval/episode_y_position_std': Array(0.00551208, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01017843, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65048575401306, 'eval/sps': 6198.40140928043, 'num_steps': 1935360}
{'eval/walltime': 7957.636993408203, 'training/sps': 127.1789690114993, 'training/walltime': 15335.992337703705, 'training/entropy_loss': Array(0.09533273, dtype=float32), 'training/policy_loss': Array(0.2642141, dtype=float32), 'training/total_loss': Array(0.3595468, dtype=float32), 'training/v_loss': Array(1.4263513e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090296, dtype=float32), 'eval/episode_forward_reward': Array(-0.04033892, dtype=float32), 'eval/episode_reward': Array(-2.0367837, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04033892, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952345, dtype=float32), 'eval/episode_train_reward': Array(-0.00121017, dtype=float32), 'eval/episode_x_position': Array(1.0071796, dtype=float32), 'eval/episode_x_velocity': Array(-0.04033892, dtype=float32), 'eval/episode_y_position': Array(0.00021565, dtype=float32), 'eval/episode_y_velocity': Array(-0.00168209, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561971, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04200332, dtype=float32), 'eval/episode_reward_std': Array(0.04575483, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04200332, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01819432, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012601, dtype=float32), 'eval/episode_x_position_std': Array(0.00564025, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04200332, dtype=float32), 'eval/episode_y_position_std': Array(0.00565446, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01283245, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.699371337890625, 'eval/sps': 6183.762681028547, 'num_steps': 1940480}
{'eval/walltime': 7978.260941743851, 'training/sps': 126.92994973831249, 'training/walltime': 15376.329547405243, 'training/entropy_loss': Array(0.09507754, dtype=float32), 'training/policy_loss': Array(-0.08871679, dtype=float32), 'training/total_loss': Array(0.00636077, dtype=float32), 'training/v_loss': Array(1.07271205e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100844, dtype=float32), 'eval/episode_forward_reward': Array(-0.03348446, dtype=float32), 'eval/episode_reward': Array(-2.0296059, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03348446, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9951172, dtype=float32), 'eval/episode_train_reward': Array(-0.00100453, dtype=float32), 'eval/episode_x_position': Array(1.0081786, dtype=float32), 'eval/episode_x_velocity': Array(-0.03348446, dtype=float32), 'eval/episode_y_position': Array(6.484517e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00252056, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558697, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0429447, dtype=float32), 'eval/episode_reward_std': Array(0.04635514, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0429447, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01712953, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128834, dtype=float32), 'eval/episode_x_position_std': Array(0.0056113, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0429447, dtype=float32), 'eval/episode_y_position_std': Array(0.00559456, dtype=float32), 'eval/episode_y_velocity_std': Array(0.012405, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.623948335647583, 'eval/sps': 6206.377067903999, 'num_steps': 1945600}
{'eval/walltime': 7998.927119255066, 'training/sps': 127.21665968366784, 'training/walltime': 15416.575848579407, 'training/entropy_loss': Array(0.09470229, dtype=float32), 'training/policy_loss': Array(0.2584749, dtype=float32), 'training/total_loss': Array(0.3531772, dtype=float32), 'training/v_loss': Array(6.5911776e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092759, dtype=float32), 'eval/episode_forward_reward': Array(-0.03849699, dtype=float32), 'eval/episode_reward': Array(-2.0373793, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03849699, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977274, dtype=float32), 'eval/episode_train_reward': Array(-0.00115491, dtype=float32), 'eval/episode_x_position': Array(1.0073955, dtype=float32), 'eval/episode_x_velocity': Array(-0.03849699, dtype=float32), 'eval/episode_y_position': Array(-0.00043644, dtype=float32), 'eval/episode_y_velocity': Array(-0.00241047, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572644, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04461293, dtype=float32), 'eval/episode_reward_std': Array(0.04746447, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04461293, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01017875, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133839, dtype=float32), 'eval/episode_x_position_std': Array(0.00572032, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04461293, dtype=float32), 'eval/episode_y_position_std': Array(0.00606419, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01010784, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66617751121521, 'eval/sps': 6193.694984499984, 'num_steps': 1950720}
{'eval/walltime': 8019.546591758728, 'training/sps': 127.06626620439322, 'training/walltime': 15456.869784593582, 'training/entropy_loss': Array(0.09492655, dtype=float32), 'training/policy_loss': Array(-0.10024049, dtype=float32), 'training/total_loss': Array(-0.00531394, dtype=float32), 'training/v_loss': Array(3.0492515e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009459, dtype=float32), 'eval/episode_forward_reward': Array(-0.03890856, dtype=float32), 'eval/episode_reward': Array(-2.0362382, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03890856, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961624, dtype=float32), 'eval/episode_train_reward': Array(-0.00116726, dtype=float32), 'eval/episode_x_position': Array(1.0075814, dtype=float32), 'eval/episode_x_velocity': Array(-0.03890856, dtype=float32), 'eval/episode_y_position': Array(-0.00037459, dtype=float32), 'eval/episode_y_velocity': Array(-0.00155707, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571586, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04399883, dtype=float32), 'eval/episode_reward_std': Array(0.04731561, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04399883, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01382103, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131997, dtype=float32), 'eval/episode_x_position_std': Array(0.00569246, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04399883, dtype=float32), 'eval/episode_y_position_std': Array(0.00574431, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01053382, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61947250366211, 'eval/sps': 6207.7242750641, 'num_steps': 1955840}
{'eval/walltime': 8040.213000535965, 'training/sps': 127.26494649136434, 'training/walltime': 15497.100815534592, 'training/entropy_loss': Array(0.09595866, dtype=float32), 'training/policy_loss': Array(-0.01648165, dtype=float32), 'training/total_loss': Array(0.079477, dtype=float32), 'training/v_loss': Array(4.1968223e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093989, dtype=float32), 'eval/episode_forward_reward': Array(-0.0341547, dtype=float32), 'eval/episode_reward': Array(-2.031251, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0341547, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960713, dtype=float32), 'eval/episode_train_reward': Array(-0.00102464, dtype=float32), 'eval/episode_x_position': Array(1.0074885, dtype=float32), 'eval/episode_x_velocity': Array(-0.0341547, dtype=float32), 'eval/episode_y_position': Array(0.00079295, dtype=float32), 'eval/episode_y_velocity': Array(-0.00157251, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00605321, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04275585, dtype=float32), 'eval/episode_reward_std': Array(0.04842263, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04275585, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01691425, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128268, dtype=float32), 'eval/episode_x_position_std': Array(0.00599714, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04275585, dtype=float32), 'eval/episode_y_position_std': Array(0.00571596, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01279547, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66640877723694, 'eval/sps': 6193.625674383538, 'num_steps': 1960960}
{'eval/walltime': 8060.824846744537, 'training/sps': 127.20805984083299, 'training/walltime': 15537.34983754158, 'training/entropy_loss': Array(0.0971085, dtype=float32), 'training/policy_loss': Array(-0.07524113, dtype=float32), 'training/total_loss': Array(0.02186737, dtype=float32), 'training/v_loss': Array(3.184e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087014, dtype=float32), 'eval/episode_forward_reward': Array(-0.03228042, dtype=float32), 'eval/episode_reward': Array(-2.026835, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03228042, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.993586, dtype=float32), 'eval/episode_train_reward': Array(-0.00096841, dtype=float32), 'eval/episode_x_position': Array(1.0067618, dtype=float32), 'eval/episode_x_velocity': Array(-0.03228042, dtype=float32), 'eval/episode_y_position': Array(-0.0005761, dtype=float32), 'eval/episode_y_velocity': Array(-0.00227662, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557437, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04122204, dtype=float32), 'eval/episode_reward_std': Array(0.04435171, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04122204, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02038085, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123666, dtype=float32), 'eval/episode_x_position_std': Array(0.00559396, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04122204, dtype=float32), 'eval/episode_y_position_std': Array(0.00567767, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01037592, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.611846208572388, 'eval/sps': 6210.021106540436, 'num_steps': 1966080}
{'eval/walltime': 8081.525188922882, 'training/sps': 127.14215051214818, 'training/walltime': 15577.619724273682, 'training/entropy_loss': Array(0.09704253, dtype=float32), 'training/policy_loss': Array(0.01933625, dtype=float32), 'training/total_loss': Array(0.11637878, dtype=float32), 'training/v_loss': Array(2.8257668e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095689, dtype=float32), 'eval/episode_forward_reward': Array(-0.04300926, dtype=float32), 'eval/episode_reward': Array(-2.0393088, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04300926, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9950092, dtype=float32), 'eval/episode_train_reward': Array(-0.00129028, dtype=float32), 'eval/episode_x_position': Array(1.0077192, dtype=float32), 'eval/episode_x_velocity': Array(-0.04300926, dtype=float32), 'eval/episode_y_position': Array(0.00065334, dtype=float32), 'eval/episode_y_velocity': Array(-0.00171144, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588785, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04414143, dtype=float32), 'eval/episode_reward_std': Array(0.04936162, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04414143, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01887415, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132424, dtype=float32), 'eval/episode_x_position_std': Array(0.00592335, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04414143, dtype=float32), 'eval/episode_y_position_std': Array(0.00585184, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01571651, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.700342178344727, 'eval/sps': 6183.472664229907, 'num_steps': 1971200}
{'eval/walltime': 8102.151515007019, 'training/sps': 127.15909786662654, 'training/walltime': 15617.884243965149, 'training/entropy_loss': Array(0.09759706, dtype=float32), 'training/policy_loss': Array(0.26741326, dtype=float32), 'training/total_loss': Array(0.36501032, dtype=float32), 'training/v_loss': Array(3.6154763e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098484, dtype=float32), 'eval/episode_forward_reward': Array(-0.03961443, dtype=float32), 'eval/episode_reward': Array(-2.0387444, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03961443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979415, dtype=float32), 'eval/episode_train_reward': Array(-0.00118843, dtype=float32), 'eval/episode_x_position': Array(1.0079731, dtype=float32), 'eval/episode_x_velocity': Array(-0.03961443, dtype=float32), 'eval/episode_y_position': Array(-6.4456253e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00325949, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00562417, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04607278, dtype=float32), 'eval/episode_reward_std': Array(0.04860411, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04607278, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01063096, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138218, dtype=float32), 'eval/episode_x_position_std': Array(0.00558115, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04607278, dtype=float32), 'eval/episode_y_position_std': Array(0.00583532, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01273919, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.626326084136963, 'eval/sps': 6205.661613118811, 'num_steps': 1976320}
{'eval/walltime': 8122.813318729401, 'training/sps': 127.13580667395544, 'training/walltime': 15658.156140089035, 'training/entropy_loss': Array(0.09860225, dtype=float32), 'training/policy_loss': Array(0.23974489, dtype=float32), 'training/total_loss': Array(0.33834714, dtype=float32), 'training/v_loss': Array(1.827706e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088553, dtype=float32), 'eval/episode_forward_reward': Array(-0.03557629, dtype=float32), 'eval/episode_reward': Array(-2.0354047, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03557629, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987612, dtype=float32), 'eval/episode_train_reward': Array(-0.00106729, dtype=float32), 'eval/episode_x_position': Array(1.0069623, dtype=float32), 'eval/episode_x_velocity': Array(-0.03557629, dtype=float32), 'eval/episode_y_position': Array(0.00040185, dtype=float32), 'eval/episode_y_velocity': Array(-0.00162677, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579923, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0421327, dtype=float32), 'eval/episode_reward_std': Array(0.04490894, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0421327, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00900375, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126398, dtype=float32), 'eval/episode_x_position_std': Array(0.00575953, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0421327, dtype=float32), 'eval/episode_y_position_std': Array(0.00611689, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01149324, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.661803722381592, 'eval/sps': 6195.006095297765, 'num_steps': 1981440}
{'eval/walltime': 8143.46994638443, 'training/sps': 127.12390728696123, 'training/walltime': 15698.431805849075, 'training/entropy_loss': Array(0.09910412, dtype=float32), 'training/policy_loss': Array(0.04954115, dtype=float32), 'training/total_loss': Array(0.14864528, dtype=float32), 'training/v_loss': Array(8.823667e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008801, dtype=float32), 'eval/episode_forward_reward': Array(-0.03650032, dtype=float32), 'eval/episode_reward': Array(-2.0293117, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03650032, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9917161, dtype=float32), 'eval/episode_train_reward': Array(-0.00109501, dtype=float32), 'eval/episode_x_position': Array(1.0068927, dtype=float32), 'eval/episode_x_velocity': Array(-0.03650032, dtype=float32), 'eval/episode_y_position': Array(0.00042238, dtype=float32), 'eval/episode_y_velocity': Array(-0.00189999, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596574, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04378153, dtype=float32), 'eval/episode_reward_std': Array(0.05108077, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04378153, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02279518, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131345, dtype=float32), 'eval/episode_x_position_std': Array(0.00597398, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04378153, dtype=float32), 'eval/episode_y_position_std': Array(0.00572429, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01298293, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.656627655029297, 'eval/sps': 6196.558418810229, 'num_steps': 1986560}
{'eval/walltime': 8164.144758224487, 'training/sps': 127.28676100026047, 'training/walltime': 15738.655941963196, 'training/entropy_loss': Array(0.10058099, dtype=float32), 'training/policy_loss': Array(0.0111081, dtype=float32), 'training/total_loss': Array(0.11168909, dtype=float32), 'training/v_loss': Array(1.752439e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091031, dtype=float32), 'eval/episode_forward_reward': Array(-0.04595828, dtype=float32), 'eval/episode_reward': Array(-2.041737, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04595828, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9944, dtype=float32), 'eval/episode_train_reward': Array(-0.00137875, dtype=float32), 'eval/episode_x_position': Array(1.0072687, dtype=float32), 'eval/episode_x_velocity': Array(-0.04595828, dtype=float32), 'eval/episode_y_position': Array(0.00057482, dtype=float32), 'eval/episode_y_velocity': Array(-0.00487654, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614713, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04549859, dtype=float32), 'eval/episode_reward_std': Array(0.05139384, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04549859, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02017814, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136496, dtype=float32), 'eval/episode_x_position_std': Array(0.00613124, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04549859, dtype=float32), 'eval/episode_y_position_std': Array(0.00579917, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01379935, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.674811840057373, 'eval/sps': 6191.108339472307, 'num_steps': 1991680}
{'eval/walltime': 8184.753365755081, 'training/sps': 127.20843208475209, 'training/walltime': 15778.904846191406, 'training/entropy_loss': Array(0.10176378, dtype=float32), 'training/policy_loss': Array(0.26042545, dtype=float32), 'training/total_loss': Array(0.3621892, dtype=float32), 'training/v_loss': Array(1.2487371e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098798, dtype=float32), 'eval/episode_forward_reward': Array(-0.02939805, dtype=float32), 'eval/episode_reward': Array(-2.0289497, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.02939805, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986696, dtype=float32), 'eval/episode_train_reward': Array(-0.00088194, dtype=float32), 'eval/episode_x_position': Array(1.0079262, dtype=float32), 'eval/episode_x_velocity': Array(-0.02939805, dtype=float32), 'eval/episode_y_position': Array(-0.00055613, dtype=float32), 'eval/episode_y_velocity': Array(-0.00171337, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571208, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04103322, dtype=float32), 'eval/episode_reward_std': Array(0.04246762, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04103322, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00806187, dtype=float32), 'eval/episode_train_reward_std': Array(0.001231, dtype=float32), 'eval/episode_x_position_std': Array(0.00574901, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04103322, dtype=float32), 'eval/episode_y_position_std': Array(0.00588749, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00917455, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.608607530593872, 'eval/sps': 6210.99702199586, 'num_steps': 1996800}
{'eval/walltime': 8205.381432056427, 'training/sps': 127.184752969794, 'training/walltime': 15819.161243915558, 'training/entropy_loss': Array(0.10293017, dtype=float32), 'training/policy_loss': Array(0.263796, dtype=float32), 'training/total_loss': Array(0.3667262, dtype=float32), 'training/v_loss': Array(7.3465484e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083823, dtype=float32), 'eval/episode_forward_reward': Array(-0.03990694, dtype=float32), 'eval/episode_reward': Array(-2.0367532, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03990694, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956489, dtype=float32), 'eval/episode_train_reward': Array(-0.00119721, dtype=float32), 'eval/episode_x_position': Array(1.0065118, dtype=float32), 'eval/episode_x_velocity': Array(-0.03990694, dtype=float32), 'eval/episode_y_position': Array(0.00051277, dtype=float32), 'eval/episode_y_velocity': Array(-0.00382899, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0056985, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04330036, dtype=float32), 'eval/episode_reward_std': Array(0.04976335, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04330036, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02037717, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129901, dtype=float32), 'eval/episode_x_position_std': Array(0.00568197, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04330036, dtype=float32), 'eval/episode_y_position_std': Array(0.00595311, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01403459, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.628066301345825, 'eval/sps': 6205.138093416394, 'num_steps': 2001920}
{'eval/walltime': 8225.996653079987, 'training/sps': 127.20421621066743, 'training/walltime': 15859.411482095718, 'training/entropy_loss': Array(0.10546079, dtype=float32), 'training/policy_loss': Array(0.268292, dtype=float32), 'training/total_loss': Array(0.37375277, dtype=float32), 'training/v_loss': Array(5.7236865e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091109, dtype=float32), 'eval/episode_forward_reward': Array(-0.04100908, dtype=float32), 'eval/episode_reward': Array(-2.0401978, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04100908, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979582, dtype=float32), 'eval/episode_train_reward': Array(-0.00123027, dtype=float32), 'eval/episode_x_position': Array(1.0072563, dtype=float32), 'eval/episode_x_velocity': Array(-0.04100908, dtype=float32), 'eval/episode_y_position': Array(0.00078508, dtype=float32), 'eval/episode_y_velocity': Array(-0.00093637, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602592, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04478233, dtype=float32), 'eval/episode_reward_std': Array(0.04848725, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04478233, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01144524, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134347, dtype=float32), 'eval/episode_x_position_std': Array(0.00598249, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04478233, dtype=float32), 'eval/episode_y_position_std': Array(0.00588761, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01513433, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61522102355957, 'eval/sps': 6209.0044949660505, 'num_steps': 2007040}
{'eval/walltime': 8246.69329380989, 'training/sps': 127.27128361288345, 'training/walltime': 15899.640509843826, 'training/entropy_loss': Array(0.10378896, dtype=float32), 'training/policy_loss': Array(0.27059978, dtype=float32), 'training/total_loss': Array(0.37438872, dtype=float32), 'training/v_loss': Array(1.5309672e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090576, dtype=float32), 'eval/episode_forward_reward': Array(-0.03667595, dtype=float32), 'eval/episode_reward': Array(-2.034614, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03667595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968379, dtype=float32), 'eval/episode_train_reward': Array(-0.00110028, dtype=float32), 'eval/episode_x_position': Array(1.0071647, dtype=float32), 'eval/episode_x_velocity': Array(-0.03667595, dtype=float32), 'eval/episode_y_position': Array(-0.00075092, dtype=float32), 'eval/episode_y_velocity': Array(-0.00343864, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0052513, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04267304, dtype=float32), 'eval/episode_reward_std': Array(0.04686176, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04267304, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01434214, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128019, dtype=float32), 'eval/episode_x_position_std': Array(0.00525566, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04267304, dtype=float32), 'eval/episode_y_position_std': Array(0.00543598, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01638954, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.696640729904175, 'eval/sps': 6184.578534769426, 'num_steps': 2012160}
{'eval/walltime': 8267.383954048157, 'training/sps': 127.2436378170663, 'training/walltime': 15939.878278017044, 'training/entropy_loss': Array(0.10379542, dtype=float32), 'training/policy_loss': Array(0.26964775, dtype=float32), 'training/total_loss': Array(0.3734432, dtype=float32), 'training/v_loss': Array(1.7433948e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089347, dtype=float32), 'eval/episode_forward_reward': Array(-0.04085037, dtype=float32), 'eval/episode_reward': Array(-2.0393598, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04085037, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997284, dtype=float32), 'eval/episode_train_reward': Array(-0.00122551, dtype=float32), 'eval/episode_x_position': Array(1.0070959, dtype=float32), 'eval/episode_x_velocity': Array(-0.04085037, dtype=float32), 'eval/episode_y_position': Array(0.0002776, dtype=float32), 'eval/episode_y_velocity': Array(-0.00231962, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600033, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04382251, dtype=float32), 'eval/episode_reward_std': Array(0.04756469, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04382251, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01195956, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131468, dtype=float32), 'eval/episode_x_position_std': Array(0.00595273, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04382251, dtype=float32), 'eval/episode_y_position_std': Array(0.00591704, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0121141, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69066023826599, 'eval/sps': 6186.366144240896, 'num_steps': 2017280}
{'eval/walltime': 8288.105285406113, 'training/sps': 127.36514262501754, 'training/walltime': 15980.077659845352, 'training/entropy_loss': Array(0.10268531, dtype=float32), 'training/policy_loss': Array(0.25824386, dtype=float32), 'training/total_loss': Array(0.3609292, dtype=float32), 'training/v_loss': Array(2.649306e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0251515, dtype=float32), 'eval/episode_forward_reward': Array(-0.03722271, dtype=float32), 'eval/episode_reward': Array(-2.0666933, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03722271, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0439792, dtype=float32), 'eval/episode_train_reward': Array(-0.00111668, dtype=float32), 'eval/episode_x_position': Array(1.0232286, dtype=float32), 'eval/episode_x_velocity': Array(-0.03722271, dtype=float32), 'eval/episode_y_position': Array(-3.4442193e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00159498, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12494871, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04385635, dtype=float32), 'eval/episode_reward_std': Array(0.2475424, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04385635, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37265897, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131569, dtype=float32), 'eval/episode_x_position_std': Array(0.1245731, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04385635, dtype=float32), 'eval/episode_y_position_std': Array(0.00565956, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01251173, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.721331357955933, 'eval/sps': 6177.209262707656, 'num_steps': 2022400}
{'eval/walltime': 8308.798817157745, 'training/sps': 126.99913600307086, 'training/walltime': 16020.392894744873, 'training/entropy_loss': Array(0.09986894, dtype=float32), 'training/policy_loss': Array(0.26184648, dtype=float32), 'training/total_loss': Array(0.36171547, dtype=float32), 'training/v_loss': Array(4.7478842e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176113, dtype=float32), 'eval/episode_forward_reward': Array(-0.03132007, dtype=float32), 'eval/episode_reward': Array(-2.0456376, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03132007, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0211906, dtype=float32), 'eval/episode_train_reward': Array(-0.0009396, dtype=float32), 'eval/episode_x_position': Array(1.0156797, dtype=float32), 'eval/episode_x_velocity': Array(-0.03132007, dtype=float32), 'eval/episode_y_position': Array(-5.076971e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00243045, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09026252, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03918927, dtype=float32), 'eval/episode_reward_std': Array(0.18002553, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03918927, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26456058, dtype=float32), 'eval/episode_train_reward_std': Array(0.00117568, dtype=float32), 'eval/episode_x_position_std': Array(0.09000155, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03918927, dtype=float32), 'eval/episode_y_position_std': Array(0.00559166, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01128852, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.69353175163269, 'eval/sps': 6185.507700487182, 'num_steps': 2027520}
{'eval/walltime': 8329.490107297897, 'training/sps': 126.87811304984444, 'training/walltime': 16060.746584415436, 'training/entropy_loss': Array(0.09892558, dtype=float32), 'training/policy_loss': Array(0.2654007, dtype=float32), 'training/total_loss': Array(0.3643263, dtype=float32), 'training/v_loss': Array(5.367543e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176398, dtype=float32), 'eval/episode_forward_reward': Array(-0.04115406, dtype=float32), 'eval/episode_reward': Array(-2.0535157, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04115406, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0189395, dtype=float32), 'eval/episode_train_reward': Array(-0.00123462, dtype=float32), 'eval/episode_x_position': Array(1.0157475, dtype=float32), 'eval/episode_x_velocity': Array(-0.04115406, dtype=float32), 'eval/episode_y_position': Array(0.00046579, dtype=float32), 'eval/episode_y_velocity': Array(-0.00296028, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09084084, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04330024, dtype=float32), 'eval/episode_reward_std': Array(0.18051916, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04330024, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26514173, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129901, dtype=float32), 'eval/episode_x_position_std': Array(0.09058011, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04330024, dtype=float32), 'eval/episode_y_position_std': Array(0.00573653, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01354298, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.691290140151978, 'eval/sps': 6186.177813611183, 'num_steps': 2032640}
{'eval/walltime': 8350.156247138977, 'training/sps': 127.31915069209231, 'training/walltime': 16100.960487604141, 'training/entropy_loss': Array(0.09871749, dtype=float32), 'training/policy_loss': Array(0.26373714, dtype=float32), 'training/total_loss': Array(0.36245462, dtype=float32), 'training/v_loss': Array(7.831466e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093462, dtype=float32), 'eval/episode_forward_reward': Array(-0.03878656, dtype=float32), 'eval/episode_reward': Array(-2.035205, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03878656, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952548, dtype=float32), 'eval/episode_train_reward': Array(-0.0011636, dtype=float32), 'eval/episode_x_position': Array(1.0075002, dtype=float32), 'eval/episode_x_velocity': Array(-0.03878656, dtype=float32), 'eval/episode_y_position': Array(-0.00024109, dtype=float32), 'eval/episode_y_velocity': Array(-0.00073482, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576598, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04375975, dtype=float32), 'eval/episode_reward_std': Array(0.04889708, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04375975, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01747555, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131279, dtype=float32), 'eval/episode_x_position_std': Array(0.00579347, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04375975, dtype=float32), 'eval/episode_y_position_std': Array(0.00563812, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01407527, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666139841079712, 'eval/sps': 6193.706274335971, 'num_steps': 2037760}
{'eval/walltime': 8370.833718776703, 'training/sps': 126.89859683710979, 'training/walltime': 16141.307663440704, 'training/entropy_loss': Array(0.09992994, dtype=float32), 'training/policy_loss': Array(0.07263969, dtype=float32), 'training/total_loss': Array(0.17256963, dtype=float32), 'training/v_loss': Array(1.1918888e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094, dtype=float32), 'eval/episode_forward_reward': Array(-0.03934388, dtype=float32), 'eval/episode_reward': Array(-2.0386395, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03934388, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998115, dtype=float32), 'eval/episode_train_reward': Array(-0.00118032, dtype=float32), 'eval/episode_x_position': Array(1.0075691, dtype=float32), 'eval/episode_x_velocity': Array(-0.03934388, dtype=float32), 'eval/episode_y_position': Array(-4.398584e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00215653, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00587644, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04211105, dtype=float32), 'eval/episode_reward_std': Array(0.04387122, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04211105, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00867902, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126333, dtype=float32), 'eval/episode_x_position_std': Array(0.00594044, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04211105, dtype=float32), 'eval/episode_y_position_std': Array(0.00576706, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01347588, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67747163772583, 'eval/sps': 6190.3119608910665, 'num_steps': 2042880}
{'eval/walltime': 8391.52967429161, 'training/sps': 127.33233768470527, 'training/walltime': 16181.51740193367, 'training/entropy_loss': Array(0.10197645, dtype=float32), 'training/policy_loss': Array(0.2655502, dtype=float32), 'training/total_loss': Array(0.36752668, dtype=float32), 'training/v_loss': Array(9.188442e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100477, dtype=float32), 'eval/episode_forward_reward': Array(-0.04252885, dtype=float32), 'eval/episode_reward': Array(-2.0401568, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04252885, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963524, dtype=float32), 'eval/episode_train_reward': Array(-0.00127587, dtype=float32), 'eval/episode_x_position': Array(1.0082469, dtype=float32), 'eval/episode_x_velocity': Array(-0.04252885, dtype=float32), 'eval/episode_y_position': Array(0.00117563, dtype=float32), 'eval/episode_y_velocity': Array(-0.00263784, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566213, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04383907, dtype=float32), 'eval/episode_reward_std': Array(0.04843336, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04383907, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0133322, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131517, dtype=float32), 'eval/episode_x_position_std': Array(0.00568749, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04383907, dtype=float32), 'eval/episode_y_position_std': Array(0.00552818, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0142597, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.695955514907837, 'eval/sps': 6184.783297770343, 'num_steps': 2048000}
{'eval/walltime': 8412.217412471771, 'training/sps': 127.21357891931434, 'training/walltime': 16221.764677762985, 'training/entropy_loss': Array(0.10161739, dtype=float32), 'training/policy_loss': Array(0.26838803, dtype=float32), 'training/total_loss': Array(0.37000543, dtype=float32), 'training/v_loss': Array(7.625657e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169652, dtype=float32), 'eval/episode_forward_reward': Array(-0.04153039, dtype=float32), 'eval/episode_reward': Array(-2.0549743, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04153039, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0200105, dtype=float32), 'eval/episode_train_reward': Array(-0.00124591, dtype=float32), 'eval/episode_x_position': Array(1.0150862, dtype=float32), 'eval/episode_x_velocity': Array(-0.04153039, dtype=float32), 'eval/episode_y_position': Array(-0.0004633, dtype=float32), 'eval/episode_y_velocity': Array(-0.00226755, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09072826, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0426306, dtype=float32), 'eval/episode_reward_std': Array(0.17865144, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0426306, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26480743, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127892, dtype=float32), 'eval/episode_x_position_std': Array(0.09046303, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0426306, dtype=float32), 'eval/episode_y_position_std': Array(0.00608946, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01073084, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.687738180160522, 'eval/sps': 6187.239943066933, 'num_steps': 2053120}
{'eval/walltime': 8432.90600013733, 'training/sps': 127.24904838911374, 'training/walltime': 16262.00073504448, 'training/entropy_loss': Array(0.1022751, dtype=float32), 'training/policy_loss': Array(0.26596516, dtype=float32), 'training/total_loss': Array(0.3682403, dtype=float32), 'training/v_loss': Array(1.8007885e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008642, dtype=float32), 'eval/episode_forward_reward': Array(-0.03655425, dtype=float32), 'eval/episode_reward': Array(-2.0341053, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03655425, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964542, dtype=float32), 'eval/episode_train_reward': Array(-0.00109663, dtype=float32), 'eval/episode_x_position': Array(1.0067749, dtype=float32), 'eval/episode_x_velocity': Array(-0.03655425, dtype=float32), 'eval/episode_y_position': Array(-0.00073904, dtype=float32), 'eval/episode_y_velocity': Array(-0.00407636, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602676, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04153459, dtype=float32), 'eval/episode_reward_std': Array(0.04580591, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04153459, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0155887, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124604, dtype=float32), 'eval/episode_x_position_std': Array(0.00602665, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04153459, dtype=float32), 'eval/episode_y_position_std': Array(0.00579976, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0127797, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68858766555786, 'eval/sps': 6186.985891409738, 'num_steps': 2058240}
{'eval/walltime': 8453.590238809586, 'training/sps': 127.35960434540638, 'training/walltime': 16302.20186495781, 'training/entropy_loss': Array(0.10441528, dtype=float32), 'training/policy_loss': Array(0.26414073, dtype=float32), 'training/total_loss': Array(0.36855602, dtype=float32), 'training/v_loss': Array(3.3758385e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086699, dtype=float32), 'eval/episode_forward_reward': Array(-0.03618445, dtype=float32), 'eval/episode_reward': Array(-2.0332367, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03618445, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995967, dtype=float32), 'eval/episode_train_reward': Array(-0.00108553, dtype=float32), 'eval/episode_x_position': Array(1.0067865, dtype=float32), 'eval/episode_x_velocity': Array(-0.03618445, dtype=float32), 'eval/episode_y_position': Array(0.00011327, dtype=float32), 'eval/episode_y_velocity': Array(-0.00201628, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594334, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04341672, dtype=float32), 'eval/episode_reward_std': Array(0.04586156, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04341672, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01435123, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013025, dtype=float32), 'eval/episode_x_position_std': Array(0.00593314, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04341672, dtype=float32), 'eval/episode_y_position_std': Array(0.00591892, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01063445, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68423867225647, 'eval/sps': 6188.286744712771, 'num_steps': 2063360}
{'eval/walltime': 8474.270495414734, 'training/sps': 127.15471360132193, 'training/walltime': 16342.467772960663, 'training/entropy_loss': Array(0.10352963, dtype=float32), 'training/policy_loss': Array(0.27129596, dtype=float32), 'training/total_loss': Array(0.3748256, dtype=float32), 'training/v_loss': Array(1.1447981e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088258, dtype=float32), 'eval/episode_forward_reward': Array(-0.04395137, dtype=float32), 'eval/episode_reward': Array(-2.043059, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04395137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977894, dtype=float32), 'eval/episode_train_reward': Array(-0.00131854, dtype=float32), 'eval/episode_x_position': Array(1.0069915, dtype=float32), 'eval/episode_x_velocity': Array(-0.04395137, dtype=float32), 'eval/episode_y_position': Array(-0.00039882, dtype=float32), 'eval/episode_y_velocity': Array(-0.00012202, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580682, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04447311, dtype=float32), 'eval/episode_reward_std': Array(0.04780114, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04447311, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01030222, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133419, dtype=float32), 'eval/episode_x_position_std': Array(0.00580515, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04447311, dtype=float32), 'eval/episode_y_position_std': Array(0.00542179, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01237417, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680256605148315, 'eval/sps': 6189.478324371208, 'num_steps': 2068480}
{'eval/walltime': 8494.93451333046, 'training/sps': 127.54734768809332, 'training/walltime': 16382.609728813171, 'training/entropy_loss': Array(0.10273106, dtype=float32), 'training/policy_loss': Array(0.2703658, dtype=float32), 'training/total_loss': Array(0.37309688, dtype=float32), 'training/v_loss': Array(4.041079e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0104828, dtype=float32), 'eval/episode_forward_reward': Array(-0.03494788, dtype=float32), 'eval/episode_reward': Array(-2.0317044, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03494788, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957082, dtype=float32), 'eval/episode_train_reward': Array(-0.00104844, dtype=float32), 'eval/episode_x_position': Array(1.0086262, dtype=float32), 'eval/episode_x_velocity': Array(-0.03494788, dtype=float32), 'eval/episode_y_position': Array(-0.00074082, dtype=float32), 'eval/episode_y_velocity': Array(-0.00190664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571236, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04274007, dtype=float32), 'eval/episode_reward_std': Array(0.04917698, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04274007, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01653231, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012822, dtype=float32), 'eval/episode_x_position_std': Array(0.00568095, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04274007, dtype=float32), 'eval/episode_y_position_std': Array(0.0056671, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01334698, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.664017915725708, 'eval/sps': 6194.342287256225, 'num_steps': 2073600}
{'eval/walltime': 8515.635605573654, 'training/sps': 127.38205352276965, 'training/walltime': 16422.803773880005, 'training/entropy_loss': Array(0.10192039, dtype=float32), 'training/policy_loss': Array(0.26743636, dtype=float32), 'training/total_loss': Array(0.36935672, dtype=float32), 'training/v_loss': Array(6.0608907e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087517, dtype=float32), 'eval/episode_forward_reward': Array(-0.03693943, dtype=float32), 'eval/episode_reward': Array(-2.0353615, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03693943, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997314, dtype=float32), 'eval/episode_train_reward': Array(-0.00110818, dtype=float32), 'eval/episode_x_position': Array(1.0068984, dtype=float32), 'eval/episode_x_velocity': Array(-0.03693943, dtype=float32), 'eval/episode_y_position': Array(0.00041331, dtype=float32), 'eval/episode_y_velocity': Array(-0.00293713, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.005938, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0415254, dtype=float32), 'eval/episode_reward_std': Array(0.0427657, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0415254, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01162975, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124576, dtype=float32), 'eval/episode_x_position_std': Array(0.00590453, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0415254, dtype=float32), 'eval/episode_y_position_std': Array(0.00559954, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01169973, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70109224319458, 'eval/sps': 6183.248617815304, 'num_steps': 2078720}
{'eval/walltime': 8536.334936380386, 'training/sps': 127.36330856418877, 'training/walltime': 16463.003734588623, 'training/entropy_loss': Array(0.10279045, dtype=float32), 'training/policy_loss': Array(0.20273975, dtype=float32), 'training/total_loss': Array(0.30553016, dtype=float32), 'training/v_loss': Array(1.1841289e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085081, dtype=float32), 'eval/episode_forward_reward': Array(-0.03961055, dtype=float32), 'eval/episode_reward': Array(-2.0359309, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03961055, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995132, dtype=float32), 'eval/episode_train_reward': Array(-0.00118832, dtype=float32), 'eval/episode_x_position': Array(1.0066522, dtype=float32), 'eval/episode_x_velocity': Array(-0.03961055, dtype=float32), 'eval/episode_y_position': Array(-0.00043128, dtype=float32), 'eval/episode_y_velocity': Array(-0.00235561, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00542566, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04186626, dtype=float32), 'eval/episode_reward_std': Array(0.04609088, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04186626, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01874492, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125599, dtype=float32), 'eval/episode_x_position_std': Array(0.00541253, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04186626, dtype=float32), 'eval/episode_y_position_std': Array(0.00599338, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01379269, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.699330806732178, 'eval/sps': 6183.774789394144, 'num_steps': 2083840}
{'eval/walltime': 8557.04022359848, 'training/sps': 127.38685699422375, 'training/walltime': 16503.19626402855, 'training/entropy_loss': Array(0.10405081, dtype=float32), 'training/policy_loss': Array(0.2717067, dtype=float32), 'training/total_loss': Array(0.37575752, dtype=float32), 'training/v_loss': Array(4.3843693e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098829, dtype=float32), 'eval/episode_forward_reward': Array(-0.03036484, dtype=float32), 'eval/episode_reward': Array(-2.025889, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03036484, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946132, dtype=float32), 'eval/episode_train_reward': Array(-0.00091095, dtype=float32), 'eval/episode_x_position': Array(1.0079215, dtype=float32), 'eval/episode_x_velocity': Array(-0.03036484, dtype=float32), 'eval/episode_y_position': Array(-0.00051303, dtype=float32), 'eval/episode_y_velocity': Array(-0.00163377, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589583, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04001937, dtype=float32), 'eval/episode_reward_std': Array(0.04483743, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04001937, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01853855, dtype=float32), 'eval/episode_train_reward_std': Array(0.00120058, dtype=float32), 'eval/episode_x_position_std': Array(0.00587718, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04001937, dtype=float32), 'eval/episode_y_position_std': Array(0.00590724, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01192461, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.705287218093872, 'eval/sps': 6181.9958666472285, 'num_steps': 2088960}
{'eval/walltime': 8577.72644996643, 'training/sps': 127.18501962152577, 'training/walltime': 16543.452577352524, 'training/entropy_loss': Array(0.10150965, dtype=float32), 'training/policy_loss': Array(0.27034003, dtype=float32), 'training/total_loss': Array(0.37184972, dtype=float32), 'training/v_loss': Array(4.5269397e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091234, dtype=float32), 'eval/episode_forward_reward': Array(-0.03801798, dtype=float32), 'eval/episode_reward': Array(-2.037444, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03801798, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982855, dtype=float32), 'eval/episode_train_reward': Array(-0.00114054, dtype=float32), 'eval/episode_x_position': Array(1.0072598, dtype=float32), 'eval/episode_x_velocity': Array(-0.03801798, dtype=float32), 'eval/episode_y_position': Array(-0.00103398, dtype=float32), 'eval/episode_y_velocity': Array(-0.00165536, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557689, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04147973, dtype=float32), 'eval/episode_reward_std': Array(0.0439352, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04147973, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01021081, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124439, dtype=float32), 'eval/episode_x_position_std': Array(0.00556576, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04147973, dtype=float32), 'eval/episode_y_position_std': Array(0.00582041, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01214926, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68622636795044, 'eval/sps': 6187.692125341566, 'num_steps': 2094080}
{'eval/walltime': 8598.411478042603, 'training/sps': 127.29008825878844, 'training/walltime': 16583.67566204071, 'training/entropy_loss': Array(0.10187285, dtype=float32), 'training/policy_loss': Array(0.2692091, dtype=float32), 'training/total_loss': Array(0.37108192, dtype=float32), 'training/v_loss': Array(2.3440123e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0163828, dtype=float32), 'eval/episode_forward_reward': Array(-0.04490907, dtype=float32), 'eval/episode_reward': Array(-2.0574079, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04490907, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0189638, dtype=float32), 'eval/episode_train_reward': Array(-0.00134727, dtype=float32), 'eval/episode_x_position': Array(1.0145215, dtype=float32), 'eval/episode_x_velocity': Array(-0.04490907, dtype=float32), 'eval/episode_y_position': Array(0.00047926, dtype=float32), 'eval/episode_y_velocity': Array(-0.00289165, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08893871, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04324057, dtype=float32), 'eval/episode_reward_std': Array(0.17990762, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04324057, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26497796, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129722, dtype=float32), 'eval/episode_x_position_std': Array(0.08866217, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04324057, dtype=float32), 'eval/episode_y_position_std': Array(0.00600027, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00961982, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.685028076171875, 'eval/sps': 6188.050580770042, 'num_steps': 2099200}
{'eval/walltime': 8619.088385105133, 'training/sps': 127.39364987383513, 'training/walltime': 16623.86604833603, 'training/entropy_loss': Array(0.10152555, dtype=float32), 'training/policy_loss': Array(0.2663465, dtype=float32), 'training/total_loss': Array(0.36787206, dtype=float32), 'training/v_loss': Array(3.826468e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097766, dtype=float32), 'eval/episode_forward_reward': Array(-0.04156733, dtype=float32), 'eval/episode_reward': Array(-2.0404425, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04156733, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976282, dtype=float32), 'eval/episode_train_reward': Array(-0.00124702, dtype=float32), 'eval/episode_x_position': Array(1.0079263, dtype=float32), 'eval/episode_x_velocity': Array(-0.04156733, dtype=float32), 'eval/episode_y_position': Array(-1.5716141e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00256467, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583316, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0443104, dtype=float32), 'eval/episode_reward_std': Array(0.04780884, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0443104, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01329392, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132931, dtype=float32), 'eval/episode_x_position_std': Array(0.00587065, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0443104, dtype=float32), 'eval/episode_y_position_std': Array(0.00607333, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01088306, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.676907062530518, 'eval/sps': 6190.4809850383335, 'num_steps': 2104320}
{'eval/walltime': 8639.741280078888, 'training/sps': 127.18524107889867, 'training/walltime': 16664.12229156494, 'training/entropy_loss': Array(0.10219364, dtype=float32), 'training/policy_loss': Array(0.26851442, dtype=float32), 'training/total_loss': Array(0.3707081, dtype=float32), 'training/v_loss': Array(1.0767865e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094416, dtype=float32), 'eval/episode_forward_reward': Array(-0.03458109, dtype=float32), 'eval/episode_reward': Array(-2.0324292, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03458109, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996811, dtype=float32), 'eval/episode_train_reward': Array(-0.00103743, dtype=float32), 'eval/episode_x_position': Array(1.0075319, dtype=float32), 'eval/episode_x_velocity': Array(-0.03458109, dtype=float32), 'eval/episode_y_position': Array(0.00113856, dtype=float32), 'eval/episode_y_velocity': Array(-0.00205224, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00606578, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04230134, dtype=float32), 'eval/episode_reward_std': Array(0.04536857, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04230134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01456006, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126904, dtype=float32), 'eval/episode_x_position_std': Array(0.00604048, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04230134, dtype=float32), 'eval/episode_y_position_std': Array(0.00547923, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01163084, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.652894973754883, 'eval/sps': 6197.678347885795, 'num_steps': 2109440}
{'eval/walltime': 8660.422762870789, 'training/sps': 127.19147986503563, 'training/walltime': 16704.37656021118, 'training/entropy_loss': Array(0.10100156, dtype=float32), 'training/policy_loss': Array(0.2698418, dtype=float32), 'training/total_loss': Array(0.37084332, dtype=float32), 'training/v_loss': Array(1.6587505e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0165703, dtype=float32), 'eval/episode_forward_reward': Array(-0.04172574, dtype=float32), 'eval/episode_reward': Array(-2.055635, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04172574, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0204701, dtype=float32), 'eval/episode_train_reward': Array(-0.00125177, dtype=float32), 'eval/episode_x_position': Array(1.0146886, dtype=float32), 'eval/episode_x_velocity': Array(-0.04172574, dtype=float32), 'eval/episode_y_position': Array(-0.0006166, dtype=float32), 'eval/episode_y_velocity': Array(-0.00334362, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09013385, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04610908, dtype=float32), 'eval/episode_reward_std': Array(0.17242402, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04610908, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2571932, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138327, dtype=float32), 'eval/episode_x_position_std': Array(0.08985928, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04610908, dtype=float32), 'eval/episode_y_position_std': Array(0.00586205, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01106181, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.681482791900635, 'eval/sps': 6189.111355696791, 'num_steps': 2114560}
{'eval/walltime': 8681.099059343338, 'training/sps': 127.39746868349123, 'training/walltime': 16744.56574177742, 'training/entropy_loss': Array(0.10243689, dtype=float32), 'training/policy_loss': Array(0.21666187, dtype=float32), 'training/total_loss': Array(0.31909877, dtype=float32), 'training/v_loss': Array(7.8333935e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090969, dtype=float32), 'eval/episode_forward_reward': Array(-0.03517544, dtype=float32), 'eval/episode_reward': Array(-2.031638, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03517544, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995407, dtype=float32), 'eval/episode_train_reward': Array(-0.00105526, dtype=float32), 'eval/episode_x_position': Array(1.0071981, dtype=float32), 'eval/episode_x_velocity': Array(-0.03517544, dtype=float32), 'eval/episode_y_position': Array(0.00060926, dtype=float32), 'eval/episode_y_velocity': Array(-0.00320241, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585195, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04087654, dtype=float32), 'eval/episode_reward_std': Array(0.04476792, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04087654, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01625968, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012263, dtype=float32), 'eval/episode_x_position_std': Array(0.00582621, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04087654, dtype=float32), 'eval/episode_y_position_std': Array(0.00596829, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01203428, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67629647254944, 'eval/sps': 6190.663795614326, 'num_steps': 2119680}
{'eval/walltime': 8701.793120145798, 'training/sps': 127.29569519610071, 'training/walltime': 16784.787054777145, 'training/entropy_loss': Array(0.10246495, dtype=float32), 'training/policy_loss': Array(0.26901323, dtype=float32), 'training/total_loss': Array(0.3714782, dtype=float32), 'training/v_loss': Array(9.3603605e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085216, dtype=float32), 'eval/episode_forward_reward': Array(-0.04313949, dtype=float32), 'eval/episode_reward': Array(-2.0390906, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04313949, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994657, dtype=float32), 'eval/episode_train_reward': Array(-0.00129418, dtype=float32), 'eval/episode_x_position': Array(1.0066569, dtype=float32), 'eval/episode_x_velocity': Array(-0.04313949, dtype=float32), 'eval/episode_y_position': Array(0.00062408, dtype=float32), 'eval/episode_y_velocity': Array(-0.00501332, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579987, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04476357, dtype=float32), 'eval/episode_reward_std': Array(0.051548, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04476357, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01909885, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134291, dtype=float32), 'eval/episode_x_position_std': Array(0.00577409, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04476357, dtype=float32), 'eval/episode_y_position_std': Array(0.00558982, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01610377, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.694060802459717, 'eval/sps': 6185.349565841896, 'num_steps': 2124800}
{'eval/walltime': 8722.434734582901, 'training/sps': 127.14643830570121, 'training/walltime': 16825.05558347702, 'training/entropy_loss': Array(0.10356952, dtype=float32), 'training/policy_loss': Array(0.25778502, dtype=float32), 'training/total_loss': Array(0.36135456, dtype=float32), 'training/v_loss': Array(6.3100116e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0174589, dtype=float32), 'eval/episode_forward_reward': Array(-0.04029507, dtype=float32), 'eval/episode_reward': Array(-2.052374, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04029507, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0186825, dtype=float32), 'eval/episode_train_reward': Array(-0.00120885, dtype=float32), 'eval/episode_x_position': Array(1.0155782, dtype=float32), 'eval/episode_x_velocity': Array(-0.04029507, dtype=float32), 'eval/episode_y_position': Array(-0.00038996, dtype=float32), 'eval/episode_y_velocity': Array(-0.00078544, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08814367, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04610863, dtype=float32), 'eval/episode_reward_std': Array(0.1787682, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04610863, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26506203, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138326, dtype=float32), 'eval/episode_x_position_std': Array(0.08786528, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04610863, dtype=float32), 'eval/episode_y_position_std': Array(0.00597992, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01277648, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.64161443710327, 'eval/sps': 6201.065347384853, 'num_steps': 2129920}
{'eval/walltime': 8743.109763145447, 'training/sps': 127.21015619026335, 'training/walltime': 16865.30394220352, 'training/entropy_loss': Array(0.10402629, dtype=float32), 'training/policy_loss': Array(0.2682749, dtype=float32), 'training/total_loss': Array(0.3723012, dtype=float32), 'training/v_loss': Array(3.8634163e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0161394, dtype=float32), 'eval/episode_forward_reward': Array(-0.03750288, dtype=float32), 'eval/episode_reward': Array(-2.0514116, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03750288, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0205965, dtype=float32), 'eval/episode_train_reward': Array(-0.00112509, dtype=float32), 'eval/episode_x_position': Array(1.0142524, dtype=float32), 'eval/episode_x_velocity': Array(-0.03750288, dtype=float32), 'eval/episode_y_position': Array(-0.00025034, dtype=float32), 'eval/episode_y_velocity': Array(-0.00133954, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08942761, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04211203, dtype=float32), 'eval/episode_reward_std': Array(0.17863718, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04211203, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26472628, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126336, dtype=float32), 'eval/episode_x_position_std': Array(0.08915338, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04211203, dtype=float32), 'eval/episode_y_position_std': Array(0.00624005, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01384877, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.675028562545776, 'eval/sps': 6191.043442226761, 'num_steps': 2135040}
{'eval/walltime': 8763.749698400497, 'training/sps': 126.914781013364, 'training/walltime': 16905.645972967148, 'training/entropy_loss': Array(0.10468382, dtype=float32), 'training/policy_loss': Array(0.26989484, dtype=float32), 'training/total_loss': Array(0.37457865, dtype=float32), 'training/v_loss': Array(9.3358425e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087787, dtype=float32), 'eval/episode_forward_reward': Array(-0.03861869, dtype=float32), 'eval/episode_reward': Array(-2.0346794, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03861869, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9949021, dtype=float32), 'eval/episode_train_reward': Array(-0.00115856, dtype=float32), 'eval/episode_x_position': Array(1.0069271, dtype=float32), 'eval/episode_x_velocity': Array(-0.03861869, dtype=float32), 'eval/episode_y_position': Array(0.00059994, dtype=float32), 'eval/episode_y_velocity': Array(-0.00188601, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571392, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04120283, dtype=float32), 'eval/episode_reward_std': Array(0.04703524, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04120283, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02017218, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123608, dtype=float32), 'eval/episode_x_position_std': Array(0.00573543, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04120283, dtype=float32), 'eval/episode_y_position_std': Array(0.00573279, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0127815, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63993525505066, 'eval/sps': 6201.569841101027, 'num_steps': 2140160}
{'eval/walltime': 8784.394153118134, 'training/sps': 127.38557316167753, 'training/walltime': 16945.83890748024, 'training/entropy_loss': Array(0.10377582, dtype=float32), 'training/policy_loss': Array(0.2723731, dtype=float32), 'training/total_loss': Array(0.3761489, dtype=float32), 'training/v_loss': Array(4.368313e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016861, dtype=float32), 'eval/episode_forward_reward': Array(-0.0457447, dtype=float32), 'eval/episode_reward': Array(-2.0583694, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0457447, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0190647, dtype=float32), 'eval/episode_train_reward': Array(-0.00137234, dtype=float32), 'eval/episode_x_position': Array(1.0149634, dtype=float32), 'eval/episode_x_velocity': Array(-0.0457447, dtype=float32), 'eval/episode_y_position': Array(0.00046385, dtype=float32), 'eval/episode_y_velocity': Array(-0.00317215, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08970729, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0465279, dtype=float32), 'eval/episode_reward_std': Array(0.17846155, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0465279, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26501685, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139584, dtype=float32), 'eval/episode_x_position_std': Array(0.0894407, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0465279, dtype=float32), 'eval/episode_y_position_std': Array(0.0059603, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01276171, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.64445471763611, 'eval/sps': 6200.212199872365, 'num_steps': 2145280}
{'eval/walltime': 8805.05697798729, 'training/sps': 127.23590050331588, 'training/walltime': 16986.079122543335, 'training/entropy_loss': Array(0.10376438, dtype=float32), 'training/policy_loss': Array(0.2702918, dtype=float32), 'training/total_loss': Array(0.3740562, dtype=float32), 'training/v_loss': Array(5.287021e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009382, dtype=float32), 'eval/episode_forward_reward': Array(-0.0386731, dtype=float32), 'eval/episode_reward': Array(-2.0360339, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0386731, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962006, dtype=float32), 'eval/episode_train_reward': Array(-0.00116019, dtype=float32), 'eval/episode_x_position': Array(1.0075262, dtype=float32), 'eval/episode_x_velocity': Array(-0.0386731, dtype=float32), 'eval/episode_y_position': Array(7.023802e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00209713, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573379, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04352149, dtype=float32), 'eval/episode_reward_std': Array(0.04802687, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04352149, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01517036, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130564, dtype=float32), 'eval/episode_x_position_std': Array(0.00572202, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04352149, dtype=float32), 'eval/episode_y_position_std': Array(0.00579605, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01326464, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.662824869155884, 'eval/sps': 6194.699941103892, 'num_steps': 2150400}
{'eval/walltime': 8825.72699046135, 'training/sps': 127.01994212897797, 'training/walltime': 17026.387753725052, 'training/entropy_loss': Array(0.10146109, dtype=float32), 'training/policy_loss': Array(0.26947877, dtype=float32), 'training/total_loss': Array(0.37093988, dtype=float32), 'training/v_loss': Array(1.1477599e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097501, dtype=float32), 'eval/episode_forward_reward': Array(-0.03571149, dtype=float32), 'eval/episode_reward': Array(-2.0323393, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03571149, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955564, dtype=float32), 'eval/episode_train_reward': Array(-0.00107134, dtype=float32), 'eval/episode_x_position': Array(1.0078511, dtype=float32), 'eval/episode_x_velocity': Array(-0.03571149, dtype=float32), 'eval/episode_y_position': Array(0.00109861, dtype=float32), 'eval/episode_y_velocity': Array(-0.00066914, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561835, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04152623, dtype=float32), 'eval/episode_reward_std': Array(0.0479141, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04152623, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01768576, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124579, dtype=float32), 'eval/episode_x_position_std': Array(0.00559432, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04152623, dtype=float32), 'eval/episode_y_position_std': Array(0.00570648, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0121106, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67001247406006, 'eval/sps': 6192.545851659948, 'num_steps': 2155520}
{'eval/walltime': 8846.402555704117, 'training/sps': 127.2835719749064, 'training/walltime': 17066.612897634506, 'training/entropy_loss': Array(0.105529, dtype=float32), 'training/policy_loss': Array(0.27136093, dtype=float32), 'training/total_loss': Array(0.3768899, dtype=float32), 'training/v_loss': Array(4.016583e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171051, dtype=float32), 'eval/episode_forward_reward': Array(-0.03652469, dtype=float32), 'eval/episode_reward': Array(-2.0498447, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03652469, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0200367, dtype=float32), 'eval/episode_train_reward': Array(-0.00109574, dtype=float32), 'eval/episode_x_position': Array(1.0152099, dtype=float32), 'eval/episode_x_velocity': Array(-0.03652469, dtype=float32), 'eval/episode_y_position': Array(-0.00014814, dtype=float32), 'eval/episode_y_velocity': Array(-0.00098316, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08769526, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04262949, dtype=float32), 'eval/episode_reward_std': Array(0.17977887, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04262949, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26508215, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127888, dtype=float32), 'eval/episode_x_position_std': Array(0.08741241, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04262949, dtype=float32), 'eval/episode_y_position_std': Array(0.00584528, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01264285, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.675565242767334, 'eval/sps': 6190.882739942338, 'num_steps': 2160640}
{'eval/walltime': 8867.09612584114, 'training/sps': 127.23897631775775, 'training/walltime': 17106.8521399498, 'training/entropy_loss': Array(0.10113776, dtype=float32), 'training/policy_loss': Array(0.27285266, dtype=float32), 'training/total_loss': Array(0.37399042, dtype=float32), 'training/v_loss': Array(5.847858e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095234, dtype=float32), 'eval/episode_forward_reward': Array(-0.03943189, dtype=float32), 'eval/episode_reward': Array(-2.0391483, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03943189, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985335, dtype=float32), 'eval/episode_train_reward': Array(-0.00118296, dtype=float32), 'eval/episode_x_position': Array(1.0077043, dtype=float32), 'eval/episode_x_velocity': Array(-0.03943189, dtype=float32), 'eval/episode_y_position': Array(0.00041176, dtype=float32), 'eval/episode_y_velocity': Array(-0.00302468, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00629036, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0414362, dtype=float32), 'eval/episode_reward_std': Array(0.04376702, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0414362, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00864234, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124309, dtype=float32), 'eval/episode_x_position_std': Array(0.00629169, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0414362, dtype=float32), 'eval/episode_y_position_std': Array(0.00559548, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01394934, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.693570137023926, 'eval/sps': 6185.49622672352, 'num_steps': 2165760}
{'eval/walltime': 8887.717287540436, 'training/sps': 127.29369788969034, 'training/walltime': 17147.074084043503, 'training/entropy_loss': Array(0.10120579, dtype=float32), 'training/policy_loss': Array(0.26987684, dtype=float32), 'training/total_loss': Array(0.3710826, dtype=float32), 'training/v_loss': Array(2.218194e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101106, dtype=float32), 'eval/episode_forward_reward': Array(-0.03742155, dtype=float32), 'eval/episode_reward': Array(-2.0341403, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03742155, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955964, dtype=float32), 'eval/episode_train_reward': Array(-0.00112265, dtype=float32), 'eval/episode_x_position': Array(1.0082326, dtype=float32), 'eval/episode_x_velocity': Array(-0.03742155, dtype=float32), 'eval/episode_y_position': Array(-0.00084724, dtype=float32), 'eval/episode_y_velocity': Array(-0.00134085, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00565322, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0421841, dtype=float32), 'eval/episode_reward_std': Array(0.0469854, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0421841, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01835317, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126552, dtype=float32), 'eval/episode_x_position_std': Array(0.0056611, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0421841, dtype=float32), 'eval/episode_y_position_std': Array(0.00624378, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01286054, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.621161699295044, 'eval/sps': 6207.215765364752, 'num_steps': 2170880}
{'eval/walltime': 8908.408816337585, 'training/sps': 127.23770601852263, 'training/walltime': 17187.3137280941, 'training/entropy_loss': Array(0.09892019, dtype=float32), 'training/policy_loss': Array(0.2716233, dtype=float32), 'training/total_loss': Array(0.37054348, dtype=float32), 'training/v_loss': Array(1.1657985e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092955, dtype=float32), 'eval/episode_forward_reward': Array(-0.03400042, dtype=float32), 'eval/episode_reward': Array(-2.031854, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03400042, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968336, dtype=float32), 'eval/episode_train_reward': Array(-0.00102001, dtype=float32), 'eval/episode_x_position': Array(1.0074049, dtype=float32), 'eval/episode_x_velocity': Array(-0.03400042, dtype=float32), 'eval/episode_y_position': Array(0.00081274, dtype=float32), 'eval/episode_y_velocity': Array(-0.00138656, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00626011, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04171946, dtype=float32), 'eval/episode_reward_std': Array(0.04615672, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04171946, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01368689, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125158, dtype=float32), 'eval/episode_x_position_std': Array(0.00627924, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04171946, dtype=float32), 'eval/episode_y_position_std': Array(0.00622088, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01375792, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.691528797149658, 'eval/sps': 6186.106461965851, 'num_steps': 2176000}
{'eval/walltime': 8929.004351615906, 'training/sps': 127.29888105595175, 'training/walltime': 17227.534034490585, 'training/entropy_loss': Array(0.10042077, dtype=float32), 'training/policy_loss': Array(0.26793978, dtype=float32), 'training/total_loss': Array(0.36836055, dtype=float32), 'training/v_loss': Array(9.547223e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101407, dtype=float32), 'eval/episode_forward_reward': Array(-0.03532561, dtype=float32), 'eval/episode_reward': Array(-2.0327022, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03532561, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996317, dtype=float32), 'eval/episode_train_reward': Array(-0.00105977, dtype=float32), 'eval/episode_x_position': Array(1.0082352, dtype=float32), 'eval/episode_x_velocity': Array(-0.03532561, dtype=float32), 'eval/episode_y_position': Array(-0.00142646, dtype=float32), 'eval/episode_y_velocity': Array(-0.00317997, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590079, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04436965, dtype=float32), 'eval/episode_reward_std': Array(0.0459891, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04436965, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01446713, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133109, dtype=float32), 'eval/episode_x_position_std': Array(0.00591306, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04436965, dtype=float32), 'eval/episode_y_position_std': Array(0.00579353, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01153364, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.595535278320312, 'eval/sps': 6214.939222033134, 'num_steps': 2181120}
{'eval/walltime': 8949.677691459656, 'training/sps': 127.30618604527196, 'training/walltime': 17267.752032995224, 'training/entropy_loss': Array(0.09796754, dtype=float32), 'training/policy_loss': Array(0.26882246, dtype=float32), 'training/total_loss': Array(0.36679, dtype=float32), 'training/v_loss': Array(1.0058557e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0163038, dtype=float32), 'eval/episode_forward_reward': Array(-0.0442847, dtype=float32), 'eval/episode_reward': Array(-2.0573087, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0442847, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.019508, dtype=float32), 'eval/episode_train_reward': Array(-0.00132854, dtype=float32), 'eval/episode_x_position': Array(1.0144746, dtype=float32), 'eval/episode_x_velocity': Array(-0.0442847, dtype=float32), 'eval/episode_y_position': Array(0.00034872, dtype=float32), 'eval/episode_y_velocity': Array(-0.00372573, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08762189, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04349187, dtype=float32), 'eval/episode_reward_std': Array(0.17231323, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04349187, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25651816, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130476, dtype=float32), 'eval/episode_x_position_std': Array(0.08733692, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04349187, dtype=float32), 'eval/episode_y_position_std': Array(0.00626281, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01674091, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.67333984375, 'eval/sps': 6191.549162710503, 'num_steps': 2186240}
{'eval/walltime': 8970.324620008469, 'training/sps': 127.39990232105406, 'training/walltime': 17307.940446853638, 'training/entropy_loss': Array(0.09848842, dtype=float32), 'training/policy_loss': Array(0.2683443, dtype=float32), 'training/total_loss': Array(0.36683273, dtype=float32), 'training/v_loss': Array(2.0657298e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0170435, dtype=float32), 'eval/episode_forward_reward': Array(-0.0402291, dtype=float32), 'eval/episode_reward': Array(-2.05295, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0402291, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0193262, dtype=float32), 'eval/episode_train_reward': Array(-0.00120687, dtype=float32), 'eval/episode_x_position': Array(1.0151224, dtype=float32), 'eval/episode_x_velocity': Array(-0.0402291, dtype=float32), 'eval/episode_y_position': Array(0.00105712, dtype=float32), 'eval/episode_y_velocity': Array(-0.00390383, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08926791, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04489781, dtype=float32), 'eval/episode_reward_std': Array(0.18160678, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04489781, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26505858, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134693, dtype=float32), 'eval/episode_x_position_std': Array(0.08899975, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04489781, dtype=float32), 'eval/episode_y_position_std': Array(0.00543091, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01513567, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.646928548812866, 'eval/sps': 6199.46931561206, 'num_steps': 2191360}
{'eval/walltime': 8990.998260974884, 'training/sps': 127.32053131798843, 'training/walltime': 17348.153913974762, 'training/entropy_loss': Array(0.10012302, dtype=float32), 'training/policy_loss': Array(0.26429823, dtype=float32), 'training/total_loss': Array(0.36442122, dtype=float32), 'training/v_loss': Array(9.7744275e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008857, dtype=float32), 'eval/episode_forward_reward': Array(-0.03356316, dtype=float32), 'eval/episode_reward': Array(-2.0292451, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03356316, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946752, dtype=float32), 'eval/episode_train_reward': Array(-0.00100689, dtype=float32), 'eval/episode_x_position': Array(1.0069474, dtype=float32), 'eval/episode_x_velocity': Array(-0.03356316, dtype=float32), 'eval/episode_y_position': Array(-0.00056904, dtype=float32), 'eval/episode_y_velocity': Array(-0.00223069, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590955, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0438667, dtype=float32), 'eval/episode_reward_std': Array(0.04913976, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0438667, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01821083, dtype=float32), 'eval/episode_train_reward_std': Array(0.001316, dtype=float32), 'eval/episode_x_position_std': Array(0.00587133, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0438667, dtype=float32), 'eval/episode_y_position_std': Array(0.00553398, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01415894, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.673640966415405, 'eval/sps': 6191.458979477183, 'num_steps': 2196480}
{'eval/walltime': 9011.63998222351, 'training/sps': 127.5082563041037, 'training/walltime': 17388.308176517487, 'training/entropy_loss': Array(0.10208108, dtype=float32), 'training/policy_loss': Array(0.2712047, dtype=float32), 'training/total_loss': Array(0.37328577, dtype=float32), 'training/v_loss': Array(2.3369466e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098344, dtype=float32), 'eval/episode_forward_reward': Array(-0.03856002, dtype=float32), 'eval/episode_reward': Array(-2.037636, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03856002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997919, dtype=float32), 'eval/episode_train_reward': Array(-0.0011568, dtype=float32), 'eval/episode_x_position': Array(1.0079883, dtype=float32), 'eval/episode_x_velocity': Array(-0.03856002, dtype=float32), 'eval/episode_y_position': Array(-0.00054241, dtype=float32), 'eval/episode_y_velocity': Array(-0.003379, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602775, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04359335, dtype=float32), 'eval/episode_reward_std': Array(0.04624244, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04359335, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01147896, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013078, dtype=float32), 'eval/episode_x_position_std': Array(0.00600533, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04359335, dtype=float32), 'eval/episode_y_position_std': Array(0.00593574, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01682976, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64172124862671, 'eval/sps': 6201.033259690775, 'num_steps': 2201600}
{'eval/walltime': 9032.316898107529, 'training/sps': 126.97056404366562, 'training/walltime': 17428.63248348236, 'training/entropy_loss': Array(0.09998269, dtype=float32), 'training/policy_loss': Array(0.27081677, dtype=float32), 'training/total_loss': Array(0.37079948, dtype=float32), 'training/v_loss': Array(2.058493e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092399, dtype=float32), 'eval/episode_forward_reward': Array(-0.04002157, dtype=float32), 'eval/episode_reward': Array(-2.0380661, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04002157, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968438, dtype=float32), 'eval/episode_train_reward': Array(-0.00120065, dtype=float32), 'eval/episode_x_position': Array(1.0073993, dtype=float32), 'eval/episode_x_velocity': Array(-0.04002157, dtype=float32), 'eval/episode_y_position': Array(-0.00019334, dtype=float32), 'eval/episode_y_velocity': Array(-0.00240418, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00615968, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04186657, dtype=float32), 'eval/episode_reward_std': Array(0.04605154, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04186657, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01295875, dtype=float32), 'eval/episode_train_reward_std': Array(0.001256, dtype=float32), 'eval/episode_x_position_std': Array(0.00614103, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04186657, dtype=float32), 'eval/episode_y_position_std': Array(0.00583899, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01117817, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.676915884017944, 'eval/sps': 6190.478343965048, 'num_steps': 2206720}
{'eval/walltime': 9052.998419046402, 'training/sps': 127.2259232230525, 'training/walltime': 17468.87585425377, 'training/entropy_loss': Array(0.10117111, dtype=float32), 'training/policy_loss': Array(0.26930785, dtype=float32), 'training/total_loss': Array(0.370479, dtype=float32), 'training/v_loss': Array(3.1075835e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096531, dtype=float32), 'eval/episode_forward_reward': Array(-0.03851345, dtype=float32), 'eval/episode_reward': Array(-2.0362842, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03851345, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966154, dtype=float32), 'eval/episode_train_reward': Array(-0.0011554, dtype=float32), 'eval/episode_x_position': Array(1.0077941, dtype=float32), 'eval/episode_x_velocity': Array(-0.03851345, dtype=float32), 'eval/episode_y_position': Array(-0.00043813, dtype=float32), 'eval/episode_y_velocity': Array(-0.00018027, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00603289, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04508752, dtype=float32), 'eval/episode_reward_std': Array(0.04623721, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04508752, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01166448, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135263, dtype=float32), 'eval/episode_x_position_std': Array(0.00606603, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04508752, dtype=float32), 'eval/episode_y_position_std': Array(0.00568614, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01303382, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68152093887329, 'eval/sps': 6189.099939908641, 'num_steps': 2211840}
{'eval/walltime': 9073.69249033928, 'training/sps': 127.01817809877518, 'training/walltime': 17509.18504524231, 'training/entropy_loss': Array(0.09877966, dtype=float32), 'training/policy_loss': Array(0.27083012, dtype=float32), 'training/total_loss': Array(0.36960977, dtype=float32), 'training/v_loss': Array(2.0359563e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092883, dtype=float32), 'eval/episode_forward_reward': Array(-0.0395424, dtype=float32), 'eval/episode_reward': Array(-2.0373902, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0395424, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966617, dtype=float32), 'eval/episode_train_reward': Array(-0.00118627, dtype=float32), 'eval/episode_x_position': Array(1.0074272, dtype=float32), 'eval/episode_x_velocity': Array(-0.0395424, dtype=float32), 'eval/episode_y_position': Array(0.00097348, dtype=float32), 'eval/episode_y_velocity': Array(0.00083187, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584679, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0436914, dtype=float32), 'eval/episode_reward_std': Array(0.04624512, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0436914, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01400487, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131074, dtype=float32), 'eval/episode_x_position_std': Array(0.00586054, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0436914, dtype=float32), 'eval/episode_y_position_std': Array(0.00589143, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01257772, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.694071292877197, 'eval/sps': 6185.346430311033, 'num_steps': 2216960}
{'eval/walltime': 9094.307897567749, 'training/sps': 127.22168207147836, 'training/walltime': 17549.429757595062, 'training/entropy_loss': Array(0.09945346, dtype=float32), 'training/policy_loss': Array(0.2691542, dtype=float32), 'training/total_loss': Array(0.36860764, dtype=float32), 'training/v_loss': Array(2.0490363e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090342, dtype=float32), 'eval/episode_forward_reward': Array(-0.03714021, dtype=float32), 'eval/episode_reward': Array(-2.031049, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03714021, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9927945, dtype=float32), 'eval/episode_train_reward': Array(-0.00111421, dtype=float32), 'eval/episode_x_position': Array(1.0071852, dtype=float32), 'eval/episode_x_velocity': Array(-0.03714021, dtype=float32), 'eval/episode_y_position': Array(-0.00017787, dtype=float32), 'eval/episode_y_velocity': Array(-0.00218895, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00537453, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04125972, dtype=float32), 'eval/episode_reward_std': Array(0.04631249, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04125972, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02137987, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123779, dtype=float32), 'eval/episode_x_position_std': Array(0.00536938, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04125972, dtype=float32), 'eval/episode_y_position_std': Array(0.0058137, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01500952, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.61540722846985, 'eval/sps': 6208.9484132640455, 'num_steps': 2222080}
{'eval/walltime': 9114.997696399689, 'training/sps': 127.18743309653172, 'training/walltime': 17589.68530702591, 'training/entropy_loss': Array(0.09848023, dtype=float32), 'training/policy_loss': Array(0.26954603, dtype=float32), 'training/total_loss': Array(0.36802626, dtype=float32), 'training/v_loss': Array(7.95735e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167689, dtype=float32), 'eval/episode_forward_reward': Array(-0.03748387, dtype=float32), 'eval/episode_reward': Array(-2.047739, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03748387, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.016943, dtype=float32), 'eval/episode_train_reward': Array(-0.00112452, dtype=float32), 'eval/episode_x_position': Array(1.0148761, dtype=float32), 'eval/episode_x_velocity': Array(-0.03748387, dtype=float32), 'eval/episode_y_position': Array(0.00035174, dtype=float32), 'eval/episode_y_velocity': Array(-0.00278104, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08962008, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04369495, dtype=float32), 'eval/episode_reward_std': Array(0.1819396, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04369495, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26555002, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131085, dtype=float32), 'eval/episode_x_position_std': Array(0.08935217, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04369495, dtype=float32), 'eval/episode_y_position_std': Array(0.00564656, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0132112, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.689798831939697, 'eval/sps': 6186.623709574262, 'num_steps': 2227200}
{'eval/walltime': 9135.640154361725, 'training/sps': 127.55862940698745, 'training/walltime': 17629.823712587357, 'training/entropy_loss': Array(0.09875236, dtype=float32), 'training/policy_loss': Array(0.26760054, dtype=float32), 'training/total_loss': Array(0.36635292, dtype=float32), 'training/v_loss': Array(4.856155e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0170097, dtype=float32), 'eval/episode_forward_reward': Array(-0.03358194, dtype=float32), 'eval/episode_reward': Array(-2.0470335, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03358194, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0202565, dtype=float32), 'eval/episode_train_reward': Array(-0.00100746, dtype=float32), 'eval/episode_x_position': Array(1.0150794, dtype=float32), 'eval/episode_x_velocity': Array(-0.03358194, dtype=float32), 'eval/episode_y_position': Array(-2.1987842e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00024247, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08929564, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04101666, dtype=float32), 'eval/episode_reward_std': Array(0.17892186, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04101666, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26474714, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012305, dtype=float32), 'eval/episode_x_position_std': Array(0.08902774, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04101666, dtype=float32), 'eval/episode_y_position_std': Array(0.00587483, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01109764, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.642457962036133, 'eval/sps': 6200.811949594704, 'num_steps': 2232320}
{'eval/walltime': 9156.3128387928, 'training/sps': 127.17616195895917, 'training/walltime': 17670.08282971382, 'training/entropy_loss': Array(0.10053191, dtype=float32), 'training/policy_loss': Array(0.2703031, dtype=float32), 'training/total_loss': Array(0.370835, dtype=float32), 'training/v_loss': Array(7.963223e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088679, dtype=float32), 'eval/episode_forward_reward': Array(-0.03289424, dtype=float32), 'eval/episode_reward': Array(-2.027563, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03289424, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.993682, dtype=float32), 'eval/episode_train_reward': Array(-0.00098683, dtype=float32), 'eval/episode_x_position': Array(1.0069628, dtype=float32), 'eval/episode_x_velocity': Array(-0.03289424, dtype=float32), 'eval/episode_y_position': Array(-0.00081295, dtype=float32), 'eval/episode_y_velocity': Array(-0.00057396, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586236, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0416567, dtype=float32), 'eval/episode_reward_std': Array(0.04635496, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0416567, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02100522, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012497, dtype=float32), 'eval/episode_x_position_std': Array(0.00583806, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0416567, dtype=float32), 'eval/episode_y_position_std': Array(0.00581253, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00985329, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67268443107605, 'eval/sps': 6191.745461348261, 'num_steps': 2237440}
{'eval/walltime': 9176.970375537872, 'training/sps': 127.52368763854166, 'training/walltime': 17710.232233285904, 'training/entropy_loss': Array(0.09965143, dtype=float32), 'training/policy_loss': Array(0.27108318, dtype=float32), 'training/total_loss': Array(0.37073463, dtype=float32), 'training/v_loss': Array(8.13235e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084677, dtype=float32), 'eval/episode_forward_reward': Array(-0.03348004, dtype=float32), 'eval/episode_reward': Array(-2.029383, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03348004, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9948983, dtype=float32), 'eval/episode_train_reward': Array(-0.0010044, dtype=float32), 'eval/episode_x_position': Array(1.0065811, dtype=float32), 'eval/episode_x_velocity': Array(-0.03348004, dtype=float32), 'eval/episode_y_position': Array(0.00097811, dtype=float32), 'eval/episode_y_velocity': Array(-0.00047685, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561042, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04019105, dtype=float32), 'eval/episode_reward_std': Array(0.0468272, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04019105, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01858593, dtype=float32), 'eval/episode_train_reward_std': Array(0.00120573, dtype=float32), 'eval/episode_x_position_std': Array(0.00559292, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04019105, dtype=float32), 'eval/episode_y_position_std': Array(0.0059097, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01217332, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65753674507141, 'eval/sps': 6196.285722717591, 'num_steps': 2242560}
{'eval/walltime': 9197.667856693268, 'training/sps': 127.08990648123807, 'training/walltime': 17750.518674135208, 'training/entropy_loss': Array(0.09981987, dtype=float32), 'training/policy_loss': Array(0.26494205, dtype=float32), 'training/total_loss': Array(0.36476192, dtype=float32), 'training/v_loss': Array(4.1410737e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084393, dtype=float32), 'eval/episode_forward_reward': Array(-0.04082584, dtype=float32), 'eval/episode_reward': Array(-2.038353, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04082584, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963021, dtype=float32), 'eval/episode_train_reward': Array(-0.00122478, dtype=float32), 'eval/episode_x_position': Array(1.0065904, dtype=float32), 'eval/episode_x_velocity': Array(-0.04082584, dtype=float32), 'eval/episode_y_position': Array(-0.00025544, dtype=float32), 'eval/episode_y_velocity': Array(-0.00374706, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593106, dtype=float32), 'eval/episode_forward_reward_std': Array(0.043648, dtype=float32), 'eval/episode_reward_std': Array(0.04552113, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.043648, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01599158, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130944, dtype=float32), 'eval/episode_x_position_std': Array(0.00593071, dtype=float32), 'eval/episode_x_velocity_std': Array(0.043648, dtype=float32), 'eval/episode_y_position_std': Array(0.00555702, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01665839, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.697481155395508, 'eval/sps': 6184.327408682405, 'num_steps': 2247680}
{'eval/walltime': 9218.30624127388, 'training/sps': 127.49506312796176, 'training/walltime': 17790.67709183693, 'training/entropy_loss': Array(0.10155946, dtype=float32), 'training/policy_loss': Array(0.2662844, dtype=float32), 'training/total_loss': Array(0.36784387, dtype=float32), 'training/v_loss': Array(1.5524971e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094764, dtype=float32), 'eval/episode_forward_reward': Array(-0.03752733, dtype=float32), 'eval/episode_reward': Array(-2.0361087, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03752733, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974556, dtype=float32), 'eval/episode_train_reward': Array(-0.00112582, dtype=float32), 'eval/episode_x_position': Array(1.007595, dtype=float32), 'eval/episode_x_velocity': Array(-0.03752733, dtype=float32), 'eval/episode_y_position': Array(-0.00026398, dtype=float32), 'eval/episode_y_velocity': Array(-0.00073866, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589988, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04369956, dtype=float32), 'eval/episode_reward_std': Array(0.04678515, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04369956, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01364862, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131099, dtype=float32), 'eval/episode_x_position_std': Array(0.00585676, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04369956, dtype=float32), 'eval/episode_y_position_std': Array(0.00598293, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01560916, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.638384580612183, 'eval/sps': 6202.035798879528, 'num_steps': 2252800}
{'eval/walltime': 9238.993108034134, 'training/sps': 127.0359716554117, 'training/walltime': 17830.9806368351, 'training/entropy_loss': Array(0.09984262, dtype=float32), 'training/policy_loss': Array(0.27403474, dtype=float32), 'training/total_loss': Array(0.3738774, dtype=float32), 'training/v_loss': Array(8.588678e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085008, dtype=float32), 'eval/episode_forward_reward': Array(-0.03743133, dtype=float32), 'eval/episode_reward': Array(-2.0325027, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03743133, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9939485, dtype=float32), 'eval/episode_train_reward': Array(-0.00112294, dtype=float32), 'eval/episode_x_position': Array(1.0066218, dtype=float32), 'eval/episode_x_velocity': Array(-0.03743133, dtype=float32), 'eval/episode_y_position': Array(-0.00033257, dtype=float32), 'eval/episode_y_velocity': Array(-0.00056634, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00631956, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04249698, dtype=float32), 'eval/episode_reward_std': Array(0.0506505, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04249698, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02034712, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127491, dtype=float32), 'eval/episode_x_position_std': Array(0.00630171, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04249698, dtype=float32), 'eval/episode_y_position_std': Array(0.00580193, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01277536, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.686866760253906, 'eval/sps': 6187.500576255897, 'num_steps': 2257920}
{'eval/walltime': 9259.631405591965, 'training/sps': 127.15667643182113, 'training/walltime': 17871.245923280716, 'training/entropy_loss': Array(0.09909365, dtype=float32), 'training/policy_loss': Array(0.269113, dtype=float32), 'training/total_loss': Array(0.36820665, dtype=float32), 'training/v_loss': Array(1.7107611e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089102, dtype=float32), 'eval/episode_forward_reward': Array(-0.03056236, dtype=float32), 'eval/episode_reward': Array(-2.0298672, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03056236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983878, dtype=float32), 'eval/episode_train_reward': Array(-0.00091687, dtype=float32), 'eval/episode_x_position': Array(1.0069667, dtype=float32), 'eval/episode_x_velocity': Array(-0.03056236, dtype=float32), 'eval/episode_y_position': Array(-0.00087509, dtype=float32), 'eval/episode_y_velocity': Array(-0.00095414, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577719, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04046033, dtype=float32), 'eval/episode_reward_std': Array(0.04223262, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04046033, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00732026, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121381, dtype=float32), 'eval/episode_x_position_std': Array(0.00578138, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04046033, dtype=float32), 'eval/episode_y_position_std': Array(0.00535002, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01167204, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63829755783081, 'eval/sps': 6202.061950184105, 'num_steps': 2263040}
{'eval/walltime': 9280.323566436768, 'training/sps': 127.11277230337981, 'training/walltime': 17911.52511715889, 'training/entropy_loss': Array(0.10081628, dtype=float32), 'training/policy_loss': Array(0.26901245, dtype=float32), 'training/total_loss': Array(0.36982876, dtype=float32), 'training/v_loss': Array(9.605919e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090082, dtype=float32), 'eval/episode_forward_reward': Array(-0.03225434, dtype=float32), 'eval/episode_reward': Array(-2.0285635, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03225434, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9953415, dtype=float32), 'eval/episode_train_reward': Array(-0.00096763, dtype=float32), 'eval/episode_x_position': Array(1.0070887, dtype=float32), 'eval/episode_x_velocity': Array(-0.03225434, dtype=float32), 'eval/episode_y_position': Array(0.00013498, dtype=float32), 'eval/episode_y_velocity': Array(-0.00174202, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00598828, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04090113, dtype=float32), 'eval/episode_reward_std': Array(0.05109175, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04090113, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02412679, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122703, dtype=float32), 'eval/episode_x_position_std': Array(0.00595908, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04090113, dtype=float32), 'eval/episode_y_position_std': Array(0.00590333, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01180084, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.692160844802856, 'eval/sps': 6185.917505669742, 'num_steps': 2268160}
{'eval/walltime': 9300.986121177673, 'training/sps': 127.18396055373196, 'training/walltime': 17951.781765699387, 'training/entropy_loss': Array(0.10201801, dtype=float32), 'training/policy_loss': Array(0.26869264, dtype=float32), 'training/total_loss': Array(0.37071067, dtype=float32), 'training/v_loss': Array(3.2299757e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095446, dtype=float32), 'eval/episode_forward_reward': Array(-0.03654083, dtype=float32), 'eval/episode_reward': Array(-2.0343559, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03654083, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996719, dtype=float32), 'eval/episode_train_reward': Array(-0.00109622, dtype=float32), 'eval/episode_x_position': Array(1.0076445, dtype=float32), 'eval/episode_x_velocity': Array(-0.03654083, dtype=float32), 'eval/episode_y_position': Array(0.00032397, dtype=float32), 'eval/episode_y_velocity': Array(-0.00184617, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00564455, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04260353, dtype=float32), 'eval/episode_reward_std': Array(0.04689447, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04260353, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01587086, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127811, dtype=float32), 'eval/episode_x_position_std': Array(0.00565307, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04260353, dtype=float32), 'eval/episode_y_position_std': Array(0.00603569, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01349765, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66255474090576, 'eval/sps': 6194.780926416508, 'num_steps': 2273280}
{'eval/walltime': 9321.683851242065, 'training/sps': 127.10310094331697, 'training/walltime': 17992.064024448395, 'training/entropy_loss': Array(0.10100057, dtype=float32), 'training/policy_loss': Array(0.27108538, dtype=float32), 'training/total_loss': Array(0.37208596, dtype=float32), 'training/v_loss': Array(6.30748e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096453, dtype=float32), 'eval/episode_forward_reward': Array(-0.03589457, dtype=float32), 'eval/episode_reward': Array(-2.032199, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03589457, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952273, dtype=float32), 'eval/episode_train_reward': Array(-0.00107684, dtype=float32), 'eval/episode_x_position': Array(1.0077598, dtype=float32), 'eval/episode_x_velocity': Array(-0.03589457, dtype=float32), 'eval/episode_y_position': Array(-0.00026234, dtype=float32), 'eval/episode_y_velocity': Array(-0.00125637, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00610132, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04253592, dtype=float32), 'eval/episode_reward_std': Array(0.0463475, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04253592, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01809184, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127608, dtype=float32), 'eval/episode_x_position_std': Array(0.0060771, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04253592, dtype=float32), 'eval/episode_y_position_std': Array(0.00551173, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01289565, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69773006439209, 'eval/sps': 6184.253036530239, 'num_steps': 2278400}
{'eval/walltime': 9342.33075094223, 'training/sps': 127.29613737365517, 'training/walltime': 18032.285197734833, 'training/entropy_loss': Array(0.10062742, dtype=float32), 'training/policy_loss': Array(0.26956427, dtype=float32), 'training/total_loss': Array(0.3701917, dtype=float32), 'training/v_loss': Array(1.3461583e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0173354, dtype=float32), 'eval/episode_forward_reward': Array(-0.03947139, dtype=float32), 'eval/episode_reward': Array(-2.0498562, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03947139, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.017013, dtype=float32), 'eval/episode_train_reward': Array(-0.00118414, dtype=float32), 'eval/episode_x_position': Array(1.0154783, dtype=float32), 'eval/episode_x_velocity': Array(-0.03947139, dtype=float32), 'eval/episode_y_position': Array(-0.00066459, dtype=float32), 'eval/episode_y_velocity': Array(-0.00222242, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08800188, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04230245, dtype=float32), 'eval/episode_reward_std': Array(0.17113015, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04230245, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25789952, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126907, dtype=float32), 'eval/episode_x_position_std': Array(0.08772989, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04230245, dtype=float32), 'eval/episode_y_position_std': Array(0.00606154, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01601238, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.646899700164795, 'eval/sps': 6199.47797775074, 'num_steps': 2283520}
{'eval/walltime': 9362.994781255722, 'training/sps': 127.34368107600496, 'training/walltime': 18072.491354465485, 'training/entropy_loss': Array(0.09933284, dtype=float32), 'training/policy_loss': Array(0.2694959, dtype=float32), 'training/total_loss': Array(0.36882874, dtype=float32), 'training/v_loss': Array(7.4464475e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0172453, dtype=float32), 'eval/episode_forward_reward': Array(-0.03825175, dtype=float32), 'eval/episode_reward': Array(-2.0521154, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03825175, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0205286, dtype=float32), 'eval/episode_train_reward': Array(-0.00114755, dtype=float32), 'eval/episode_x_position': Array(1.0153735, dtype=float32), 'eval/episode_x_velocity': Array(-0.03825175, dtype=float32), 'eval/episode_y_position': Array(-0.0010689, dtype=float32), 'eval/episode_y_velocity': Array(-0.00048731, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09108633, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04223708, dtype=float32), 'eval/episode_reward_std': Array(0.17967075, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04223708, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26469705, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126711, dtype=float32), 'eval/episode_x_position_std': Array(0.09082165, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04223708, dtype=float32), 'eval/episode_y_position_std': Array(0.00554832, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01599791, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.66403031349182, 'eval/sps': 6194.338570846322, 'num_steps': 2288640}
{'eval/walltime': 9383.594654798508, 'training/sps': 127.24529803564353, 'training/walltime': 18112.72859764099, 'training/entropy_loss': Array(0.1000206, dtype=float32), 'training/policy_loss': Array(0.27089387, dtype=float32), 'training/total_loss': Array(0.37091446, dtype=float32), 'training/v_loss': Array(2.912332e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009851, dtype=float32), 'eval/episode_forward_reward': Array(-0.03734681, dtype=float32), 'eval/episode_reward': Array(-2.0335927, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03734681, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9951253, dtype=float32), 'eval/episode_train_reward': Array(-0.0011204, dtype=float32), 'eval/episode_x_position': Array(1.0079706, dtype=float32), 'eval/episode_x_velocity': Array(-0.03734681, dtype=float32), 'eval/episode_y_position': Array(-0.00071868, dtype=float32), 'eval/episode_y_velocity': Array(-0.00354468, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566948, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04095032, dtype=float32), 'eval/episode_reward_std': Array(0.04575546, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04095032, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01699296, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122851, dtype=float32), 'eval/episode_x_position_std': Array(0.00567053, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04095032, dtype=float32), 'eval/episode_y_position_std': Array(0.00572972, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01354266, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.599873542785645, 'eval/sps': 6213.630376620799, 'num_steps': 2293760}
{'eval/walltime': 9404.258737564087, 'training/sps': 127.51974918886282, 'training/walltime': 18152.879241228104, 'training/entropy_loss': Array(0.09892517, dtype=float32), 'training/policy_loss': Array(0.2707088, dtype=float32), 'training/total_loss': Array(0.36963397, dtype=float32), 'training/v_loss': Array(7.247067e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089549, dtype=float32), 'eval/episode_forward_reward': Array(-0.03456798, dtype=float32), 'eval/episode_reward': Array(-2.03138, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03456798, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957747, dtype=float32), 'eval/episode_train_reward': Array(-0.00103704, dtype=float32), 'eval/episode_x_position': Array(1.0070226, dtype=float32), 'eval/episode_x_velocity': Array(-0.03456798, dtype=float32), 'eval/episode_y_position': Array(-0.00150259, dtype=float32), 'eval/episode_y_velocity': Array(-0.00103659, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569835, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04155407, dtype=float32), 'eval/episode_reward_std': Array(0.04315957, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04155407, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01598263, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124662, dtype=float32), 'eval/episode_x_position_std': Array(0.00569032, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04155407, dtype=float32), 'eval/episode_y_position_std': Array(0.00575119, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01312361, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.664082765579224, 'eval/sps': 6194.322847622997, 'num_steps': 2298880}
{'eval/walltime': 9424.881213903427, 'training/sps': 127.09938100265799, 'training/walltime': 18193.162678956985, 'training/entropy_loss': Array(0.09810771, dtype=float32), 'training/policy_loss': Array(0.2709884, dtype=float32), 'training/total_loss': Array(0.36909616, dtype=float32), 'training/v_loss': Array(1.1189666e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171026, dtype=float32), 'eval/episode_forward_reward': Array(-0.03548432, dtype=float32), 'eval/episode_reward': Array(-2.047121, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03548432, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0183845, dtype=float32), 'eval/episode_train_reward': Array(-0.00106453, dtype=float32), 'eval/episode_x_position': Array(1.0151966, dtype=float32), 'eval/episode_x_velocity': Array(-0.03548432, dtype=float32), 'eval/episode_y_position': Array(0.00057251, dtype=float32), 'eval/episode_y_velocity': Array(-1.2966368e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09061279, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04031927, dtype=float32), 'eval/episode_reward_std': Array(0.18073595, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04031927, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26565892, dtype=float32), 'eval/episode_train_reward_std': Array(0.00120958, dtype=float32), 'eval/episode_x_position_std': Array(0.09033982, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04031927, dtype=float32), 'eval/episode_y_position_std': Array(0.00604954, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01502793, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.62247633934021, 'eval/sps': 6206.820068248661, 'num_steps': 2304000}
{'eval/walltime': 9445.570880889893, 'training/sps': 127.35273428491467, 'training/walltime': 18233.36597752571, 'training/entropy_loss': Array(0.09909977, dtype=float32), 'training/policy_loss': Array(0.14911641, dtype=float32), 'training/total_loss': Array(0.24821618, dtype=float32), 'training/v_loss': Array(1.5629237e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095136, dtype=float32), 'eval/episode_forward_reward': Array(-0.04451031, dtype=float32), 'eval/episode_reward': Array(-2.0406759, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04451031, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9948304, dtype=float32), 'eval/episode_train_reward': Array(-0.00133531, dtype=float32), 'eval/episode_x_position': Array(1.0076767, dtype=float32), 'eval/episode_x_velocity': Array(-0.04451031, dtype=float32), 'eval/episode_y_position': Array(0.00013377, dtype=float32), 'eval/episode_y_velocity': Array(-0.00297757, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00611881, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04449695, dtype=float32), 'eval/episode_reward_std': Array(0.04942705, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04449695, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01893205, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133491, dtype=float32), 'eval/episode_x_position_std': Array(0.00613857, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04449695, dtype=float32), 'eval/episode_y_position_std': Array(0.00587983, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01296315, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.689666986465454, 'eval/sps': 6186.663134004702, 'num_steps': 2309120}
{'eval/walltime': 9466.162604570389, 'training/sps': 127.1750766788643, 'training/walltime': 18273.62543821335, 'training/entropy_loss': Array(0.09817785, dtype=float32), 'training/policy_loss': Array(0.26174197, dtype=float32), 'training/total_loss': Array(0.35991985, dtype=float32), 'training/v_loss': Array(2.9639548e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085592, dtype=float32), 'eval/episode_forward_reward': Array(-0.03588099, dtype=float32), 'eval/episode_reward': Array(-2.0318024, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03588099, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994845, dtype=float32), 'eval/episode_train_reward': Array(-0.00107643, dtype=float32), 'eval/episode_x_position': Array(1.0066876, dtype=float32), 'eval/episode_x_velocity': Array(-0.03588099, dtype=float32), 'eval/episode_y_position': Array(-0.0006081, dtype=float32), 'eval/episode_y_velocity': Array(-0.00161335, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578266, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04267028, dtype=float32), 'eval/episode_reward_std': Array(0.04847478, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04267028, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01837328, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128011, dtype=float32), 'eval/episode_x_position_std': Array(0.00576764, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04267028, dtype=float32), 'eval/episode_y_position_std': Array(0.0057676, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01097262, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.591723680496216, 'eval/sps': 6216.08962834118, 'num_steps': 2314240}
{'eval/walltime': 9486.837577581406, 'training/sps': 127.41162136091468, 'training/walltime': 18313.81015563011, 'training/entropy_loss': Array(0.09601142, dtype=float32), 'training/policy_loss': Array(0.26453003, dtype=float32), 'training/total_loss': Array(0.36054146, dtype=float32), 'training/v_loss': Array(5.8770135e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088462, dtype=float32), 'eval/episode_forward_reward': Array(-0.04138479, dtype=float32), 'eval/episode_reward': Array(-2.032269, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04138479, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9896424, dtype=float32), 'eval/episode_train_reward': Array(-0.00124154, dtype=float32), 'eval/episode_x_position': Array(1.0069538, dtype=float32), 'eval/episode_x_velocity': Array(-0.04138479, dtype=float32), 'eval/episode_y_position': Array(-0.0004825, dtype=float32), 'eval/episode_y_velocity': Array(-0.00271602, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573274, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0455789, dtype=float32), 'eval/episode_reward_std': Array(0.05537771, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0455789, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02695652, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136737, dtype=float32), 'eval/episode_x_position_std': Array(0.0057789, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0455789, dtype=float32), 'eval/episode_y_position_std': Array(0.00556959, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00991297, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.674973011016846, 'eval/sps': 6191.060076924601, 'num_steps': 2319360}
{'eval/walltime': 9507.454671144485, 'training/sps': 127.3851658770654, 'training/walltime': 18354.003218650818, 'training/entropy_loss': Array(0.09903839, dtype=float32), 'training/policy_loss': Array(0.0931267, dtype=float32), 'training/total_loss': Array(0.19216509, dtype=float32), 'training/v_loss': Array(1.5577225e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101886, dtype=float32), 'eval/episode_forward_reward': Array(-0.03611871, dtype=float32), 'eval/episode_reward': Array(-2.0322084, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03611871, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9950063, dtype=float32), 'eval/episode_train_reward': Array(-0.00108356, dtype=float32), 'eval/episode_x_position': Array(1.0083237, dtype=float32), 'eval/episode_x_velocity': Array(-0.03611871, dtype=float32), 'eval/episode_y_position': Array(-0.00062879, dtype=float32), 'eval/episode_y_velocity': Array(-0.00107432, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057385, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04238062, dtype=float32), 'eval/episode_reward_std': Array(0.04324466, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04238062, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01825589, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127142, dtype=float32), 'eval/episode_x_position_std': Array(0.0057182, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04238062, dtype=float32), 'eval/episode_y_position_std': Array(0.00589013, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01361871, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.617093563079834, 'eval/sps': 6208.440564542844, 'num_steps': 2324480}
{'eval/walltime': 9528.112727880478, 'training/sps': 127.31009848345515, 'training/walltime': 18394.219981193542, 'training/entropy_loss': Array(0.1019041, dtype=float32), 'training/policy_loss': Array(0.12415563, dtype=float32), 'training/total_loss': Array(0.22605973, dtype=float32), 'training/v_loss': Array(1.6512187e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098305, dtype=float32), 'eval/episode_forward_reward': Array(-0.02971238, dtype=float32), 'eval/episode_reward': Array(-2.0231714, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.02971238, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9925675, dtype=float32), 'eval/episode_train_reward': Array(-0.00089137, dtype=float32), 'eval/episode_x_position': Array(1.0078865, dtype=float32), 'eval/episode_x_velocity': Array(-0.02971238, dtype=float32), 'eval/episode_y_position': Array(-0.00075349, dtype=float32), 'eval/episode_y_velocity': Array(-0.00217, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00611722, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04069939, dtype=float32), 'eval/episode_reward_std': Array(0.04828791, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04069939, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02251544, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122098, dtype=float32), 'eval/episode_x_position_std': Array(0.00607295, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04069939, dtype=float32), 'eval/episode_y_position_std': Array(0.00591157, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01072671, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65805673599243, 'eval/sps': 6196.129753917571, 'num_steps': 2329600}
{'eval/walltime': 9548.734545707703, 'training/sps': 127.29788423140536, 'training/walltime': 18434.44060254097, 'training/entropy_loss': Array(0.10052539, dtype=float32), 'training/policy_loss': Array(0.26842147, dtype=float32), 'training/total_loss': Array(0.36894685, dtype=float32), 'training/v_loss': Array(5.5220113e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0081797, dtype=float32), 'eval/episode_forward_reward': Array(-0.03334453, dtype=float32), 'eval/episode_reward': Array(-2.0302153, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03334453, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958706, dtype=float32), 'eval/episode_train_reward': Array(-0.00100034, dtype=float32), 'eval/episode_x_position': Array(1.0062637, dtype=float32), 'eval/episode_x_velocity': Array(-0.03334453, dtype=float32), 'eval/episode_y_position': Array(-0.00099222, dtype=float32), 'eval/episode_y_velocity': Array(-0.00064749, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589748, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04279803, dtype=float32), 'eval/episode_reward_std': Array(0.04852006, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04279803, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0159424, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128394, dtype=float32), 'eval/episode_x_position_std': Array(0.00591747, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04279803, dtype=float32), 'eval/episode_y_position_std': Array(0.0056787, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00913472, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62181782722473, 'eval/sps': 6207.018269311622, 'num_steps': 2334720}
{'eval/walltime': 9569.41201877594, 'training/sps': 127.12488106999439, 'training/walltime': 18474.71595978737, 'training/entropy_loss': Array(0.10099345, dtype=float32), 'training/policy_loss': Array(0.21863356, dtype=float32), 'training/total_loss': Array(0.31962702, dtype=float32), 'training/v_loss': Array(1.27226265e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094817, dtype=float32), 'eval/episode_forward_reward': Array(-0.04532894, dtype=float32), 'eval/episode_reward': Array(-2.0400774, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04532894, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9933884, dtype=float32), 'eval/episode_train_reward': Array(-0.00135987, dtype=float32), 'eval/episode_x_position': Array(1.0076418, dtype=float32), 'eval/episode_x_velocity': Array(-0.04532894, dtype=float32), 'eval/episode_y_position': Array(-0.00038081, dtype=float32), 'eval/episode_y_velocity': Array(-0.00113689, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00608193, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04509377, dtype=float32), 'eval/episode_reward_std': Array(0.05061047, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04509377, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02163528, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135281, dtype=float32), 'eval/episode_x_position_std': Array(0.00605203, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04509377, dtype=float32), 'eval/episode_y_position_std': Array(0.00597554, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01408801, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677473068237305, 'eval/sps': 6190.311532632147, 'num_steps': 2339840}
{'eval/walltime': 9590.040918827057, 'training/sps': 127.2149934298213, 'training/walltime': 18514.96278810501, 'training/entropy_loss': Array(0.10148667, dtype=float32), 'training/policy_loss': Array(0.26841298, dtype=float32), 'training/total_loss': Array(0.36989963, dtype=float32), 'training/v_loss': Array(2.3764937e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093839, dtype=float32), 'eval/episode_forward_reward': Array(-0.03698523, dtype=float32), 'eval/episode_reward': Array(-2.033485, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03698523, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9953902, dtype=float32), 'eval/episode_train_reward': Array(-0.00110956, dtype=float32), 'eval/episode_x_position': Array(1.0074818, dtype=float32), 'eval/episode_x_velocity': Array(-0.03698523, dtype=float32), 'eval/episode_y_position': Array(-0.00046986, dtype=float32), 'eval/episode_y_velocity': Array(-0.00187998, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00625041, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04241265, dtype=float32), 'eval/episode_reward_std': Array(0.04564351, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04241265, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01800109, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127238, dtype=float32), 'eval/episode_x_position_std': Array(0.00622025, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04241265, dtype=float32), 'eval/episode_y_position_std': Array(0.00592369, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01125082, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.628900051116943, 'eval/sps': 6204.8873029015185, 'num_steps': 2344960}
{'eval/walltime': 9610.73505973816, 'training/sps': 127.03512773705626, 'training/walltime': 18555.266600847244, 'training/entropy_loss': Array(0.10168235, dtype=float32), 'training/policy_loss': Array(0.26544636, dtype=float32), 'training/total_loss': Array(0.36712873, dtype=float32), 'training/v_loss': Array(1.2870205e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094259, dtype=float32), 'eval/episode_forward_reward': Array(-0.03883933, dtype=float32), 'eval/episode_reward': Array(-2.0354645, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03883933, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99546, dtype=float32), 'eval/episode_train_reward': Array(-0.00116518, dtype=float32), 'eval/episode_x_position': Array(1.007529, dtype=float32), 'eval/episode_x_velocity': Array(-0.03883933, dtype=float32), 'eval/episode_y_position': Array(0.00054108, dtype=float32), 'eval/episode_y_velocity': Array(-0.00253927, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588748, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04327531, dtype=float32), 'eval/episode_reward_std': Array(0.04657185, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04327531, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01766918, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129826, dtype=float32), 'eval/episode_x_position_std': Array(0.00587831, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04327531, dtype=float32), 'eval/episode_y_position_std': Array(0.00592824, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01147455, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.694140911102295, 'eval/sps': 6185.325621868588, 'num_steps': 2350080}
{'eval/walltime': 9631.376435518265, 'training/sps': 127.26613587917956, 'training/walltime': 18595.497255802155, 'training/entropy_loss': Array(0.10178331, dtype=float32), 'training/policy_loss': Array(0.27010724, dtype=float32), 'training/total_loss': Array(0.37189054, dtype=float32), 'training/v_loss': Array(3.4530923e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089214, dtype=float32), 'eval/episode_forward_reward': Array(-0.03911462, dtype=float32), 'eval/episode_reward': Array(-2.034431, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03911462, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994143, dtype=float32), 'eval/episode_train_reward': Array(-0.00117344, dtype=float32), 'eval/episode_x_position': Array(1.0070641, dtype=float32), 'eval/episode_x_velocity': Array(-0.03911462, dtype=float32), 'eval/episode_y_position': Array(0.00045991, dtype=float32), 'eval/episode_y_velocity': Array(-0.00401563, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585689, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04426654, dtype=float32), 'eval/episode_reward_std': Array(0.05380655, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04426654, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02403475, dtype=float32), 'eval/episode_train_reward_std': Array(0.001328, dtype=float32), 'eval/episode_x_position_std': Array(0.00583956, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04426654, dtype=float32), 'eval/episode_y_position_std': Array(0.00605121, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0135535, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64137578010559, 'eval/sps': 6201.137044526265, 'num_steps': 2355200}
{'eval/walltime': 9652.049330234528, 'training/sps': 127.05923304557793, 'training/walltime': 18635.793422222137, 'training/entropy_loss': Array(0.10213424, dtype=float32), 'training/policy_loss': Array(0.24477094, dtype=float32), 'training/total_loss': Array(0.34690517, dtype=float32), 'training/v_loss': Array(4.207517e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097322, dtype=float32), 'eval/episode_forward_reward': Array(-0.03963275, dtype=float32), 'eval/episode_reward': Array(-2.0373476, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03963275, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965258, dtype=float32), 'eval/episode_train_reward': Array(-0.00118898, dtype=float32), 'eval/episode_x_position': Array(1.0078727, dtype=float32), 'eval/episode_x_velocity': Array(-0.03963275, dtype=float32), 'eval/episode_y_position': Array(0.00016157, dtype=float32), 'eval/episode_y_velocity': Array(-0.00334255, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057579, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04338649, dtype=float32), 'eval/episode_reward_std': Array(0.04754985, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04338649, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01590909, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130159, dtype=float32), 'eval/episode_x_position_std': Array(0.00576319, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04338649, dtype=float32), 'eval/episode_y_position_std': Array(0.00593331, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01586283, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672894716262817, 'eval/sps': 6191.68247876316, 'num_steps': 2360320}
{'eval/walltime': 9672.685035705566, 'training/sps': 127.2131569084201, 'training/walltime': 18676.040831565857, 'training/entropy_loss': Array(0.10053796, dtype=float32), 'training/policy_loss': Array(-0.03822865, dtype=float32), 'training/total_loss': Array(0.06230987, dtype=float32), 'training/v_loss': Array(5.663167e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090351, dtype=float32), 'eval/episode_forward_reward': Array(-0.03426025, dtype=float32), 'eval/episode_reward': Array(-2.0322514, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03426025, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969635, dtype=float32), 'eval/episode_train_reward': Array(-0.00102781, dtype=float32), 'eval/episode_x_position': Array(1.0071052, dtype=float32), 'eval/episode_x_velocity': Array(-0.03426025, dtype=float32), 'eval/episode_y_position': Array(-0.00051486, dtype=float32), 'eval/episode_y_velocity': Array(-0.00168997, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583043, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04292865, dtype=float32), 'eval/episode_reward_std': Array(0.0456483, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04292865, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01699036, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128786, dtype=float32), 'eval/episode_x_position_std': Array(0.00580839, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04292865, dtype=float32), 'eval/episode_y_position_std': Array(0.0054402, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01131391, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63570547103882, 'eval/sps': 6202.841001953706, 'num_steps': 2365440}
{'eval/walltime': 9693.414689540863, 'training/sps': 127.21905024257703, 'training/walltime': 18716.286376476288, 'training/entropy_loss': Array(0.10094158, dtype=float32), 'training/policy_loss': Array(-0.01101151, dtype=float32), 'training/total_loss': Array(0.08993006, dtype=float32), 'training/v_loss': Array(3.5174017e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099434, dtype=float32), 'eval/episode_forward_reward': Array(-0.03295439, dtype=float32), 'eval/episode_reward': Array(-2.0311031, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03295439, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99716, dtype=float32), 'eval/episode_train_reward': Array(-0.00098863, dtype=float32), 'eval/episode_x_position': Array(1.0080333, dtype=float32), 'eval/episode_x_velocity': Array(-0.03295439, dtype=float32), 'eval/episode_y_position': Array(0.0013567, dtype=float32), 'eval/episode_y_velocity': Array(-0.00333655, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561419, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04179518, dtype=float32), 'eval/episode_reward_std': Array(0.0443601, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04179518, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01234119, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125386, dtype=float32), 'eval/episode_x_position_std': Array(0.00557371, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04179518, dtype=float32), 'eval/episode_y_position_std': Array(0.00567539, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01346934, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72965383529663, 'eval/sps': 6174.729255828327, 'num_steps': 2370560}
{'eval/walltime': 9714.05864071846, 'training/sps': 127.05345974618744, 'training/walltime': 18756.58437395096, 'training/entropy_loss': Array(0.10123082, dtype=float32), 'training/policy_loss': Array(-0.000253, dtype=float32), 'training/total_loss': Array(0.10097781, dtype=float32), 'training/v_loss': Array(2.4601552e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0105879, dtype=float32), 'eval/episode_forward_reward': Array(-0.0379812, dtype=float32), 'eval/episode_reward': Array(-2.0370111, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0379812, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978905, dtype=float32), 'eval/episode_train_reward': Array(-0.00113944, dtype=float32), 'eval/episode_x_position': Array(1.0087242, dtype=float32), 'eval/episode_x_velocity': Array(-0.0379812, dtype=float32), 'eval/episode_y_position': Array(0.00022904, dtype=float32), 'eval/episode_y_velocity': Array(-0.00252076, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581469, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04201197, dtype=float32), 'eval/episode_reward_std': Array(0.0438572, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04201197, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01104949, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126036, dtype=float32), 'eval/episode_x_position_std': Array(0.00583916, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04201197, dtype=float32), 'eval/episode_y_position_std': Array(0.00541097, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0112689, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.643951177597046, 'eval/sps': 6200.363433280469, 'num_steps': 2375680}
{'eval/walltime': 9734.74503159523, 'training/sps': 127.05139561829264, 'training/walltime': 18796.883026123047, 'training/entropy_loss': Array(0.1014355, dtype=float32), 'training/policy_loss': Array(0.04033715, dtype=float32), 'training/total_loss': Array(0.14177263, dtype=float32), 'training/v_loss': Array(1.7832553e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171344, dtype=float32), 'eval/episode_forward_reward': Array(-0.03484567, dtype=float32), 'eval/episode_reward': Array(-2.050394, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03484567, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0223157, dtype=float32), 'eval/episode_train_reward': Array(-0.00104537, dtype=float32), 'eval/episode_x_position': Array(1.0151868, dtype=float32), 'eval/episode_x_velocity': Array(-0.03484567, dtype=float32), 'eval/episode_y_position': Array(-5.7864636e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.0002966, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0903857, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04281322, dtype=float32), 'eval/episode_reward_std': Array(0.1800553, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04281322, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26435792, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012844, dtype=float32), 'eval/episode_x_position_std': Array(0.09012047, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04281322, dtype=float32), 'eval/episode_y_position_std': Array(0.00591751, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01804097, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.68639087677002, 'eval/sps': 6187.64291763136, 'num_steps': 2380800}
{'eval/walltime': 9755.362402677536, 'training/sps': 127.37829003649512, 'training/walltime': 18837.078258752823, 'training/entropy_loss': Array(0.1001385, dtype=float32), 'training/policy_loss': Array(0.2634821, dtype=float32), 'training/total_loss': Array(0.36362058, dtype=float32), 'training/v_loss': Array(1.3416908e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009776, dtype=float32), 'eval/episode_forward_reward': Array(-0.03881232, dtype=float32), 'eval/episode_reward': Array(-2.0377464, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03881232, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977696, dtype=float32), 'eval/episode_train_reward': Array(-0.00116437, dtype=float32), 'eval/episode_x_position': Array(1.007901, dtype=float32), 'eval/episode_x_velocity': Array(-0.03881232, dtype=float32), 'eval/episode_y_position': Array(-0.00014211, dtype=float32), 'eval/episode_y_velocity': Array(-0.00077653, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576113, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04220291, dtype=float32), 'eval/episode_reward_std': Array(0.04663813, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04220291, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01275982, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126609, dtype=float32), 'eval/episode_x_position_std': Array(0.00575472, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04220291, dtype=float32), 'eval/episode_y_position_std': Array(0.00596367, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01084556, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.617371082305908, 'eval/sps': 6208.35699609885, 'num_steps': 2385920}
{'eval/walltime': 9776.023623466492, 'training/sps': 127.29130452459336, 'training/walltime': 18877.30095911026, 'training/entropy_loss': Array(0.09965, dtype=float32), 'training/policy_loss': Array(-0.02133342, dtype=float32), 'training/total_loss': Array(0.07831659, dtype=float32), 'training/v_loss': Array(1.3321561e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0173126, dtype=float32), 'eval/episode_forward_reward': Array(-0.03941978, dtype=float32), 'eval/episode_reward': Array(-2.054801, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03941978, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0220113, dtype=float32), 'eval/episode_train_reward': Array(-0.00118259, dtype=float32), 'eval/episode_x_position': Array(1.0154221, dtype=float32), 'eval/episode_x_velocity': Array(-0.03941978, dtype=float32), 'eval/episode_y_position': Array(-0.00074883, dtype=float32), 'eval/episode_y_velocity': Array(-0.00234347, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08778167, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04459595, dtype=float32), 'eval/episode_reward_std': Array(0.17828184, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04459595, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2643822, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133788, dtype=float32), 'eval/episode_x_position_std': Array(0.08750634, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04459595, dtype=float32), 'eval/episode_y_position_std': Array(0.00603149, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01201058, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.66122078895569, 'eval/sps': 6195.180880522874, 'num_steps': 2391040}
{'eval/walltime': 9796.66519021988, 'training/sps': 127.23741351404222, 'training/walltime': 18917.540695667267, 'training/entropy_loss': Array(0.09887403, dtype=float32), 'training/policy_loss': Array(0.26650578, dtype=float32), 'training/total_loss': Array(0.3653798, dtype=float32), 'training/v_loss': Array(1.143337e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0166373, dtype=float32), 'eval/episode_forward_reward': Array(-0.03753168, dtype=float32), 'eval/episode_reward': Array(-2.0513792, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03753168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.020534, dtype=float32), 'eval/episode_train_reward': Array(-0.00112595, dtype=float32), 'eval/episode_x_position': Array(1.014753, dtype=float32), 'eval/episode_x_velocity': Array(-0.03753168, dtype=float32), 'eval/episode_y_position': Array(-5.660033e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00299937, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08837333, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04160999, dtype=float32), 'eval/episode_reward_std': Array(0.1806059, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04160999, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26464874, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012483, dtype=float32), 'eval/episode_x_position_std': Array(0.0880968, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04160999, dtype=float32), 'eval/episode_y_position_std': Array(0.0062068, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01317883, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.64156675338745, 'eval/sps': 6201.079672355499, 'num_steps': 2396160}
{'eval/walltime': 9817.34131526947, 'training/sps': 127.34758373628452, 'training/walltime': 18957.745620250702, 'training/entropy_loss': Array(0.09862888, dtype=float32), 'training/policy_loss': Array(-0.04605201, dtype=float32), 'training/total_loss': Array(0.05257687, dtype=float32), 'training/v_loss': Array(8.329337e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097662, dtype=float32), 'eval/episode_forward_reward': Array(-0.04013512, dtype=float32), 'eval/episode_reward': Array(-2.0377245, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04013512, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963853, dtype=float32), 'eval/episode_train_reward': Array(-0.00120405, dtype=float32), 'eval/episode_x_position': Array(1.0079039, dtype=float32), 'eval/episode_x_velocity': Array(-0.04013512, dtype=float32), 'eval/episode_y_position': Array(0.00043405, dtype=float32), 'eval/episode_y_velocity': Array(-0.00049046, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559782, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04233553, dtype=float32), 'eval/episode_reward_std': Array(0.04454178, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04233553, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01466291, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127007, dtype=float32), 'eval/episode_x_position_std': Array(0.00560726, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04233553, dtype=float32), 'eval/episode_y_position_std': Array(0.00536561, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01391641, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.676125049591064, 'eval/sps': 6190.7151215711765, 'num_steps': 2401280}
{'eval/walltime': 9837.963421821594, 'training/sps': 127.29530131356236, 'training/walltime': 18997.967057704926, 'training/entropy_loss': Array(0.09904279, dtype=float32), 'training/policy_loss': Array(0.06394339, dtype=float32), 'training/total_loss': Array(0.16298619, dtype=float32), 'training/v_loss': Array(6.819372e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091847, dtype=float32), 'eval/episode_forward_reward': Array(-0.03163688, dtype=float32), 'eval/episode_reward': Array(-2.0262616, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03163688, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9936755, dtype=float32), 'eval/episode_train_reward': Array(-0.00094911, dtype=float32), 'eval/episode_x_position': Array(1.0073016, dtype=float32), 'eval/episode_x_velocity': Array(-0.03163688, dtype=float32), 'eval/episode_y_position': Array(0.00047646, dtype=float32), 'eval/episode_y_velocity': Array(0.00010305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579714, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04044299, dtype=float32), 'eval/episode_reward_std': Array(0.04593411, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04044299, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0195106, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121329, dtype=float32), 'eval/episode_x_position_std': Array(0.00580853, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04044299, dtype=float32), 'eval/episode_y_position_std': Array(0.00569479, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01320214, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.622106552124023, 'eval/sps': 6206.931366418351, 'num_steps': 2406400}
{'eval/walltime': 9858.660020112991, 'training/sps': 127.2548628542123, 'training/walltime': 19038.201276540756, 'training/entropy_loss': Array(0.09959449, dtype=float32), 'training/policy_loss': Array(0.11006217, dtype=float32), 'training/total_loss': Array(0.20965666, dtype=float32), 'training/v_loss': Array(8.167481e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009239, dtype=float32), 'eval/episode_forward_reward': Array(-0.03328687, dtype=float32), 'eval/episode_reward': Array(-2.0277605, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03328687, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9934752, dtype=float32), 'eval/episode_train_reward': Array(-0.00099861, dtype=float32), 'eval/episode_x_position': Array(1.0073205, dtype=float32), 'eval/episode_x_velocity': Array(-0.03328687, dtype=float32), 'eval/episode_y_position': Array(0.00016189, dtype=float32), 'eval/episode_y_velocity': Array(-0.00210543, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00597983, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0410823, dtype=float32), 'eval/episode_reward_std': Array(0.04658931, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0410823, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02063224, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123247, dtype=float32), 'eval/episode_x_position_std': Array(0.00593988, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0410823, dtype=float32), 'eval/episode_y_position_std': Array(0.00595584, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01286335, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.696598291397095, 'eval/sps': 6184.591216287241, 'num_steps': 2411520}
{'eval/walltime': 9879.308249950409, 'training/sps': 127.2259782460701, 'training/walltime': 19078.444629907608, 'training/entropy_loss': Array(0.10073172, dtype=float32), 'training/policy_loss': Array(0.11366323, dtype=float32), 'training/total_loss': Array(0.21439494, dtype=float32), 'training/v_loss': Array(5.359191e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088282, dtype=float32), 'eval/episode_forward_reward': Array(-0.03568758, dtype=float32), 'eval/episode_reward': Array(-2.0301838, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03568758, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9934258, dtype=float32), 'eval/episode_train_reward': Array(-0.00107063, dtype=float32), 'eval/episode_x_position': Array(1.0069661, dtype=float32), 'eval/episode_x_velocity': Array(-0.03568758, dtype=float32), 'eval/episode_y_position': Array(0.00074757, dtype=float32), 'eval/episode_y_velocity': Array(-0.00203203, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00554499, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04142826, dtype=float32), 'eval/episode_reward_std': Array(0.04778704, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04142826, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0204653, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124285, dtype=float32), 'eval/episode_x_position_std': Array(0.00559585, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04142826, dtype=float32), 'eval/episode_y_position_std': Array(0.00585379, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01393843, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.648229837417603, 'eval/sps': 6199.078613898676, 'num_steps': 2416640}
{'eval/walltime': 9900.021466493607, 'training/sps': 127.03615201341559, 'training/walltime': 19118.748117685318, 'training/entropy_loss': Array(0.10111906, dtype=float32), 'training/policy_loss': Array(0.2601973, dtype=float32), 'training/total_loss': Array(0.36131638, dtype=float32), 'training/v_loss': Array(5.287065e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093683, dtype=float32), 'eval/episode_forward_reward': Array(-0.04083004, dtype=float32), 'eval/episode_reward': Array(-2.0405223, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04083004, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984674, dtype=float32), 'eval/episode_train_reward': Array(-0.0012249, dtype=float32), 'eval/episode_x_position': Array(1.0075234, dtype=float32), 'eval/episode_x_velocity': Array(-0.04083004, dtype=float32), 'eval/episode_y_position': Array(0.00075565, dtype=float32), 'eval/episode_y_velocity': Array(-0.00246022, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600464, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04269912, dtype=float32), 'eval/episode_reward_std': Array(0.04480608, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04269912, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00987294, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128097, dtype=float32), 'eval/episode_x_position_std': Array(0.00600145, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04269912, dtype=float32), 'eval/episode_y_position_std': Array(0.00571754, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0129346, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.713216543197632, 'eval/sps': 6179.629307358162, 'num_steps': 2421760}
{'eval/walltime': 9920.666686296463, 'training/sps': 127.27382633213995, 'training/walltime': 19158.976341724396, 'training/entropy_loss': Array(0.10065895, dtype=float32), 'training/policy_loss': Array(0.26521915, dtype=float32), 'training/total_loss': Array(0.3658781, dtype=float32), 'training/v_loss': Array(2.3231612e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097183, dtype=float32), 'eval/episode_forward_reward': Array(-0.03681394, dtype=float32), 'eval/episode_reward': Array(-2.0339644, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03681394, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996046, dtype=float32), 'eval/episode_train_reward': Array(-0.00110442, dtype=float32), 'eval/episode_x_position': Array(1.0078508, dtype=float32), 'eval/episode_x_velocity': Array(-0.03681394, dtype=float32), 'eval/episode_y_position': Array(0.00089165, dtype=float32), 'eval/episode_y_velocity': Array(-0.00061285, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586712, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04185901, dtype=float32), 'eval/episode_reward_std': Array(0.04653376, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04185901, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01599581, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125577, dtype=float32), 'eval/episode_x_position_std': Array(0.00582075, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04185901, dtype=float32), 'eval/episode_y_position_std': Array(0.00578594, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00954662, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.645219802856445, 'eval/sps': 6199.982428004476, 'num_steps': 2426880}
{'eval/walltime': 9941.40325140953, 'training/sps': 126.82268832472543, 'training/walltime': 19199.347666978836, 'training/entropy_loss': Array(0.10060899, dtype=float32), 'training/policy_loss': Array(0.26518273, dtype=float32), 'training/total_loss': Array(0.3657917, dtype=float32), 'training/v_loss': Array(1.875954e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092695, dtype=float32), 'eval/episode_forward_reward': Array(-0.03701231, dtype=float32), 'eval/episode_reward': Array(-2.0348625, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03701231, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9967399, dtype=float32), 'eval/episode_train_reward': Array(-0.00111037, dtype=float32), 'eval/episode_x_position': Array(1.0073488, dtype=float32), 'eval/episode_x_velocity': Array(-0.03701231, dtype=float32), 'eval/episode_y_position': Array(-0.00101329, dtype=float32), 'eval/episode_y_velocity': Array(-0.00271849, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560579, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04434307, dtype=float32), 'eval/episode_reward_std': Array(0.04472263, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04434307, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01384063, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133029, dtype=float32), 'eval/episode_x_position_std': Array(0.00557492, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04434307, dtype=float32), 'eval/episode_y_position_std': Array(0.00577472, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01189859, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.736565113067627, 'eval/sps': 6172.6712838925205, 'num_steps': 2432000}
{'eval/walltime': 9962.054764032364, 'training/sps': 127.26040635674215, 'training/walltime': 19239.58013319969, 'training/entropy_loss': Array(0.10105287, dtype=float32), 'training/policy_loss': Array(0.22524396, dtype=float32), 'training/total_loss': Array(0.3262968, dtype=float32), 'training/v_loss': Array(1.0696536e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100021, dtype=float32), 'eval/episode_forward_reward': Array(-0.03778648, dtype=float32), 'eval/episode_reward': Array(-2.0355585, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03778648, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966383, dtype=float32), 'eval/episode_train_reward': Array(-0.00113359, dtype=float32), 'eval/episode_x_position': Array(1.00812, dtype=float32), 'eval/episode_x_velocity': Array(-0.03778648, dtype=float32), 'eval/episode_y_position': Array(0.00035631, dtype=float32), 'eval/episode_y_velocity': Array(-0.00174913, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00551216, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0433443, dtype=float32), 'eval/episode_reward_std': Array(0.04640996, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0433443, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01544341, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130033, dtype=float32), 'eval/episode_x_position_std': Array(0.0054898, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0433443, dtype=float32), 'eval/episode_y_position_std': Array(0.00561297, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01397756, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.651512622833252, 'eval/sps': 6198.093202067793, 'num_steps': 2437120}
{'eval/walltime': 9982.731014966965, 'training/sps': 127.27254930261994, 'training/walltime': 19279.808760881424, 'training/entropy_loss': Array(0.10136862, dtype=float32), 'training/policy_loss': Array(-0.08492076, dtype=float32), 'training/total_loss': Array(0.01644788, dtype=float32), 'training/v_loss': Array(2.8426333e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091004, dtype=float32), 'eval/episode_forward_reward': Array(-0.03889537, dtype=float32), 'eval/episode_reward': Array(-2.0356343, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03889537, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995572, dtype=float32), 'eval/episode_train_reward': Array(-0.00116686, dtype=float32), 'eval/episode_x_position': Array(1.0072087, dtype=float32), 'eval/episode_x_velocity': Array(-0.03889537, dtype=float32), 'eval/episode_y_position': Array(-0.00022486, dtype=float32), 'eval/episode_y_velocity': Array(-0.00359492, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593153, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0425536, dtype=float32), 'eval/episode_reward_std': Array(0.04803149, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0425536, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01698256, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127661, dtype=float32), 'eval/episode_x_position_std': Array(0.00590863, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0425536, dtype=float32), 'eval/episode_y_position_std': Array(0.00588381, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01301624, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67625093460083, 'eval/sps': 6190.677430103995, 'num_steps': 2442240}
{'eval/walltime': 10003.36661863327, 'training/sps': 127.29194737422158, 'training/walltime': 19320.03125810623, 'training/entropy_loss': Array(0.10162833, dtype=float32), 'training/policy_loss': Array(-0.01465016, dtype=float32), 'training/total_loss': Array(0.08697817, dtype=float32), 'training/v_loss': Array(6.765751e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.01698, dtype=float32), 'eval/episode_forward_reward': Array(-0.03660602, dtype=float32), 'eval/episode_reward': Array(-2.049593, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03660602, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0197012, dtype=float32), 'eval/episode_train_reward': Array(-0.00109818, dtype=float32), 'eval/episode_x_position': Array(1.0150589, dtype=float32), 'eval/episode_x_velocity': Array(-0.03660602, dtype=float32), 'eval/episode_y_position': Array(6.872209e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00195555, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08783395, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04359409, dtype=float32), 'eval/episode_reward_std': Array(0.17843345, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04359409, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.264898, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130782, dtype=float32), 'eval/episode_x_position_std': Array(0.08757085, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04359409, dtype=float32), 'eval/episode_y_position_std': Array(0.00562751, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0092597, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.635603666305542, 'eval/sps': 6202.871603363967, 'num_steps': 2447360}
{'eval/walltime': 10024.097871780396, 'training/sps': 127.22437053834139, 'training/walltime': 19360.275120019913, 'training/entropy_loss': Array(0.10181488, dtype=float32), 'training/policy_loss': Array(0.11584541, dtype=float32), 'training/total_loss': Array(0.21766031, dtype=float32), 'training/v_loss': Array(6.2805e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017504, dtype=float32), 'eval/episode_forward_reward': Array(-0.0305026, dtype=float32), 'eval/episode_reward': Array(-2.0413632, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0305026, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.017758, dtype=float32), 'eval/episode_train_reward': Array(-0.00091508, dtype=float32), 'eval/episode_x_position': Array(1.0155799, dtype=float32), 'eval/episode_x_velocity': Array(-0.0305026, dtype=float32), 'eval/episode_y_position': Array(6.991967e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0011331, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09076283, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03926756, dtype=float32), 'eval/episode_reward_std': Array(0.18113716, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03926756, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26540074, dtype=float32), 'eval/episode_train_reward_std': Array(0.00117803, dtype=float32), 'eval/episode_x_position_std': Array(0.09050527, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03926756, dtype=float32), 'eval/episode_y_position_std': Array(0.00577976, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01338409, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.731253147125244, 'eval/sps': 6174.252906547015, 'num_steps': 2452480}
{'eval/walltime': 10044.7629840374, 'training/sps': 127.13090245080706, 'training/walltime': 19400.54856967926, 'training/entropy_loss': Array(0.10165088, dtype=float32), 'training/policy_loss': Array(0.26751044, dtype=float32), 'training/total_loss': Array(0.3691613, dtype=float32), 'training/v_loss': Array(6.8065636e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094869, dtype=float32), 'eval/episode_forward_reward': Array(-0.04051331, dtype=float32), 'eval/episode_reward': Array(-2.0375152, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04051331, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957864, dtype=float32), 'eval/episode_train_reward': Array(-0.0012154, dtype=float32), 'eval/episode_x_position': Array(1.0076475, dtype=float32), 'eval/episode_x_velocity': Array(-0.04051331, dtype=float32), 'eval/episode_y_position': Array(-0.00020324, dtype=float32), 'eval/episode_y_velocity': Array(-0.00179168, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00521721, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04251391, dtype=float32), 'eval/episode_reward_std': Array(0.04604382, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04251391, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01726126, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127542, dtype=float32), 'eval/episode_x_position_std': Array(0.00525251, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04251391, dtype=float32), 'eval/episode_y_position_std': Array(0.00598614, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0128291, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.665112257003784, 'eval/sps': 6194.014259787941, 'num_steps': 2457600}
{'eval/walltime': 10065.445057153702, 'training/sps': 127.2700488730784, 'training/walltime': 19440.777987718582, 'training/entropy_loss': Array(0.10148553, dtype=float32), 'training/policy_loss': Array(0.09397456, dtype=float32), 'training/total_loss': Array(0.19546008, dtype=float32), 'training/v_loss': Array(7.901013e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097605, dtype=float32), 'eval/episode_forward_reward': Array(-0.03612491, dtype=float32), 'eval/episode_reward': Array(-2.0327482, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03612491, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955397, dtype=float32), 'eval/episode_train_reward': Array(-0.00108375, dtype=float32), 'eval/episode_x_position': Array(1.007869, dtype=float32), 'eval/episode_x_velocity': Array(-0.03612491, dtype=float32), 'eval/episode_y_position': Array(0.00045959, dtype=float32), 'eval/episode_y_velocity': Array(-0.00135044, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614679, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04209134, dtype=float32), 'eval/episode_reward_std': Array(0.04809007, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04209134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01659397, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126274, dtype=float32), 'eval/episode_x_position_std': Array(0.00610859, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04209134, dtype=float32), 'eval/episode_y_position_std': Array(0.00581013, dtype=float32), 'eval/episode_y_velocity_std': Array(0.012603, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68207311630249, 'eval/sps': 6188.934701091688, 'num_steps': 2462720}
{'eval/walltime': 10086.06549835205, 'training/sps': 127.46258690848184, 'training/walltime': 19480.946637392044, 'training/entropy_loss': Array(0.10219035, dtype=float32), 'training/policy_loss': Array(0.08913778, dtype=float32), 'training/total_loss': Array(0.19132812, dtype=float32), 'training/v_loss': Array(2.5881244e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091283, dtype=float32), 'eval/episode_forward_reward': Array(-0.03896126, dtype=float32), 'eval/episode_reward': Array(-2.0354571, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03896126, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995327, dtype=float32), 'eval/episode_train_reward': Array(-0.00116884, dtype=float32), 'eval/episode_x_position': Array(1.0072337, dtype=float32), 'eval/episode_x_velocity': Array(-0.03896126, dtype=float32), 'eval/episode_y_position': Array(8.2704384e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00032145, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00601911, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04327418, dtype=float32), 'eval/episode_reward_std': Array(0.05066717, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04327418, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01920278, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129823, dtype=float32), 'eval/episode_x_position_std': Array(0.00602924, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04327418, dtype=float32), 'eval/episode_y_position_std': Array(0.0057418, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01166143, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.620441198349, 'eval/sps': 6207.432652326007, 'num_steps': 2467840}
{'eval/walltime': 10106.761667490005, 'training/sps': 127.17796502596505, 'training/walltime': 19521.20518374443, 'training/entropy_loss': Array(0.10245851, dtype=float32), 'training/policy_loss': Array(0.26030427, dtype=float32), 'training/total_loss': Array(0.36276278, dtype=float32), 'training/v_loss': Array(2.9936675e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090455, dtype=float32), 'eval/episode_forward_reward': Array(-0.03579352, dtype=float32), 'eval/episode_reward': Array(-2.0333312, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03579352, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996464, dtype=float32), 'eval/episode_train_reward': Array(-0.00107381, dtype=float32), 'eval/episode_x_position': Array(1.007226, dtype=float32), 'eval/episode_x_velocity': Array(-0.03579352, dtype=float32), 'eval/episode_y_position': Array(-0.00012993, dtype=float32), 'eval/episode_y_velocity': Array(-0.00206223, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572606, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04189144, dtype=float32), 'eval/episode_reward_std': Array(0.04646463, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04189144, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01408749, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125674, dtype=float32), 'eval/episode_x_position_std': Array(0.00569701, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04189144, dtype=float32), 'eval/episode_y_position_std': Array(0.0058191, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01040919, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.696169137954712, 'eval/sps': 6184.719459277164, 'num_steps': 2472960}
{'eval/walltime': 10127.378054618835, 'training/sps': 127.27108900966219, 'training/walltime': 19561.434273004532, 'training/entropy_loss': Array(0.10232039, dtype=float32), 'training/policy_loss': Array(0.16279459, dtype=float32), 'training/total_loss': Array(0.26511496, dtype=float32), 'training/v_loss': Array(1.1812615e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091293, dtype=float32), 'eval/episode_forward_reward': Array(-0.04072674, dtype=float32), 'eval/episode_reward': Array(-2.03889, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04072674, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969413, dtype=float32), 'eval/episode_train_reward': Array(-0.0012218, dtype=float32), 'eval/episode_x_position': Array(1.0072597, dtype=float32), 'eval/episode_x_velocity': Array(-0.04072674, dtype=float32), 'eval/episode_y_position': Array(-0.00025941, dtype=float32), 'eval/episode_y_velocity': Array(-0.00210179, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00591182, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04247424, dtype=float32), 'eval/episode_reward_std': Array(0.04648566, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04247424, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01349612, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127423, dtype=float32), 'eval/episode_x_position_std': Array(0.00587013, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04247424, dtype=float32), 'eval/episode_y_position_std': Array(0.00587469, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0146254, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.616387128829956, 'eval/sps': 6208.653300897944, 'num_steps': 2478080}
{'eval/walltime': 10148.077847242355, 'training/sps': 127.38837813125835, 'training/walltime': 19601.62632250786, 'training/entropy_loss': Array(0.1032214, dtype=float32), 'training/policy_loss': Array(0.2647869, dtype=float32), 'training/total_loss': Array(0.36800832, dtype=float32), 'training/v_loss': Array(1.7123813e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084453, dtype=float32), 'eval/episode_forward_reward': Array(-0.04660113, dtype=float32), 'eval/episode_reward': Array(-2.0426466, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04660113, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946475, dtype=float32), 'eval/episode_train_reward': Array(-0.00139803, dtype=float32), 'eval/episode_x_position': Array(1.0066605, dtype=float32), 'eval/episode_x_velocity': Array(-0.04660113, dtype=float32), 'eval/episode_y_position': Array(-0.00016018, dtype=float32), 'eval/episode_y_velocity': Array(-0.0001534, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561188, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0427384, dtype=float32), 'eval/episode_reward_std': Array(0.0501319, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0427384, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02230261, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128215, dtype=float32), 'eval/episode_x_position_std': Array(0.00557765, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0427384, dtype=float32), 'eval/episode_y_position_std': Array(0.00588721, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01677094, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.699792623519897, 'eval/sps': 6183.636828059885, 'num_steps': 2483200}
{'eval/walltime': 10168.685105085373, 'training/sps': 127.30648943176175, 'training/walltime': 19641.844225168228, 'training/entropy_loss': Array(0.10498965, dtype=float32), 'training/policy_loss': Array(0.19927673, dtype=float32), 'training/total_loss': Array(0.3042664, dtype=float32), 'training/v_loss': Array(3.1972336e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094092, dtype=float32), 'eval/episode_forward_reward': Array(-0.03695527, dtype=float32), 'eval/episode_reward': Array(-2.035478, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03695527, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974144, dtype=float32), 'eval/episode_train_reward': Array(-0.00110866, dtype=float32), 'eval/episode_x_position': Array(1.0074996, dtype=float32), 'eval/episode_x_velocity': Array(-0.03695527, dtype=float32), 'eval/episode_y_position': Array(0.00037967, dtype=float32), 'eval/episode_y_velocity': Array(-0.00274102, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00604222, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04413098, dtype=float32), 'eval/episode_reward_std': Array(0.04405135, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04413098, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0123271, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132393, dtype=float32), 'eval/episode_x_position_std': Array(0.00601075, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04413098, dtype=float32), 'eval/episode_y_position_std': Array(0.00605068, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01359023, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.607257843017578, 'eval/sps': 6211.403815834266, 'num_steps': 2488320}
{'eval/walltime': 10189.392053842545, 'training/sps': 126.96734354955932, 'training/walltime': 19682.169554948807, 'training/entropy_loss': Array(0.10608444, dtype=float32), 'training/policy_loss': Array(0.26632267, dtype=float32), 'training/total_loss': Array(0.37240714, dtype=float32), 'training/v_loss': Array(2.1918647e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092888, dtype=float32), 'eval/episode_forward_reward': Array(-0.03760013, dtype=float32), 'eval/episode_reward': Array(-2.034936, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03760013, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996208, dtype=float32), 'eval/episode_train_reward': Array(-0.001128, dtype=float32), 'eval/episode_x_position': Array(1.007412, dtype=float32), 'eval/episode_x_velocity': Array(-0.03760013, dtype=float32), 'eval/episode_y_position': Array(-0.00050835, dtype=float32), 'eval/episode_y_velocity': Array(-0.00157621, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594063, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04213702, dtype=float32), 'eval/episode_reward_std': Array(0.04329845, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04213702, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01410144, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126411, dtype=float32), 'eval/episode_x_position_std': Array(0.00592334, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04213702, dtype=float32), 'eval/episode_y_position_std': Array(0.00554124, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01199239, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70694875717163, 'eval/sps': 6181.499819265674, 'num_steps': 2493440}
{'eval/walltime': 10210.066420316696, 'training/sps': 127.26323900073673, 'training/walltime': 19722.40112566948, 'training/entropy_loss': Array(0.1063775, dtype=float32), 'training/policy_loss': Array(0.26935184, dtype=float32), 'training/total_loss': Array(0.37572932, dtype=float32), 'training/v_loss': Array(1.3086652e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094303, dtype=float32), 'eval/episode_forward_reward': Array(-0.04405513, dtype=float32), 'eval/episode_reward': Array(-2.0418634, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04405513, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964867, dtype=float32), 'eval/episode_train_reward': Array(-0.00132165, dtype=float32), 'eval/episode_x_position': Array(1.0075846, dtype=float32), 'eval/episode_x_velocity': Array(-0.04405513, dtype=float32), 'eval/episode_y_position': Array(0.00051122, dtype=float32), 'eval/episode_y_velocity': Array(-0.00379617, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588053, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04374158, dtype=float32), 'eval/episode_reward_std': Array(0.04678247, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04374158, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01517764, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131225, dtype=float32), 'eval/episode_x_position_std': Array(0.00586727, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04374158, dtype=float32), 'eval/episode_y_position_std': Array(0.00600565, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01377998, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67436647415161, 'eval/sps': 6191.241707939811, 'num_steps': 2498560}
{'eval/walltime': 10230.682269573212, 'training/sps': 127.10269922437406, 'training/walltime': 19762.68351173401, 'training/entropy_loss': Array(0.10692856, dtype=float32), 'training/policy_loss': Array(0.2684723, dtype=float32), 'training/total_loss': Array(0.37540084, dtype=float32), 'training/v_loss': Array(1.4923233e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092096, dtype=float32), 'eval/episode_forward_reward': Array(-0.03971121, dtype=float32), 'eval/episode_reward': Array(-2.0371509, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03971121, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962482, dtype=float32), 'eval/episode_train_reward': Array(-0.00119134, dtype=float32), 'eval/episode_x_position': Array(1.0073547, dtype=float32), 'eval/episode_x_velocity': Array(-0.03971121, dtype=float32), 'eval/episode_y_position': Array(-0.00042214, dtype=float32), 'eval/episode_y_velocity': Array(-0.00147206, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584831, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04421389, dtype=float32), 'eval/episode_reward_std': Array(0.04621166, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04421389, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01527019, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132642, dtype=float32), 'eval/episode_x_position_std': Array(0.0058308, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04421389, dtype=float32), 'eval/episode_y_position_std': Array(0.00540913, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01410628, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.615849256515503, 'eval/sps': 6208.815286110343, 'num_steps': 2503680}
{'eval/walltime': 10251.392313241959, 'training/sps': 127.1536173940131, 'training/walltime': 19802.949766874313, 'training/entropy_loss': Array(0.10619461, dtype=float32), 'training/policy_loss': Array(0.26939934, dtype=float32), 'training/total_loss': Array(0.37559396, dtype=float32), 'training/v_loss': Array(2.2986285e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0178137, dtype=float32), 'eval/episode_forward_reward': Array(-0.03687254, dtype=float32), 'eval/episode_reward': Array(-2.0502572, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03687254, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0200906, dtype=float32), 'eval/episode_train_reward': Array(-0.00110618, dtype=float32), 'eval/episode_x_position': Array(1.0159086, dtype=float32), 'eval/episode_x_velocity': Array(-0.03687254, dtype=float32), 'eval/episode_y_position': Array(3.4840778e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00382236, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09094366, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04411471, dtype=float32), 'eval/episode_reward_std': Array(0.1792803, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04411471, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26478413, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132344, dtype=float32), 'eval/episode_x_position_std': Array(0.09068065, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04411471, dtype=float32), 'eval/episode_y_position_std': Array(0.00593677, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01279119, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.71004366874695, 'eval/sps': 6180.576055141876, 'num_steps': 2508800}
{'eval/walltime': 10272.039984464645, 'training/sps': 127.18046409810592, 'training/walltime': 19843.207522153854, 'training/entropy_loss': Array(0.10397428, dtype=float32), 'training/policy_loss': Array(0.2696436, dtype=float32), 'training/total_loss': Array(0.3736179, dtype=float32), 'training/v_loss': Array(3.8763207e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099916, dtype=float32), 'eval/episode_forward_reward': Array(-0.0332642, dtype=float32), 'eval/episode_reward': Array(-2.0269675, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0332642, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9927053, dtype=float32), 'eval/episode_train_reward': Array(-0.00099793, dtype=float32), 'eval/episode_x_position': Array(1.0080954, dtype=float32), 'eval/episode_x_velocity': Array(-0.0332642, dtype=float32), 'eval/episode_y_position': Array(-0.00012403, dtype=float32), 'eval/episode_y_velocity': Array(-0.00099653, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575536, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04199955, dtype=float32), 'eval/episode_reward_std': Array(0.05043398, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04199955, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02309249, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125999, dtype=float32), 'eval/episode_x_position_std': Array(0.00578873, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04199955, dtype=float32), 'eval/episode_y_position_std': Array(0.00571939, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01007413, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647671222686768, 'eval/sps': 6199.246327564492, 'num_steps': 2513920}
{'eval/walltime': 10292.733349323273, 'training/sps': 127.06557901805233, 'training/walltime': 19883.50167608261, 'training/entropy_loss': Array(0.1051368, dtype=float32), 'training/policy_loss': Array(0.26736987, dtype=float32), 'training/total_loss': Array(0.37250668, dtype=float32), 'training/v_loss': Array(4.9771903e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0177437, dtype=float32), 'eval/episode_forward_reward': Array(-0.03984563, dtype=float32), 'eval/episode_reward': Array(-2.0523126, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03984563, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0190842, dtype=float32), 'eval/episode_train_reward': Array(-0.00119537, dtype=float32), 'eval/episode_x_position': Array(1.0158374, dtype=float32), 'eval/episode_x_velocity': Array(-0.03984563, dtype=float32), 'eval/episode_y_position': Array(8.4692474e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00110763, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09007128, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04434959, dtype=float32), 'eval/episode_reward_std': Array(0.17990844, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04434959, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2653343, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133049, dtype=float32), 'eval/episode_x_position_std': Array(0.08980352, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04434959, dtype=float32), 'eval/episode_y_position_std': Array(0.00594217, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0150408, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.69336485862732, 'eval/sps': 6185.557586911015, 'num_steps': 2519040}
{'eval/walltime': 10313.394228935242, 'training/sps': 127.17479349987418, 'training/walltime': 19923.761226415634, 'training/entropy_loss': Array(0.10736005, dtype=float32), 'training/policy_loss': Array(0.22407615, dtype=float32), 'training/total_loss': Array(0.3314362, dtype=float32), 'training/v_loss': Array(6.4508114e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098531, dtype=float32), 'eval/episode_forward_reward': Array(-0.0325928, dtype=float32), 'eval/episode_reward': Array(-2.030386, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0325928, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968152, dtype=float32), 'eval/episode_train_reward': Array(-0.00097778, dtype=float32), 'eval/episode_x_position': Array(1.0079417, dtype=float32), 'eval/episode_x_velocity': Array(-0.0325928, dtype=float32), 'eval/episode_y_position': Array(0.00024399, dtype=float32), 'eval/episode_y_velocity': Array(-0.00216502, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00631134, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04263213, dtype=float32), 'eval/episode_reward_std': Array(0.04457389, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04263213, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01382078, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127896, dtype=float32), 'eval/episode_x_position_std': Array(0.00631971, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04263213, dtype=float32), 'eval/episode_y_position_std': Array(0.00611059, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01061321, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.660879611968994, 'eval/sps': 6195.283182708673, 'num_steps': 2524160}
{'eval/walltime': 10334.082753419876, 'training/sps': 127.4024977997169, 'training/walltime': 19963.948821544647, 'training/entropy_loss': Array(0.10762019, dtype=float32), 'training/policy_loss': Array(0.26882094, dtype=float32), 'training/total_loss': Array(0.37644115, dtype=float32), 'training/v_loss': Array(1.01575255e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085597, dtype=float32), 'eval/episode_forward_reward': Array(-0.03783483, dtype=float32), 'eval/episode_reward': Array(-2.031339, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03783483, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.992369, dtype=float32), 'eval/episode_train_reward': Array(-0.00113504, dtype=float32), 'eval/episode_x_position': Array(1.0066601, dtype=float32), 'eval/episode_x_velocity': Array(-0.03783483, dtype=float32), 'eval/episode_y_position': Array(0.00047428, dtype=float32), 'eval/episode_y_velocity': Array(-0.00245735, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0052893, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04386198, dtype=float32), 'eval/episode_reward_std': Array(0.05296704, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04386198, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02623221, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131586, dtype=float32), 'eval/episode_x_position_std': Array(0.00530653, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04386198, dtype=float32), 'eval/episode_y_position_std': Array(0.00579803, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01139067, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6885244846344, 'eval/sps': 6187.004785917286, 'num_steps': 2529280}
{'eval/walltime': 10354.730701446533, 'training/sps': 127.26051118343962, 'training/walltime': 20004.18125462532, 'training/entropy_loss': Array(0.10835612, dtype=float32), 'training/policy_loss': Array(0.27421808, dtype=float32), 'training/total_loss': Array(0.3825742, dtype=float32), 'training/v_loss': Array(1.2959707e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008639, dtype=float32), 'eval/episode_forward_reward': Array(-0.03806145, dtype=float32), 'eval/episode_reward': Array(-2.0349698, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03806145, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957664, dtype=float32), 'eval/episode_train_reward': Array(-0.00114184, dtype=float32), 'eval/episode_x_position': Array(1.0067623, dtype=float32), 'eval/episode_x_velocity': Array(-0.03806145, dtype=float32), 'eval/episode_y_position': Array(0.00015781, dtype=float32), 'eval/episode_y_velocity': Array(-0.00151387, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579868, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04284197, dtype=float32), 'eval/episode_reward_std': Array(0.04640314, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04284197, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01484421, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128526, dtype=float32), 'eval/episode_x_position_std': Array(0.0057841, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04284197, dtype=float32), 'eval/episode_y_position_std': Array(0.0057589, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01550919, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647948026657104, 'eval/sps': 6199.163221195068, 'num_steps': 2534400}
{'eval/walltime': 10375.397139787674, 'training/sps': 127.40141318817028, 'training/walltime': 20044.369191884995, 'training/entropy_loss': Array(0.10708208, dtype=float32), 'training/policy_loss': Array(0.26835108, dtype=float32), 'training/total_loss': Array(0.37543315, dtype=float32), 'training/v_loss': Array(4.8761983e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095286, dtype=float32), 'eval/episode_forward_reward': Array(-0.04197293, dtype=float32), 'eval/episode_reward': Array(-2.0359073, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04197293, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9926753, dtype=float32), 'eval/episode_train_reward': Array(-0.00125919, dtype=float32), 'eval/episode_x_position': Array(1.0077012, dtype=float32), 'eval/episode_x_velocity': Array(-0.04197293, dtype=float32), 'eval/episode_y_position': Array(-4.6009372e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.002904, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00605429, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04579918, dtype=float32), 'eval/episode_reward_std': Array(0.05342947, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04579918, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02569977, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137398, dtype=float32), 'eval/episode_x_position_std': Array(0.00603114, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04579918, dtype=float32), 'eval/episode_y_position_std': Array(0.00582429, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01440368, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666438341140747, 'eval/sps': 6193.616814233054, 'num_steps': 2539520}
{'eval/walltime': 10396.02501296997, 'training/sps': 127.2458258162919, 'training/walltime': 20084.606268167496, 'training/entropy_loss': Array(0.10768349, dtype=float32), 'training/policy_loss': Array(0.27004862, dtype=float32), 'training/total_loss': Array(0.3777321, dtype=float32), 'training/v_loss': Array(7.0487394e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090826, dtype=float32), 'eval/episode_forward_reward': Array(-0.03470465, dtype=float32), 'eval/episode_reward': Array(-2.0324152, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03470465, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966693, dtype=float32), 'eval/episode_train_reward': Array(-0.00104114, dtype=float32), 'eval/episode_x_position': Array(1.0071964, dtype=float32), 'eval/episode_x_velocity': Array(-0.03470465, dtype=float32), 'eval/episode_y_position': Array(0.00049858, dtype=float32), 'eval/episode_y_velocity': Array(-0.00257098, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582971, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04180823, dtype=float32), 'eval/episode_reward_std': Array(0.04672201, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04180823, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0148744, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125425, dtype=float32), 'eval/episode_x_position_std': Array(0.00581055, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04180823, dtype=float32), 'eval/episode_y_position_std': Array(0.00555661, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00931836, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.627873182296753, 'eval/sps': 6205.196186190059, 'num_steps': 2544640}
{'eval/walltime': 10416.728677034378, 'training/sps': 127.04008920595234, 'training/walltime': 20124.90850687027, 'training/entropy_loss': Array(0.10620143, dtype=float32), 'training/policy_loss': Array(0.26943967, dtype=float32), 'training/total_loss': Array(0.37564108, dtype=float32), 'training/v_loss': Array(2.501487e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169156, dtype=float32), 'eval/episode_forward_reward': Array(-0.03702589, dtype=float32), 'eval/episode_reward': Array(-2.0485291, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03702589, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0182047, dtype=float32), 'eval/episode_train_reward': Array(-0.00111078, dtype=float32), 'eval/episode_x_position': Array(1.0150334, dtype=float32), 'eval/episode_x_velocity': Array(-0.03702589, dtype=float32), 'eval/episode_y_position': Array(0.000168, dtype=float32), 'eval/episode_y_velocity': Array(-0.00155424, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08867321, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04296948, dtype=float32), 'eval/episode_reward_std': Array(0.18083182, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04296948, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26545757, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128908, dtype=float32), 'eval/episode_x_position_std': Array(0.08840129, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04296948, dtype=float32), 'eval/episode_y_position_std': Array(0.00577534, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01322282, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.70366406440735, 'eval/sps': 6182.480531069419, 'num_steps': 2549760}
{'eval/walltime': 10437.388991355896, 'training/sps': 127.15466466309257, 'training/walltime': 20165.17443037033, 'training/entropy_loss': Array(0.10644563, dtype=float32), 'training/policy_loss': Array(0.26976433, dtype=float32), 'training/total_loss': Array(0.37620997, dtype=float32), 'training/v_loss': Array(2.053507e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091043, dtype=float32), 'eval/episode_forward_reward': Array(-0.0363631, dtype=float32), 'eval/episode_reward': Array(-2.0306997, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0363631, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9932456, dtype=float32), 'eval/episode_train_reward': Array(-0.00109089, dtype=float32), 'eval/episode_x_position': Array(1.0071775, dtype=float32), 'eval/episode_x_velocity': Array(-0.0363631, dtype=float32), 'eval/episode_y_position': Array(0.00117939, dtype=float32), 'eval/episode_y_velocity': Array(-0.00265475, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599866, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04255194, dtype=float32), 'eval/episode_reward_std': Array(0.04836437, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04255194, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02023393, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127656, dtype=float32), 'eval/episode_x_position_std': Array(0.00599651, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04255194, dtype=float32), 'eval/episode_y_position_std': Array(0.00610338, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01054944, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.660314321517944, 'eval/sps': 6195.452692928616, 'num_steps': 2554880}
{'eval/walltime': 10458.066219091415, 'training/sps': 127.43742460290582, 'training/walltime': 20205.351011276245, 'training/entropy_loss': Array(0.10443792, dtype=float32), 'training/policy_loss': Array(0.27000064, dtype=float32), 'training/total_loss': Array(0.37443852, dtype=float32), 'training/v_loss': Array(6.8131495e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091516, dtype=float32), 'eval/episode_forward_reward': Array(-0.03504738, dtype=float32), 'eval/episode_reward': Array(-2.0316658, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03504738, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955668, dtype=float32), 'eval/episode_train_reward': Array(-0.00105142, dtype=float32), 'eval/episode_x_position': Array(1.0072544, dtype=float32), 'eval/episode_x_velocity': Array(-0.03504738, dtype=float32), 'eval/episode_y_position': Array(0.00018373, dtype=float32), 'eval/episode_y_velocity': Array(-0.00040585, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567105, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04259167, dtype=float32), 'eval/episode_reward_std': Array(0.04848756, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04259167, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01736553, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127775, dtype=float32), 'eval/episode_x_position_std': Array(0.00563038, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04259167, dtype=float32), 'eval/episode_y_position_std': Array(0.00560436, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01267972, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67722773551941, 'eval/sps': 6190.384979903335, 'num_steps': 2560000}
{'eval/walltime': 10478.703785657883, 'training/sps': 127.35531575765592, 'training/walltime': 20245.553494930267, 'training/entropy_loss': Array(0.1019488, dtype=float32), 'training/policy_loss': Array(0.265014, dtype=float32), 'training/total_loss': Array(0.36696285, dtype=float32), 'training/v_loss': Array(4.0929162e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0102994, dtype=float32), 'eval/episode_forward_reward': Array(-0.04063035, dtype=float32), 'eval/episode_reward': Array(-2.0356295, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04063035, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9937804, dtype=float32), 'eval/episode_train_reward': Array(-0.00121891, dtype=float32), 'eval/episode_x_position': Array(1.0084271, dtype=float32), 'eval/episode_x_velocity': Array(-0.04063035, dtype=float32), 'eval/episode_y_position': Array(-2.0338754e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00232301, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00549088, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04285633, dtype=float32), 'eval/episode_reward_std': Array(0.04959058, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04285633, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02182984, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128569, dtype=float32), 'eval/episode_x_position_std': Array(0.00549369, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04285633, dtype=float32), 'eval/episode_y_position_std': Array(0.00561121, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01364361, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.637566566467285, 'eval/sps': 6202.281629849681, 'num_steps': 2565120}
{'eval/walltime': 10499.370955705643, 'training/sps': 127.32792410152034, 'training/walltime': 20285.764627218246, 'training/entropy_loss': Array(0.10264038, dtype=float32), 'training/policy_loss': Array(0.26357818, dtype=float32), 'training/total_loss': Array(0.36621857, dtype=float32), 'training/v_loss': Array(2.0283368e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097545, dtype=float32), 'eval/episode_forward_reward': Array(-0.03669163, dtype=float32), 'eval/episode_reward': Array(-2.0324244, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03669163, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994632, dtype=float32), 'eval/episode_train_reward': Array(-0.00110075, dtype=float32), 'eval/episode_x_position': Array(1.0078554, dtype=float32), 'eval/episode_x_velocity': Array(-0.03669163, dtype=float32), 'eval/episode_y_position': Array(-0.0003213, dtype=float32), 'eval/episode_y_velocity': Array(-0.00024147, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583158, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04367049, dtype=float32), 'eval/episode_reward_std': Array(0.04728327, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04367049, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01921281, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131011, dtype=float32), 'eval/episode_x_position_std': Array(0.00579376, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04367049, dtype=float32), 'eval/episode_y_position_std': Array(0.00557844, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01379688, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66717004776001, 'eval/sps': 6193.397533586034, 'num_steps': 2570240}
{'eval/walltime': 10520.01175236702, 'training/sps': 127.2354911598122, 'training/walltime': 20326.00497174263, 'training/entropy_loss': Array(0.10072272, dtype=float32), 'training/policy_loss': Array(0.26795432, dtype=float32), 'training/total_loss': Array(0.36867702, dtype=float32), 'training/v_loss': Array(6.754283e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176597, dtype=float32), 'eval/episode_forward_reward': Array(-0.04244216, dtype=float32), 'eval/episode_reward': Array(-2.0563076, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04244216, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0204046, dtype=float32), 'eval/episode_train_reward': Array(-0.00127326, dtype=float32), 'eval/episode_x_position': Array(1.0157809, dtype=float32), 'eval/episode_x_velocity': Array(-0.04244216, dtype=float32), 'eval/episode_y_position': Array(0.00018934, dtype=float32), 'eval/episode_y_velocity': Array(-0.00382213, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08889, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04276204, dtype=float32), 'eval/episode_reward_std': Array(0.18031828, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04276204, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.264817, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128286, dtype=float32), 'eval/episode_x_position_std': Array(0.08862156, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04276204, dtype=float32), 'eval/episode_y_position_std': Array(0.00554323, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0107601, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.640796661376953, 'eval/sps': 6201.311029797291, 'num_steps': 2575360}
{'eval/walltime': 10540.666613578796, 'training/sps': 127.59742644221217, 'training/walltime': 20366.13117289543, 'training/entropy_loss': Array(0.10159622, dtype=float32), 'training/policy_loss': Array(0.15607479, dtype=float32), 'training/total_loss': Array(0.25767103, dtype=float32), 'training/v_loss': Array(1.2282563e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092902, dtype=float32), 'eval/episode_forward_reward': Array(-0.04177238, dtype=float32), 'eval/episode_reward': Array(-2.0417464, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04177238, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998721, dtype=float32), 'eval/episode_train_reward': Array(-0.00125317, dtype=float32), 'eval/episode_x_position': Array(1.0073906, dtype=float32), 'eval/episode_x_velocity': Array(-0.04177238, dtype=float32), 'eval/episode_y_position': Array(-2.3310422e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.0032118, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574639, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04511268, dtype=float32), 'eval/episode_reward_std': Array(0.04702827, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04511268, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00730577, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135338, dtype=float32), 'eval/episode_x_position_std': Array(0.00578982, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04511268, dtype=float32), 'eval/episode_y_position_std': Array(0.00596513, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01513603, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.654861211776733, 'eval/sps': 6197.088360342917, 'num_steps': 2580480}
{'eval/walltime': 10561.314090013504, 'training/sps': 127.4223241244652, 'training/walltime': 20406.31251502037, 'training/entropy_loss': Array(0.10418661, dtype=float32), 'training/policy_loss': Array(0.26794702, dtype=float32), 'training/total_loss': Array(0.3721336, dtype=float32), 'training/v_loss': Array(3.0076325e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096021, dtype=float32), 'eval/episode_forward_reward': Array(-0.03156143, dtype=float32), 'eval/episode_reward': Array(-2.0295758, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03156143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970675, dtype=float32), 'eval/episode_train_reward': Array(-0.00094684, dtype=float32), 'eval/episode_x_position': Array(1.0076532, dtype=float32), 'eval/episode_x_velocity': Array(-0.03156143, dtype=float32), 'eval/episode_y_position': Array(-0.00061717, dtype=float32), 'eval/episode_y_velocity': Array(-0.00142944, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00555252, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04168912, dtype=float32), 'eval/episode_reward_std': Array(0.04417604, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04168912, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01222746, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125067, dtype=float32), 'eval/episode_x_position_std': Array(0.00555974, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04168912, dtype=float32), 'eval/episode_y_position_std': Array(0.00525984, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01074807, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64747643470764, 'eval/sps': 6199.304811160203, 'num_steps': 2585600}
{'eval/walltime': 10581.995518922806, 'training/sps': 127.28568363954214, 'training/walltime': 20446.536991596222, 'training/entropy_loss': Array(0.10514396, dtype=float32), 'training/policy_loss': Array(0.2708426, dtype=float32), 'training/total_loss': Array(0.37598658, dtype=float32), 'training/v_loss': Array(9.556085e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098671, dtype=float32), 'eval/episode_forward_reward': Array(-0.03684762, dtype=float32), 'eval/episode_reward': Array(-2.0341058, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03684762, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961529, dtype=float32), 'eval/episode_train_reward': Array(-0.00110543, dtype=float32), 'eval/episode_x_position': Array(1.007956, dtype=float32), 'eval/episode_x_velocity': Array(-0.03684762, dtype=float32), 'eval/episode_y_position': Array(-0.00030795, dtype=float32), 'eval/episode_y_velocity': Array(-0.00222293, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563454, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04267852, dtype=float32), 'eval/episode_reward_std': Array(0.04519677, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04267852, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01631923, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128036, dtype=float32), 'eval/episode_x_position_std': Array(0.00565708, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04267852, dtype=float32), 'eval/episode_y_position_std': Array(0.00588817, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00941341, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.681428909301758, 'eval/sps': 6189.1274805693065, 'num_steps': 2590720}
{'eval/walltime': 10602.651683568954, 'training/sps': 127.17664096425442, 'training/walltime': 20486.79595708847, 'training/entropy_loss': Array(0.10375345, dtype=float32), 'training/policy_loss': Array(0.27065456, dtype=float32), 'training/total_loss': Array(0.374408, dtype=float32), 'training/v_loss': Array(5.7468796e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093651, dtype=float32), 'eval/episode_forward_reward': Array(-0.04161972, dtype=float32), 'eval/episode_reward': Array(-2.0376492, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04161972, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947808, dtype=float32), 'eval/episode_train_reward': Array(-0.00124859, dtype=float32), 'eval/episode_x_position': Array(1.007525, dtype=float32), 'eval/episode_x_velocity': Array(-0.04161972, dtype=float32), 'eval/episode_y_position': Array(-6.658028e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00222187, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573085, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04209059, dtype=float32), 'eval/episode_reward_std': Array(0.05104269, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04209059, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02743178, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126272, dtype=float32), 'eval/episode_x_position_std': Array(0.005708, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04209059, dtype=float32), 'eval/episode_y_position_std': Array(0.00600542, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01143176, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65616464614868, 'eval/sps': 6196.6973149521955, 'num_steps': 2595840}
{'eval/walltime': 10623.342478990555, 'training/sps': 127.24085881970848, 'training/walltime': 20527.03460407257, 'training/entropy_loss': Array(0.1046527, dtype=float32), 'training/policy_loss': Array(0.26907587, dtype=float32), 'training/total_loss': Array(0.37372857, dtype=float32), 'training/v_loss': Array(8.1130136e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090945, dtype=float32), 'eval/episode_forward_reward': Array(-0.04033217, dtype=float32), 'eval/episode_reward': Array(-2.0384483, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04033217, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969063, dtype=float32), 'eval/episode_train_reward': Array(-0.00120996, dtype=float32), 'eval/episode_x_position': Array(1.0072066, dtype=float32), 'eval/episode_x_velocity': Array(-0.04033217, dtype=float32), 'eval/episode_y_position': Array(-0.00042801, dtype=float32), 'eval/episode_y_velocity': Array(-0.00130592, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00605194, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04425713, dtype=float32), 'eval/episode_reward_std': Array(0.04740879, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04425713, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01323024, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132771, dtype=float32), 'eval/episode_x_position_std': Array(0.00600447, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04425713, dtype=float32), 'eval/episode_y_position_std': Array(0.00548527, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01158221, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.690795421600342, 'eval/sps': 6186.325725610976, 'num_steps': 2600960}
{'eval/walltime': 10644.026097774506, 'training/sps': 127.37191883499412, 'training/walltime': 20567.231847286224, 'training/entropy_loss': Array(0.10545228, dtype=float32), 'training/policy_loss': Array(0.26703888, dtype=float32), 'training/total_loss': Array(0.37249115, dtype=float32), 'training/v_loss': Array(1.1696812e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0082936, dtype=float32), 'eval/episode_forward_reward': Array(-0.04433771, dtype=float32), 'eval/episode_reward': Array(-2.043054, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04433771, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997386, dtype=float32), 'eval/episode_train_reward': Array(-0.00133013, dtype=float32), 'eval/episode_x_position': Array(1.0064551, dtype=float32), 'eval/episode_x_velocity': Array(-0.04433771, dtype=float32), 'eval/episode_y_position': Array(-0.0003853, dtype=float32), 'eval/episode_y_velocity': Array(-0.00140847, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576558, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04482778, dtype=float32), 'eval/episode_reward_std': Array(0.04801204, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04482778, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01248314, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134483, dtype=float32), 'eval/episode_x_position_std': Array(0.00571605, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04482778, dtype=float32), 'eval/episode_y_position_std': Array(0.0057069, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00970453, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.683618783950806, 'eval/sps': 6188.472207741519, 'num_steps': 2606080}
{'eval/walltime': 10664.736963510513, 'training/sps': 127.31367000078659, 'training/walltime': 20607.447481632233, 'training/entropy_loss': Array(0.10619783, dtype=float32), 'training/policy_loss': Array(0.26694536, dtype=float32), 'training/total_loss': Array(0.3731432, dtype=float32), 'training/v_loss': Array(5.7797434e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100529, dtype=float32), 'eval/episode_forward_reward': Array(-0.03615053, dtype=float32), 'eval/episode_reward': Array(-2.0343637, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03615053, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997129, dtype=float32), 'eval/episode_train_reward': Array(-0.00108452, dtype=float32), 'eval/episode_x_position': Array(1.0081704, dtype=float32), 'eval/episode_x_velocity': Array(-0.03615053, dtype=float32), 'eval/episode_y_position': Array(-0.00071744, dtype=float32), 'eval/episode_y_velocity': Array(-0.00152411, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584564, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04178588, dtype=float32), 'eval/episode_reward_std': Array(0.04508224, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04178588, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01319485, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125358, dtype=float32), 'eval/episode_x_position_std': Array(0.00583334, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04178588, dtype=float32), 'eval/episode_y_position_std': Array(0.00567438, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0133805, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71086573600769, 'eval/sps': 6180.330732261982, 'num_steps': 2611200}
{'eval/walltime': 10685.413880586624, 'training/sps': 127.21402580175999, 'training/walltime': 20647.69461607933, 'training/entropy_loss': Array(0.1082139, dtype=float32), 'training/policy_loss': Array(0.27055544, dtype=float32), 'training/total_loss': Array(0.37876934, dtype=float32), 'training/v_loss': Array(2.6812583e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008858, dtype=float32), 'eval/episode_forward_reward': Array(-0.03414997, dtype=float32), 'eval/episode_reward': Array(-2.0300674, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03414997, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994893, dtype=float32), 'eval/episode_train_reward': Array(-0.0010245, dtype=float32), 'eval/episode_x_position': Array(1.0069371, dtype=float32), 'eval/episode_x_velocity': Array(-0.03414997, dtype=float32), 'eval/episode_y_position': Array(-0.00023998, dtype=float32), 'eval/episode_y_velocity': Array(-0.00273625, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057396, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04253501, dtype=float32), 'eval/episode_reward_std': Array(0.04788579, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04253501, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01859917, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127605, dtype=float32), 'eval/episode_x_position_std': Array(0.00575119, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04253501, dtype=float32), 'eval/episode_y_position_std': Array(0.00585397, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01240264, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67691707611084, 'eval/sps': 6190.477987063426, 'num_steps': 2616320}
{'eval/walltime': 10706.072856903076, 'training/sps': 127.1015016054418, 'training/walltime': 20687.977381706238, 'training/entropy_loss': Array(0.10768634, dtype=float32), 'training/policy_loss': Array(0.27020216, dtype=float32), 'training/total_loss': Array(0.3778885, dtype=float32), 'training/v_loss': Array(1.0936926e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089313, dtype=float32), 'eval/episode_forward_reward': Array(-0.03975467, dtype=float32), 'eval/episode_reward': Array(-2.0371847, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03975467, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962378, dtype=float32), 'eval/episode_train_reward': Array(-0.00119264, dtype=float32), 'eval/episode_x_position': Array(1.0070432, dtype=float32), 'eval/episode_x_velocity': Array(-0.03975467, dtype=float32), 'eval/episode_y_position': Array(-0.00061393, dtype=float32), 'eval/episode_y_velocity': Array(-0.00045869, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559587, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04392374, dtype=float32), 'eval/episode_reward_std': Array(0.04862541, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04392374, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01743091, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131771, dtype=float32), 'eval/episode_x_position_std': Array(0.0056057, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04392374, dtype=float32), 'eval/episode_y_position_std': Array(0.00617643, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01207246, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.658976316452026, 'eval/sps': 6195.853949358839, 'num_steps': 2621440}
{'eval/walltime': 10726.697907924652, 'training/sps': 127.29004827029497, 'training/walltime': 20728.20047903061, 'training/entropy_loss': Array(0.10601059, dtype=float32), 'training/policy_loss': Array(0.27300772, dtype=float32), 'training/total_loss': Array(0.3790183, dtype=float32), 'training/v_loss': Array(7.5654295e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096815, dtype=float32), 'eval/episode_forward_reward': Array(-0.04102662, dtype=float32), 'eval/episode_reward': Array(-2.034812, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04102662, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9925547, dtype=float32), 'eval/episode_train_reward': Array(-0.0012308, dtype=float32), 'eval/episode_x_position': Array(1.0077947, dtype=float32), 'eval/episode_x_velocity': Array(-0.04102662, dtype=float32), 'eval/episode_y_position': Array(0.00021034, dtype=float32), 'eval/episode_y_velocity': Array(-0.00254252, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00545379, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04554975, dtype=float32), 'eval/episode_reward_std': Array(0.0517271, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04554975, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0221455, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136649, dtype=float32), 'eval/episode_x_position_std': Array(0.00543307, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04554975, dtype=float32), 'eval/episode_y_position_std': Array(0.00616349, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01240255, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.625051021575928, 'eval/sps': 6206.045253711073, 'num_steps': 2626560}
{'eval/walltime': 10747.350516319275, 'training/sps': 127.22616969639262, 'training/walltime': 20768.443771839142, 'training/entropy_loss': Array(0.1055705, dtype=float32), 'training/policy_loss': Array(0.26964033, dtype=float32), 'training/total_loss': Array(0.37521088, dtype=float32), 'training/v_loss': Array(1.0641917e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095972, dtype=float32), 'eval/episode_forward_reward': Array(-0.03245318, dtype=float32), 'eval/episode_reward': Array(-2.0307474, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03245318, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973207, dtype=float32), 'eval/episode_train_reward': Array(-0.0009736, dtype=float32), 'eval/episode_x_position': Array(1.007736, dtype=float32), 'eval/episode_x_velocity': Array(-0.03245318, dtype=float32), 'eval/episode_y_position': Array(-0.00032344, dtype=float32), 'eval/episode_y_velocity': Array(-0.00073697, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593554, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04106404, dtype=float32), 'eval/episode_reward_std': Array(0.04365376, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04106404, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.012224, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123192, dtype=float32), 'eval/episode_x_position_std': Array(0.00587775, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04106404, dtype=float32), 'eval/episode_y_position_std': Array(0.00548612, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01208083, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.652608394622803, 'eval/sps': 6197.764347932274, 'num_steps': 2631680}
{'eval/walltime': 10767.940766334534, 'training/sps': 127.27471415807707, 'training/walltime': 20808.671715259552, 'training/entropy_loss': Array(0.10467734, dtype=float32), 'training/policy_loss': Array(0.27072546, dtype=float32), 'training/total_loss': Array(0.37540278, dtype=float32), 'training/v_loss': Array(2.6179587e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098464, dtype=float32), 'eval/episode_forward_reward': Array(-0.04021614, dtype=float32), 'eval/episode_reward': Array(-2.037197, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04021614, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957747, dtype=float32), 'eval/episode_train_reward': Array(-0.00120648, dtype=float32), 'eval/episode_x_position': Array(1.0079775, dtype=float32), 'eval/episode_x_velocity': Array(-0.04021614, dtype=float32), 'eval/episode_y_position': Array(0.00033856, dtype=float32), 'eval/episode_y_velocity': Array(-0.00076915, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572685, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0440877, dtype=float32), 'eval/episode_reward_std': Array(0.04884286, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0440877, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01524564, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132263, dtype=float32), 'eval/episode_x_position_std': Array(0.00574363, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0440877, dtype=float32), 'eval/episode_y_position_std': Array(0.0059913, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01203646, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.59025001525879, 'eval/sps': 6216.534520228905, 'num_steps': 2636800}
{'eval/walltime': 10788.614079236984, 'training/sps': 126.96692542279672, 'training/walltime': 20848.99717783928, 'training/entropy_loss': Array(0.1046263, dtype=float32), 'training/policy_loss': Array(0.26647252, dtype=float32), 'training/total_loss': Array(0.37109882, dtype=float32), 'training/v_loss': Array(1.7200636e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087198, dtype=float32), 'eval/episode_forward_reward': Array(-0.04179178, dtype=float32), 'eval/episode_reward': Array(-2.0397186, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04179178, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966729, dtype=float32), 'eval/episode_train_reward': Array(-0.00125375, dtype=float32), 'eval/episode_x_position': Array(1.0068908, dtype=float32), 'eval/episode_x_velocity': Array(-0.04179178, dtype=float32), 'eval/episode_y_position': Array(0.00060979, dtype=float32), 'eval/episode_y_velocity': Array(-0.00114025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599848, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04298937, dtype=float32), 'eval/episode_reward_std': Array(0.04488, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04298937, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01409617, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128968, dtype=float32), 'eval/episode_x_position_std': Array(0.00599662, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04298937, dtype=float32), 'eval/episode_y_position_std': Array(0.00572627, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01285872, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67331290245056, 'eval/sps': 6191.557231488873, 'num_steps': 2641920}
{'eval/walltime': 10809.224355697632, 'training/sps': 127.0719504376921, 'training/walltime': 20889.289311408997, 'training/entropy_loss': Array(0.10620898, dtype=float32), 'training/policy_loss': Array(0.26627558, dtype=float32), 'training/total_loss': Array(0.37248456, dtype=float32), 'training/v_loss': Array(1.0715654e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176995, dtype=float32), 'eval/episode_forward_reward': Array(-0.03930911, dtype=float32), 'eval/episode_reward': Array(-2.0512018, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03930911, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.018526, dtype=float32), 'eval/episode_train_reward': Array(-0.00117927, dtype=float32), 'eval/episode_x_position': Array(1.0157855, dtype=float32), 'eval/episode_x_velocity': Array(-0.03930911, dtype=float32), 'eval/episode_y_position': Array(-0.00028556, dtype=float32), 'eval/episode_y_velocity': Array(-0.00447894, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08883079, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0435383, dtype=float32), 'eval/episode_reward_std': Array(0.17716828, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0435383, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26264277, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130615, dtype=float32), 'eval/episode_x_position_std': Array(0.08855473, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0435383, dtype=float32), 'eval/episode_y_position_std': Array(0.00597459, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01726155, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.610276460647583, 'eval/sps': 6210.494082619316, 'num_steps': 2647040}
{'eval/walltime': 10829.967492818832, 'training/sps': 126.80506153446252, 'training/walltime': 20929.66624855995, 'training/entropy_loss': Array(0.10634965, dtype=float32), 'training/policy_loss': Array(0.26813668, dtype=float32), 'training/total_loss': Array(0.37448633, dtype=float32), 'training/v_loss': Array(2.3071332e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.00862, dtype=float32), 'eval/episode_forward_reward': Array(-0.03735519, dtype=float32), 'eval/episode_reward': Array(-2.0342286, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03735519, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957526, dtype=float32), 'eval/episode_train_reward': Array(-0.00112066, dtype=float32), 'eval/episode_x_position': Array(1.0067339, dtype=float32), 'eval/episode_x_velocity': Array(-0.03735519, dtype=float32), 'eval/episode_y_position': Array(4.8860384e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00210119, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00551495, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04279422, dtype=float32), 'eval/episode_reward_std': Array(0.04428719, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04279422, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01599516, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128383, dtype=float32), 'eval/episode_x_position_std': Array(0.00549236, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04279422, dtype=float32), 'eval/episode_y_position_std': Array(0.00585473, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01319343, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.74313712120056, 'eval/sps': 6170.715608353057, 'num_steps': 2652160}
{'eval/walltime': 10850.629477739334, 'training/sps': 127.26018463753368, 'training/walltime': 20969.89878487587, 'training/entropy_loss': Array(0.10441961, dtype=float32), 'training/policy_loss': Array(0.27186432, dtype=float32), 'training/total_loss': Array(0.37628394, dtype=float32), 'training/v_loss': Array(1.6023549e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092618, dtype=float32), 'eval/episode_forward_reward': Array(-0.04208057, dtype=float32), 'eval/episode_reward': Array(-2.0407314, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04208057, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973884, dtype=float32), 'eval/episode_train_reward': Array(-0.00126242, dtype=float32), 'eval/episode_x_position': Array(1.0074033, dtype=float32), 'eval/episode_x_velocity': Array(-0.04208057, dtype=float32), 'eval/episode_y_position': Array(0.00026151, dtype=float32), 'eval/episode_y_velocity': Array(-0.00239191, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0062015, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04432672, dtype=float32), 'eval/episode_reward_std': Array(0.04813799, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04432672, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01204945, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013298, dtype=float32), 'eval/episode_x_position_std': Array(0.00615483, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04432672, dtype=float32), 'eval/episode_y_position_std': Array(0.0061491, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01020413, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66198492050171, 'eval/sps': 6194.951767339298, 'num_steps': 2657280}
{'eval/walltime': 10871.31966471672, 'training/sps': 127.44102898171712, 'training/walltime': 21010.074229478836, 'training/entropy_loss': Array(0.10187568, dtype=float32), 'training/policy_loss': Array(0.26957732, dtype=float32), 'training/total_loss': Array(0.37145308, dtype=float32), 'training/v_loss': Array(4.0674713e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088184, dtype=float32), 'eval/episode_forward_reward': Array(-0.04028583, dtype=float32), 'eval/episode_reward': Array(-2.0383663, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04028583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996872, dtype=float32), 'eval/episode_train_reward': Array(-0.00120857, dtype=float32), 'eval/episode_x_position': Array(1.0069339, dtype=float32), 'eval/episode_x_velocity': Array(-0.04028583, dtype=float32), 'eval/episode_y_position': Array(-0.00028185, dtype=float32), 'eval/episode_y_velocity': Array(-0.00384815, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600666, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04452614, dtype=float32), 'eval/episode_reward_std': Array(0.04808874, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04452614, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01300101, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133578, dtype=float32), 'eval/episode_x_position_std': Array(0.0060007, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04452614, dtype=float32), 'eval/episode_y_position_std': Array(0.00630633, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01135952, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.690186977386475, 'eval/sps': 6186.507649249315, 'num_steps': 2662400}
{'eval/walltime': 10891.950022935867, 'training/sps': 127.3999416227962, 'training/walltime': 21050.262630939484, 'training/entropy_loss': Array(0.10543548, dtype=float32), 'training/policy_loss': Array(0.2685007, dtype=float32), 'training/total_loss': Array(0.37393618, dtype=float32), 'training/v_loss': Array(2.050928e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017513, dtype=float32), 'eval/episode_forward_reward': Array(-0.03298753, dtype=float32), 'eval/episode_reward': Array(-2.0451114, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03298753, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0189466, dtype=float32), 'eval/episode_train_reward': Array(-0.00098963, dtype=float32), 'eval/episode_x_position': Array(1.0155764, dtype=float32), 'eval/episode_x_velocity': Array(-0.03298753, dtype=float32), 'eval/episode_y_position': Array(-0.00013867, dtype=float32), 'eval/episode_y_velocity': Array(-0.0018969, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08869245, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04178255, dtype=float32), 'eval/episode_reward_std': Array(0.17890178, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04178255, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26513863, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125348, dtype=float32), 'eval/episode_x_position_std': Array(0.08841999, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04178255, dtype=float32), 'eval/episode_y_position_std': Array(0.00608317, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00918204, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.63035821914673, 'eval/sps': 6204.4487371627465, 'num_steps': 2667520}
{'eval/walltime': 10912.648622274399, 'training/sps': 127.22101807459207, 'training/walltime': 21090.507553339005, 'training/entropy_loss': Array(0.10323173, dtype=float32), 'training/policy_loss': Array(0.26812243, dtype=float32), 'training/total_loss': Array(0.37135416, dtype=float32), 'training/v_loss': Array(2.5056995e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091794, dtype=float32), 'eval/episode_forward_reward': Array(-0.04643504, dtype=float32), 'eval/episode_reward': Array(-2.0422413, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04643504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9944131, dtype=float32), 'eval/episode_train_reward': Array(-0.00139305, dtype=float32), 'eval/episode_x_position': Array(1.0073723, dtype=float32), 'eval/episode_x_velocity': Array(-0.04643504, dtype=float32), 'eval/episode_y_position': Array(0.00024762, dtype=float32), 'eval/episode_y_velocity': Array(-0.00324314, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00540503, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04526446, dtype=float32), 'eval/episode_reward_std': Array(0.0545912, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04526446, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01963896, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135793, dtype=float32), 'eval/episode_x_position_std': Array(0.00541181, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04526446, dtype=float32), 'eval/episode_y_position_std': Array(0.00570415, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01410295, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.698599338531494, 'eval/sps': 6183.993317930528, 'num_steps': 2672640}
{'eval/walltime': 10933.273440122604, 'training/sps': 127.59047839462043, 'training/walltime': 21130.635939598083, 'training/entropy_loss': Array(0.10450622, dtype=float32), 'training/policy_loss': Array(0.26996338, dtype=float32), 'training/total_loss': Array(0.37446964, dtype=float32), 'training/v_loss': Array(2.2102792e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093002, dtype=float32), 'eval/episode_forward_reward': Array(-0.03537381, dtype=float32), 'eval/episode_reward': Array(-2.034575, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03537381, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981396, dtype=float32), 'eval/episode_train_reward': Array(-0.00106121, dtype=float32), 'eval/episode_x_position': Array(1.0074347, dtype=float32), 'eval/episode_x_velocity': Array(-0.03537381, dtype=float32), 'eval/episode_y_position': Array(5.0118084e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00258676, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575966, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04244415, dtype=float32), 'eval/episode_reward_std': Array(0.04404144, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04244415, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00909848, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127332, dtype=float32), 'eval/episode_x_position_std': Array(0.00576498, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04244415, dtype=float32), 'eval/episode_y_position_std': Array(0.00578442, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01392498, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.624817848205566, 'eval/sps': 6206.115416002885, 'num_steps': 2677760}
{'eval/walltime': 10953.977489709854, 'training/sps': 127.22469313185165, 'training/walltime': 21170.879699468613, 'training/entropy_loss': Array(0.10236749, dtype=float32), 'training/policy_loss': Array(0.27254087, dtype=float32), 'training/total_loss': Array(0.37490833, dtype=float32), 'training/v_loss': Array(5.059549e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0102608, dtype=float32), 'eval/episode_forward_reward': Array(-0.03934939, dtype=float32), 'eval/episode_reward': Array(-2.036439, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03934939, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959092, dtype=float32), 'eval/episode_train_reward': Array(-0.00118048, dtype=float32), 'eval/episode_x_position': Array(1.0084251, dtype=float32), 'eval/episode_x_velocity': Array(-0.03934939, dtype=float32), 'eval/episode_y_position': Array(0.00078598, dtype=float32), 'eval/episode_y_velocity': Array(-0.00292462, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557952, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04223958, dtype=float32), 'eval/episode_reward_std': Array(0.04502999, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04223958, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0148847, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126719, dtype=float32), 'eval/episode_x_position_std': Array(0.00552637, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04223958, dtype=float32), 'eval/episode_y_position_std': Array(0.00566195, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01644455, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.704049587249756, 'eval/sps': 6182.365409268855, 'num_steps': 2682880}
{'eval/walltime': 10974.615200042725, 'training/sps': 127.2765554746307, 'training/walltime': 21211.10706090927, 'training/entropy_loss': Array(0.0975549, dtype=float32), 'training/policy_loss': Array(0.26892525, dtype=float32), 'training/total_loss': Array(0.3664801, dtype=float32), 'training/v_loss': Array(5.925248e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0168324, dtype=float32), 'eval/episode_forward_reward': Array(-0.04090245, dtype=float32), 'eval/episode_reward': Array(-2.0549912, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04090245, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.020674, dtype=float32), 'eval/episode_train_reward': Array(-0.00122707, dtype=float32), 'eval/episode_x_position': Array(1.0149527, dtype=float32), 'eval/episode_x_velocity': Array(-0.04090245, dtype=float32), 'eval/episode_y_position': Array(-0.00043653, dtype=float32), 'eval/episode_y_velocity': Array(-0.0027851, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09041768, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04417352, dtype=float32), 'eval/episode_reward_std': Array(0.17863934, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04417352, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26460692, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132521, dtype=float32), 'eval/episode_x_position_std': Array(0.09014919, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04417352, dtype=float32), 'eval/episode_y_position_std': Array(0.00542842, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01545502, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.637710332870483, 'eval/sps': 6202.238423519756, 'num_steps': 2688000}
{'eval/walltime': 10995.309086561203, 'training/sps': 127.38136291657864, 'training/walltime': 21251.301323890686, 'training/entropy_loss': Array(0.09679333, dtype=float32), 'training/policy_loss': Array(-0.04312255, dtype=float32), 'training/total_loss': Array(0.05367079, dtype=float32), 'training/v_loss': Array(6.564356e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095298, dtype=float32), 'eval/episode_forward_reward': Array(-0.03693214, dtype=float32), 'eval/episode_reward': Array(-2.0329049, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03693214, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994865, dtype=float32), 'eval/episode_train_reward': Array(-0.00110796, dtype=float32), 'eval/episode_x_position': Array(1.0076379, dtype=float32), 'eval/episode_x_velocity': Array(-0.03693214, dtype=float32), 'eval/episode_y_position': Array(-0.00076252, dtype=float32), 'eval/episode_y_velocity': Array(-0.00189511, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594032, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04383012, dtype=float32), 'eval/episode_reward_std': Array(0.04826228, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04383012, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0172038, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013149, dtype=float32), 'eval/episode_x_position_std': Array(0.00593798, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04383012, dtype=float32), 'eval/episode_y_position_std': Array(0.00523662, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0097195, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.693886518478394, 'eval/sps': 6185.401658876583, 'num_steps': 2693120}
{'eval/walltime': 11015.933851718903, 'training/sps': 127.28998111986245, 'training/walltime': 21291.52444243431, 'training/entropy_loss': Array(0.10080649, dtype=float32), 'training/policy_loss': Array(0.18902795, dtype=float32), 'training/total_loss': Array(0.28983444, dtype=float32), 'training/v_loss': Array(8.2172025e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087776, dtype=float32), 'eval/episode_forward_reward': Array(-0.0411054, dtype=float32), 'eval/episode_reward': Array(-2.0387552, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0411054, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964166, dtype=float32), 'eval/episode_train_reward': Array(-0.00123316, dtype=float32), 'eval/episode_x_position': Array(1.0069308, dtype=float32), 'eval/episode_x_velocity': Array(-0.0411054, dtype=float32), 'eval/episode_y_position': Array(-0.00020661, dtype=float32), 'eval/episode_y_velocity': Array(-0.00179499, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585161, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04347081, dtype=float32), 'eval/episode_reward_std': Array(0.04489745, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04347081, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01355057, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130412, dtype=float32), 'eval/episode_x_position_std': Array(0.0058392, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04347081, dtype=float32), 'eval/episode_y_position_std': Array(0.00616928, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01236499, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.624765157699585, 'eval/sps': 6206.131270891847, 'num_steps': 2698240}
{'eval/walltime': 11036.638707399368, 'training/sps': 127.5295969052408, 'training/walltime': 21331.67198562622, 'training/entropy_loss': Array(0.10249171, dtype=float32), 'training/policy_loss': Array(0.2578661, dtype=float32), 'training/total_loss': Array(0.36035782, dtype=float32), 'training/v_loss': Array(4.5675455e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009932, dtype=float32), 'eval/episode_forward_reward': Array(-0.04471272, dtype=float32), 'eval/episode_reward': Array(-2.0410566, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04471272, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9950027, dtype=float32), 'eval/episode_train_reward': Array(-0.00134138, dtype=float32), 'eval/episode_x_position': Array(1.0081105, dtype=float32), 'eval/episode_x_velocity': Array(-0.04471272, dtype=float32), 'eval/episode_y_position': Array(0.00032931, dtype=float32), 'eval/episode_y_velocity': Array(-0.00218723, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0061935, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04432343, dtype=float32), 'eval/episode_reward_std': Array(0.04944465, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04432343, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01743408, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013297, dtype=float32), 'eval/episode_x_position_std': Array(0.00615162, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04432343, dtype=float32), 'eval/episode_y_position_std': Array(0.00573737, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01589398, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7048556804657, 'eval/sps': 6182.124713902907, 'num_steps': 2703360}
{'eval/walltime': 11057.298872232437, 'training/sps': 127.27119234540713, 'training/walltime': 21371.901042222977, 'training/entropy_loss': Array(0.1035732, dtype=float32), 'training/policy_loss': Array(0.2677564, dtype=float32), 'training/total_loss': Array(0.3713296, dtype=float32), 'training/v_loss': Array(6.4371655e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0103979, dtype=float32), 'eval/episode_forward_reward': Array(-0.03543271, dtype=float32), 'eval/episode_reward': Array(-2.033916, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03543271, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974203, dtype=float32), 'eval/episode_train_reward': Array(-0.00106298, dtype=float32), 'eval/episode_x_position': Array(1.0084932, dtype=float32), 'eval/episode_x_velocity': Array(-0.03543271, dtype=float32), 'eval/episode_y_position': Array(0.00041074, dtype=float32), 'eval/episode_y_velocity': Array(-0.00343579, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585032, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04168222, dtype=float32), 'eval/episode_reward_std': Array(0.0424977, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04168222, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01146044, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125047, dtype=float32), 'eval/episode_x_position_std': Array(0.00582467, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04168222, dtype=float32), 'eval/episode_y_position_std': Array(0.00598813, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01014696, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.660164833068848, 'eval/sps': 6195.49752067428, 'num_steps': 2708480}
{'eval/walltime': 11077.993720531464, 'training/sps': 127.33229842466245, 'training/walltime': 21412.11079311371, 'training/entropy_loss': Array(0.10595421, dtype=float32), 'training/policy_loss': Array(0.2699238, dtype=float32), 'training/total_loss': Array(0.37587798, dtype=float32), 'training/v_loss': Array(1.1179513e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008992, dtype=float32), 'eval/episode_forward_reward': Array(-0.03610388, dtype=float32), 'eval/episode_reward': Array(-2.0331442, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03610388, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959574, dtype=float32), 'eval/episode_train_reward': Array(-0.00108312, dtype=float32), 'eval/episode_x_position': Array(1.0071303, dtype=float32), 'eval/episode_x_velocity': Array(-0.03610388, dtype=float32), 'eval/episode_y_position': Array(0.00038592, dtype=float32), 'eval/episode_y_velocity': Array(-0.00229376, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00527917, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0423868, dtype=float32), 'eval/episode_reward_std': Array(0.04482859, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0423868, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01701109, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012716, dtype=float32), 'eval/episode_x_position_std': Array(0.0052531, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0423868, dtype=float32), 'eval/episode_y_position_std': Array(0.00536247, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01031649, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69484829902649, 'eval/sps': 6185.114196078513, 'num_steps': 2713600}
{'eval/walltime': 11098.635085344315, 'training/sps': 127.61117011212517, 'training/walltime': 21452.232672691345, 'training/entropy_loss': Array(0.10320373, dtype=float32), 'training/policy_loss': Array(0.2701912, dtype=float32), 'training/total_loss': Array(0.37339494, dtype=float32), 'training/v_loss': Array(1.1104176e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0082788, dtype=float32), 'eval/episode_forward_reward': Array(-0.03951253, dtype=float32), 'eval/episode_reward': Array(-2.0334327, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03951253, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.992735, dtype=float32), 'eval/episode_train_reward': Array(-0.00118538, dtype=float32), 'eval/episode_x_position': Array(1.0063701, dtype=float32), 'eval/episode_x_velocity': Array(-0.03951253, dtype=float32), 'eval/episode_y_position': Array(1.849285e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00382098, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584432, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04349125, dtype=float32), 'eval/episode_reward_std': Array(0.05199969, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04349125, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02396631, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130474, dtype=float32), 'eval/episode_x_position_std': Array(0.00581249, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04349125, dtype=float32), 'eval/episode_y_position_std': Array(0.00582518, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01379214, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.641364812850952, 'eval/sps': 6201.1403393398405, 'num_steps': 2718720}
{'eval/walltime': 11119.337735176086, 'training/sps': 127.26195313366738, 'training/walltime': 21492.464649915695, 'training/entropy_loss': Array(0.10457347, dtype=float32), 'training/policy_loss': Array(0.26752108, dtype=float32), 'training/total_loss': Array(0.37209457, dtype=float32), 'training/v_loss': Array(2.451963e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089383, dtype=float32), 'eval/episode_forward_reward': Array(-0.03779214, dtype=float32), 'eval/episode_reward': Array(-2.0354836, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03779214, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965577, dtype=float32), 'eval/episode_train_reward': Array(-0.00113376, dtype=float32), 'eval/episode_x_position': Array(1.0070376, dtype=float32), 'eval/episode_x_velocity': Array(-0.03779214, dtype=float32), 'eval/episode_y_position': Array(0.00047234, dtype=float32), 'eval/episode_y_velocity': Array(-0.00320619, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00553518, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04341557, dtype=float32), 'eval/episode_reward_std': Array(0.04786863, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04341557, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01594587, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130247, dtype=float32), 'eval/episode_x_position_std': Array(0.00549543, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04341557, dtype=float32), 'eval/episode_y_position_std': Array(0.00605414, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01427945, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70264983177185, 'eval/sps': 6182.783413723278, 'num_steps': 2723840}
{'eval/walltime': 11140.004776000977, 'training/sps': 127.26048177161498, 'training/walltime': 21532.697092294693, 'training/entropy_loss': Array(0.10276346, dtype=float32), 'training/policy_loss': Array(0.27102628, dtype=float32), 'training/total_loss': Array(0.37378973, dtype=float32), 'training/v_loss': Array(4.41736e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0175579, dtype=float32), 'eval/episode_forward_reward': Array(-0.03665725, dtype=float32), 'eval/episode_reward': Array(-2.048727, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03665725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0187826, dtype=float32), 'eval/episode_train_reward': Array(-0.00109972, dtype=float32), 'eval/episode_x_position': Array(1.0156424, dtype=float32), 'eval/episode_x_velocity': Array(-0.03665725, dtype=float32), 'eval/episode_y_position': Array(0.00049136, dtype=float32), 'eval/episode_y_velocity': Array(-0.00324333, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08882502, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04149452, dtype=float32), 'eval/episode_reward_std': Array(0.1808341, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04149452, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2650745, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124484, dtype=float32), 'eval/episode_x_position_std': Array(0.08856141, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04149452, dtype=float32), 'eval/episode_y_position_std': Array(0.00577719, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01121913, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.667040824890137, 'eval/sps': 6193.436258462533, 'num_steps': 2728960}
{'eval/walltime': 11160.721175670624, 'training/sps': 127.04514501223707, 'training/walltime': 21572.997727155685, 'training/entropy_loss': Array(0.10145132, dtype=float32), 'training/policy_loss': Array(0.26739436, dtype=float32), 'training/total_loss': Array(0.36884573, dtype=float32), 'training/v_loss': Array(1.766168e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093911, dtype=float32), 'eval/episode_forward_reward': Array(-0.03968878, dtype=float32), 'eval/episode_reward': Array(-2.040091, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03968878, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9992118, dtype=float32), 'eval/episode_train_reward': Array(-0.00119066, dtype=float32), 'eval/episode_x_position': Array(1.0075076, dtype=float32), 'eval/episode_x_velocity': Array(-0.03968878, dtype=float32), 'eval/episode_y_position': Array(-0.00061949, dtype=float32), 'eval/episode_y_velocity': Array(-0.00022293, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00541344, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0448039, dtype=float32), 'eval/episode_reward_std': Array(0.04588941, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0448039, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00397626, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134412, dtype=float32), 'eval/episode_x_position_std': Array(0.00541487, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0448039, dtype=float32), 'eval/episode_y_position_std': Array(0.00563023, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01359069, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.716399669647217, 'eval/sps': 6178.679791910953, 'num_steps': 2734080}
{'eval/walltime': 11181.39126420021, 'training/sps': 127.01903306129799, 'training/walltime': 21613.306646823883, 'training/entropy_loss': Array(0.10426518, dtype=float32), 'training/policy_loss': Array(0.26789635, dtype=float32), 'training/total_loss': Array(0.37216154, dtype=float32), 'training/v_loss': Array(5.3803095e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0247923, dtype=float32), 'eval/episode_forward_reward': Array(-0.04067823, dtype=float32), 'eval/episode_reward': Array(-2.067816, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04067823, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0415423, dtype=float32), 'eval/episode_train_reward': Array(-0.00122035, dtype=float32), 'eval/episode_x_position': Array(1.0228844, dtype=float32), 'eval/episode_x_velocity': Array(-0.04067823, dtype=float32), 'eval/episode_y_position': Array(0.00056042, dtype=float32), 'eval/episode_y_velocity': Array(-0.0034176, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12446316, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04303393, dtype=float32), 'eval/episode_reward_std': Array(0.24967359, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04303393, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3730553, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129102, dtype=float32), 'eval/episode_x_position_std': Array(0.12408205, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04303393, dtype=float32), 'eval/episode_y_position_std': Array(0.0055621, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01355354, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.670088529586792, 'eval/sps': 6192.523066206664, 'num_steps': 2739200}
{'eval/walltime': 11202.104016780853, 'training/sps': 127.11724773335347, 'training/walltime': 21653.58442258835, 'training/entropy_loss': Array(0.10571821, dtype=float32), 'training/policy_loss': Array(0.269136, dtype=float32), 'training/total_loss': Array(0.3748542, dtype=float32), 'training/v_loss': Array(3.0807884e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086054, dtype=float32), 'eval/episode_forward_reward': Array(-0.04183253, dtype=float32), 'eval/episode_reward': Array(-2.0408916, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04183253, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978042, dtype=float32), 'eval/episode_train_reward': Array(-0.00125498, dtype=float32), 'eval/episode_x_position': Array(1.0067408, dtype=float32), 'eval/episode_x_velocity': Array(-0.04183253, dtype=float32), 'eval/episode_y_position': Array(0.00029693, dtype=float32), 'eval/episode_y_velocity': Array(-0.00323061, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579348, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04192949, dtype=float32), 'eval/episode_reward_std': Array(0.0466372, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04192949, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01263197, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125788, dtype=float32), 'eval/episode_x_position_std': Array(0.00573276, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04192949, dtype=float32), 'eval/episode_y_position_std': Array(0.00546614, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0125827, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7127525806427, 'eval/sps': 6179.767730128907, 'num_steps': 2744320}
{'eval/walltime': 11222.771168470383, 'training/sps': 126.73171341135365, 'training/walltime': 21693.984728574753, 'training/entropy_loss': Array(0.10518024, dtype=float32), 'training/policy_loss': Array(0.27351695, dtype=float32), 'training/total_loss': Array(0.37869722, dtype=float32), 'training/v_loss': Array(1.5678188e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167162, dtype=float32), 'eval/episode_forward_reward': Array(-0.0422094, dtype=float32), 'eval/episode_reward': Array(-2.0544534, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0422094, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0187902, dtype=float32), 'eval/episode_train_reward': Array(-0.00126628, dtype=float32), 'eval/episode_x_position': Array(1.0148139, dtype=float32), 'eval/episode_x_velocity': Array(-0.0422094, dtype=float32), 'eval/episode_y_position': Array(0.00042582, dtype=float32), 'eval/episode_y_velocity': Array(-0.00261792, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0902907, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04716571, dtype=float32), 'eval/episode_reward_std': Array(0.17968072, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04716571, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26500097, dtype=float32), 'eval/episode_train_reward_std': Array(0.00141497, dtype=float32), 'eval/episode_x_position_std': Array(0.09002524, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04716571, dtype=float32), 'eval/episode_y_position_std': Array(0.00590842, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0132454, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.66715168952942, 'eval/sps': 6193.403035061117, 'num_steps': 2749440}
{'eval/walltime': 11243.485733270645, 'training/sps': 127.24540811524598, 'training/walltime': 21734.221936941147, 'training/entropy_loss': Array(0.10348053, dtype=float32), 'training/policy_loss': Array(0.27202892, dtype=float32), 'training/total_loss': Array(0.37550944, dtype=float32), 'training/v_loss': Array(1.054166e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0174634, dtype=float32), 'eval/episode_forward_reward': Array(-0.03400639, dtype=float32), 'eval/episode_reward': Array(-2.0475416, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03400639, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0203276, dtype=float32), 'eval/episode_train_reward': Array(-0.00102019, dtype=float32), 'eval/episode_x_position': Array(1.0155346, dtype=float32), 'eval/episode_x_velocity': Array(-0.03400639, dtype=float32), 'eval/episode_y_position': Array(0.00110867, dtype=float32), 'eval/episode_y_velocity': Array(-0.0011242, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08786464, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04301096, dtype=float32), 'eval/episode_reward_std': Array(0.17898683, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04301096, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2638839, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129033, dtype=float32), 'eval/episode_x_position_std': Array(0.08759665, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04301096, dtype=float32), 'eval/episode_y_position_std': Array(0.00564929, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01278266, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.71456480026245, 'eval/sps': 6179.227091383463, 'num_steps': 2754560}
{'eval/walltime': 11264.14395570755, 'training/sps': 127.0850599476776, 'training/walltime': 21774.509914159775, 'training/entropy_loss': Array(0.10321004, dtype=float32), 'training/policy_loss': Array(0.26712006, dtype=float32), 'training/total_loss': Array(0.37033013, dtype=float32), 'training/v_loss': Array(5.6384826e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087929, dtype=float32), 'eval/episode_forward_reward': Array(-0.0366595, dtype=float32), 'eval/episode_reward': Array(-2.0329797, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0366595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952204, dtype=float32), 'eval/episode_train_reward': Array(-0.00109978, dtype=float32), 'eval/episode_x_position': Array(1.006893, dtype=float32), 'eval/episode_x_velocity': Array(-0.0366595, dtype=float32), 'eval/episode_y_position': Array(0.00013116, dtype=float32), 'eval/episode_y_velocity': Array(-0.00338513, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00539017, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0439397, dtype=float32), 'eval/episode_reward_std': Array(0.05179645, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0439397, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02409319, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131819, dtype=float32), 'eval/episode_x_position_std': Array(0.00542068, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0439397, dtype=float32), 'eval/episode_y_position_std': Array(0.00592649, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01288081, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.658222436904907, 'eval/sps': 6196.080054367807, 'num_steps': 2759680}
{'eval/walltime': 11284.84261250496, 'training/sps': 127.12567199748676, 'training/walltime': 21814.785020828247, 'training/entropy_loss': Array(0.10432319, dtype=float32), 'training/policy_loss': Array(0.26667875, dtype=float32), 'training/total_loss': Array(0.37100193, dtype=float32), 'training/v_loss': Array(1.0167915e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094244, dtype=float32), 'eval/episode_forward_reward': Array(-0.04007644, dtype=float32), 'eval/episode_reward': Array(-2.0352798, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04007644, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994001, dtype=float32), 'eval/episode_train_reward': Array(-0.00120229, dtype=float32), 'eval/episode_x_position': Array(1.0075465, dtype=float32), 'eval/episode_x_velocity': Array(-0.04007644, dtype=float32), 'eval/episode_y_position': Array(-0.00044153, dtype=float32), 'eval/episode_y_velocity': Array(-0.00199675, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577232, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04401878, dtype=float32), 'eval/episode_reward_std': Array(0.0510022, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04401878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01785863, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132056, dtype=float32), 'eval/episode_x_position_std': Array(0.00573274, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04401878, dtype=float32), 'eval/episode_y_position_std': Array(0.00559502, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0112959, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.698656797409058, 'eval/sps': 6183.976151342455, 'num_steps': 2764800}
{'eval/walltime': 11305.506551980972, 'training/sps': 127.10333264753238, 'training/walltime': 21855.067206144333, 'training/entropy_loss': Array(0.10626334, dtype=float32), 'training/policy_loss': Array(0.2663865, dtype=float32), 'training/total_loss': Array(0.37264985, dtype=float32), 'training/v_loss': Array(1.5438828e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092938, dtype=float32), 'eval/episode_forward_reward': Array(-0.0433637, dtype=float32), 'eval/episode_reward': Array(-2.0407505, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0433637, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960861, dtype=float32), 'eval/episode_train_reward': Array(-0.00130091, dtype=float32), 'eval/episode_x_position': Array(1.007437, dtype=float32), 'eval/episode_x_velocity': Array(-0.0433637, dtype=float32), 'eval/episode_y_position': Array(7.2341645e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00099683, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00547665, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04394473, dtype=float32), 'eval/episode_reward_std': Array(0.04718188, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04394473, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01562716, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131834, dtype=float32), 'eval/episode_x_position_std': Array(0.00541833, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04394473, dtype=float32), 'eval/episode_y_position_std': Array(0.00568822, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01212568, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.663939476013184, 'eval/sps': 6194.365800799171, 'num_steps': 2769920}
{'eval/walltime': 11326.246355295181, 'training/sps': 127.14843927462421, 'training/walltime': 21895.335101127625, 'training/entropy_loss': Array(0.10645096, dtype=float32), 'training/policy_loss': Array(0.27023423, dtype=float32), 'training/total_loss': Array(0.3766852, dtype=float32), 'training/v_loss': Array(1.2477037e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087543, dtype=float32), 'eval/episode_forward_reward': Array(-0.04211433, dtype=float32), 'eval/episode_reward': Array(-2.0367844, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04211433, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9934065, dtype=float32), 'eval/episode_train_reward': Array(-0.00126343, dtype=float32), 'eval/episode_x_position': Array(1.0068698, dtype=float32), 'eval/episode_x_velocity': Array(-0.04211433, dtype=float32), 'eval/episode_y_position': Array(-6.7322224e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00181677, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584971, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04620937, dtype=float32), 'eval/episode_reward_std': Array(0.05493834, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04620937, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02229413, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138628, dtype=float32), 'eval/episode_x_position_std': Array(0.0058762, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04620937, dtype=float32), 'eval/episode_y_position_std': Array(0.00584652, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01451162, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.739803314208984, 'eval/sps': 6171.70751625722, 'num_steps': 2775040}
{'eval/walltime': 11346.867152452469, 'training/sps': 127.41806230854178, 'training/walltime': 21935.517787218094, 'training/entropy_loss': Array(0.10537277, dtype=float32), 'training/policy_loss': Array(0.26817524, dtype=float32), 'training/total_loss': Array(0.37354797, dtype=float32), 'training/v_loss': Array(3.336512e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008968, dtype=float32), 'eval/episode_forward_reward': Array(-0.03543621, dtype=float32), 'eval/episode_reward': Array(-2.0338442, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03543621, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997345, dtype=float32), 'eval/episode_train_reward': Array(-0.00106309, dtype=float32), 'eval/episode_x_position': Array(1.0070744, dtype=float32), 'eval/episode_x_velocity': Array(-0.03543621, dtype=float32), 'eval/episode_y_position': Array(6.6472567e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00290006, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00620802, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0415097, dtype=float32), 'eval/episode_reward_std': Array(0.04581816, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0415097, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01290973, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124529, dtype=float32), 'eval/episode_x_position_std': Array(0.00618562, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0415097, dtype=float32), 'eval/episode_y_position_std': Array(0.00584528, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01418073, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.620797157287598, 'eval/sps': 6207.325498799328, 'num_steps': 2780160}
{'eval/walltime': 11367.59270453453, 'training/sps': 127.33466011031173, 'training/walltime': 21975.72679233551, 'training/entropy_loss': Array(0.10412373, dtype=float32), 'training/policy_loss': Array(0.26829937, dtype=float32), 'training/total_loss': Array(0.3724231, dtype=float32), 'training/v_loss': Array(1.7907028e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092173, dtype=float32), 'eval/episode_forward_reward': Array(-0.04462471, dtype=float32), 'eval/episode_reward': Array(-2.0427687, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04462471, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968052, dtype=float32), 'eval/episode_train_reward': Array(-0.00133874, dtype=float32), 'eval/episode_x_position': Array(1.0073749, dtype=float32), 'eval/episode_x_velocity': Array(-0.04462471, dtype=float32), 'eval/episode_y_position': Array(0.00034246, dtype=float32), 'eval/episode_y_velocity': Array(-0.00118288, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0061266, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04728553, dtype=float32), 'eval/episode_reward_std': Array(0.05091401, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04728553, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01379336, dtype=float32), 'eval/episode_train_reward_std': Array(0.00141857, dtype=float32), 'eval/episode_x_position_std': Array(0.0060951, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04728553, dtype=float32), 'eval/episode_y_position_std': Array(0.00579891, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01222796, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.725552082061768, 'eval/sps': 6175.951284346517, 'num_steps': 2785280}
{'eval/walltime': 11388.21266579628, 'training/sps': 127.28788213869146, 'training/walltime': 22015.950574159622, 'training/entropy_loss': Array(0.10373144, dtype=float32), 'training/policy_loss': Array(0.26927578, dtype=float32), 'training/total_loss': Array(0.37300724, dtype=float32), 'training/v_loss': Array(3.351355e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092262, dtype=float32), 'eval/episode_forward_reward': Array(-0.03268345, dtype=float32), 'eval/episode_reward': Array(-2.0292003, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03268345, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955363, dtype=float32), 'eval/episode_train_reward': Array(-0.0009805, dtype=float32), 'eval/episode_x_position': Array(1.0072746, dtype=float32), 'eval/episode_x_velocity': Array(-0.03268345, dtype=float32), 'eval/episode_y_position': Array(0.00035622, dtype=float32), 'eval/episode_y_velocity': Array(-0.00182963, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579464, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04229463, dtype=float32), 'eval/episode_reward_std': Array(0.04627103, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04229463, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01619356, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126884, dtype=float32), 'eval/episode_x_position_std': Array(0.00577817, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04229463, dtype=float32), 'eval/episode_y_position_std': Array(0.00562565, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01216089, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.619961261749268, 'eval/sps': 6207.577132428681, 'num_steps': 2790400}
{'eval/walltime': 11408.884759902954, 'training/sps': 127.35735729484627, 'training/walltime': 22056.152413368225, 'training/entropy_loss': Array(0.10385162, dtype=float32), 'training/policy_loss': Array(0.2671218, dtype=float32), 'training/total_loss': Array(0.3709734, dtype=float32), 'training/v_loss': Array(2.3477607e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008518, dtype=float32), 'eval/episode_forward_reward': Array(-0.03588992, dtype=float32), 'eval/episode_reward': Array(-2.031728, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03588992, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947615, dtype=float32), 'eval/episode_train_reward': Array(-0.0010767, dtype=float32), 'eval/episode_x_position': Array(1.0066255, dtype=float32), 'eval/episode_x_velocity': Array(-0.03588992, dtype=float32), 'eval/episode_y_position': Array(0.00026065, dtype=float32), 'eval/episode_y_velocity': Array(-0.00163102, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585408, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04232951, dtype=float32), 'eval/episode_reward_std': Array(0.04618311, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04232951, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01793017, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126989, dtype=float32), 'eval/episode_x_position_std': Array(0.00581063, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04232951, dtype=float32), 'eval/episode_y_position_std': Array(0.00562128, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01287236, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672094106674194, 'eval/sps': 6191.922276450643, 'num_steps': 2795520}
{'eval/walltime': 11429.532456159592, 'training/sps': 127.28364741723776, 'training/walltime': 22096.37753343582, 'training/entropy_loss': Array(0.10848638, dtype=float32), 'training/policy_loss': Array(0.27028978, dtype=float32), 'training/total_loss': Array(0.37877613, dtype=float32), 'training/v_loss': Array(5.813183e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094079, dtype=float32), 'eval/episode_forward_reward': Array(-0.03865144, dtype=float32), 'eval/episode_reward': Array(-2.036645, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03865144, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996834, dtype=float32), 'eval/episode_train_reward': Array(-0.00115954, dtype=float32), 'eval/episode_x_position': Array(1.0075436, dtype=float32), 'eval/episode_x_velocity': Array(-0.03865144, dtype=float32), 'eval/episode_y_position': Array(0.00018137, dtype=float32), 'eval/episode_y_velocity': Array(-0.00221503, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00546002, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04112116, dtype=float32), 'eval/episode_reward_std': Array(0.04469128, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04112116, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01353324, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123363, dtype=float32), 'eval/episode_x_position_std': Array(0.00546837, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04112116, dtype=float32), 'eval/episode_y_position_std': Array(0.00572961, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0138171, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647696256637573, 'eval/sps': 6199.238811392922, 'num_steps': 2800640}
{'eval/walltime': 11450.247025489807, 'training/sps': 127.1252957224762, 'training/walltime': 22136.652759313583, 'training/entropy_loss': Array(0.10579597, dtype=float32), 'training/policy_loss': Array(0.2713446, dtype=float32), 'training/total_loss': Array(0.37714058, dtype=float32), 'training/v_loss': Array(6.737003e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171118, dtype=float32), 'eval/episode_forward_reward': Array(-0.03466825, dtype=float32), 'eval/episode_reward': Array(-2.0473604, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03466825, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.019465, dtype=float32), 'eval/episode_train_reward': Array(-0.00104005, dtype=float32), 'eval/episode_x_position': Array(1.0151939, dtype=float32), 'eval/episode_x_velocity': Array(-0.03466825, dtype=float32), 'eval/episode_y_position': Array(-0.00020049, dtype=float32), 'eval/episode_y_velocity': Array(0.00010675, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08865014, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04508171, dtype=float32), 'eval/episode_reward_std': Array(0.17909865, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04508171, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26500213, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135245, dtype=float32), 'eval/episode_x_position_std': Array(0.08838435, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04508171, dtype=float32), 'eval/episode_y_position_std': Array(0.00534269, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01523332, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.714569330215454, 'eval/sps': 6179.225740082942, 'num_steps': 2805760}
{'eval/walltime': 11470.936575651169, 'training/sps': 127.07131732728269, 'training/walltime': 22176.945093631744, 'training/entropy_loss': Array(0.10457656, dtype=float32), 'training/policy_loss': Array(0.26838505, dtype=float32), 'training/total_loss': Array(0.3729616, dtype=float32), 'training/v_loss': Array(5.0758344e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091863, dtype=float32), 'eval/episode_forward_reward': Array(-0.03838982, dtype=float32), 'eval/episode_reward': Array(-2.033144, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03838982, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9936023, dtype=float32), 'eval/episode_train_reward': Array(-0.00115169, dtype=float32), 'eval/episode_x_position': Array(1.007273, dtype=float32), 'eval/episode_x_velocity': Array(-0.03838982, dtype=float32), 'eval/episode_y_position': Array(-0.0003676, dtype=float32), 'eval/episode_y_velocity': Array(-0.00440794, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00542316, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04322129, dtype=float32), 'eval/episode_reward_std': Array(0.05082944, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04322129, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02014237, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129664, dtype=float32), 'eval/episode_x_position_std': Array(0.00541809, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04322129, dtype=float32), 'eval/episode_y_position_std': Array(0.00566368, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0113998, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.689550161361694, 'eval/sps': 6186.698067464199, 'num_steps': 2810880}
{'eval/walltime': 11491.656779289246, 'training/sps': 127.30868940441874, 'training/walltime': 22217.162301301956, 'training/entropy_loss': Array(0.10664012, dtype=float32), 'training/policy_loss': Array(0.26704794, dtype=float32), 'training/total_loss': Array(0.37368804, dtype=float32), 'training/v_loss': Array(1.1857654e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0164204, dtype=float32), 'eval/episode_forward_reward': Array(-0.03266637, dtype=float32), 'eval/episode_reward': Array(-2.0455008, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03266637, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0196671, dtype=float32), 'eval/episode_train_reward': Array(-0.00097999, dtype=float32), 'eval/episode_x_position': Array(1.0144565, dtype=float32), 'eval/episode_x_velocity': Array(-0.03266637, dtype=float32), 'eval/episode_y_position': Array(-0.00041835, dtype=float32), 'eval/episode_y_velocity': Array(-0.00328881, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08813088, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04200798, dtype=float32), 'eval/episode_reward_std': Array(0.18105325, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04200798, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2648164, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126024, dtype=float32), 'eval/episode_x_position_std': Array(0.08786291, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04200798, dtype=float32), 'eval/episode_y_position_std': Array(0.00606118, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00903899, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.720203638076782, 'eval/sps': 6177.545464117879, 'num_steps': 2816000}
{'eval/walltime': 11512.347230196, 'training/sps': 127.19550579643959, 'training/walltime': 22257.41529583931, 'training/entropy_loss': Array(0.10491459, dtype=float32), 'training/policy_loss': Array(0.27129844, dtype=float32), 'training/total_loss': Array(0.37621307, dtype=float32), 'training/v_loss': Array(1.4354848e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087419, dtype=float32), 'eval/episode_forward_reward': Array(-0.03916902, dtype=float32), 'eval/episode_reward': Array(-2.0337286, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03916902, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9933846, dtype=float32), 'eval/episode_train_reward': Array(-0.00117507, dtype=float32), 'eval/episode_x_position': Array(1.0068932, dtype=float32), 'eval/episode_x_velocity': Array(-0.03916902, dtype=float32), 'eval/episode_y_position': Array(0.00069829, dtype=float32), 'eval/episode_y_velocity': Array(-0.00145984, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058102, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04288614, dtype=float32), 'eval/episode_reward_std': Array(0.04909094, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04288614, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02182289, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128658, dtype=float32), 'eval/episode_x_position_std': Array(0.00582894, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04288614, dtype=float32), 'eval/episode_y_position_std': Array(0.0056841, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01586821, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69045090675354, 'eval/sps': 6186.4287335671215, 'num_steps': 2821120}
{'eval/walltime': 11533.027614593506, 'training/sps': 127.33831002316911, 'training/walltime': 22297.623148441315, 'training/entropy_loss': Array(0.10454878, dtype=float32), 'training/policy_loss': Array(0.27083892, dtype=float32), 'training/total_loss': Array(0.37538773, dtype=float32), 'training/v_loss': Array(3.3466891e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167898, dtype=float32), 'eval/episode_forward_reward': Array(-0.03885594, dtype=float32), 'eval/episode_reward': Array(-2.0518847, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03885594, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0196757, dtype=float32), 'eval/episode_train_reward': Array(-0.00116568, dtype=float32), 'eval/episode_x_position': Array(1.0149362, dtype=float32), 'eval/episode_x_velocity': Array(-0.03885594, dtype=float32), 'eval/episode_y_position': Array(-0.00016217, dtype=float32), 'eval/episode_y_velocity': Array(-0.0010254, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08772358, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04220256, dtype=float32), 'eval/episode_reward_std': Array(0.17911763, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04220256, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2648669, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126608, dtype=float32), 'eval/episode_x_position_std': Array(0.08744822, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04220256, dtype=float32), 'eval/episode_y_position_std': Array(0.00549578, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01311721, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.680384397506714, 'eval/sps': 6189.440077111528, 'num_steps': 2826240}
{'eval/walltime': 11553.712605953217, 'training/sps': 127.43397696259802, 'training/walltime': 22337.80081629753, 'training/entropy_loss': Array(0.10346894, dtype=float32), 'training/policy_loss': Array(0.26988128, dtype=float32), 'training/total_loss': Array(0.37335026, dtype=float32), 'training/v_loss': Array(5.841244e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088835, dtype=float32), 'eval/episode_forward_reward': Array(-0.03872199, dtype=float32), 'eval/episode_reward': Array(-2.0364199, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03872199, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965365, dtype=float32), 'eval/episode_train_reward': Array(-0.00116166, dtype=float32), 'eval/episode_x_position': Array(1.0070344, dtype=float32), 'eval/episode_x_velocity': Array(-0.03872199, dtype=float32), 'eval/episode_y_position': Array(0.00056829, dtype=float32), 'eval/episode_y_velocity': Array(-0.00122091, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00591138, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04219816, dtype=float32), 'eval/episode_reward_std': Array(0.04584751, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04219816, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01330228, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126594, dtype=float32), 'eval/episode_x_position_std': Array(0.00587813, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04219816, dtype=float32), 'eval/episode_y_position_std': Array(0.00606016, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01422787, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.684991359710693, 'eval/sps': 6188.061564739771, 'num_steps': 2831360}
{'eval/walltime': 11574.385776996613, 'training/sps': 127.13034100311144, 'training/walltime': 22378.07444381714, 'training/entropy_loss': Array(0.10339037, dtype=float32), 'training/policy_loss': Array(0.2656123, dtype=float32), 'training/total_loss': Array(0.36900264, dtype=float32), 'training/v_loss': Array(2.6472785e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093924, dtype=float32), 'eval/episode_forward_reward': Array(-0.04106256, dtype=float32), 'eval/episode_reward': Array(-2.0398502, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04106256, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975557, dtype=float32), 'eval/episode_train_reward': Array(-0.00123188, dtype=float32), 'eval/episode_x_position': Array(1.0075369, dtype=float32), 'eval/episode_x_velocity': Array(-0.04106256, dtype=float32), 'eval/episode_y_position': Array(-0.00115412, dtype=float32), 'eval/episode_y_velocity': Array(-0.00046765, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00542039, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04559715, dtype=float32), 'eval/episode_reward_std': Array(0.04924538, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04559715, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01144193, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136791, dtype=float32), 'eval/episode_x_position_std': Array(0.0054709, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04559715, dtype=float32), 'eval/episode_y_position_std': Array(0.00554976, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01589774, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.673171043395996, 'eval/sps': 6191.599717881179, 'num_steps': 2836480}
{'eval/walltime': 11595.07165312767, 'training/sps': 127.20756251430022, 'training/walltime': 22418.32362318039, 'training/entropy_loss': Array(0.10568338, dtype=float32), 'training/policy_loss': Array(0.26788265, dtype=float32), 'training/total_loss': Array(0.37356603, dtype=float32), 'training/v_loss': Array(1.2616861e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0164981, dtype=float32), 'eval/episode_forward_reward': Array(-0.03918299, dtype=float32), 'eval/episode_reward': Array(-2.0512328, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03918299, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0186868, dtype=float32), 'eval/episode_train_reward': Array(-0.00117549, dtype=float32), 'eval/episode_x_position': Array(1.0146058, dtype=float32), 'eval/episode_x_velocity': Array(-0.03918299, dtype=float32), 'eval/episode_y_position': Array(-0.00018756, dtype=float32), 'eval/episode_y_velocity': Array(-0.00443922, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0877851, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04244411, dtype=float32), 'eval/episode_reward_std': Array(0.17234188, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04244411, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2577283, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127332, dtype=float32), 'eval/episode_x_position_std': Array(0.08751525, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04244411, dtype=float32), 'eval/episode_y_position_std': Array(0.00573082, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01682402, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.68587613105774, 'eval/sps': 6187.7968904503405, 'num_steps': 2841600}
{'eval/walltime': 11615.765122413635, 'training/sps': 127.21643585598643, 'training/walltime': 22458.56999516487, 'training/entropy_loss': Array(0.10446846, dtype=float32), 'training/policy_loss': Array(0.27041522, dtype=float32), 'training/total_loss': Array(0.3748837, dtype=float32), 'training/v_loss': Array(2.4678468e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096033, dtype=float32), 'eval/episode_forward_reward': Array(-0.04351822, dtype=float32), 'eval/episode_reward': Array(-2.0398386, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04351822, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9950147, dtype=float32), 'eval/episode_train_reward': Array(-0.00130555, dtype=float32), 'eval/episode_x_position': Array(1.0077341, dtype=float32), 'eval/episode_x_velocity': Array(-0.04351822, dtype=float32), 'eval/episode_y_position': Array(0.00084738, dtype=float32), 'eval/episode_y_velocity': Array(-0.00206653, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059348, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04436175, dtype=float32), 'eval/episode_reward_std': Array(0.05062594, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04436175, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0175993, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133085, dtype=float32), 'eval/episode_x_position_std': Array(0.00586527, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04436175, dtype=float32), 'eval/episode_y_position_std': Array(0.0054604, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01317578, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.693469285964966, 'eval/sps': 6185.526372168734, 'num_steps': 2846720}
{'eval/walltime': 11636.463259220123, 'training/sps': 127.52415336248063, 'training/walltime': 22498.719252109528, 'training/entropy_loss': Array(0.10356516, dtype=float32), 'training/policy_loss': Array(0.2697228, dtype=float32), 'training/total_loss': Array(0.37328795, dtype=float32), 'training/v_loss': Array(1.345935e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095503, dtype=float32), 'eval/episode_forward_reward': Array(-0.03625709, dtype=float32), 'eval/episode_reward': Array(-2.0329618, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03625709, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956174, dtype=float32), 'eval/episode_train_reward': Array(-0.00108771, dtype=float32), 'eval/episode_x_position': Array(1.0076647, dtype=float32), 'eval/episode_x_velocity': Array(-0.03625709, dtype=float32), 'eval/episode_y_position': Array(0.00061923, dtype=float32), 'eval/episode_y_velocity': Array(0.00022176, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576515, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04192155, dtype=float32), 'eval/episode_reward_std': Array(0.04614897, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04192155, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0142642, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125765, dtype=float32), 'eval/episode_x_position_std': Array(0.00573085, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04192155, dtype=float32), 'eval/episode_y_position_std': Array(0.00522956, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01480948, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.698136806488037, 'eval/sps': 6184.131508874611, 'num_steps': 2851840}
{'eval/walltime': 11657.174492835999, 'training/sps': 127.17614614280814, 'training/walltime': 22538.978374242783, 'training/entropy_loss': Array(0.10228804, dtype=float32), 'training/policy_loss': Array(0.2723748, dtype=float32), 'training/total_loss': Array(0.37466285, dtype=float32), 'training/v_loss': Array(1.0273936e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089529, dtype=float32), 'eval/episode_forward_reward': Array(-0.04176097, dtype=float32), 'eval/episode_reward': Array(-2.0357025, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04176097, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9926887, dtype=float32), 'eval/episode_train_reward': Array(-0.00125283, dtype=float32), 'eval/episode_x_position': Array(1.0070782, dtype=float32), 'eval/episode_x_velocity': Array(-0.04176097, dtype=float32), 'eval/episode_y_position': Array(0.00026097, dtype=float32), 'eval/episode_y_velocity': Array(-0.00101181, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582781, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04442311, dtype=float32), 'eval/episode_reward_std': Array(0.05313918, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04442311, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02433488, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133269, dtype=float32), 'eval/episode_x_position_std': Array(0.00583489, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04442311, dtype=float32), 'eval/episode_y_position_std': Array(0.00579957, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01239024, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.711233615875244, 'eval/sps': 6180.22095515776, 'num_steps': 2856960}
{'eval/walltime': 11677.907579421997, 'training/sps': 127.27175503788261, 'training/walltime': 22579.20725297928, 'training/entropy_loss': Array(0.10007554, dtype=float32), 'training/policy_loss': Array(0.2691981, dtype=float32), 'training/total_loss': Array(0.3692736, dtype=float32), 'training/v_loss': Array(4.9284665e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090537, dtype=float32), 'eval/episode_forward_reward': Array(-0.03929017, dtype=float32), 'eval/episode_reward': Array(-2.034954, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03929017, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9944851, dtype=float32), 'eval/episode_train_reward': Array(-0.00117871, dtype=float32), 'eval/episode_x_position': Array(1.0071952, dtype=float32), 'eval/episode_x_velocity': Array(-0.03929017, dtype=float32), 'eval/episode_y_position': Array(0.00014713, dtype=float32), 'eval/episode_y_velocity': Array(-0.00019979, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575866, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04268389, dtype=float32), 'eval/episode_reward_std': Array(0.04643536, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04268389, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02337444, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128052, dtype=float32), 'eval/episode_x_position_std': Array(0.00572085, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04268389, dtype=float32), 'eval/episode_y_position_std': Array(0.00605589, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0112586, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.733086585998535, 'eval/sps': 6173.706913781036, 'num_steps': 2862080}
{'eval/walltime': 11698.647054672241, 'training/sps': 127.39087036573103, 'training/walltime': 22619.39851617813, 'training/entropy_loss': Array(0.101448, dtype=float32), 'training/policy_loss': Array(0.2622046, dtype=float32), 'training/total_loss': Array(0.3636526, dtype=float32), 'training/v_loss': Array(7.0081796e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0080142, dtype=float32), 'eval/episode_forward_reward': Array(-0.04343161, dtype=float32), 'eval/episode_reward': Array(-2.0409827, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04343161, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962482, dtype=float32), 'eval/episode_train_reward': Array(-0.00130295, dtype=float32), 'eval/episode_x_position': Array(1.0061622, dtype=float32), 'eval/episode_x_velocity': Array(-0.04343161, dtype=float32), 'eval/episode_y_position': Array(-0.00061312, dtype=float32), 'eval/episode_y_velocity': Array(-0.00096362, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559549, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04526538, dtype=float32), 'eval/episode_reward_std': Array(0.04871793, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04526538, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01533633, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135796, dtype=float32), 'eval/episode_x_position_std': Array(0.00562275, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04526538, dtype=float32), 'eval/episode_y_position_std': Array(0.00565088, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01160925, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.73947525024414, 'eval/sps': 6171.805142393524, 'num_steps': 2867200}
{'eval/walltime': 11719.355318307877, 'training/sps': 127.38011395087655, 'training/walltime': 22659.593173265457, 'training/entropy_loss': Array(0.10290362, dtype=float32), 'training/policy_loss': Array(0.22661063, dtype=float32), 'training/total_loss': Array(0.32951427, dtype=float32), 'training/v_loss': Array(5.4992197e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091295, dtype=float32), 'eval/episode_forward_reward': Array(-0.04029476, dtype=float32), 'eval/episode_reward': Array(-2.038594, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04029476, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970903, dtype=float32), 'eval/episode_train_reward': Array(-0.00120884, dtype=float32), 'eval/episode_x_position': Array(1.0072682, dtype=float32), 'eval/episode_x_velocity': Array(-0.04029476, dtype=float32), 'eval/episode_y_position': Array(-0.00012801, dtype=float32), 'eval/episode_y_velocity': Array(-0.00323204, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574042, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04305867, dtype=float32), 'eval/episode_reward_std': Array(0.0453863, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04305867, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01269907, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129176, dtype=float32), 'eval/episode_x_position_std': Array(0.00576593, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04305867, dtype=float32), 'eval/episode_y_position_std': Array(0.00566329, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01284296, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.708263635635376, 'eval/sps': 6181.107322766256, 'num_steps': 2872320}
{'eval/walltime': 11740.024891853333, 'training/sps': 127.28872790962139, 'training/walltime': 22699.816687822342, 'training/entropy_loss': Array(0.10409254, dtype=float32), 'training/policy_loss': Array(0.26670253, dtype=float32), 'training/total_loss': Array(0.3707951, dtype=float32), 'training/v_loss': Array(5.771234e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085158, dtype=float32), 'eval/episode_forward_reward': Array(-0.04556426, dtype=float32), 'eval/episode_reward': Array(-2.0430527, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04556426, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961214, dtype=float32), 'eval/episode_train_reward': Array(-0.00136693, dtype=float32), 'eval/episode_x_position': Array(1.0066962, dtype=float32), 'eval/episode_x_velocity': Array(-0.04556426, dtype=float32), 'eval/episode_y_position': Array(0.00061082, dtype=float32), 'eval/episode_y_velocity': Array(-0.00277447, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569862, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04471359, dtype=float32), 'eval/episode_reward_std': Array(0.04989178, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04471359, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01460206, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134141, dtype=float32), 'eval/episode_x_position_std': Array(0.00573621, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04471359, dtype=float32), 'eval/episode_y_position_std': Array(0.00571494, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01397723, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.669573545455933, 'eval/sps': 6192.677353429962, 'num_steps': 2877440}
{'eval/walltime': 11760.77225804329, 'training/sps': 127.09528969551542, 'training/walltime': 22740.101422309875, 'training/entropy_loss': Array(0.10368325, dtype=float32), 'training/policy_loss': Array(0.2717858, dtype=float32), 'training/total_loss': Array(0.37546903, dtype=float32), 'training/v_loss': Array(2.2027988e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093565, dtype=float32), 'eval/episode_forward_reward': Array(-0.03494322, dtype=float32), 'eval/episode_reward': Array(-2.0332103, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03494322, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972188, dtype=float32), 'eval/episode_train_reward': Array(-0.0010483, dtype=float32), 'eval/episode_x_position': Array(1.0074506, dtype=float32), 'eval/episode_x_velocity': Array(-0.03494322, dtype=float32), 'eval/episode_y_position': Array(0.00041539, dtype=float32), 'eval/episode_y_velocity': Array(-0.00066547, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575915, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04095208, dtype=float32), 'eval/episode_reward_std': Array(0.04245563, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04095208, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01323845, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122856, dtype=float32), 'eval/episode_x_position_std': Array(0.00571954, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04095208, dtype=float32), 'eval/episode_y_position_std': Array(0.00559609, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01506071, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.747366189956665, 'eval/sps': 6169.45779180212, 'num_steps': 2882560}
{'eval/walltime': 11781.512043714523, 'training/sps': 127.15849852280668, 'training/walltime': 22780.36613178253, 'training/entropy_loss': Array(0.10300937, dtype=float32), 'training/policy_loss': Array(0.26968545, dtype=float32), 'training/total_loss': Array(0.37269482, dtype=float32), 'training/v_loss': Array(5.4888014e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098906, dtype=float32), 'eval/episode_forward_reward': Array(-0.03283168, dtype=float32), 'eval/episode_reward': Array(-2.0298576, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03283168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996041, dtype=float32), 'eval/episode_train_reward': Array(-0.00098495, dtype=float32), 'eval/episode_x_position': Array(1.0079618, dtype=float32), 'eval/episode_x_velocity': Array(-0.03283168, dtype=float32), 'eval/episode_y_position': Array(-0.00010575, dtype=float32), 'eval/episode_y_velocity': Array(-0.00142364, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00556344, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04185591, dtype=float32), 'eval/episode_reward_std': Array(0.04520413, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04185591, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01747429, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125568, dtype=float32), 'eval/episode_x_position_std': Array(0.00562393, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04185591, dtype=float32), 'eval/episode_y_position_std': Array(0.00548061, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01387868, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.73978567123413, 'eval/sps': 6171.712766421433, 'num_steps': 2887680}
{'eval/walltime': 11802.230649471283, 'training/sps': 127.16323921575278, 'training/walltime': 22820.629340171814, 'training/entropy_loss': Array(0.10101013, dtype=float32), 'training/policy_loss': Array(0.2713771, dtype=float32), 'training/total_loss': Array(0.37238723, dtype=float32), 'training/v_loss': Array(4.3405155e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093596, dtype=float32), 'eval/episode_forward_reward': Array(-0.04243866, dtype=float32), 'eval/episode_reward': Array(-2.0391672, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04243866, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9954553, dtype=float32), 'eval/episode_train_reward': Array(-0.00127316, dtype=float32), 'eval/episode_x_position': Array(1.0074664, dtype=float32), 'eval/episode_x_velocity': Array(-0.04243866, dtype=float32), 'eval/episode_y_position': Array(-0.00067219, dtype=float32), 'eval/episode_y_velocity': Array(-0.00223885, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00611386, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04403922, dtype=float32), 'eval/episode_reward_std': Array(0.05027458, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04403922, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01907667, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132118, dtype=float32), 'eval/episode_x_position_std': Array(0.00607484, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04403922, dtype=float32), 'eval/episode_y_position_std': Array(0.00569996, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01051702, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.718605756759644, 'eval/sps': 6178.021895041792, 'num_steps': 2892800}
{'eval/walltime': 11822.938605070114, 'training/sps': 127.09201623771922, 'training/walltime': 22860.915112257004, 'training/entropy_loss': Array(0.10027433, dtype=float32), 'training/policy_loss': Array(0.26382834, dtype=float32), 'training/total_loss': Array(0.36410272, dtype=float32), 'training/v_loss': Array(3.0518879e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094101, dtype=float32), 'eval/episode_forward_reward': Array(-0.04189656, dtype=float32), 'eval/episode_reward': Array(-2.0368385, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04189656, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.993685, dtype=float32), 'eval/episode_train_reward': Array(-0.0012569, dtype=float32), 'eval/episode_x_position': Array(1.0075375, dtype=float32), 'eval/episode_x_velocity': Array(-0.04189656, dtype=float32), 'eval/episode_y_position': Array(-9.086155e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00270854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575209, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04460523, dtype=float32), 'eval/episode_reward_std': Array(0.04874176, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04460523, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02206708, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133816, dtype=float32), 'eval/episode_x_position_std': Array(0.0057074, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04460523, dtype=float32), 'eval/episode_y_position_std': Array(0.00604226, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01533682, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.707955598831177, 'eval/sps': 6181.199268518073, 'num_steps': 2897920}
{'eval/walltime': 11843.647647619247, 'training/sps': 126.99237761995845, 'training/walltime': 22901.232492685318, 'training/entropy_loss': Array(0.10229602, dtype=float32), 'training/policy_loss': Array(0.14928585, dtype=float32), 'training/total_loss': Array(0.2515819, dtype=float32), 'training/v_loss': Array(8.380435e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101607, dtype=float32), 'eval/episode_forward_reward': Array(-0.03743304, dtype=float32), 'eval/episode_reward': Array(-2.032517, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03743304, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9939609, dtype=float32), 'eval/episode_train_reward': Array(-0.00112299, dtype=float32), 'eval/episode_x_position': Array(1.0083106, dtype=float32), 'eval/episode_x_velocity': Array(-0.03743304, dtype=float32), 'eval/episode_y_position': Array(-0.00055526, dtype=float32), 'eval/episode_y_velocity': Array(-0.00252987, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593239, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04216236, dtype=float32), 'eval/episode_reward_std': Array(0.04816672, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04216236, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01839554, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126487, dtype=float32), 'eval/episode_x_position_std': Array(0.00592496, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04216236, dtype=float32), 'eval/episode_y_position_std': Array(0.0057784, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01471676, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7090425491333, 'eval/sps': 6180.874837468377, 'num_steps': 2903040}
{'eval/walltime': 11864.386647224426, 'training/sps': 127.13227071810472, 'training/walltime': 22941.50550889969, 'training/entropy_loss': Array(0.10400639, dtype=float32), 'training/policy_loss': Array(0.26624244, dtype=float32), 'training/total_loss': Array(0.37024885, dtype=float32), 'training/v_loss': Array(1.8231782e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094819, dtype=float32), 'eval/episode_forward_reward': Array(-0.03931136, dtype=float32), 'eval/episode_reward': Array(-2.033644, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03931136, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.993153, dtype=float32), 'eval/episode_train_reward': Array(-0.00117934, dtype=float32), 'eval/episode_x_position': Array(1.0075977, dtype=float32), 'eval/episode_x_velocity': Array(-0.03931136, dtype=float32), 'eval/episode_y_position': Array(-9.5517025e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00339969, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00542519, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04422367, dtype=float32), 'eval/episode_reward_std': Array(0.05187787, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04422367, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01991104, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132671, dtype=float32), 'eval/episode_x_position_std': Array(0.00537391, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04422367, dtype=float32), 'eval/episode_y_position_std': Array(0.00563163, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01575239, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.738999605178833, 'eval/sps': 6171.946691586633, 'num_steps': 2908160}
{'eval/walltime': 11885.11406135559, 'training/sps': 127.05100099113551, 'training/walltime': 22981.80428624153, 'training/entropy_loss': Array(0.10123082, dtype=float32), 'training/policy_loss': Array(0.27310628, dtype=float32), 'training/total_loss': Array(0.3743371, dtype=float32), 'training/v_loss': Array(1.9025834e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093206, dtype=float32), 'eval/episode_forward_reward': Array(-0.03873666, dtype=float32), 'eval/episode_reward': Array(-2.0352657, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03873666, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995367, dtype=float32), 'eval/episode_train_reward': Array(-0.0011621, dtype=float32), 'eval/episode_x_position': Array(1.0074298, dtype=float32), 'eval/episode_x_velocity': Array(-0.03873666, dtype=float32), 'eval/episode_y_position': Array(0.00018359, dtype=float32), 'eval/episode_y_velocity': Array(-0.00231571, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593594, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04236308, dtype=float32), 'eval/episode_reward_std': Array(0.04859177, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04236308, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01831432, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127089, dtype=float32), 'eval/episode_x_position_std': Array(0.00590564, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04236308, dtype=float32), 'eval/episode_y_position_std': Array(0.00557954, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01073467, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72741413116455, 'eval/sps': 6175.396467210377, 'num_steps': 2913280}
{'eval/walltime': 11905.841980695724, 'training/sps': 127.2758448906064, 'training/walltime': 23022.03187227249, 'training/entropy_loss': Array(0.10140963, dtype=float32), 'training/policy_loss': Array(0.26765767, dtype=float32), 'training/total_loss': Array(0.36906734, dtype=float32), 'training/v_loss': Array(2.2746818e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0175115, dtype=float32), 'eval/episode_forward_reward': Array(-0.03235384, dtype=float32), 'eval/episode_reward': Array(-2.0421484, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03235384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0166364, dtype=float32), 'eval/episode_train_reward': Array(-0.00097062, dtype=float32), 'eval/episode_x_position': Array(1.0155987, dtype=float32), 'eval/episode_x_velocity': Array(-0.03235384, dtype=float32), 'eval/episode_y_position': Array(0.00031544, dtype=float32), 'eval/episode_y_velocity': Array(-0.0001023, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08723914, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04151914, dtype=float32), 'eval/episode_reward_std': Array(0.18043527, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04151914, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26428664, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124557, dtype=float32), 'eval/episode_x_position_std': Array(0.08696261, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04151914, dtype=float32), 'eval/episode_y_position_std': Array(0.00619689, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01276313, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.727919340133667, 'eval/sps': 6175.245952070295, 'num_steps': 2918400}
{'eval/walltime': 11926.562861204147, 'training/sps': 127.31230839277583, 'training/walltime': 23062.247936725616, 'training/entropy_loss': Array(0.10387498, dtype=float32), 'training/policy_loss': Array(0.26460886, dtype=float32), 'training/total_loss': Array(0.36848384, dtype=float32), 'training/v_loss': Array(1.448548e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100952, dtype=float32), 'eval/episode_forward_reward': Array(-0.03686889, dtype=float32), 'eval/episode_reward': Array(-2.0352821, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03686889, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973073, dtype=float32), 'eval/episode_train_reward': Array(-0.00110607, dtype=float32), 'eval/episode_x_position': Array(1.0082319, dtype=float32), 'eval/episode_x_velocity': Array(-0.03686889, dtype=float32), 'eval/episode_y_position': Array(0.00085339, dtype=float32), 'eval/episode_y_velocity': Array(-0.00126554, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593379, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04238386, dtype=float32), 'eval/episode_reward_std': Array(0.04610003, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04238386, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01318949, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127152, dtype=float32), 'eval/episode_x_position_std': Array(0.00590311, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04238386, dtype=float32), 'eval/episode_y_position_std': Array(0.0055766, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01419782, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72088050842285, 'eval/sps': 6177.343667802589, 'num_steps': 2923520}
{'eval/walltime': 11947.291600227356, 'training/sps': 127.00984018817117, 'training/walltime': 23102.559773921967, 'training/entropy_loss': Array(0.10499316, dtype=float32), 'training/policy_loss': Array(0.26456326, dtype=float32), 'training/total_loss': Array(0.36955646, dtype=float32), 'training/v_loss': Array(6.455061e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091064, dtype=float32), 'eval/episode_forward_reward': Array(-0.03877841, dtype=float32), 'eval/episode_reward': Array(-2.0355635, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03877841, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956217, dtype=float32), 'eval/episode_train_reward': Array(-0.00116335, dtype=float32), 'eval/episode_x_position': Array(1.0072137, dtype=float32), 'eval/episode_x_velocity': Array(-0.03877841, dtype=float32), 'eval/episode_y_position': Array(0.00061056, dtype=float32), 'eval/episode_y_velocity': Array(-0.00157803, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568087, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04350979, dtype=float32), 'eval/episode_reward_std': Array(0.04489277, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04350979, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01807443, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130529, dtype=float32), 'eval/episode_x_position_std': Array(0.0056494, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04350979, dtype=float32), 'eval/episode_y_position_std': Array(0.00622167, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01060858, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.728739023208618, 'eval/sps': 6175.001762368986, 'num_steps': 2928640}
{'eval/walltime': 11967.999504804611, 'training/sps': 127.07977836904861, 'training/walltime': 23142.849425554276, 'training/entropy_loss': Array(0.10745446, dtype=float32), 'training/policy_loss': Array(0.2707786, dtype=float32), 'training/total_loss': Array(0.37823308, dtype=float32), 'training/v_loss': Array(5.45428e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099647, dtype=float32), 'eval/episode_forward_reward': Array(-0.03576473, dtype=float32), 'eval/episode_reward': Array(-2.033512, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03576473, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966745, dtype=float32), 'eval/episode_train_reward': Array(-0.00107294, dtype=float32), 'eval/episode_x_position': Array(1.0080773, dtype=float32), 'eval/episode_x_velocity': Array(-0.03576473, dtype=float32), 'eval/episode_y_position': Array(0.00042914, dtype=float32), 'eval/episode_y_velocity': Array(-0.00412614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00554013, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04286387, dtype=float32), 'eval/episode_reward_std': Array(0.04420233, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04286387, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01372848, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128592, dtype=float32), 'eval/episode_x_position_std': Array(0.00551871, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04286387, dtype=float32), 'eval/episode_y_position_std': Array(0.00601052, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01402896, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70790457725525, 'eval/sps': 6181.214498186851, 'num_steps': 2933760}
{'eval/walltime': 11988.749296426773, 'training/sps': 127.19423335157698, 'training/walltime': 23183.10282278061, 'training/entropy_loss': Array(0.10697185, dtype=float32), 'training/policy_loss': Array(0.26991874, dtype=float32), 'training/total_loss': Array(0.3768906, dtype=float32), 'training/v_loss': Array(1.1734747e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089912, dtype=float32), 'eval/episode_forward_reward': Array(-0.04206295, dtype=float32), 'eval/episode_reward': Array(-2.0366817, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04206295, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9933567, dtype=float32), 'eval/episode_train_reward': Array(-0.00126189, dtype=float32), 'eval/episode_x_position': Array(1.007149, dtype=float32), 'eval/episode_x_velocity': Array(-0.04206295, dtype=float32), 'eval/episode_y_position': Array(0.00040743, dtype=float32), 'eval/episode_y_velocity': Array(-0.00257649, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569767, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04512021, dtype=float32), 'eval/episode_reward_std': Array(0.05041465, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04512021, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02087436, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135361, dtype=float32), 'eval/episode_x_position_std': Array(0.00566788, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04512021, dtype=float32), 'eval/episode_y_position_std': Array(0.00616075, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01385325, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.749791622161865, 'eval/sps': 6168.736647132846, 'num_steps': 2938880}
{'eval/walltime': 12009.46539735794, 'training/sps': 127.02305334254113, 'training/walltime': 23223.41046667099, 'training/entropy_loss': Array(0.10335088, dtype=float32), 'training/policy_loss': Array(0.27084598, dtype=float32), 'training/total_loss': Array(0.37419683, dtype=float32), 'training/v_loss': Array(2.408681e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0168486, dtype=float32), 'eval/episode_forward_reward': Array(-0.04458847, dtype=float32), 'eval/episode_reward': Array(-2.0524864, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04458847, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0143728, dtype=float32), 'eval/episode_train_reward': Array(-0.00133765, dtype=float32), 'eval/episode_x_position': Array(1.0150094, dtype=float32), 'eval/episode_x_velocity': Array(-0.04458847, dtype=float32), 'eval/episode_y_position': Array(-0.00041609, dtype=float32), 'eval/episode_y_velocity': Array(-0.00193856, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08802798, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04365718, dtype=float32), 'eval/episode_reward_std': Array(0.18242994, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04365718, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26618403, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130972, dtype=float32), 'eval/episode_x_position_std': Array(0.0877439, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04365718, dtype=float32), 'eval/episode_y_position_std': Array(0.00547317, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0152403, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.716100931167603, 'eval/sps': 6178.768892143337, 'num_steps': 2944000}
{'eval/walltime': 12030.165673732758, 'training/sps': 127.14288745608371, 'training/walltime': 23263.680119991302, 'training/entropy_loss': Array(0.10179366, dtype=float32), 'training/policy_loss': Array(0.05137668, dtype=float32), 'training/total_loss': Array(0.1531704, dtype=float32), 'training/v_loss': Array(5.1936876e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176158, dtype=float32), 'eval/episode_forward_reward': Array(-0.03488385, dtype=float32), 'eval/episode_reward': Array(-2.0466871, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03488385, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0185695, dtype=float32), 'eval/episode_train_reward': Array(-0.00104652, dtype=float32), 'eval/episode_x_position': Array(1.0156976, dtype=float32), 'eval/episode_x_velocity': Array(-0.03488385, dtype=float32), 'eval/episode_y_position': Array(0.0006674, dtype=float32), 'eval/episode_y_velocity': Array(-0.00176529, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09012511, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04174735, dtype=float32), 'eval/episode_reward_std': Array(0.17841299, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04174735, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2646879, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125242, dtype=float32), 'eval/episode_x_position_std': Array(0.08986137, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04174735, dtype=float32), 'eval/episode_y_position_std': Array(0.00580828, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00954645, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.700276374816895, 'eval/sps': 6183.4923206976855, 'num_steps': 2949120}
{'eval/walltime': 12050.8729865551, 'training/sps': 127.03473396242596, 'training/walltime': 23303.98405766487, 'training/entropy_loss': Array(0.10567716, dtype=float32), 'training/policy_loss': Array(0.27013958, dtype=float32), 'training/total_loss': Array(0.37581676, dtype=float32), 'training/v_loss': Array(1.5319735e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091554, dtype=float32), 'eval/episode_forward_reward': Array(-0.03936569, dtype=float32), 'eval/episode_reward': Array(-2.0351815, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03936569, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946349, dtype=float32), 'eval/episode_train_reward': Array(-0.00118097, dtype=float32), 'eval/episode_x_position': Array(1.0073, dtype=float32), 'eval/episode_x_velocity': Array(-0.03936569, dtype=float32), 'eval/episode_y_position': Array(0.00110807, dtype=float32), 'eval/episode_y_velocity': Array(-0.00092772, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584095, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04386479, dtype=float32), 'eval/episode_reward_std': Array(0.04857948, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04386479, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01819539, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131594, dtype=float32), 'eval/episode_x_position_std': Array(0.00584147, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04386479, dtype=float32), 'eval/episode_y_position_std': Array(0.00574853, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01291368, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70731282234192, 'eval/sps': 6181.391139360963, 'num_steps': 2954240}
{'eval/walltime': 12071.576366186142, 'training/sps': 126.96393555889436, 'training/walltime': 23344.3104698658, 'training/entropy_loss': Array(0.10365765, dtype=float32), 'training/policy_loss': Array(0.26744175, dtype=float32), 'training/total_loss': Array(0.3710994, dtype=float32), 'training/v_loss': Array(1.7332105e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097958, dtype=float32), 'eval/episode_forward_reward': Array(-0.03367957, dtype=float32), 'eval/episode_reward': Array(-2.0328548, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03367957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981651, dtype=float32), 'eval/episode_train_reward': Array(-0.00101039, dtype=float32), 'eval/episode_x_position': Array(1.0078895, dtype=float32), 'eval/episode_x_velocity': Array(-0.03367957, dtype=float32), 'eval/episode_y_position': Array(0.00032757, dtype=float32), 'eval/episode_y_velocity': Array(-0.00061818, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600726, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0440446, dtype=float32), 'eval/episode_reward_std': Array(0.04486088, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0440446, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00956916, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132134, dtype=float32), 'eval/episode_x_position_std': Array(0.00602971, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0440446, dtype=float32), 'eval/episode_y_position_std': Array(0.00605015, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0169261, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70337963104248, 'eval/sps': 6182.56546907336, 'num_steps': 2959360}
{'eval/walltime': 12092.272136688232, 'training/sps': 127.17467601108886, 'training/walltime': 23384.57005739212, 'training/entropy_loss': Array(0.10385397, dtype=float32), 'training/policy_loss': Array(0.2676034, dtype=float32), 'training/total_loss': Array(0.3714574, dtype=float32), 'training/v_loss': Array(2.7343316e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094892, dtype=float32), 'eval/episode_forward_reward': Array(-0.03803824, dtype=float32), 'eval/episode_reward': Array(-2.0363004, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03803824, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971213, dtype=float32), 'eval/episode_train_reward': Array(-0.00114115, dtype=float32), 'eval/episode_x_position': Array(1.0076225, dtype=float32), 'eval/episode_x_velocity': Array(-0.03803824, dtype=float32), 'eval/episode_y_position': Array(0.00058175, dtype=float32), 'eval/episode_y_velocity': Array(-0.00254149, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563073, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04238543, dtype=float32), 'eval/episode_reward_std': Array(0.04794099, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04238543, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01724162, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127156, dtype=float32), 'eval/episode_x_position_std': Array(0.00562587, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04238543, dtype=float32), 'eval/episode_y_position_std': Array(0.0059383, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01187045, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.695770502090454, 'eval/sps': 6184.838587530282, 'num_steps': 2964480}
{'eval/walltime': 12112.982175588608, 'training/sps': 127.32527881617266, 'training/walltime': 23424.7820250988, 'training/entropy_loss': Array(0.10457642, dtype=float32), 'training/policy_loss': Array(0.26614016, dtype=float32), 'training/total_loss': Array(0.3707166, dtype=float32), 'training/v_loss': Array(1.15102254e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088334, dtype=float32), 'eval/episode_forward_reward': Array(-0.034944, dtype=float32), 'eval/episode_reward': Array(-2.0299215, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.034944, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9939294, dtype=float32), 'eval/episode_train_reward': Array(-0.00104832, dtype=float32), 'eval/episode_x_position': Array(1.006949, dtype=float32), 'eval/episode_x_velocity': Array(-0.034944, dtype=float32), 'eval/episode_y_position': Array(0.00051971, dtype=float32), 'eval/episode_y_velocity': Array(-0.00051388, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058796, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04185805, dtype=float32), 'eval/episode_reward_std': Array(0.04546602, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04185805, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01917431, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125574, dtype=float32), 'eval/episode_x_position_std': Array(0.00586369, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04185805, dtype=float32), 'eval/episode_y_position_std': Array(0.00565003, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01227273, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.710038900375366, 'eval/sps': 6180.577478185231, 'num_steps': 2969600}
{'eval/walltime': 12133.66941356659, 'training/sps': 127.17559107371329, 'training/walltime': 23465.04132294655, 'training/entropy_loss': Array(0.10485033, dtype=float32), 'training/policy_loss': Array(0.26750052, dtype=float32), 'training/total_loss': Array(0.37235087, dtype=float32), 'training/v_loss': Array(2.9171654e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099446, dtype=float32), 'eval/episode_forward_reward': Array(-0.02915606, dtype=float32), 'eval/episode_reward': Array(-2.0239491, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.02915606, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9939187, dtype=float32), 'eval/episode_train_reward': Array(-0.00087468, dtype=float32), 'eval/episode_x_position': Array(1.0080442, dtype=float32), 'eval/episode_x_velocity': Array(-0.02915606, dtype=float32), 'eval/episode_y_position': Array(-0.000461, dtype=float32), 'eval/episode_y_velocity': Array(-0.00070789, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560946, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0399636, dtype=float32), 'eval/episode_reward_std': Array(0.04866029, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0399636, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02064708, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119891, dtype=float32), 'eval/episode_x_position_std': Array(0.00556341, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0399636, dtype=float32), 'eval/episode_y_position_std': Array(0.00579975, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01288407, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.687237977981567, 'eval/sps': 6187.3895459720925, 'num_steps': 2974720}
{'eval/walltime': 12154.370376348495, 'training/sps': 127.07760058833797, 'training/walltime': 23505.331665039062, 'training/entropy_loss': Array(0.10601586, dtype=float32), 'training/policy_loss': Array(0.26807326, dtype=float32), 'training/total_loss': Array(0.37408912, dtype=float32), 'training/v_loss': Array(3.3370753e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0179927, dtype=float32), 'eval/episode_forward_reward': Array(-0.03264844, dtype=float32), 'eval/episode_reward': Array(-2.0447536, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03264844, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.018938, dtype=float32), 'eval/episode_train_reward': Array(-0.00097945, dtype=float32), 'eval/episode_x_position': Array(1.0160471, dtype=float32), 'eval/episode_x_velocity': Array(-0.03264844, dtype=float32), 'eval/episode_y_position': Array(0.00075914, dtype=float32), 'eval/episode_y_velocity': Array(-0.0026553, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08907146, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04193059, dtype=float32), 'eval/episode_reward_std': Array(0.17942818, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04193059, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26508135, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125792, dtype=float32), 'eval/episode_x_position_std': Array(0.08880917, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04193059, dtype=float32), 'eval/episode_y_position_std': Array(0.00628486, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01231781, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.700962781906128, 'eval/sps': 6183.287287095633, 'num_steps': 2979840}
{'eval/walltime': 12175.082416534424, 'training/sps': 127.33906509952858, 'training/walltime': 23545.53927922249, 'training/entropy_loss': Array(0.10576861, dtype=float32), 'training/policy_loss': Array(0.26876146, dtype=float32), 'training/total_loss': Array(0.37453008, dtype=float32), 'training/v_loss': Array(6.604141e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092748, dtype=float32), 'eval/episode_forward_reward': Array(-0.03727704, dtype=float32), 'eval/episode_reward': Array(-2.036304, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03727704, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979088, dtype=float32), 'eval/episode_train_reward': Array(-0.00111831, dtype=float32), 'eval/episode_x_position': Array(1.0074039, dtype=float32), 'eval/episode_x_velocity': Array(-0.03727704, dtype=float32), 'eval/episode_y_position': Array(0.00056961, dtype=float32), 'eval/episode_y_velocity': Array(-0.00140574, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00552522, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04543428, dtype=float32), 'eval/episode_reward_std': Array(0.04850198, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04543428, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01143929, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136303, dtype=float32), 'eval/episode_x_position_std': Array(0.00550783, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04543428, dtype=float32), 'eval/episode_y_position_std': Array(0.00574912, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01337793, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.712040185928345, 'eval/sps': 6179.980284460946, 'num_steps': 2984960}
{'eval/walltime': 12195.784626722336, 'training/sps': 126.97683734458434, 'training/walltime': 23585.861593961716, 'training/entropy_loss': Array(0.10635868, dtype=float32), 'training/policy_loss': Array(0.26826394, dtype=float32), 'training/total_loss': Array(0.3746226, dtype=float32), 'training/v_loss': Array(2.0013853e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087473, dtype=float32), 'eval/episode_forward_reward': Array(-0.04123741, dtype=float32), 'eval/episode_reward': Array(-2.0375578, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04123741, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9950833, dtype=float32), 'eval/episode_train_reward': Array(-0.00123712, dtype=float32), 'eval/episode_x_position': Array(1.00688, dtype=float32), 'eval/episode_x_velocity': Array(-0.04123741, dtype=float32), 'eval/episode_y_position': Array(-0.00035257, dtype=float32), 'eval/episode_y_velocity': Array(-0.00248559, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574216, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04323545, dtype=float32), 'eval/episode_reward_std': Array(0.04918857, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04323545, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01873546, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129706, dtype=float32), 'eval/episode_x_position_std': Array(0.00573877, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04323545, dtype=float32), 'eval/episode_y_position_std': Array(0.00569862, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01222053, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.702210187911987, 'eval/sps': 6182.914714813356, 'num_steps': 2990080}
{'eval/walltime': 12216.499376535416, 'training/sps': 127.20753990864112, 'training/walltime': 23626.110780477524, 'training/entropy_loss': Array(0.10724912, dtype=float32), 'training/policy_loss': Array(0.2698168, dtype=float32), 'training/total_loss': Array(0.37706593, dtype=float32), 'training/v_loss': Array(7.733382e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0173609, dtype=float32), 'eval/episode_forward_reward': Array(-0.03591188, dtype=float32), 'eval/episode_reward': Array(-2.047889, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03591188, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.018712, dtype=float32), 'eval/episode_train_reward': Array(-0.00107736, dtype=float32), 'eval/episode_x_position': Array(1.015413, dtype=float32), 'eval/episode_x_velocity': Array(-0.03591188, dtype=float32), 'eval/episode_y_position': Array(-0.00024179, dtype=float32), 'eval/episode_y_velocity': Array(-0.00149058, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0903644, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04288435, dtype=float32), 'eval/episode_reward_std': Array(0.17919958, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04288435, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2650616, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128653, dtype=float32), 'eval/episode_x_position_std': Array(0.09010424, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04288435, dtype=float32), 'eval/episode_y_position_std': Array(0.00557458, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01073071, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.714749813079834, 'eval/sps': 6179.171901906218, 'num_steps': 2995200}
{'eval/walltime': 12237.211643218994, 'training/sps': 127.13655182384322, 'training/walltime': 23666.382440567017, 'training/entropy_loss': Array(0.10488914, dtype=float32), 'training/policy_loss': Array(0.2702236, dtype=float32), 'training/total_loss': Array(0.37511274, dtype=float32), 'training/v_loss': Array(6.955899e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098532, dtype=float32), 'eval/episode_forward_reward': Array(-0.03404101, dtype=float32), 'eval/episode_reward': Array(-2.0287488, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03404101, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9936867, dtype=float32), 'eval/episode_train_reward': Array(-0.00102123, dtype=float32), 'eval/episode_x_position': Array(1.0079248, dtype=float32), 'eval/episode_x_velocity': Array(-0.03404101, dtype=float32), 'eval/episode_y_position': Array(1.7557759e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00207571, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586826, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04208587, dtype=float32), 'eval/episode_reward_std': Array(0.04837758, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04208587, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01960642, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126258, dtype=float32), 'eval/episode_x_position_std': Array(0.00590623, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04208587, dtype=float32), 'eval/episode_y_position_std': Array(0.0057517, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00685913, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71226668357849, 'eval/sps': 6179.912703687013, 'num_steps': 3000320}
{'eval/walltime': 12257.887609958649, 'training/sps': 127.16207132799018, 'training/walltime': 23706.646018743515, 'training/entropy_loss': Array(0.09950425, dtype=float32), 'training/policy_loss': Array(0.27026758, dtype=float32), 'training/total_loss': Array(0.36977184, dtype=float32), 'training/v_loss': Array(1.8253882e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093861, dtype=float32), 'eval/episode_forward_reward': Array(-0.0355825, dtype=float32), 'eval/episode_reward': Array(-2.0318942, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0355825, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952443, dtype=float32), 'eval/episode_train_reward': Array(-0.00106747, dtype=float32), 'eval/episode_x_position': Array(1.0074978, dtype=float32), 'eval/episode_x_velocity': Array(-0.0355825, dtype=float32), 'eval/episode_y_position': Array(7.64298e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00133469, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573256, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04211096, dtype=float32), 'eval/episode_reward_std': Array(0.04647538, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04211096, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01806323, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126333, dtype=float32), 'eval/episode_x_position_std': Array(0.00573399, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04211096, dtype=float32), 'eval/episode_y_position_std': Array(0.00593161, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01517067, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67596673965454, 'eval/sps': 6190.762522098092, 'num_steps': 3005440}
{'eval/walltime': 12278.580544948578, 'training/sps': 126.94329335179285, 'training/walltime': 23746.978988409042, 'training/entropy_loss': Array(0.09947096, dtype=float32), 'training/policy_loss': Array(0.2655211, dtype=float32), 'training/total_loss': Array(0.36499208, dtype=float32), 'training/v_loss': Array(1.510416e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087419, dtype=float32), 'eval/episode_forward_reward': Array(-0.04393934, dtype=float32), 'eval/episode_reward': Array(-2.0376954, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04393934, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9924378, dtype=float32), 'eval/episode_train_reward': Array(-0.00131818, dtype=float32), 'eval/episode_x_position': Array(1.0068731, dtype=float32), 'eval/episode_x_velocity': Array(-0.04393934, dtype=float32), 'eval/episode_y_position': Array(-0.00032892, dtype=float32), 'eval/episode_y_velocity': Array(-0.00278511, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00620041, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04425598, dtype=float32), 'eval/episode_reward_std': Array(0.05414725, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04425598, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02662585, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132768, dtype=float32), 'eval/episode_x_position_std': Array(0.00615877, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04425598, dtype=float32), 'eval/episode_y_position_std': Array(0.00546311, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01154979, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6929349899292, 'eval/sps': 6185.68608379115, 'num_steps': 3010560}
{'eval/walltime': 12299.246791362762, 'training/sps': 127.40641767179329, 'training/walltime': 23787.165347099304, 'training/entropy_loss': Array(0.10165313, dtype=float32), 'training/policy_loss': Array(-0.03183981, dtype=float32), 'training/total_loss': Array(0.06981333, dtype=float32), 'training/v_loss': Array(1.0479237e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091418, dtype=float32), 'eval/episode_forward_reward': Array(-0.03690195, dtype=float32), 'eval/episode_reward': Array(-2.0321002, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03690195, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994091, dtype=float32), 'eval/episode_train_reward': Array(-0.00110706, dtype=float32), 'eval/episode_x_position': Array(1.0072507, dtype=float32), 'eval/episode_x_velocity': Array(-0.03690195, dtype=float32), 'eval/episode_y_position': Array(-0.00050986, dtype=float32), 'eval/episode_y_velocity': Array(0.00015164, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567635, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04417766, dtype=float32), 'eval/episode_reward_std': Array(0.04893237, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04417766, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02041387, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132533, dtype=float32), 'eval/episode_x_position_std': Array(0.00566314, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04417766, dtype=float32), 'eval/episode_y_position_std': Array(0.00595016, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01065278, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66624641418457, 'eval/sps': 6193.67433421027, 'num_steps': 3015680}
{'eval/walltime': 12319.940779209137, 'training/sps': 127.11319440091799, 'training/walltime': 23827.444407224655, 'training/entropy_loss': Array(0.10499376, dtype=float32), 'training/policy_loss': Array(0.16378337, dtype=float32), 'training/total_loss': Array(0.26877713, dtype=float32), 'training/v_loss': Array(1.6593149e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171916, dtype=float32), 'eval/episode_forward_reward': Array(-0.04369416, dtype=float32), 'eval/episode_reward': Array(-2.055406, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04369416, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0182137, dtype=float32), 'eval/episode_train_reward': Array(-0.00131082, dtype=float32), 'eval/episode_x_position': Array(1.0153395, dtype=float32), 'eval/episode_x_velocity': Array(-0.04369416, dtype=float32), 'eval/episode_y_position': Array(0.00046089, dtype=float32), 'eval/episode_y_velocity': Array(-0.00135113, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08971723, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04258524, dtype=float32), 'eval/episode_reward_std': Array(0.17938769, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04258524, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26554635, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127756, dtype=float32), 'eval/episode_x_position_std': Array(0.08945003, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04258524, dtype=float32), 'eval/episode_y_position_std': Array(0.00604889, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01276629, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.69398784637451, 'eval/sps': 6185.371372121734, 'num_steps': 3020800}
{'eval/walltime': 12340.633764982224, 'training/sps': 127.41035895102796, 'training/walltime': 23867.629522800446, 'training/entropy_loss': Array(0.10801992, dtype=float32), 'training/policy_loss': Array(0.0618475, dtype=float32), 'training/total_loss': Array(0.16986763, dtype=float32), 'training/v_loss': Array(2.2169702e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092788, dtype=float32), 'eval/episode_forward_reward': Array(-0.03218659, dtype=float32), 'eval/episode_reward': Array(-2.0290837, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03218659, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959316, dtype=float32), 'eval/episode_train_reward': Array(-0.0009656, dtype=float32), 'eval/episode_x_position': Array(1.00736, dtype=float32), 'eval/episode_x_velocity': Array(-0.03218659, dtype=float32), 'eval/episode_y_position': Array(0.00043597, dtype=float32), 'eval/episode_y_velocity': Array(-0.00111232, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579941, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04207304, dtype=float32), 'eval/episode_reward_std': Array(0.04824086, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04207304, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01612953, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126219, dtype=float32), 'eval/episode_x_position_std': Array(0.00577897, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04207304, dtype=float32), 'eval/episode_y_position_std': Array(0.00551534, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0116762, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.692985773086548, 'eval/sps': 6185.67090334918, 'num_steps': 3025920}
{'eval/walltime': 12361.328781366348, 'training/sps': 127.16980945482726, 'training/walltime': 23907.890650987625, 'training/entropy_loss': Array(0.10513782, dtype=float32), 'training/policy_loss': Array(0.26697692, dtype=float32), 'training/total_loss': Array(0.37211475, dtype=float32), 'training/v_loss': Array(9.870877e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087152, dtype=float32), 'eval/episode_forward_reward': Array(-0.03995064, dtype=float32), 'eval/episode_reward': Array(-2.0353112, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03995064, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994162, dtype=float32), 'eval/episode_train_reward': Array(-0.00119852, dtype=float32), 'eval/episode_x_position': Array(1.0068567, dtype=float32), 'eval/episode_x_velocity': Array(-0.03995064, dtype=float32), 'eval/episode_y_position': Array(0.00063319, dtype=float32), 'eval/episode_y_velocity': Array(-0.0004123, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574456, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04264826, dtype=float32), 'eval/episode_reward_std': Array(0.04961788, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04264826, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02281211, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127945, dtype=float32), 'eval/episode_x_position_std': Array(0.0057328, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04264826, dtype=float32), 'eval/episode_y_position_std': Array(0.00564992, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01343796, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.695016384124756, 'eval/sps': 6185.0639605286515, 'num_steps': 3031040}
{'eval/walltime': 12382.06663775444, 'training/sps': 127.29440112756372, 'training/walltime': 23948.112372875214, 'training/entropy_loss': Array(0.10377848, dtype=float32), 'training/policy_loss': Array(-0.04021712, dtype=float32), 'training/total_loss': Array(0.06356137, dtype=float32), 'training/v_loss': Array(7.2024724e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0103121, dtype=float32), 'eval/episode_forward_reward': Array(-0.04111766, dtype=float32), 'eval/episode_reward': Array(-2.0366817, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04111766, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9943304, dtype=float32), 'eval/episode_train_reward': Array(-0.00123353, dtype=float32), 'eval/episode_x_position': Array(1.0084578, dtype=float32), 'eval/episode_x_velocity': Array(-0.04111766, dtype=float32), 'eval/episode_y_position': Array(0.00047452, dtype=float32), 'eval/episode_y_velocity': Array(-0.00261819, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00622966, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04327877, dtype=float32), 'eval/episode_reward_std': Array(0.04615776, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04327877, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02308015, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129836, dtype=float32), 'eval/episode_x_position_std': Array(0.00624466, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04327877, dtype=float32), 'eval/episode_y_position_std': Array(0.00582206, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01186461, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.73785638809204, 'eval/sps': 6172.286932872163, 'num_steps': 3036160}
{'eval/walltime': 12402.758593797684, 'training/sps': 126.98915601920764, 'training/walltime': 23988.430776119232, 'training/entropy_loss': Array(0.10241271, dtype=float32), 'training/policy_loss': Array(0.20709026, dtype=float32), 'training/total_loss': Array(0.30950296, dtype=float32), 'training/v_loss': Array(5.863113e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093734, dtype=float32), 'eval/episode_forward_reward': Array(-0.0397712, dtype=float32), 'eval/episode_reward': Array(-2.036474, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0397712, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955096, dtype=float32), 'eval/episode_train_reward': Array(-0.00119314, dtype=float32), 'eval/episode_x_position': Array(1.0075192, dtype=float32), 'eval/episode_x_velocity': Array(-0.0397712, dtype=float32), 'eval/episode_y_position': Array(-0.00021403, dtype=float32), 'eval/episode_y_velocity': Array(-0.00166049, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561874, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04298547, dtype=float32), 'eval/episode_reward_std': Array(0.04521071, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04298547, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01675224, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128956, dtype=float32), 'eval/episode_x_position_std': Array(0.00559872, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04298547, dtype=float32), 'eval/episode_y_position_std': Array(0.00590217, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01611318, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.691956043243408, 'eval/sps': 6185.978731662545, 'num_steps': 3041280}
{'eval/walltime': 12423.461553812027, 'training/sps': 127.02676806518357, 'training/walltime': 24028.737241268158, 'training/entropy_loss': Array(0.10199609, dtype=float32), 'training/policy_loss': Array(0.25748706, dtype=float32), 'training/total_loss': Array(0.35948318, dtype=float32), 'training/v_loss': Array(4.7982884e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088838, dtype=float32), 'eval/episode_forward_reward': Array(-0.04331271, dtype=float32), 'eval/episode_reward': Array(-2.039748, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04331271, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9951358, dtype=float32), 'eval/episode_train_reward': Array(-0.00129938, dtype=float32), 'eval/episode_x_position': Array(1.0070357, dtype=float32), 'eval/episode_x_velocity': Array(-0.04331271, dtype=float32), 'eval/episode_y_position': Array(-6.0918406e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00225558, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00618071, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04319232, dtype=float32), 'eval/episode_reward_std': Array(0.04768379, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04319232, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01687679, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129577, dtype=float32), 'eval/episode_x_position_std': Array(0.00615774, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04319232, dtype=float32), 'eval/episode_y_position_std': Array(0.00567476, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01511922, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70296001434326, 'eval/sps': 6182.690780029525, 'num_steps': 3046400}
{'eval/walltime': 12444.15588593483, 'training/sps': 127.2139059796832, 'training/walltime': 24068.98441362381, 'training/entropy_loss': Array(0.10133065, dtype=float32), 'training/policy_loss': Array(-0.08072604, dtype=float32), 'training/total_loss': Array(0.02060461, dtype=float32), 'training/v_loss': Array(4.680608e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085915, dtype=float32), 'eval/episode_forward_reward': Array(-0.03097447, dtype=float32), 'eval/episode_reward': Array(-2.0258257, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03097447, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9939222, dtype=float32), 'eval/episode_train_reward': Array(-0.00092923, dtype=float32), 'eval/episode_x_position': Array(1.0066745, dtype=float32), 'eval/episode_x_velocity': Array(-0.03097447, dtype=float32), 'eval/episode_y_position': Array(0.00077083, dtype=float32), 'eval/episode_y_velocity': Array(-0.0015096, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586146, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04083187, dtype=float32), 'eval/episode_reward_std': Array(0.04569619, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04083187, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02053172, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122496, dtype=float32), 'eval/episode_x_position_std': Array(0.00586319, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04083187, dtype=float32), 'eval/episode_y_position_std': Array(0.00530223, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0108156, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.694332122802734, 'eval/sps': 6185.268470633994, 'num_steps': 3051520}
{'eval/walltime': 12464.849741458893, 'training/sps': 126.80292086242373, 'training/walltime': 24109.362032413483, 'training/entropy_loss': Array(0.10147916, dtype=float32), 'training/policy_loss': Array(-0.03891816, dtype=float32), 'training/total_loss': Array(0.062561, dtype=float32), 'training/v_loss': Array(3.8284248e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090547, dtype=float32), 'eval/episode_forward_reward': Array(-0.04406561, dtype=float32), 'eval/episode_reward': Array(-2.041991, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04406561, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966035, dtype=float32), 'eval/episode_train_reward': Array(-0.00132197, dtype=float32), 'eval/episode_x_position': Array(1.007184, dtype=float32), 'eval/episode_x_velocity': Array(-0.04406561, dtype=float32), 'eval/episode_y_position': Array(6.632088e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00205064, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602743, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0433075, dtype=float32), 'eval/episode_reward_std': Array(0.04697035, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0433075, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01580156, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129923, dtype=float32), 'eval/episode_x_position_std': Array(0.00604537, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0433075, dtype=float32), 'eval/episode_y_position_std': Array(0.00576944, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01281482, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69385552406311, 'eval/sps': 6185.410923119656, 'num_steps': 3056640}
{'eval/walltime': 12485.550624608994, 'training/sps': 127.06280704095786, 'training/walltime': 24149.65706539154, 'training/entropy_loss': Array(0.10220105, dtype=float32), 'training/policy_loss': Array(-0.07671563, dtype=float32), 'training/total_loss': Array(0.02548542, dtype=float32), 'training/v_loss': Array(4.2781712e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009201, dtype=float32), 'eval/episode_forward_reward': Array(-0.03838795, dtype=float32), 'eval/episode_reward': Array(-2.033739, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03838795, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9941995, dtype=float32), 'eval/episode_train_reward': Array(-0.00115164, dtype=float32), 'eval/episode_x_position': Array(1.0073637, dtype=float32), 'eval/episode_x_velocity': Array(-0.03838795, dtype=float32), 'eval/episode_y_position': Array(0.00110617, dtype=float32), 'eval/episode_y_velocity': Array(-0.00157934, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580523, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04080096, dtype=float32), 'eval/episode_reward_std': Array(0.04636774, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04080096, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01993914, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122403, dtype=float32), 'eval/episode_x_position_std': Array(0.00579972, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04080096, dtype=float32), 'eval/episode_y_position_std': Array(0.00525751, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01122452, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.700883150100708, 'eval/sps': 6183.311072860062, 'num_steps': 3061760}
{'eval/walltime': 12506.282842636108, 'training/sps': 127.13104845812485, 'training/walltime': 24189.930468797684, 'training/entropy_loss': Array(0.103273, dtype=float32), 'training/policy_loss': Array(-0.07942569, dtype=float32), 'training/total_loss': Array(0.02384731, dtype=float32), 'training/v_loss': Array(2.37249e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095098, dtype=float32), 'eval/episode_forward_reward': Array(-0.03816746, dtype=float32), 'eval/episode_reward': Array(-2.0337117, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03816746, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994399, dtype=float32), 'eval/episode_train_reward': Array(-0.00114502, dtype=float32), 'eval/episode_x_position': Array(1.0076435, dtype=float32), 'eval/episode_x_velocity': Array(-0.03816746, dtype=float32), 'eval/episode_y_position': Array(0.00110978, dtype=float32), 'eval/episode_y_velocity': Array(-0.00131623, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566343, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04356176, dtype=float32), 'eval/episode_reward_std': Array(0.04757561, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04356176, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0180438, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130685, dtype=float32), 'eval/episode_x_position_std': Array(0.00561238, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04356176, dtype=float32), 'eval/episode_y_position_std': Array(0.0056761, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01342565, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.732218027114868, 'eval/sps': 6173.965556053566, 'num_steps': 3066880}
{'eval/walltime': 12527.04059290886, 'training/sps': 126.91652117056681, 'training/walltime': 24230.271946430206, 'training/entropy_loss': Array(0.10427295, dtype=float32), 'training/policy_loss': Array(-0.06180734, dtype=float32), 'training/total_loss': Array(0.04246561, dtype=float32), 'training/v_loss': Array(2.6818847e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171919, dtype=float32), 'eval/episode_forward_reward': Array(-0.04046853, dtype=float32), 'eval/episode_reward': Array(-2.0533257, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04046853, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0194554, dtype=float32), 'eval/episode_train_reward': Array(-0.00121406, dtype=float32), 'eval/episode_x_position': Array(1.0153137, dtype=float32), 'eval/episode_x_velocity': Array(-0.04046853, dtype=float32), 'eval/episode_y_position': Array(0.0012459, dtype=float32), 'eval/episode_y_velocity': Array(-0.00067818, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09006356, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0441331, dtype=float32), 'eval/episode_reward_std': Array(0.18163548, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0441331, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26499322, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132399, dtype=float32), 'eval/episode_x_position_std': Array(0.08979849, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0441331, dtype=float32), 'eval/episode_y_position_std': Array(0.00589262, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01738819, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.757750272750854, 'eval/sps': 6166.3715151264905, 'num_steps': 3072000}
{'eval/walltime': 12547.733122825623, 'training/sps': 127.14001952009347, 'training/walltime': 24270.542508125305, 'training/entropy_loss': Array(0.10485785, dtype=float32), 'training/policy_loss': Array(-0.04255727, dtype=float32), 'training/total_loss': Array(0.06230057, dtype=float32), 'training/v_loss': Array(2.5113334e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093166, dtype=float32), 'eval/episode_forward_reward': Array(-0.03910888, dtype=float32), 'eval/episode_reward': Array(-2.0346866, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03910888, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9944043, dtype=float32), 'eval/episode_train_reward': Array(-0.00117327, dtype=float32), 'eval/episode_x_position': Array(1.0074472, dtype=float32), 'eval/episode_x_velocity': Array(-0.03910888, dtype=float32), 'eval/episode_y_position': Array(-0.00010688, dtype=float32), 'eval/episode_y_velocity': Array(-0.00180274, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00653652, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04454347, dtype=float32), 'eval/episode_reward_std': Array(0.05167421, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04454347, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01962264, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013363, dtype=float32), 'eval/episode_x_position_std': Array(0.00648077, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04454347, dtype=float32), 'eval/episode_y_position_std': Array(0.00576106, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01342706, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.692529916763306, 'eval/sps': 6185.807173646052, 'num_steps': 3077120}
{'eval/walltime': 12568.437793254852, 'training/sps': 127.12499094135048, 'training/walltime': 24310.81783056259, 'training/entropy_loss': Array(0.10432141, dtype=float32), 'training/policy_loss': Array(0.26345253, dtype=float32), 'training/total_loss': Array(0.36777392, dtype=float32), 'training/v_loss': Array(1.790813e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089576, dtype=float32), 'eval/episode_forward_reward': Array(-0.04246365, dtype=float32), 'eval/episode_reward': Array(-2.038393, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04246365, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946554, dtype=float32), 'eval/episode_train_reward': Array(-0.00127391, dtype=float32), 'eval/episode_x_position': Array(1.0071295, dtype=float32), 'eval/episode_x_velocity': Array(-0.04246365, dtype=float32), 'eval/episode_y_position': Array(0.00056196, dtype=float32), 'eval/episode_y_velocity': Array(-0.001791, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584712, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04365285, dtype=float32), 'eval/episode_reward_std': Array(0.05131981, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04365285, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01931245, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130959, dtype=float32), 'eval/episode_x_position_std': Array(0.00584596, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04365285, dtype=float32), 'eval/episode_y_position_std': Array(0.00572737, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01417448, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.704670429229736, 'eval/sps': 6182.180027328352, 'num_steps': 3082240}
{'eval/walltime': 12589.135181427002, 'training/sps': 127.18638001471287, 'training/walltime': 24351.073713302612, 'training/entropy_loss': Array(0.10456702, dtype=float32), 'training/policy_loss': Array(-0.02961201, dtype=float32), 'training/total_loss': Array(0.07495501, dtype=float32), 'training/v_loss': Array(1.1617253e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.010083, dtype=float32), 'eval/episode_forward_reward': Array(-0.04332078, dtype=float32), 'eval/episode_reward': Array(-2.0412936, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04332078, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966736, dtype=float32), 'eval/episode_train_reward': Array(-0.00129962, dtype=float32), 'eval/episode_x_position': Array(1.0082461, dtype=float32), 'eval/episode_x_velocity': Array(-0.04332078, dtype=float32), 'eval/episode_y_position': Array(-0.00082299, dtype=float32), 'eval/episode_y_velocity': Array(-0.0015065, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00632641, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0436484, dtype=float32), 'eval/episode_reward_std': Array(0.04757493, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0436484, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01213292, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130945, dtype=float32), 'eval/episode_x_position_std': Array(0.00632893, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0436484, dtype=float32), 'eval/episode_y_position_std': Array(0.00575056, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01026359, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.697388172149658, 'eval/sps': 6184.355191841858, 'num_steps': 3087360}
{'eval/walltime': 12609.83127784729, 'training/sps': 127.25606487320034, 'training/walltime': 24391.307552099228, 'training/entropy_loss': Array(0.10621821, dtype=float32), 'training/policy_loss': Array(0.22360063, dtype=float32), 'training/total_loss': Array(0.32981881, dtype=float32), 'training/v_loss': Array(9.277249e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0079358, dtype=float32), 'eval/episode_forward_reward': Array(-0.04141739, dtype=float32), 'eval/episode_reward': Array(-2.035614, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04141739, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.992954, dtype=float32), 'eval/episode_train_reward': Array(-0.00124252, dtype=float32), 'eval/episode_x_position': Array(1.006067, dtype=float32), 'eval/episode_x_velocity': Array(-0.04141739, dtype=float32), 'eval/episode_y_position': Array(-9.0907226e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0022315, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00527802, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04543044, dtype=float32), 'eval/episode_reward_std': Array(0.05456235, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04543044, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02275261, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136291, dtype=float32), 'eval/episode_x_position_std': Array(0.00529167, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04543044, dtype=float32), 'eval/episode_y_position_std': Array(0.00569761, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01363179, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.696096420288086, 'eval/sps': 6184.74118986629, 'num_steps': 3092480}
{'eval/walltime': 12630.565121173859, 'training/sps': 127.18935475214823, 'training/walltime': 24431.56249332428, 'training/entropy_loss': Array(0.10681156, dtype=float32), 'training/policy_loss': Array(0.2641105, dtype=float32), 'training/total_loss': Array(0.3709221, dtype=float32), 'training/v_loss': Array(1.4128787e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096556, dtype=float32), 'eval/episode_forward_reward': Array(-0.04169904, dtype=float32), 'eval/episode_reward': Array(-2.0394073, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04169904, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996457, dtype=float32), 'eval/episode_train_reward': Array(-0.00125097, dtype=float32), 'eval/episode_x_position': Array(1.0078104, dtype=float32), 'eval/episode_x_velocity': Array(-0.04169904, dtype=float32), 'eval/episode_y_position': Array(0.0006705, dtype=float32), 'eval/episode_y_velocity': Array(-0.00185251, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00604286, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04644372, dtype=float32), 'eval/episode_reward_std': Array(0.05097372, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04644372, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01371804, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139331, dtype=float32), 'eval/episode_x_position_std': Array(0.00608892, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04644372, dtype=float32), 'eval/episode_y_position_std': Array(0.00555185, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01201892, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.733843326568604, 'eval/sps': 6173.48158679193, 'num_steps': 3097600}
{'eval/walltime': 12651.289801120758, 'training/sps': 127.1167729375913, 'training/walltime': 24471.84041953087, 'training/entropy_loss': Array(0.10759152, dtype=float32), 'training/policy_loss': Array(0.26620573, dtype=float32), 'training/total_loss': Array(0.37379727, dtype=float32), 'training/v_loss': Array(4.930451e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093683, dtype=float32), 'eval/episode_forward_reward': Array(-0.04080155, dtype=float32), 'eval/episode_reward': Array(-2.035285, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04080155, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9932594, dtype=float32), 'eval/episode_train_reward': Array(-0.00122405, dtype=float32), 'eval/episode_x_position': Array(1.0074794, dtype=float32), 'eval/episode_x_velocity': Array(-0.04080155, dtype=float32), 'eval/episode_y_position': Array(-0.00012568, dtype=float32), 'eval/episode_y_velocity': Array(-0.00205113, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00545354, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04265577, dtype=float32), 'eval/episode_reward_std': Array(0.04902415, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04265577, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02043652, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127967, dtype=float32), 'eval/episode_x_position_std': Array(0.00548222, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04265577, dtype=float32), 'eval/episode_y_position_std': Array(0.00641056, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00995281, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.724679946899414, 'eval/sps': 6176.211180484352, 'num_steps': 3102720}
{'eval/walltime': 12671.980418682098, 'training/sps': 127.0759229359343, 'training/walltime': 24512.131293535233, 'training/entropy_loss': Array(0.10723668, dtype=float32), 'training/policy_loss': Array(0.2661006, dtype=float32), 'training/total_loss': Array(0.37333724, dtype=float32), 'training/v_loss': Array(8.1161945e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092883, dtype=float32), 'eval/episode_forward_reward': Array(-0.03743754, dtype=float32), 'eval/episode_reward': Array(-2.0364249, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03743754, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978642, dtype=float32), 'eval/episode_train_reward': Array(-0.00112313, dtype=float32), 'eval/episode_x_position': Array(1.007426, dtype=float32), 'eval/episode_x_velocity': Array(-0.03743754, dtype=float32), 'eval/episode_y_position': Array(-0.00056299, dtype=float32), 'eval/episode_y_velocity': Array(-0.00199803, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574264, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04465194, dtype=float32), 'eval/episode_reward_std': Array(0.04659532, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04465194, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01031879, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133956, dtype=float32), 'eval/episode_x_position_std': Array(0.00566354, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04465194, dtype=float32), 'eval/episode_y_position_std': Array(0.00574661, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0144451, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.690617561340332, 'eval/sps': 6186.378904376607, 'num_steps': 3107840}
{'eval/walltime': 12692.723500967026, 'training/sps': 127.22795458381846, 'training/walltime': 24552.37402176857, 'training/entropy_loss': Array(0.10998106, dtype=float32), 'training/policy_loss': Array(0.26644713, dtype=float32), 'training/total_loss': Array(0.3764282, dtype=float32), 'training/v_loss': Array(1.829049e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094767, dtype=float32), 'eval/episode_forward_reward': Array(-0.03936499, dtype=float32), 'eval/episode_reward': Array(-2.0365987, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03936499, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960527, dtype=float32), 'eval/episode_train_reward': Array(-0.00118095, dtype=float32), 'eval/episode_x_position': Array(1.0075883, dtype=float32), 'eval/episode_x_velocity': Array(-0.03936499, dtype=float32), 'eval/episode_y_position': Array(0.00013064, dtype=float32), 'eval/episode_y_velocity': Array(-0.00129474, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00621097, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04599434, dtype=float32), 'eval/episode_reward_std': Array(0.05163031, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04599434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01506721, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137983, dtype=float32), 'eval/episode_x_position_std': Array(0.00616113, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04599434, dtype=float32), 'eval/episode_y_position_std': Array(0.00613762, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00958369, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.743082284927368, 'eval/sps': 6170.731921215449, 'num_steps': 3112960}
{'eval/walltime': 12713.463329553604, 'training/sps': 127.14769473819815, 'training/walltime': 24592.642152547836, 'training/entropy_loss': Array(0.109047, dtype=float32), 'training/policy_loss': Array(0.26961058, dtype=float32), 'training/total_loss': Array(0.37865758, dtype=float32), 'training/v_loss': Array(2.1136351e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008946, dtype=float32), 'eval/episode_forward_reward': Array(-0.03718212, dtype=float32), 'eval/episode_reward': Array(-2.033011, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03718212, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947133, dtype=float32), 'eval/episode_train_reward': Array(-0.00111546, dtype=float32), 'eval/episode_x_position': Array(1.0070355, dtype=float32), 'eval/episode_x_velocity': Array(-0.03718212, dtype=float32), 'eval/episode_y_position': Array(-5.8638107e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00481801, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576304, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04366215, dtype=float32), 'eval/episode_reward_std': Array(0.0481123, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04366215, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01761523, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130986, dtype=float32), 'eval/episode_x_position_std': Array(0.00574849, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04366215, dtype=float32), 'eval/episode_y_position_std': Array(0.00585528, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01815389, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.73982858657837, 'eval/sps': 6171.699995767288, 'num_steps': 3118080}
{'eval/walltime': 12734.187958955765, 'training/sps': 126.99397646572878, 'training/walltime': 24632.959025382996, 'training/entropy_loss': Array(0.11045472, dtype=float32), 'training/policy_loss': Array(0.26718378, dtype=float32), 'training/total_loss': Array(0.37763852, dtype=float32), 'training/v_loss': Array(4.8777288e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089989, dtype=float32), 'eval/episode_forward_reward': Array(-0.03553461, dtype=float32), 'eval/episode_reward': Array(-2.0331898, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03553461, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965892, dtype=float32), 'eval/episode_train_reward': Array(-0.00106604, dtype=float32), 'eval/episode_x_position': Array(1.0071065, dtype=float32), 'eval/episode_x_velocity': Array(-0.03553461, dtype=float32), 'eval/episode_y_position': Array(-0.00089332, dtype=float32), 'eval/episode_y_velocity': Array(-0.00232352, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581993, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04315285, dtype=float32), 'eval/episode_reward_std': Array(0.04776737, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04315285, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0143878, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129459, dtype=float32), 'eval/episode_x_position_std': Array(0.00580543, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04315285, dtype=float32), 'eval/episode_y_position_std': Array(0.00601808, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01429357, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.724629402160645, 'eval/sps': 6176.226243478948, 'num_steps': 3123200}
{'eval/walltime': 12754.920636892319, 'training/sps': 127.02776891353479, 'training/walltime': 24673.265172958374, 'training/entropy_loss': Array(0.11047688, dtype=float32), 'training/policy_loss': Array(0.2708495, dtype=float32), 'training/total_loss': Array(0.38132635, dtype=float32), 'training/v_loss': Array(7.8622414e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0102623, dtype=float32), 'eval/episode_forward_reward': Array(-0.03823677, dtype=float32), 'eval/episode_reward': Array(-2.035924, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03823677, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99654, dtype=float32), 'eval/episode_train_reward': Array(-0.0011471, dtype=float32), 'eval/episode_x_position': Array(1.0083833, dtype=float32), 'eval/episode_x_velocity': Array(-0.03823677, dtype=float32), 'eval/episode_y_position': Array(0.00043917, dtype=float32), 'eval/episode_y_velocity': Array(-0.00436447, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0055265, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04423916, dtype=float32), 'eval/episode_reward_std': Array(0.04819492, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04423916, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01511399, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132717, dtype=float32), 'eval/episode_x_position_std': Array(0.00552716, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04423916, dtype=float32), 'eval/episode_y_position_std': Array(0.00512023, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01486455, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.732677936553955, 'eval/sps': 6173.828600034449, 'num_steps': 3128320}
{'eval/walltime': 12775.664691209793, 'training/sps': 127.05011553188336, 'training/walltime': 24713.564231157303, 'training/entropy_loss': Array(0.11072063, dtype=float32), 'training/policy_loss': Array(0.27127868, dtype=float32), 'training/total_loss': Array(0.3819993, dtype=float32), 'training/v_loss': Array(1.4579595e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098032, dtype=float32), 'eval/episode_forward_reward': Array(-0.03849125, dtype=float32), 'eval/episode_reward': Array(-2.0317082, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03849125, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.992062, dtype=float32), 'eval/episode_train_reward': Array(-0.00115474, dtype=float32), 'eval/episode_x_position': Array(1.0079021, dtype=float32), 'eval/episode_x_velocity': Array(-0.03849125, dtype=float32), 'eval/episode_y_position': Array(0.0002139, dtype=float32), 'eval/episode_y_velocity': Array(-0.00308195, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569074, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0431118, dtype=float32), 'eval/episode_reward_std': Array(0.05088106, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0431118, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02460581, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129335, dtype=float32), 'eval/episode_x_position_std': Array(0.00572336, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0431118, dtype=float32), 'eval/episode_y_position_std': Array(0.0058221, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01076662, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.744054317474365, 'eval/sps': 6170.442770783502, 'num_steps': 3133440}
{'eval/walltime': 12796.399558067322, 'training/sps': 127.27324702673651, 'training/walltime': 24753.79263830185, 'training/entropy_loss': Array(0.10896298, dtype=float32), 'training/policy_loss': Array(0.27146977, dtype=float32), 'training/total_loss': Array(0.38043272, dtype=float32), 'training/v_loss': Array(1.1587223e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0181789, dtype=float32), 'eval/episode_forward_reward': Array(-0.03635022, dtype=float32), 'eval/episode_reward': Array(-2.048768, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03635022, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0191398, dtype=float32), 'eval/episode_train_reward': Array(-0.00109051, dtype=float32), 'eval/episode_x_position': Array(1.0162501, dtype=float32), 'eval/episode_x_velocity': Array(-0.03635022, dtype=float32), 'eval/episode_y_position': Array(-0.00050258, dtype=float32), 'eval/episode_y_velocity': Array(-0.00315416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09039368, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04184386, dtype=float32), 'eval/episode_reward_std': Array(0.17991407, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04184386, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26492932, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125532, dtype=float32), 'eval/episode_x_position_std': Array(0.09012651, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04184386, dtype=float32), 'eval/episode_y_position_std': Array(0.0057973, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01200645, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.734866857528687, 'eval/sps': 6173.176846492462, 'num_steps': 3138560}
{'eval/walltime': 12817.122834205627, 'training/sps': 127.19083426314637, 'training/walltime': 24794.047111272812, 'training/entropy_loss': Array(0.10885853, dtype=float32), 'training/policy_loss': Array(0.2697574, dtype=float32), 'training/total_loss': Array(0.37861592, dtype=float32), 'training/v_loss': Array(1.7342934e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091902, dtype=float32), 'eval/episode_forward_reward': Array(-0.04178821, dtype=float32), 'eval/episode_reward': Array(-2.039884, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04178821, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968424, dtype=float32), 'eval/episode_train_reward': Array(-0.00125365, dtype=float32), 'eval/episode_x_position': Array(1.0073494, dtype=float32), 'eval/episode_x_velocity': Array(-0.04178821, dtype=float32), 'eval/episode_y_position': Array(-0.00014176, dtype=float32), 'eval/episode_y_velocity': Array(-0.00230382, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576637, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04301741, dtype=float32), 'eval/episode_reward_std': Array(0.04512672, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04301741, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01382907, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129052, dtype=float32), 'eval/episode_x_position_std': Array(0.00575259, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04301741, dtype=float32), 'eval/episode_y_position_std': Array(0.00603597, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01186436, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.723276138305664, 'eval/sps': 6176.629561162876, 'num_steps': 3143680}
{'eval/walltime': 12837.833437681198, 'training/sps': 127.26387553340564, 'training/walltime': 24834.278480768204, 'training/entropy_loss': Array(0.10795097, dtype=float32), 'training/policy_loss': Array(0.27022952, dtype=float32), 'training/total_loss': Array(0.3781805, dtype=float32), 'training/v_loss': Array(3.488863e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088413, dtype=float32), 'eval/episode_forward_reward': Array(-0.04374927, dtype=float32), 'eval/episode_reward': Array(-2.0399697, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04374927, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9949079, dtype=float32), 'eval/episode_train_reward': Array(-0.00131248, dtype=float32), 'eval/episode_x_position': Array(1.0070106, dtype=float32), 'eval/episode_x_velocity': Array(-0.04374927, dtype=float32), 'eval/episode_y_position': Array(0.00036046, dtype=float32), 'eval/episode_y_velocity': Array(-0.00203898, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584395, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04427341, dtype=float32), 'eval/episode_reward_std': Array(0.05196411, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04427341, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02040775, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013282, dtype=float32), 'eval/episode_x_position_std': Array(0.00581066, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04427341, dtype=float32), 'eval/episode_y_position_std': Array(0.00556486, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01576956, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71060347557068, 'eval/sps': 6180.408994406329, 'num_steps': 3148800}
{'eval/walltime': 12858.512566566467, 'training/sps': 126.96509530610636, 'training/walltime': 24874.604524612427, 'training/entropy_loss': Array(0.10697037, dtype=float32), 'training/policy_loss': Array(0.268327, dtype=float32), 'training/total_loss': Array(0.3752974, dtype=float32), 'training/v_loss': Array(9.960485e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093013, dtype=float32), 'eval/episode_forward_reward': Array(-0.03841411, dtype=float32), 'eval/episode_reward': Array(-2.0369225, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03841411, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997356, dtype=float32), 'eval/episode_train_reward': Array(-0.00115242, dtype=float32), 'eval/episode_x_position': Array(1.0074304, dtype=float32), 'eval/episode_x_velocity': Array(-0.03841411, dtype=float32), 'eval/episode_y_position': Array(1.6091966e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00128184, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00565502, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04298366, dtype=float32), 'eval/episode_reward_std': Array(0.04594712, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04298366, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01234702, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128951, dtype=float32), 'eval/episode_x_position_std': Array(0.0056477, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04298366, dtype=float32), 'eval/episode_y_position_std': Array(0.0056473, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01096086, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.679128885269165, 'eval/sps': 6189.815862658565, 'num_steps': 3153920}
{'eval/walltime': 12879.187925577164, 'training/sps': 127.25190088677799, 'training/walltime': 24914.839679956436, 'training/entropy_loss': Array(0.10745269, dtype=float32), 'training/policy_loss': Array(0.26552165, dtype=float32), 'training/total_loss': Array(0.37297434, dtype=float32), 'training/v_loss': Array(8.754176e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0162714, dtype=float32), 'eval/episode_forward_reward': Array(-0.04521393, dtype=float32), 'eval/episode_reward': Array(-2.0585341, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04521393, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0197763, dtype=float32), 'eval/episode_train_reward': Array(-0.00135642, dtype=float32), 'eval/episode_x_position': Array(1.0144031, dtype=float32), 'eval/episode_x_velocity': Array(-0.04521393, dtype=float32), 'eval/episode_y_position': Array(-0.00029945, dtype=float32), 'eval/episode_y_velocity': Array(-0.00281644, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08955013, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04305837, dtype=float32), 'eval/episode_reward_std': Array(0.17990115, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04305837, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26487896, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129175, dtype=float32), 'eval/episode_x_position_std': Array(0.08928159, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04305837, dtype=float32), 'eval/episode_y_position_std': Array(0.00548677, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01326324, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.67535901069641, 'eval/sps': 6190.944492609735, 'num_steps': 3159040}
{'eval/walltime': 12899.88614487648, 'training/sps': 127.16770991665616, 'training/walltime': 24955.101472854614, 'training/entropy_loss': Array(0.10805893, dtype=float32), 'training/policy_loss': Array(0.26965746, dtype=float32), 'training/total_loss': Array(0.3777164, dtype=float32), 'training/v_loss': Array(8.608066e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008713, dtype=float32), 'eval/episode_forward_reward': Array(-0.04014629, dtype=float32), 'eval/episode_reward': Array(-2.0360599, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04014629, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947093, dtype=float32), 'eval/episode_train_reward': Array(-0.00120439, dtype=float32), 'eval/episode_x_position': Array(1.0068307, dtype=float32), 'eval/episode_x_velocity': Array(-0.04014629, dtype=float32), 'eval/episode_y_position': Array(0.00071013, dtype=float32), 'eval/episode_y_velocity': Array(-0.00189102, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00624461, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04441054, dtype=float32), 'eval/episode_reward_std': Array(0.04833161, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04441054, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01919622, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133232, dtype=float32), 'eval/episode_x_position_std': Array(0.00625838, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04441054, dtype=float32), 'eval/episode_y_position_std': Array(0.00610238, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01168673, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.698219299316406, 'eval/sps': 6184.10686199597, 'num_steps': 3164160}
{'eval/walltime': 12920.613448858261, 'training/sps': 126.88904725996836, 'training/walltime': 24995.4516851902, 'training/entropy_loss': Array(0.10590094, dtype=float32), 'training/policy_loss': Array(0.26990727, dtype=float32), 'training/total_loss': Array(0.37580824, dtype=float32), 'training/v_loss': Array(5.288773e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090292, dtype=float32), 'eval/episode_forward_reward': Array(-0.0340989, dtype=float32), 'eval/episode_reward': Array(-2.033711, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0340989, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985893, dtype=float32), 'eval/episode_train_reward': Array(-0.00102297, dtype=float32), 'eval/episode_x_position': Array(1.0070994, dtype=float32), 'eval/episode_x_velocity': Array(-0.0340989, dtype=float32), 'eval/episode_y_position': Array(-0.00051903, dtype=float32), 'eval/episode_y_velocity': Array(0.00062752, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00620878, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04260872, dtype=float32), 'eval/episode_reward_std': Array(0.04565302, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04260872, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00815181, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127826, dtype=float32), 'eval/episode_x_position_std': Array(0.00618198, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04260872, dtype=float32), 'eval/episode_y_position_std': Array(0.00576904, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0196604, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.727303981781006, 'eval/sps': 6175.429284604988, 'num_steps': 3169280}
{'eval/walltime': 12941.317062616348, 'training/sps': 127.05521949448843, 'training/walltime': 25035.749124526978, 'training/entropy_loss': Array(0.10645083, dtype=float32), 'training/policy_loss': Array(0.03930069, dtype=float32), 'training/total_loss': Array(0.14575152, dtype=float32), 'training/v_loss': Array(3.521396e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095077, dtype=float32), 'eval/episode_forward_reward': Array(-0.04171564, dtype=float32), 'eval/episode_reward': Array(-2.038145, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04171564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995178, dtype=float32), 'eval/episode_train_reward': Array(-0.00125147, dtype=float32), 'eval/episode_x_position': Array(1.0076585, dtype=float32), 'eval/episode_x_velocity': Array(-0.04171564, dtype=float32), 'eval/episode_y_position': Array(-0.0002655, dtype=float32), 'eval/episode_y_velocity': Array(-0.00293837, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0056754, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04455486, dtype=float32), 'eval/episode_reward_std': Array(0.05086903, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04455486, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01826625, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133665, dtype=float32), 'eval/episode_x_position_std': Array(0.0056687, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04455486, dtype=float32), 'eval/episode_y_position_std': Array(0.00557015, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01214294, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.703613758087158, 'eval/sps': 6182.495553463519, 'num_steps': 3174400}
{'eval/walltime': 12962.026141881943, 'training/sps': 127.28824956857105, 'training/walltime': 25075.97279024124, 'training/entropy_loss': Array(0.10728714, dtype=float32), 'training/policy_loss': Array(0.26752526, dtype=float32), 'training/total_loss': Array(0.37481236, dtype=float32), 'training/v_loss': Array(2.9495667e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089176, dtype=float32), 'eval/episode_forward_reward': Array(-0.04089492, dtype=float32), 'eval/episode_reward': Array(-2.036903, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04089492, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994781, dtype=float32), 'eval/episode_train_reward': Array(-0.00122685, dtype=float32), 'eval/episode_x_position': Array(1.0070689, dtype=float32), 'eval/episode_x_velocity': Array(-0.04089492, dtype=float32), 'eval/episode_y_position': Array(-0.00045332, dtype=float32), 'eval/episode_y_velocity': Array(-0.00106691, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575222, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04510814, dtype=float32), 'eval/episode_reward_std': Array(0.0526874, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04510814, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01903007, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135324, dtype=float32), 'eval/episode_x_position_std': Array(0.00572785, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04510814, dtype=float32), 'eval/episode_y_position_std': Array(0.00534705, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01344818, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.709079265594482, 'eval/sps': 6180.863878997065, 'num_steps': 3179520}
{'eval/walltime': 12982.760847091675, 'training/sps': 127.06394002593166, 'training/walltime': 25116.2674639225, 'training/entropy_loss': Array(0.1104878, dtype=float32), 'training/policy_loss': Array(0.2681619, dtype=float32), 'training/total_loss': Array(0.3786497, dtype=float32), 'training/v_loss': Array(7.96021e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094541, dtype=float32), 'eval/episode_forward_reward': Array(-0.04052899, dtype=float32), 'eval/episode_reward': Array(-2.0364337, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04052899, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946887, dtype=float32), 'eval/episode_train_reward': Array(-0.00121587, dtype=float32), 'eval/episode_x_position': Array(1.0075753, dtype=float32), 'eval/episode_x_velocity': Array(-0.04052899, dtype=float32), 'eval/episode_y_position': Array(-0.00012318, dtype=float32), 'eval/episode_y_velocity': Array(-0.00171627, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575999, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0437302, dtype=float32), 'eval/episode_reward_std': Array(0.0496315, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0437302, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02124804, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131191, dtype=float32), 'eval/episode_x_position_std': Array(0.00575015, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0437302, dtype=float32), 'eval/episode_y_position_std': Array(0.0055373, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01560366, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.734705209732056, 'eval/sps': 6173.224972589523, 'num_steps': 3184640}
{'eval/walltime': 13003.487902879715, 'training/sps': 127.22198128686959, 'training/walltime': 25156.512081623077, 'training/entropy_loss': Array(0.10968289, dtype=float32), 'training/policy_loss': Array(0.2691669, dtype=float32), 'training/total_loss': Array(0.3788498, dtype=float32), 'training/v_loss': Array(2.1216952e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096023, dtype=float32), 'eval/episode_forward_reward': Array(-0.04556139, dtype=float32), 'eval/episode_reward': Array(-2.0433474, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04556139, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964192, dtype=float32), 'eval/episode_train_reward': Array(-0.00136684, dtype=float32), 'eval/episode_x_position': Array(1.0077529, dtype=float32), 'eval/episode_x_velocity': Array(-0.04556139, dtype=float32), 'eval/episode_y_position': Array(0.00015716, dtype=float32), 'eval/episode_y_velocity': Array(-0.00247565, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586144, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04471232, dtype=float32), 'eval/episode_reward_std': Array(0.04870486, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04471232, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01395357, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134137, dtype=float32), 'eval/episode_x_position_std': Array(0.00580742, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04471232, dtype=float32), 'eval/episode_y_position_std': Array(0.0063665, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00971948, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72705578804016, 'eval/sps': 6175.50323157127, 'num_steps': 3189760}
{'eval/walltime': 13024.219895839691, 'training/sps': 127.10750045852271, 'training/walltime': 25196.792946100235, 'training/entropy_loss': Array(0.10892761, dtype=float32), 'training/policy_loss': Array(0.26643378, dtype=float32), 'training/total_loss': Array(0.37536138, dtype=float32), 'training/v_loss': Array(6.3819183e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089121, dtype=float32), 'eval/episode_forward_reward': Array(-0.03304689, dtype=float32), 'eval/episode_reward': Array(-2.030803, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03304689, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996765, dtype=float32), 'eval/episode_train_reward': Array(-0.00099141, dtype=float32), 'eval/episode_x_position': Array(1.0070348, dtype=float32), 'eval/episode_x_velocity': Array(-0.03304689, dtype=float32), 'eval/episode_y_position': Array(-0.00093561, dtype=float32), 'eval/episode_y_velocity': Array(-0.00317342, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00657078, dtype=float32), 'eval/episode_forward_reward_std': Array(0.041649, dtype=float32), 'eval/episode_reward_std': Array(0.04395215, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.041649, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01392264, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124947, dtype=float32), 'eval/episode_x_position_std': Array(0.00655858, dtype=float32), 'eval/episode_x_velocity_std': Array(0.041649, dtype=float32), 'eval/episode_y_position_std': Array(0.00552549, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01473369, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.731992959976196, 'eval/sps': 6174.0325808092, 'num_steps': 3194880}
{'eval/walltime': 13044.947694063187, 'training/sps': 127.0264697673369, 'training/walltime': 25237.099505901337, 'training/entropy_loss': Array(0.11130828, dtype=float32), 'training/policy_loss': Array(0.2699012, dtype=float32), 'training/total_loss': Array(0.38120946, dtype=float32), 'training/v_loss': Array(1.0454166e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.00932, dtype=float32), 'eval/episode_forward_reward': Array(-0.04063322, dtype=float32), 'eval/episode_reward': Array(-2.0365398, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04063322, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946876, dtype=float32), 'eval/episode_train_reward': Array(-0.001219, dtype=float32), 'eval/episode_x_position': Array(1.00747, dtype=float32), 'eval/episode_x_velocity': Array(-0.04063322, dtype=float32), 'eval/episode_y_position': Array(-0.00071748, dtype=float32), 'eval/episode_y_velocity': Array(-0.00448629, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584082, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0427505, dtype=float32), 'eval/episode_reward_std': Array(0.05066583, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0427505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01909168, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128252, dtype=float32), 'eval/episode_x_position_std': Array(0.00588053, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0427505, dtype=float32), 'eval/episode_y_position_std': Array(0.00561409, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01771232, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.727798223495483, 'eval/sps': 6175.28203525779, 'num_steps': 3200000}
{'eval/walltime': 13065.642601013184, 'training/sps': 127.02409245119853, 'training/walltime': 25277.406820058823, 'training/entropy_loss': Array(0.10890882, dtype=float32), 'training/policy_loss': Array(0.27027038, dtype=float32), 'training/total_loss': Array(0.3791792, dtype=float32), 'training/v_loss': Array(8.617673e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099546, dtype=float32), 'eval/episode_forward_reward': Array(-0.04691049, dtype=float32), 'eval/episode_reward': Array(-2.0401342, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04691049, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9918165, dtype=float32), 'eval/episode_train_reward': Array(-0.00140731, dtype=float32), 'eval/episode_x_position': Array(1.0081122, dtype=float32), 'eval/episode_x_velocity': Array(-0.04691049, dtype=float32), 'eval/episode_y_position': Array(0.00042422, dtype=float32), 'eval/episode_y_velocity': Array(-0.00154293, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566937, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04658433, dtype=float32), 'eval/episode_reward_std': Array(0.05081755, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04658433, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02453865, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139753, dtype=float32), 'eval/episode_x_position_std': Array(0.00564373, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04658433, dtype=float32), 'eval/episode_y_position_std': Array(0.0055679, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01099431, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69490694999695, 'eval/sps': 6185.096666985442, 'num_steps': 3205120}
{'eval/walltime': 13086.340885400772, 'training/sps': 127.44756291074741, 'training/walltime': 25317.580204963684, 'training/entropy_loss': Array(0.10916202, dtype=float32), 'training/policy_loss': Array(0.27084732, dtype=float32), 'training/total_loss': Array(0.38000935, dtype=float32), 'training/v_loss': Array(3.9889345e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100284, dtype=float32), 'eval/episode_forward_reward': Array(-0.03928373, dtype=float32), 'eval/episode_reward': Array(-2.0362434, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03928373, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995781, dtype=float32), 'eval/episode_train_reward': Array(-0.00117851, dtype=float32), 'eval/episode_x_position': Array(1.0081669, dtype=float32), 'eval/episode_x_velocity': Array(-0.03928373, dtype=float32), 'eval/episode_y_position': Array(0.00015073, dtype=float32), 'eval/episode_y_velocity': Array(-0.00232084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574917, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04437627, dtype=float32), 'eval/episode_reward_std': Array(0.04750293, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04437627, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01440816, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133129, dtype=float32), 'eval/episode_x_position_std': Array(0.00578442, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04437627, dtype=float32), 'eval/episode_y_position_std': Array(0.00561934, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00969049, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6982843875885, 'eval/sps': 6184.087415319977, 'num_steps': 3210240}
{'eval/walltime': 13107.019171237946, 'training/sps': 127.09876642472578, 'training/walltime': 25357.863837480545, 'training/entropy_loss': Array(0.10716778, dtype=float32), 'training/policy_loss': Array(0.27010196, dtype=float32), 'training/total_loss': Array(0.37726974, dtype=float32), 'training/v_loss': Array(1.4742879e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089465, dtype=float32), 'eval/episode_forward_reward': Array(-0.04283781, dtype=float32), 'eval/episode_reward': Array(-2.0402265, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04283781, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961033, dtype=float32), 'eval/episode_train_reward': Array(-0.00128513, dtype=float32), 'eval/episode_x_position': Array(1.007089, dtype=float32), 'eval/episode_x_velocity': Array(-0.04283781, dtype=float32), 'eval/episode_y_position': Array(-0.00040959, dtype=float32), 'eval/episode_y_velocity': Array(-0.00368433, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00590011, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04358518, dtype=float32), 'eval/episode_reward_std': Array(0.05167301, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04358518, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02103952, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130756, dtype=float32), 'eval/episode_x_position_std': Array(0.00587032, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04358518, dtype=float32), 'eval/episode_y_position_std': Array(0.00571664, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01562206, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.678285837173462, 'eval/sps': 6190.068219769636, 'num_steps': 3215360}
{'eval/walltime': 13127.72798371315, 'training/sps': 127.35423270456454, 'training/walltime': 25398.06666302681, 'training/entropy_loss': Array(0.10697676, dtype=float32), 'training/policy_loss': Array(0.2690575, dtype=float32), 'training/total_loss': Array(0.37603432, dtype=float32), 'training/v_loss': Array(4.7299387e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009553, dtype=float32), 'eval/episode_forward_reward': Array(-0.04348671, dtype=float32), 'eval/episode_reward': Array(-2.0391755, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04348671, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9943843, dtype=float32), 'eval/episode_train_reward': Array(-0.0013046, dtype=float32), 'eval/episode_x_position': Array(1.0077178, dtype=float32), 'eval/episode_x_velocity': Array(-0.04348671, dtype=float32), 'eval/episode_y_position': Array(-0.00024947, dtype=float32), 'eval/episode_y_velocity': Array(-0.00338293, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00545401, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0442824, dtype=float32), 'eval/episode_reward_std': Array(0.05219005, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0442824, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01916007, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132847, dtype=float32), 'eval/episode_x_position_std': Array(0.00545037, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0442824, dtype=float32), 'eval/episode_y_position_std': Array(0.00584777, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01420085, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.708812475204468, 'eval/sps': 6180.943506695991, 'num_steps': 3220480}
{'eval/walltime': 13148.419243097305, 'training/sps': 127.2565542839232, 'training/walltime': 25438.300347089767, 'training/entropy_loss': Array(0.10545628, dtype=float32), 'training/policy_loss': Array(0.26701987, dtype=float32), 'training/total_loss': Array(0.37247613, dtype=float32), 'training/v_loss': Array(2.1266606e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095996, dtype=float32), 'eval/episode_forward_reward': Array(-0.03667013, dtype=float32), 'eval/episode_reward': Array(-2.0338058, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03667013, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960358, dtype=float32), 'eval/episode_train_reward': Array(-0.0011001, dtype=float32), 'eval/episode_x_position': Array(1.0077019, dtype=float32), 'eval/episode_x_velocity': Array(-0.03667013, dtype=float32), 'eval/episode_y_position': Array(-0.00018438, dtype=float32), 'eval/episode_y_velocity': Array(-0.00234357, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00598062, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04322804, dtype=float32), 'eval/episode_reward_std': Array(0.04999555, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04322804, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01734338, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129684, dtype=float32), 'eval/episode_x_position_std': Array(0.00594502, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04322804, dtype=float32), 'eval/episode_y_position_std': Array(0.0056041, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0113774, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.691259384155273, 'eval/sps': 6186.187008897991, 'num_steps': 3225600}
{'eval/walltime': 13169.087509155273, 'training/sps': 127.42065399090787, 'training/walltime': 25478.482215881348, 'training/entropy_loss': Array(0.10837351, dtype=float32), 'training/policy_loss': Array(0.26497924, dtype=float32), 'training/total_loss': Array(0.3733528, dtype=float32), 'training/v_loss': Array(1.2052782e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0102168, dtype=float32), 'eval/episode_forward_reward': Array(-0.03819789, dtype=float32), 'eval/episode_reward': Array(-2.0360227, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03819789, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966788, dtype=float32), 'eval/episode_train_reward': Array(-0.00114594, dtype=float32), 'eval/episode_x_position': Array(1.0083449, dtype=float32), 'eval/episode_x_velocity': Array(-0.03819789, dtype=float32), 'eval/episode_y_position': Array(0.00016768, dtype=float32), 'eval/episode_y_velocity': Array(-0.00407354, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00553693, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0429165, dtype=float32), 'eval/episode_reward_std': Array(0.04459402, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0429165, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01527208, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012875, dtype=float32), 'eval/episode_x_position_std': Array(0.00553075, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0429165, dtype=float32), 'eval/episode_y_position_std': Array(0.00585957, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01125263, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66826605796814, 'eval/sps': 6193.069106087531, 'num_steps': 3230720}
{'eval/walltime': 13189.80168223381, 'training/sps': 127.08937397623477, 'training/walltime': 25518.768825531006, 'training/entropy_loss': Array(0.11085165, dtype=float32), 'training/policy_loss': Array(0.26929352, dtype=float32), 'training/total_loss': Array(0.38014513, dtype=float32), 'training/v_loss': Array(1.621967e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096726, dtype=float32), 'eval/episode_forward_reward': Array(-0.04285233, dtype=float32), 'eval/episode_reward': Array(-2.0398936, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04285233, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957557, dtype=float32), 'eval/episode_train_reward': Array(-0.00128557, dtype=float32), 'eval/episode_x_position': Array(1.0078335, dtype=float32), 'eval/episode_x_velocity': Array(-0.04285233, dtype=float32), 'eval/episode_y_position': Array(0.00119609, dtype=float32), 'eval/episode_y_velocity': Array(-0.00190892, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058813, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04244136, dtype=float32), 'eval/episode_reward_std': Array(0.04563035, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04244136, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01741039, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127324, dtype=float32), 'eval/episode_x_position_std': Array(0.00590863, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04244136, dtype=float32), 'eval/episode_y_position_std': Array(0.00563, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01272813, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.714173078536987, 'eval/sps': 6179.343945553266, 'num_steps': 3235840}
{'eval/walltime': 13210.523055791855, 'training/sps': 126.98390643681208, 'training/walltime': 25559.08889555931, 'training/entropy_loss': Array(0.10803813, dtype=float32), 'training/policy_loss': Array(0.27434933, dtype=float32), 'training/total_loss': Array(0.38238746, dtype=float32), 'training/v_loss': Array(2.7232439e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095084, dtype=float32), 'eval/episode_forward_reward': Array(-0.04406041, dtype=float32), 'eval/episode_reward': Array(-2.0357268, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04406041, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9903445, dtype=float32), 'eval/episode_train_reward': Array(-0.00132181, dtype=float32), 'eval/episode_x_position': Array(1.0076728, dtype=float32), 'eval/episode_x_velocity': Array(-0.04406041, dtype=float32), 'eval/episode_y_position': Array(0.00045519, dtype=float32), 'eval/episode_y_velocity': Array(-0.00241817, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00619956, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04332674, dtype=float32), 'eval/episode_reward_std': Array(0.05532864, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04332674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.03214011, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012998, dtype=float32), 'eval/episode_x_position_std': Array(0.00619841, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04332674, dtype=float32), 'eval/episode_y_position_std': Array(0.00590561, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01364504, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.721373558044434, 'eval/sps': 6177.19668251953, 'num_steps': 3240960}
{'eval/walltime': 13231.206996440887, 'training/sps': 127.09732516123564, 'training/walltime': 25599.37298488617, 'training/entropy_loss': Array(0.11031255, dtype=float32), 'training/policy_loss': Array(0.27152336, dtype=float32), 'training/total_loss': Array(0.3818359, dtype=float32), 'training/v_loss': Array(1.076393e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089706, dtype=float32), 'eval/episode_forward_reward': Array(-0.03843111, dtype=float32), 'eval/episode_reward': Array(-2.0370905, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03843111, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975066, dtype=float32), 'eval/episode_train_reward': Array(-0.00115293, dtype=float32), 'eval/episode_x_position': Array(1.0070974, dtype=float32), 'eval/episode_x_velocity': Array(-0.03843111, dtype=float32), 'eval/episode_y_position': Array(0.00041676, dtype=float32), 'eval/episode_y_velocity': Array(-0.00084444, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00632074, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04290942, dtype=float32), 'eval/episode_reward_std': Array(0.04795283, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04290942, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01605154, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128728, dtype=float32), 'eval/episode_x_position_std': Array(0.00628903, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04290942, dtype=float32), 'eval/episode_y_position_std': Array(0.00588925, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01198936, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.683940649032593, 'eval/sps': 6188.375908242933, 'num_steps': 3246080}
{'eval/walltime': 13251.936598300934, 'training/sps': 127.11943590292672, 'training/walltime': 25639.650067329407, 'training/entropy_loss': Array(0.10654896, dtype=float32), 'training/policy_loss': Array(0.27030352, dtype=float32), 'training/total_loss': Array(0.37685245, dtype=float32), 'training/v_loss': Array(6.1234334e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091223, dtype=float32), 'eval/episode_forward_reward': Array(-0.03693625, dtype=float32), 'eval/episode_reward': Array(-2.0355892, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03693625, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975448, dtype=float32), 'eval/episode_train_reward': Array(-0.00110809, dtype=float32), 'eval/episode_x_position': Array(1.0072063, dtype=float32), 'eval/episode_x_velocity': Array(-0.03693625, dtype=float32), 'eval/episode_y_position': Array(-2.4344277e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0027291, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581469, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04263251, dtype=float32), 'eval/episode_reward_std': Array(0.0462954, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04263251, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01194591, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127898, dtype=float32), 'eval/episode_x_position_std': Array(0.00581366, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04263251, dtype=float32), 'eval/episode_y_position_std': Array(0.00606707, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01495726, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.729601860046387, 'eval/sps': 6174.744737703012, 'num_steps': 3251200}
{'eval/walltime': 13272.632071495056, 'training/sps': 127.35024580800865, 'training/walltime': 25679.85415148735, 'training/entropy_loss': Array(0.10689639, dtype=float32), 'training/policy_loss': Array(0.26593256, dtype=float32), 'training/total_loss': Array(0.37282896, dtype=float32), 'training/v_loss': Array(2.5003533e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100291, dtype=float32), 'eval/episode_forward_reward': Array(-0.04016725, dtype=float32), 'eval/episode_reward': Array(-2.039215, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04016725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978428, dtype=float32), 'eval/episode_train_reward': Array(-0.00120502, dtype=float32), 'eval/episode_x_position': Array(1.0081503, dtype=float32), 'eval/episode_x_velocity': Array(-0.04016725, dtype=float32), 'eval/episode_y_position': Array(-0.0006652, dtype=float32), 'eval/episode_y_velocity': Array(-5.851034e-07, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00601345, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04509199, dtype=float32), 'eval/episode_reward_std': Array(0.04728214, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04509199, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01160346, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135276, dtype=float32), 'eval/episode_x_position_std': Array(0.00601115, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04509199, dtype=float32), 'eval/episode_y_position_std': Array(0.00549685, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01145567, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.695473194122314, 'eval/sps': 6184.927437965181, 'num_steps': 3256320}
{'eval/walltime': 13293.331903934479, 'training/sps': 127.17752818799596, 'training/walltime': 25720.112836122513, 'training/entropy_loss': Array(0.10897855, dtype=float32), 'training/policy_loss': Array(0.19245625, dtype=float32), 'training/total_loss': Array(0.3014348, dtype=float32), 'training/v_loss': Array(1.2958875e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009351, dtype=float32), 'eval/episode_forward_reward': Array(-0.04275322, dtype=float32), 'eval/episode_reward': Array(-2.0400586, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04275322, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960227, dtype=float32), 'eval/episode_train_reward': Array(-0.0012826, dtype=float32), 'eval/episode_x_position': Array(1.0075321, dtype=float32), 'eval/episode_x_velocity': Array(-0.04275322, dtype=float32), 'eval/episode_y_position': Array(0.00102652, dtype=float32), 'eval/episode_y_velocity': Array(0.0004797, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575275, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04432402, dtype=float32), 'eval/episode_reward_std': Array(0.04671742, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04432402, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01687937, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132972, dtype=float32), 'eval/episode_x_position_std': Array(0.00576753, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04432402, dtype=float32), 'eval/episode_y_position_std': Array(0.00564205, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01352821, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.699832439422607, 'eval/sps': 6183.624933901657, 'num_steps': 3261440}
{'eval/walltime': 13314.018817424774, 'training/sps': 127.19575516546783, 'training/walltime': 25760.365751743317, 'training/entropy_loss': Array(0.10719348, dtype=float32), 'training/policy_loss': Array(0.26910532, dtype=float32), 'training/total_loss': Array(0.37629882, dtype=float32), 'training/v_loss': Array(7.052307e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092158, dtype=float32), 'eval/episode_forward_reward': Array(-0.03420608, dtype=float32), 'eval/episode_reward': Array(-2.0304115, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03420608, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9951792, dtype=float32), 'eval/episode_train_reward': Array(-0.00102618, dtype=float32), 'eval/episode_x_position': Array(1.0073171, dtype=float32), 'eval/episode_x_velocity': Array(-0.03420608, dtype=float32), 'eval/episode_y_position': Array(0.00058613, dtype=float32), 'eval/episode_y_velocity': Array(-0.0015585, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00622942, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04433621, dtype=float32), 'eval/episode_reward_std': Array(0.0490858, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04433621, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01896994, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133009, dtype=float32), 'eval/episode_x_position_std': Array(0.00620262, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04433621, dtype=float32), 'eval/episode_y_position_std': Array(0.00596148, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01283324, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68691349029541, 'eval/sps': 6187.486599199393, 'num_steps': 3266560}
{'eval/walltime': 13334.72933268547, 'training/sps': 127.11808220866813, 'training/walltime': 25800.643263101578, 'training/entropy_loss': Array(0.10815923, dtype=float32), 'training/policy_loss': Array(0.26981795, dtype=float32), 'training/total_loss': Array(0.3779772, dtype=float32), 'training/v_loss': Array(3.517664e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098047, dtype=float32), 'eval/episode_forward_reward': Array(-0.04349556, dtype=float32), 'eval/episode_reward': Array(-2.0405598, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04349556, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957595, dtype=float32), 'eval/episode_train_reward': Array(-0.00130487, dtype=float32), 'eval/episode_x_position': Array(1.0079713, dtype=float32), 'eval/episode_x_velocity': Array(-0.04349556, dtype=float32), 'eval/episode_y_position': Array(-5.5920216e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00268142, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566937, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04538452, dtype=float32), 'eval/episode_reward_std': Array(0.04956716, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04538452, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01516818, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136154, dtype=float32), 'eval/episode_x_position_std': Array(0.00563946, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04538452, dtype=float32), 'eval/episode_y_position_std': Array(0.00561888, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01708415, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71051526069641, 'eval/sps': 6180.43531939127, 'num_steps': 3271680}
{'eval/walltime': 13355.457561969757, 'training/sps': 126.7025006290333, 'training/walltime': 25841.05288386345, 'training/entropy_loss': Array(0.10747651, dtype=float32), 'training/policy_loss': Array(0.2653219, dtype=float32), 'training/total_loss': Array(0.37279847, dtype=float32), 'training/v_loss': Array(1.113734e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095919, dtype=float32), 'eval/episode_forward_reward': Array(-0.03658786, dtype=float32), 'eval/episode_reward': Array(-2.0355434, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03658786, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978578, dtype=float32), 'eval/episode_train_reward': Array(-0.00109764, dtype=float32), 'eval/episode_x_position': Array(1.0077255, dtype=float32), 'eval/episode_x_velocity': Array(-0.03658786, dtype=float32), 'eval/episode_y_position': Array(-9.482002e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00139615, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560966, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04479502, dtype=float32), 'eval/episode_reward_std': Array(0.04701391, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04479502, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00929604, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134385, dtype=float32), 'eval/episode_x_position_std': Array(0.00559587, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04479502, dtype=float32), 'eval/episode_y_position_std': Array(0.00535292, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01230404, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7282292842865, 'eval/sps': 6175.153615124919, 'num_steps': 3276800}
{'eval/walltime': 13376.173944234848, 'training/sps': 127.13487035658108, 'training/walltime': 25881.325076580048, 'training/entropy_loss': Array(0.1085742, dtype=float32), 'training/policy_loss': Array(0.2631075, dtype=float32), 'training/total_loss': Array(0.3716817, dtype=float32), 'training/v_loss': Array(5.4191346e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095044, dtype=float32), 'eval/episode_forward_reward': Array(-0.03870569, dtype=float32), 'eval/episode_reward': Array(-2.036347, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03870569, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99648, dtype=float32), 'eval/episode_train_reward': Array(-0.00116117, dtype=float32), 'eval/episode_x_position': Array(1.0076354, dtype=float32), 'eval/episode_x_velocity': Array(-0.03870569, dtype=float32), 'eval/episode_y_position': Array(0.0007642, dtype=float32), 'eval/episode_y_velocity': Array(-0.00282611, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00607888, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04301523, dtype=float32), 'eval/episode_reward_std': Array(0.04732506, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04301523, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01454232, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129046, dtype=float32), 'eval/episode_x_position_std': Array(0.00607637, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04301523, dtype=float32), 'eval/episode_y_position_std': Array(0.00581141, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01117819, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.716382265090942, 'eval/sps': 6178.684982835641, 'num_steps': 3281920}
{'eval/walltime': 13396.881388664246, 'training/sps': 126.98594809808549, 'training/walltime': 25921.644498348236, 'training/entropy_loss': Array(0.10892069, dtype=float32), 'training/policy_loss': Array(0.26922178, dtype=float32), 'training/total_loss': Array(0.37814248, dtype=float32), 'training/v_loss': Array(1.0843293e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090431, dtype=float32), 'eval/episode_forward_reward': Array(-0.03950911, dtype=float32), 'eval/episode_reward': Array(-2.0351822, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03950911, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9944878, dtype=float32), 'eval/episode_train_reward': Array(-0.00118527, dtype=float32), 'eval/episode_x_position': Array(1.0071865, dtype=float32), 'eval/episode_x_velocity': Array(-0.03950911, dtype=float32), 'eval/episode_y_position': Array(-0.00031727, dtype=float32), 'eval/episode_y_velocity': Array(-0.0026162, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571507, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04297825, dtype=float32), 'eval/episode_reward_std': Array(0.04815874, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04297825, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01653064, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128935, dtype=float32), 'eval/episode_x_position_std': Array(0.00573489, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04297825, dtype=float32), 'eval/episode_y_position_std': Array(0.00551461, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01662709, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.707444429397583, 'eval/sps': 6181.351853263129, 'num_steps': 3287040}
{'eval/walltime': 13417.616064786911, 'training/sps': 127.09944193420888, 'training/walltime': 25961.927916765213, 'training/entropy_loss': Array(0.1089529, dtype=float32), 'training/policy_loss': Array(0.27016908, dtype=float32), 'training/total_loss': Array(0.37912202, dtype=float32), 'training/v_loss': Array(1.4619155e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092623, dtype=float32), 'eval/episode_forward_reward': Array(-0.03675721, dtype=float32), 'eval/episode_reward': Array(-2.033253, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03675721, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995393, dtype=float32), 'eval/episode_train_reward': Array(-0.00110272, dtype=float32), 'eval/episode_x_position': Array(1.0073984, dtype=float32), 'eval/episode_x_velocity': Array(-0.03675721, dtype=float32), 'eval/episode_y_position': Array(-0.00043328, dtype=float32), 'eval/episode_y_velocity': Array(-0.00186421, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567925, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04102157, dtype=float32), 'eval/episode_reward_std': Array(0.04318283, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04102157, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01800748, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123065, dtype=float32), 'eval/episode_x_position_std': Array(0.00564658, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04102157, dtype=float32), 'eval/episode_y_position_std': Array(0.0059439, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01363678, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.734676122665405, 'eval/sps': 6173.233632527356, 'num_steps': 3292160}
{'eval/walltime': 13438.316981315613, 'training/sps': 127.14881267534643, 'training/walltime': 26002.19569349289, 'training/entropy_loss': Array(0.11000792, dtype=float32), 'training/policy_loss': Array(0.26863563, dtype=float32), 'training/total_loss': Array(0.3786435, dtype=float32), 'training/v_loss': Array(1.4395484e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089413, dtype=float32), 'eval/episode_forward_reward': Array(-0.03671615, dtype=float32), 'eval/episode_reward': Array(-2.0342655, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03671615, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996448, dtype=float32), 'eval/episode_train_reward': Array(-0.00110148, dtype=float32), 'eval/episode_x_position': Array(1.0070624, dtype=float32), 'eval/episode_x_velocity': Array(-0.03671615, dtype=float32), 'eval/episode_y_position': Array(-0.00037957, dtype=float32), 'eval/episode_y_velocity': Array(0.00078738, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00603983, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04253298, dtype=float32), 'eval/episode_reward_std': Array(0.04656677, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04253298, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01189946, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127599, dtype=float32), 'eval/episode_x_position_std': Array(0.00600748, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04253298, dtype=float32), 'eval/episode_y_position_std': Array(0.00509887, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01087887, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.700916528701782, 'eval/sps': 6183.301102756887, 'num_steps': 3297280}
{'eval/walltime': 13459.036926269531, 'training/sps': 127.18373156841993, 'training/walltime': 26042.452414512634, 'training/entropy_loss': Array(0.10962035, dtype=float32), 'training/policy_loss': Array(0.2686322, dtype=float32), 'training/total_loss': Array(0.37825257, dtype=float32), 'training/v_loss': Array(1.0104141e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093005, dtype=float32), 'eval/episode_forward_reward': Array(-0.03789815, dtype=float32), 'eval/episode_reward': Array(-2.0318537, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03789815, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9928184, dtype=float32), 'eval/episode_train_reward': Array(-0.00113694, dtype=float32), 'eval/episode_x_position': Array(1.0073967, dtype=float32), 'eval/episode_x_velocity': Array(-0.03789815, dtype=float32), 'eval/episode_y_position': Array(0.00036948, dtype=float32), 'eval/episode_y_velocity': Array(-0.00268124, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579143, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04506088, dtype=float32), 'eval/episode_reward_std': Array(0.05331598, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04506088, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0253061, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135183, dtype=float32), 'eval/episode_x_position_std': Array(0.00575555, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04506088, dtype=float32), 'eval/episode_y_position_std': Array(0.00574999, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01231631, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.719944953918457, 'eval/sps': 6177.6225894747495, 'num_steps': 3302400}
{'eval/walltime': 13479.735391616821, 'training/sps': 127.09724993961281, 'training/walltime': 26082.73652768135, 'training/entropy_loss': Array(0.1079073, dtype=float32), 'training/policy_loss': Array(0.27040026, dtype=float32), 'training/total_loss': Array(0.37830755, dtype=float32), 'training/v_loss': Array(7.59122e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095872, dtype=float32), 'eval/episode_forward_reward': Array(-0.03815869, dtype=float32), 'eval/episode_reward': Array(-2.0352445, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03815869, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959412, dtype=float32), 'eval/episode_train_reward': Array(-0.00114476, dtype=float32), 'eval/episode_x_position': Array(1.0077186, dtype=float32), 'eval/episode_x_velocity': Array(-0.03815869, dtype=float32), 'eval/episode_y_position': Array(-0.00066981, dtype=float32), 'eval/episode_y_velocity': Array(-0.00213342, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0056266, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04263528, dtype=float32), 'eval/episode_reward_std': Array(0.0474546, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04263528, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01737581, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127906, dtype=float32), 'eval/episode_x_position_std': Array(0.0056132, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04263528, dtype=float32), 'eval/episode_y_position_std': Array(0.0059714, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01305946, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69846534729004, 'eval/sps': 6184.033349929418, 'num_steps': 3307520}
{'eval/walltime': 13500.454775094986, 'training/sps': 127.27914291237984, 'training/walltime': 26122.963071346283, 'training/entropy_loss': Array(0.10765296, dtype=float32), 'training/policy_loss': Array(0.26839048, dtype=float32), 'training/total_loss': Array(0.37604344, dtype=float32), 'training/v_loss': Array(1.0464417e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101146, dtype=float32), 'eval/episode_forward_reward': Array(-0.03794255, dtype=float32), 'eval/episode_reward': Array(-2.0338354, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03794255, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947548, dtype=float32), 'eval/episode_train_reward': Array(-0.00113828, dtype=float32), 'eval/episode_x_position': Array(1.0082123, dtype=float32), 'eval/episode_x_velocity': Array(-0.03794255, dtype=float32), 'eval/episode_y_position': Array(0.00063046, dtype=float32), 'eval/episode_y_velocity': Array(-0.00156746, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00551874, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04409895, dtype=float32), 'eval/episode_reward_std': Array(0.04905304, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04409895, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02003321, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132297, dtype=float32), 'eval/episode_x_position_std': Array(0.00554547, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04409895, dtype=float32), 'eval/episode_y_position_std': Array(0.00572557, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01209868, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.719383478164673, 'eval/sps': 6177.789997221397, 'num_steps': 3312640}
{'eval/walltime': 13521.13637804985, 'training/sps': 126.91188585755333, 'training/walltime': 26163.306022405624, 'training/entropy_loss': Array(0.10876685, dtype=float32), 'training/policy_loss': Array(0.2704826, dtype=float32), 'training/total_loss': Array(0.37924945, dtype=float32), 'training/v_loss': Array(9.2458213e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098696, dtype=float32), 'eval/episode_forward_reward': Array(-0.04899657, dtype=float32), 'eval/episode_reward': Array(-2.0450394, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04899657, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994573, dtype=float32), 'eval/episode_train_reward': Array(-0.0014699, dtype=float32), 'eval/episode_x_position': Array(1.0080234, dtype=float32), 'eval/episode_x_velocity': Array(-0.04899657, dtype=float32), 'eval/episode_y_position': Array(5.11534e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00284996, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572783, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04458228, dtype=float32), 'eval/episode_reward_std': Array(0.04931091, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04458228, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0176248, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133747, dtype=float32), 'eval/episode_x_position_std': Array(0.00572907, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04458228, dtype=float32), 'eval/episode_y_position_std': Array(0.00594219, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01005101, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.681602954864502, 'eval/sps': 6189.075396106723, 'num_steps': 3317760}
{'eval/walltime': 13541.859326839447, 'training/sps': 126.97863326242067, 'training/walltime': 26203.62776684761, 'training/entropy_loss': Array(0.10582925, dtype=float32), 'training/policy_loss': Array(0.27204108, dtype=float32), 'training/total_loss': Array(0.37787035, dtype=float32), 'training/v_loss': Array(8.368399e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100701, dtype=float32), 'eval/episode_forward_reward': Array(-0.03776583, dtype=float32), 'eval/episode_reward': Array(-2.036915, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03776583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998016, dtype=float32), 'eval/episode_train_reward': Array(-0.00113297, dtype=float32), 'eval/episode_x_position': Array(1.0082073, dtype=float32), 'eval/episode_x_velocity': Array(-0.03776583, dtype=float32), 'eval/episode_y_position': Array(-0.00014847, dtype=float32), 'eval/episode_y_velocity': Array(-0.00033304, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574986, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04248887, dtype=float32), 'eval/episode_reward_std': Array(0.04363234, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04248887, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00851189, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127467, dtype=float32), 'eval/episode_x_position_std': Array(0.00575069, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04248887, dtype=float32), 'eval/episode_y_position_std': Array(0.00585191, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0116091, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.722948789596558, 'eval/sps': 6176.727129888929, 'num_steps': 3322880}
{'eval/walltime': 13562.606040716171, 'training/sps': 127.15973636977581, 'training/walltime': 26243.892084360123, 'training/entropy_loss': Array(0.10509016, dtype=float32), 'training/policy_loss': Array(0.2670725, dtype=float32), 'training/total_loss': Array(0.37216267, dtype=float32), 'training/v_loss': Array(4.4190673e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009073, dtype=float32), 'eval/episode_forward_reward': Array(-0.03858633, dtype=float32), 'eval/episode_reward': Array(-2.0352345, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03858633, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9954906, dtype=float32), 'eval/episode_train_reward': Array(-0.00115759, dtype=float32), 'eval/episode_x_position': Array(1.0072101, dtype=float32), 'eval/episode_x_velocity': Array(-0.03858633, dtype=float32), 'eval/episode_y_position': Array(-0.0009838, dtype=float32), 'eval/episode_y_velocity': Array(-0.0021202, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.005431, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04170364, dtype=float32), 'eval/episode_reward_std': Array(0.04508408, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04170364, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01879274, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125111, dtype=float32), 'eval/episode_x_position_std': Array(0.00544951, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04170364, dtype=float32), 'eval/episode_y_position_std': Array(0.00606161, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0155877, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.746713876724243, 'eval/sps': 6169.651770423427, 'num_steps': 3328000}
{'eval/walltime': 13583.313868999481, 'training/sps': 126.97468110901187, 'training/walltime': 26284.21508383751, 'training/entropy_loss': Array(0.10702749, dtype=float32), 'training/policy_loss': Array(0.26138324, dtype=float32), 'training/total_loss': Array(0.36841074, dtype=float32), 'training/v_loss': Array(6.115371e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.01637, dtype=float32), 'eval/episode_forward_reward': Array(-0.03903142, dtype=float32), 'eval/episode_reward': Array(-2.049158, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03903142, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0167685, dtype=float32), 'eval/episode_train_reward': Array(-0.00117094, dtype=float32), 'eval/episode_x_position': Array(1.0144168, dtype=float32), 'eval/episode_x_velocity': Array(-0.03903142, dtype=float32), 'eval/episode_y_position': Array(-0.00021392, dtype=float32), 'eval/episode_y_velocity': Array(-0.00056664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09066357, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0460202, dtype=float32), 'eval/episode_reward_std': Array(0.18213241, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0460202, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26562425, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138061, dtype=float32), 'eval/episode_x_position_std': Array(0.09039829, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0460202, dtype=float32), 'eval/episode_y_position_std': Array(0.00569109, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01464989, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.707828283309937, 'eval/sps': 6181.237271663356, 'num_steps': 3333120}
{'eval/walltime': 13604.00546336174, 'training/sps': 127.08242549582954, 'training/walltime': 26324.50389623642, 'training/entropy_loss': Array(0.10872631, dtype=float32), 'training/policy_loss': Array(0.2692427, dtype=float32), 'training/total_loss': Array(0.377969, dtype=float32), 'training/v_loss': Array(2.0456227e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090228, dtype=float32), 'eval/episode_forward_reward': Array(-0.04066931, dtype=float32), 'eval/episode_reward': Array(-2.0362802, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04066931, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994391, dtype=float32), 'eval/episode_train_reward': Array(-0.00122008, dtype=float32), 'eval/episode_x_position': Array(1.007153, dtype=float32), 'eval/episode_x_velocity': Array(-0.04066931, dtype=float32), 'eval/episode_y_position': Array(-0.00013242, dtype=float32), 'eval/episode_y_velocity': Array(-0.0009284, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00624021, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0440627, dtype=float32), 'eval/episode_reward_std': Array(0.05012573, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0440627, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02213126, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132188, dtype=float32), 'eval/episode_x_position_std': Array(0.00624584, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0440627, dtype=float32), 'eval/episode_y_position_std': Array(0.00593531, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01139128, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69159436225891, 'eval/sps': 6186.086860153689, 'num_steps': 3338240}
{'eval/walltime': 13624.720771551132, 'training/sps': 127.18826698699598, 'training/walltime': 26364.7591817379, 'training/entropy_loss': Array(0.10820672, dtype=float32), 'training/policy_loss': Array(0.26966798, dtype=float32), 'training/total_loss': Array(0.3778747, dtype=float32), 'training/v_loss': Array(9.234716e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009692, dtype=float32), 'eval/episode_forward_reward': Array(-0.03572872, dtype=float32), 'eval/episode_reward': Array(-2.0319636, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03572872, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995163, dtype=float32), 'eval/episode_train_reward': Array(-0.00107186, dtype=float32), 'eval/episode_x_position': Array(1.0077891, dtype=float32), 'eval/episode_x_velocity': Array(-0.03572872, dtype=float32), 'eval/episode_y_position': Array(0.00019489, dtype=float32), 'eval/episode_y_velocity': Array(-0.00197151, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0060986, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04266148, dtype=float32), 'eval/episode_reward_std': Array(0.04848904, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04266148, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01796882, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127984, dtype=float32), 'eval/episode_x_position_std': Array(0.00609758, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04266148, dtype=float32), 'eval/episode_y_position_std': Array(0.00559153, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01119633, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71530818939209, 'eval/sps': 6179.005343765358, 'num_steps': 3343360}
{'eval/walltime': 13645.425900697708, 'training/sps': 126.99579840293954, 'training/walltime': 26405.075476169586, 'training/entropy_loss': Array(0.10847273, dtype=float32), 'training/policy_loss': Array(0.26484305, dtype=float32), 'training/total_loss': Array(0.37331578, dtype=float32), 'training/v_loss': Array(3.7794528e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0174346, dtype=float32), 'eval/episode_forward_reward': Array(-0.03419623, dtype=float32), 'eval/episode_reward': Array(-2.046681, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03419623, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0192716, dtype=float32), 'eval/episode_train_reward': Array(-0.00102589, dtype=float32), 'eval/episode_x_position': Array(1.0154736, dtype=float32), 'eval/episode_x_velocity': Array(-0.03419623, dtype=float32), 'eval/episode_y_position': Array(0.00015015, dtype=float32), 'eval/episode_y_velocity': Array(-0.00107911, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08847868, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04168071, dtype=float32), 'eval/episode_reward_std': Array(0.17962483, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04168071, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26518708, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125042, dtype=float32), 'eval/episode_x_position_std': Array(0.08821337, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04168071, dtype=float32), 'eval/episode_y_position_std': Array(0.00568908, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00998688, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.705129146575928, 'eval/sps': 6182.043062560069, 'num_steps': 3348480}
{'eval/walltime': 13666.137586593628, 'training/sps': 127.09966083692926, 'training/walltime': 26445.358825206757, 'training/entropy_loss': Array(0.10814968, dtype=float32), 'training/policy_loss': Array(0.26703006, dtype=float32), 'training/total_loss': Array(0.37517974, dtype=float32), 'training/v_loss': Array(3.5891323e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092313, dtype=float32), 'eval/episode_forward_reward': Array(-0.04135755, dtype=float32), 'eval/episode_reward': Array(-2.037249, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04135755, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946508, dtype=float32), 'eval/episode_train_reward': Array(-0.00124073, dtype=float32), 'eval/episode_x_position': Array(1.0073761, dtype=float32), 'eval/episode_x_velocity': Array(-0.04135755, dtype=float32), 'eval/episode_y_position': Array(-2.7110786e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00046205, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599042, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04341677, dtype=float32), 'eval/episode_reward_std': Array(0.04814513, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04341677, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01925662, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013025, dtype=float32), 'eval/episode_x_position_std': Array(0.00599934, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04341677, dtype=float32), 'eval/episode_y_position_std': Array(0.00569928, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01083926, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7116858959198, 'eval/sps': 6180.085997983196, 'num_steps': 3353600}
{'eval/walltime': 13686.834519147873, 'training/sps': 127.28982418429644, 'training/walltime': 26485.581993341446, 'training/entropy_loss': Array(0.10638124, dtype=float32), 'training/policy_loss': Array(0.26831114, dtype=float32), 'training/total_loss': Array(0.37469238, dtype=float32), 'training/v_loss': Array(3.946381e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092689, dtype=float32), 'eval/episode_forward_reward': Array(-0.0407976, dtype=float32), 'eval/episode_reward': Array(-2.0354772, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0407976, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9934556, dtype=float32), 'eval/episode_train_reward': Array(-0.00122393, dtype=float32), 'eval/episode_x_position': Array(1.0074334, dtype=float32), 'eval/episode_x_velocity': Array(-0.0407976, dtype=float32), 'eval/episode_y_position': Array(-0.00047872, dtype=float32), 'eval/episode_y_velocity': Array(0.00108354, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00562782, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04372869, dtype=float32), 'eval/episode_reward_std': Array(0.046705, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04372869, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02013906, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131186, dtype=float32), 'eval/episode_x_position_std': Array(0.0055874, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04372869, dtype=float32), 'eval/episode_y_position_std': Array(0.005769, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01333261, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.696932554244995, 'eval/sps': 6184.491332931694, 'num_steps': 3358720}
{'eval/walltime': 13707.511900901794, 'training/sps': 127.23716925875392, 'training/walltime': 26525.821807146072, 'training/entropy_loss': Array(0.10459256, dtype=float32), 'training/policy_loss': Array(0.26720876, dtype=float32), 'training/total_loss': Array(0.3718013, dtype=float32), 'training/v_loss': Array(8.476015e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089023, dtype=float32), 'eval/episode_forward_reward': Array(-0.04129003, dtype=float32), 'eval/episode_reward': Array(-2.0380206, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04129003, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9954917, dtype=float32), 'eval/episode_train_reward': Array(-0.0012387, dtype=float32), 'eval/episode_x_position': Array(1.0070562, dtype=float32), 'eval/episode_x_velocity': Array(-0.04129003, dtype=float32), 'eval/episode_y_position': Array(-0.00103577, dtype=float32), 'eval/episode_y_velocity': Array(-0.00190913, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596125, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04399785, dtype=float32), 'eval/episode_reward_std': Array(0.05033286, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04399785, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01754099, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131994, dtype=float32), 'eval/episode_x_position_std': Array(0.00597834, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04399785, dtype=float32), 'eval/episode_y_position_std': Array(0.0051193, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01874762, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67738175392151, 'eval/sps': 6190.338869945394, 'num_steps': 3363840}
{'eval/walltime': 13728.18656206131, 'training/sps': 127.19765296361297, 'training/walltime': 26566.074122190475, 'training/entropy_loss': Array(0.10748561, dtype=float32), 'training/policy_loss': Array(0.26703817, dtype=float32), 'training/total_loss': Array(0.37452376, dtype=float32), 'training/v_loss': Array(9.0530516e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096738, dtype=float32), 'eval/episode_forward_reward': Array(-0.0323758, dtype=float32), 'eval/episode_reward': Array(-2.0293365, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0323758, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959893, dtype=float32), 'eval/episode_train_reward': Array(-0.00097127, dtype=float32), 'eval/episode_x_position': Array(1.0077507, dtype=float32), 'eval/episode_x_velocity': Array(-0.0323758, dtype=float32), 'eval/episode_y_position': Array(0.00033908, dtype=float32), 'eval/episode_y_velocity': Array(-0.00225355, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567436, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0409046, dtype=float32), 'eval/episode_reward_std': Array(0.04464249, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0409046, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01494663, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122714, dtype=float32), 'eval/episode_x_position_std': Array(0.00570162, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0409046, dtype=float32), 'eval/episode_y_position_std': Array(0.006151, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01014523, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67466115951538, 'eval/sps': 6191.153461351351, 'num_steps': 3368960}
{'eval/walltime': 13748.86346244812, 'training/sps': 127.49638096021103, 'training/walltime': 26606.23212480545, 'training/entropy_loss': Array(0.10963618, dtype=float32), 'training/policy_loss': Array(0.2729303, dtype=float32), 'training/total_loss': Array(0.38256648, dtype=float32), 'training/v_loss': Array(3.0366327e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008359, dtype=float32), 'eval/episode_forward_reward': Array(-0.03177572, dtype=float32), 'eval/episode_reward': Array(-2.0263748, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03177572, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9936461, dtype=float32), 'eval/episode_train_reward': Array(-0.00095327, dtype=float32), 'eval/episode_x_position': Array(1.0064316, dtype=float32), 'eval/episode_x_velocity': Array(-0.03177572, dtype=float32), 'eval/episode_y_position': Array(0.00031633, dtype=float32), 'eval/episode_y_velocity': Array(-0.00187009, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557962, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04037582, dtype=float32), 'eval/episode_reward_std': Array(0.04995944, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04037582, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02344607, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121127, dtype=float32), 'eval/episode_x_position_std': Array(0.00559261, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04037582, dtype=float32), 'eval/episode_y_position_std': Array(0.00597228, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01144011, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.676900386810303, 'eval/sps': 6190.482983689886, 'num_steps': 3374080}
{'eval/walltime': 13769.53358078003, 'training/sps': 127.14960691199882, 'training/walltime': 26646.499650001526, 'training/entropy_loss': Array(0.10620977, dtype=float32), 'training/policy_loss': Array(0.27020258, dtype=float32), 'training/total_loss': Array(0.37641236, dtype=float32), 'training/v_loss': Array(1.5391056e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101609, dtype=float32), 'eval/episode_forward_reward': Array(-0.041565, dtype=float32), 'eval/episode_reward': Array(-2.038383, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.041565, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955711, dtype=float32), 'eval/episode_train_reward': Array(-0.00124695, dtype=float32), 'eval/episode_x_position': Array(1.0082908, dtype=float32), 'eval/episode_x_velocity': Array(-0.041565, dtype=float32), 'eval/episode_y_position': Array(9.961131e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0024904, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00536377, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04370714, dtype=float32), 'eval/episode_reward_std': Array(0.04823247, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04370714, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02110452, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131121, dtype=float32), 'eval/episode_x_position_std': Array(0.00531064, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04370714, dtype=float32), 'eval/episode_y_position_std': Array(0.00565381, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01327382, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67011833190918, 'eval/sps': 6192.514137783234, 'num_steps': 3379200}
{'eval/walltime': 13790.226998806, 'training/sps': 127.23167903933812, 'training/walltime': 26686.741200208664, 'training/entropy_loss': Array(0.10706718, dtype=float32), 'training/policy_loss': Array(0.26678026, dtype=float32), 'training/total_loss': Array(0.37384742, dtype=float32), 'training/v_loss': Array(4.1204435e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016602, dtype=float32), 'eval/episode_forward_reward': Array(-0.03822039, dtype=float32), 'eval/episode_reward': Array(-2.049183, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03822039, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0176287, dtype=float32), 'eval/episode_train_reward': Array(-0.00114661, dtype=float32), 'eval/episode_x_position': Array(1.0147061, dtype=float32), 'eval/episode_x_velocity': Array(-0.03822039, dtype=float32), 'eval/episode_y_position': Array(0.00054858, dtype=float32), 'eval/episode_y_velocity': Array(-0.00104965, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08918396, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0418038, dtype=float32), 'eval/episode_reward_std': Array(0.17982681, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0418038, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26543686, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125411, dtype=float32), 'eval/episode_x_position_std': Array(0.08891698, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0418038, dtype=float32), 'eval/episode_y_position_std': Array(0.00573592, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01173917, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.69341802597046, 'eval/sps': 6185.541694434368, 'num_steps': 3384320}
{'eval/walltime': 13810.899711847305, 'training/sps': 127.14177489232594, 'training/walltime': 26727.011205911636, 'training/entropy_loss': Array(0.110083, dtype=float32), 'training/policy_loss': Array(0.26783556, dtype=float32), 'training/total_loss': Array(0.37791857, dtype=float32), 'training/v_loss': Array(8.74096e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098586, dtype=float32), 'eval/episode_forward_reward': Array(-0.03720083, dtype=float32), 'eval/episode_reward': Array(-2.035583, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03720083, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972663, dtype=float32), 'eval/episode_train_reward': Array(-0.00111602, dtype=float32), 'eval/episode_x_position': Array(1.0080061, dtype=float32), 'eval/episode_x_velocity': Array(-0.03720083, dtype=float32), 'eval/episode_y_position': Array(-0.00012937, dtype=float32), 'eval/episode_y_velocity': Array(-0.00198812, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00636429, dtype=float32), 'eval/episode_forward_reward_std': Array(0.042567, dtype=float32), 'eval/episode_reward_std': Array(0.04533906, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.042567, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01369482, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127701, dtype=float32), 'eval/episode_x_position_std': Array(0.00632897, dtype=float32), 'eval/episode_x_velocity_std': Array(0.042567, dtype=float32), 'eval/episode_y_position_std': Array(0.00612926, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01094211, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672713041305542, 'eval/sps': 6191.7368922137575, 'num_steps': 3389440}
{'eval/walltime': 13831.586710453033, 'training/sps': 127.34139381141493, 'training/walltime': 26767.218084812164, 'training/entropy_loss': Array(0.10945974, dtype=float32), 'training/policy_loss': Array(0.2710817, dtype=float32), 'training/total_loss': Array(0.3805414, dtype=float32), 'training/v_loss': Array(3.6972844e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009047, dtype=float32), 'eval/episode_forward_reward': Array(-0.03592988, dtype=float32), 'eval/episode_reward': Array(-2.0334344, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03592988, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964266, dtype=float32), 'eval/episode_train_reward': Array(-0.0010779, dtype=float32), 'eval/episode_x_position': Array(1.0071477, dtype=float32), 'eval/episode_x_velocity': Array(-0.03592988, dtype=float32), 'eval/episode_y_position': Array(-0.00061649, dtype=float32), 'eval/episode_y_velocity': Array(-0.00314675, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576109, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04229552, dtype=float32), 'eval/episode_reward_std': Array(0.04718901, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04229552, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0143161, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126887, dtype=float32), 'eval/episode_x_position_std': Array(0.00577158, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04229552, dtype=float32), 'eval/episode_y_position_std': Array(0.00580551, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01115804, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68699860572815, 'eval/sps': 6187.461141151588, 'num_steps': 3394560}
{'eval/walltime': 13852.265932321548, 'training/sps': 127.22412784056391, 'training/walltime': 26807.462023496628, 'training/entropy_loss': Array(0.10911775, dtype=float32), 'training/policy_loss': Array(0.267782, dtype=float32), 'training/total_loss': Array(0.37689975, dtype=float32), 'training/v_loss': Array(3.1804506e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008933, dtype=float32), 'eval/episode_forward_reward': Array(-0.04599725, dtype=float32), 'eval/episode_reward': Array(-2.0433035, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04599725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959264, dtype=float32), 'eval/episode_train_reward': Array(-0.00137992, dtype=float32), 'eval/episode_x_position': Array(1.0070722, dtype=float32), 'eval/episode_x_velocity': Array(-0.04599725, dtype=float32), 'eval/episode_y_position': Array(0.00130398, dtype=float32), 'eval/episode_y_velocity': Array(-0.00183578, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582722, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04470308, dtype=float32), 'eval/episode_reward_std': Array(0.04715225, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04470308, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01467529, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134109, dtype=float32), 'eval/episode_x_position_std': Array(0.00580791, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04470308, dtype=float32), 'eval/episode_y_position_std': Array(0.00549057, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01269501, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.679221868515015, 'eval/sps': 6189.788030413532, 'num_steps': 3399680}
{'eval/walltime': 13872.94955587387, 'training/sps': 127.19359525530102, 'training/walltime': 26847.715622663498, 'training/entropy_loss': Array(0.10984148, dtype=float32), 'training/policy_loss': Array(0.26544017, dtype=float32), 'training/total_loss': Array(0.37528163, dtype=float32), 'training/v_loss': Array(6.5078196e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092136, dtype=float32), 'eval/episode_forward_reward': Array(-0.03966798, dtype=float32), 'eval/episode_reward': Array(-2.0336437, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03966798, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9927857, dtype=float32), 'eval/episode_train_reward': Array(-0.00119004, dtype=float32), 'eval/episode_x_position': Array(1.0073326, dtype=float32), 'eval/episode_x_velocity': Array(-0.03966798, dtype=float32), 'eval/episode_y_position': Array(0.00162868, dtype=float32), 'eval/episode_y_velocity': Array(-4.2722182e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00611729, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04435363, dtype=float32), 'eval/episode_reward_std': Array(0.0487463, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04435363, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02215826, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133061, dtype=float32), 'eval/episode_x_position_std': Array(0.00617939, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04435363, dtype=float32), 'eval/episode_y_position_std': Array(0.00558027, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01082683, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.683623552322388, 'eval/sps': 6188.4707810604095, 'num_steps': 3404800}
{'eval/walltime': 13893.640759706497, 'training/sps': 127.3640828214815, 'training/walltime': 26887.915338993073, 'training/entropy_loss': Array(0.11033519, dtype=float32), 'training/policy_loss': Array(0.2715198, dtype=float32), 'training/total_loss': Array(0.381855, dtype=float32), 'training/v_loss': Array(1.9614141e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089707, dtype=float32), 'eval/episode_forward_reward': Array(-0.04134118, dtype=float32), 'eval/episode_reward': Array(-2.0360153, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04134118, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9934335, dtype=float32), 'eval/episode_train_reward': Array(-0.00124024, dtype=float32), 'eval/episode_x_position': Array(1.0071112, dtype=float32), 'eval/episode_x_velocity': Array(-0.04134118, dtype=float32), 'eval/episode_y_position': Array(0.00013262, dtype=float32), 'eval/episode_y_velocity': Array(-0.00355576, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00552235, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04353483, dtype=float32), 'eval/episode_reward_std': Array(0.04947322, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04353483, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02140374, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130604, dtype=float32), 'eval/episode_x_position_std': Array(0.00547854, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04353483, dtype=float32), 'eval/episode_y_position_std': Array(0.00583734, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01130656, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.691203832626343, 'eval/sps': 6186.203617508557, 'num_steps': 3409920}
{'eval/walltime': 13914.344701766968, 'training/sps': 127.38355036561197, 'training/walltime': 26928.1089117527, 'training/entropy_loss': Array(0.10719971, dtype=float32), 'training/policy_loss': Array(0.2736742, dtype=float32), 'training/total_loss': Array(0.3808739, dtype=float32), 'training/v_loss': Array(9.475669e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090973, dtype=float32), 'eval/episode_forward_reward': Array(-0.03782877, dtype=float32), 'eval/episode_reward': Array(-2.0330882, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03782877, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994125, dtype=float32), 'eval/episode_train_reward': Array(-0.00113486, dtype=float32), 'eval/episode_x_position': Array(1.0072018, dtype=float32), 'eval/episode_x_velocity': Array(-0.03782877, dtype=float32), 'eval/episode_y_position': Array(0.00056628, dtype=float32), 'eval/episode_y_velocity': Array(-0.00238454, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00609427, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0437035, dtype=float32), 'eval/episode_reward_std': Array(0.05087705, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0437035, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02167595, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131111, dtype=float32), 'eval/episode_x_position_std': Array(0.00604724, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0437035, dtype=float32), 'eval/episode_y_position_std': Array(0.00544584, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01152592, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70394206047058, 'eval/sps': 6182.397517639241, 'num_steps': 3415040}
{'eval/walltime': 13935.01928782463, 'training/sps': 127.23971513847445, 'training/walltime': 26968.347920417786, 'training/entropy_loss': Array(0.10462907, dtype=float32), 'training/policy_loss': Array(0.26864305, dtype=float32), 'training/total_loss': Array(0.37327212, dtype=float32), 'training/v_loss': Array(1.0359904e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086592, dtype=float32), 'eval/episode_forward_reward': Array(-0.03863196, dtype=float32), 'eval/episode_reward': Array(-2.035526, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03863196, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995735, dtype=float32), 'eval/episode_train_reward': Array(-0.00115896, dtype=float32), 'eval/episode_x_position': Array(1.0067899, dtype=float32), 'eval/episode_x_velocity': Array(-0.03863196, dtype=float32), 'eval/episode_y_position': Array(-0.00032947, dtype=float32), 'eval/episode_y_velocity': Array(-0.00214734, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579573, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04339324, dtype=float32), 'eval/episode_reward_std': Array(0.04718776, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04339324, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01507971, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013018, dtype=float32), 'eval/episode_x_position_std': Array(0.00581431, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04339324, dtype=float32), 'eval/episode_y_position_std': Array(0.00568638, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01237611, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.674586057662964, 'eval/sps': 6191.175951141099, 'num_steps': 3420160}
{'eval/walltime': 13955.73590373993, 'training/sps': 127.36687929060989, 'training/walltime': 27008.54675412178, 'training/entropy_loss': Array(0.10686339, dtype=float32), 'training/policy_loss': Array(0.21434748, dtype=float32), 'training/total_loss': Array(0.3212109, dtype=float32), 'training/v_loss': Array(1.1318351e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088401, dtype=float32), 'eval/episode_forward_reward': Array(-0.03955001, dtype=float32), 'eval/episode_reward': Array(-2.037012, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03955001, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962754, dtype=float32), 'eval/episode_train_reward': Array(-0.0011865, dtype=float32), 'eval/episode_x_position': Array(1.0069988, dtype=float32), 'eval/episode_x_velocity': Array(-0.03955001, dtype=float32), 'eval/episode_y_position': Array(-2.223291e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00258177, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559181, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04286478, dtype=float32), 'eval/episode_reward_std': Array(0.04713392, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04286478, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01669768, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128594, dtype=float32), 'eval/episode_x_position_std': Array(0.00562264, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04286478, dtype=float32), 'eval/episode_y_position_std': Array(0.00535539, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01395596, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.716615915298462, 'eval/sps': 6178.615297176828, 'num_steps': 3425280}
{'eval/walltime': 13976.42312335968, 'training/sps': 127.159024830708, 'training/walltime': 27048.81129693985, 'training/entropy_loss': Array(0.1085818, dtype=float32), 'training/policy_loss': Array(0.26812166, dtype=float32), 'training/total_loss': Array(0.37670344, dtype=float32), 'training/v_loss': Array(1.2716755e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093125, dtype=float32), 'eval/episode_forward_reward': Array(-0.03958354, dtype=float32), 'eval/episode_reward': Array(-2.0363283, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03958354, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955573, dtype=float32), 'eval/episode_train_reward': Array(-0.00118751, dtype=float32), 'eval/episode_x_position': Array(1.0074589, dtype=float32), 'eval/episode_x_velocity': Array(-0.03958354, dtype=float32), 'eval/episode_y_position': Array(-0.00065923, dtype=float32), 'eval/episode_y_velocity': Array(-0.00078099, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00533042, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04168913, dtype=float32), 'eval/episode_reward_std': Array(0.0495847, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04168913, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01759427, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125067, dtype=float32), 'eval/episode_x_position_std': Array(0.00536094, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04168913, dtype=float32), 'eval/episode_y_position_std': Array(0.00560013, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0125868, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.687219619750977, 'eval/sps': 6187.39503677879, 'num_steps': 3430400}
{'eval/walltime': 13997.120415210724, 'training/sps': 127.30160372669376, 'training/walltime': 27089.0307431221, 'training/entropy_loss': Array(0.10620873, dtype=float32), 'training/policy_loss': Array(0.26812398, dtype=float32), 'training/total_loss': Array(0.37433273, dtype=float32), 'training/v_loss': Array(1.5849563e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100033, dtype=float32), 'eval/episode_forward_reward': Array(-0.03196501, dtype=float32), 'eval/episode_reward': Array(-2.0301304, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03196501, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972062, dtype=float32), 'eval/episode_train_reward': Array(-0.00095895, dtype=float32), 'eval/episode_x_position': Array(1.0081028, dtype=float32), 'eval/episode_x_velocity': Array(-0.03196501, dtype=float32), 'eval/episode_y_position': Array(-0.00029855, dtype=float32), 'eval/episode_y_velocity': Array(-0.00247314, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580704, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0422741, dtype=float32), 'eval/episode_reward_std': Array(0.04660677, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0422741, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01409817, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126822, dtype=float32), 'eval/episode_x_position_std': Array(0.00579417, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0422741, dtype=float32), 'eval/episode_y_position_std': Array(0.00603692, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0156689, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6972918510437, 'eval/sps': 6184.383972608733, 'num_steps': 3435520}
{'eval/walltime': 14017.81642818451, 'training/sps': 127.23352815684902, 'training/walltime': 27129.271708488464, 'training/entropy_loss': Array(0.10707723, dtype=float32), 'training/policy_loss': Array(0.26113585, dtype=float32), 'training/total_loss': Array(0.3682131, dtype=float32), 'training/v_loss': Array(2.502187e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094588, dtype=float32), 'eval/episode_forward_reward': Array(-0.03703738, dtype=float32), 'eval/episode_reward': Array(-2.034174, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03703738, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960256, dtype=float32), 'eval/episode_train_reward': Array(-0.00111112, dtype=float32), 'eval/episode_x_position': Array(1.0075599, dtype=float32), 'eval/episode_x_velocity': Array(-0.03703738, dtype=float32), 'eval/episode_y_position': Array(3.615336e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00148258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00591377, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04458811, dtype=float32), 'eval/episode_reward_std': Array(0.04859289, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04458811, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0166337, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133764, dtype=float32), 'eval/episode_x_position_std': Array(0.00588841, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04458811, dtype=float32), 'eval/episode_y_position_std': Array(0.00564943, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01370574, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6960129737854, 'eval/sps': 6184.766126796073, 'num_steps': 3440640}
{'eval/walltime': 14038.537068367004, 'training/sps': 127.50185544072134, 'training/walltime': 27169.427986860275, 'training/entropy_loss': Array(0.11139865, dtype=float32), 'training/policy_loss': Array(0.27075684, dtype=float32), 'training/total_loss': Array(0.3821555, dtype=float32), 'training/v_loss': Array(1.911566e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088663, dtype=float32), 'eval/episode_forward_reward': Array(-0.03085759, dtype=float32), 'eval/episode_reward': Array(-2.0277228, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03085759, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959395, dtype=float32), 'eval/episode_train_reward': Array(-0.00092573, dtype=float32), 'eval/episode_x_position': Array(1.0069416, dtype=float32), 'eval/episode_x_velocity': Array(-0.03085759, dtype=float32), 'eval/episode_y_position': Array(0.00058407, dtype=float32), 'eval/episode_y_velocity': Array(0.00038367, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578018, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04078187, dtype=float32), 'eval/episode_reward_std': Array(0.04486245, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04078187, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01651059, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122346, dtype=float32), 'eval/episode_x_position_std': Array(0.00577057, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04078187, dtype=float32), 'eval/episode_y_position_std': Array(0.00551265, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01431101, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.720640182495117, 'eval/sps': 6177.415315002426, 'num_steps': 3445760}
{'eval/walltime': 14059.232657432556, 'training/sps': 127.26360628835987, 'training/walltime': 27209.6594414711, 'training/entropy_loss': Array(0.10978873, dtype=float32), 'training/policy_loss': Array(0.2717397, dtype=float32), 'training/total_loss': Array(0.38152844, dtype=float32), 'training/v_loss': Array(7.7220985e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097212, dtype=float32), 'eval/episode_forward_reward': Array(-0.04959036, dtype=float32), 'eval/episode_reward': Array(-2.0446763, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04959036, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.993598, dtype=float32), 'eval/episode_train_reward': Array(-0.00148771, dtype=float32), 'eval/episode_x_position': Array(1.0079286, dtype=float32), 'eval/episode_x_velocity': Array(-0.04959036, dtype=float32), 'eval/episode_y_position': Array(-0.00034156, dtype=float32), 'eval/episode_y_velocity': Array(-0.00225005, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00598104, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04131652, dtype=float32), 'eval/episode_reward_std': Array(0.04670608, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04131652, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02020516, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012395, dtype=float32), 'eval/episode_x_position_std': Array(0.006011, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04131652, dtype=float32), 'eval/episode_y_position_std': Array(0.00604426, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0147744, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.695589065551758, 'eval/sps': 6184.892809504934, 'num_steps': 3450880}
{'eval/walltime': 14079.933609247208, 'training/sps': 127.35092021718103, 'training/walltime': 27249.863312721252, 'training/entropy_loss': Array(0.1087663, dtype=float32), 'training/policy_loss': Array(0.27211148, dtype=float32), 'training/total_loss': Array(0.38087776, dtype=float32), 'training/v_loss': Array(2.118471e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089251, dtype=float32), 'eval/episode_forward_reward': Array(-0.03067443, dtype=float32), 'eval/episode_reward': Array(-2.0269125, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03067443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9953177, dtype=float32), 'eval/episode_train_reward': Array(-0.00092023, dtype=float32), 'eval/episode_x_position': Array(1.0069921, dtype=float32), 'eval/episode_x_velocity': Array(-0.03067443, dtype=float32), 'eval/episode_y_position': Array(0.00104452, dtype=float32), 'eval/episode_y_velocity': Array(-0.00166036, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00597681, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04064047, dtype=float32), 'eval/episode_reward_std': Array(0.0463329, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04064047, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01806032, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121921, dtype=float32), 'eval/episode_x_position_std': Array(0.0059322, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04064047, dtype=float32), 'eval/episode_y_position_std': Array(0.00609036, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01112974, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70095181465149, 'eval/sps': 6183.29056296849, 'num_steps': 3456000}
{'eval/walltime': 14100.648816347122, 'training/sps': 127.18863308870267, 'training/walltime': 27290.118482351303, 'training/entropy_loss': Array(0.10833347, dtype=float32), 'training/policy_loss': Array(0.27184132, dtype=float32), 'training/total_loss': Array(0.3801748, dtype=float32), 'training/v_loss': Array(2.1829671e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096214, dtype=float32), 'eval/episode_forward_reward': Array(-0.04108514, dtype=float32), 'eval/episode_reward': Array(-2.0391097, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04108514, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996792, dtype=float32), 'eval/episode_train_reward': Array(-0.00123255, dtype=float32), 'eval/episode_x_position': Array(1.0078001, dtype=float32), 'eval/episode_x_velocity': Array(-0.04108514, dtype=float32), 'eval/episode_y_position': Array(0.00081608, dtype=float32), 'eval/episode_y_velocity': Array(-0.00035505, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059319, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0431729, dtype=float32), 'eval/episode_reward_std': Array(0.04827827, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0431729, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01514193, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129519, dtype=float32), 'eval/episode_x_position_std': Array(0.00589797, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0431729, dtype=float32), 'eval/episode_y_position_std': Array(0.00601381, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01158201, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71520709991455, 'eval/sps': 6179.035497092761, 'num_steps': 3461120}
{'eval/walltime': 14121.346709251404, 'training/sps': 127.25595175877686, 'training/walltime': 27330.352356910706, 'training/entropy_loss': Array(0.10509506, dtype=float32), 'training/policy_loss': Array(0.2703607, dtype=float32), 'training/total_loss': Array(0.37545577, dtype=float32), 'training/v_loss': Array(4.9911275e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0179253, dtype=float32), 'eval/episode_forward_reward': Array(-0.03886044, dtype=float32), 'eval/episode_reward': Array(-2.0512042, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03886044, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0189905, dtype=float32), 'eval/episode_train_reward': Array(-0.00116581, dtype=float32), 'eval/episode_x_position': Array(1.0160457, dtype=float32), 'eval/episode_x_velocity': Array(-0.03886044, dtype=float32), 'eval/episode_y_position': Array(0.0001492, dtype=float32), 'eval/episode_y_velocity': Array(7.843549e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08973156, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04270214, dtype=float32), 'eval/episode_reward_std': Array(0.17997697, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04270214, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26503378, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128106, dtype=float32), 'eval/episode_x_position_std': Array(0.08945586, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04270214, dtype=float32), 'eval/episode_y_position_std': Array(0.00595786, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01430616, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.697892904281616, 'eval/sps': 6184.204382153393, 'num_steps': 3466240}
{'eval/walltime': 14142.066951751709, 'training/sps': 126.94872569022016, 'training/walltime': 27370.68360066414, 'training/entropy_loss': Array(0.10615928, dtype=float32), 'training/policy_loss': Array(0.2671966, dtype=float32), 'training/total_loss': Array(0.37335587, dtype=float32), 'training/v_loss': Array(2.604055e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089874, dtype=float32), 'eval/episode_forward_reward': Array(-0.03505677, dtype=float32), 'eval/episode_reward': Array(-2.0301843, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03505677, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9940755, dtype=float32), 'eval/episode_train_reward': Array(-0.0010517, dtype=float32), 'eval/episode_x_position': Array(1.0070903, dtype=float32), 'eval/episode_x_velocity': Array(-0.03505677, dtype=float32), 'eval/episode_y_position': Array(9.0630914e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00213499, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00598443, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04312051, dtype=float32), 'eval/episode_reward_std': Array(0.04883738, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04312051, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02038241, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129362, dtype=float32), 'eval/episode_x_position_std': Array(0.00593962, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04312051, dtype=float32), 'eval/episode_y_position_std': Array(0.00579651, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01184559, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.720242500305176, 'eval/sps': 6177.533877709914, 'num_steps': 3471360}
{'eval/walltime': 14162.792097568512, 'training/sps': 127.41705908057476, 'training/walltime': 27410.866603136063, 'training/entropy_loss': Array(0.11064763, dtype=float32), 'training/policy_loss': Array(0.2649551, dtype=float32), 'training/total_loss': Array(0.37560272, dtype=float32), 'training/v_loss': Array(7.3528955e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092616, dtype=float32), 'eval/episode_forward_reward': Array(-0.03231177, dtype=float32), 'eval/episode_reward': Array(-2.0294957, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03231177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962146, dtype=float32), 'eval/episode_train_reward': Array(-0.00096935, dtype=float32), 'eval/episode_x_position': Array(1.0073458, dtype=float32), 'eval/episode_x_velocity': Array(-0.03231177, dtype=float32), 'eval/episode_y_position': Array(0.00025032, dtype=float32), 'eval/episode_y_velocity': Array(-0.00128913, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583044, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04086377, dtype=float32), 'eval/episode_reward_std': Array(0.04532362, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04086377, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01419668, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122591, dtype=float32), 'eval/episode_x_position_std': Array(0.00581313, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04086377, dtype=float32), 'eval/episode_y_position_std': Array(0.00558769, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00984821, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72514581680298, 'eval/sps': 6176.072348606763, 'num_steps': 3476480}
{'eval/walltime': 14183.502665519714, 'training/sps': 126.90088472011301, 'training/walltime': 27451.21305155754, 'training/entropy_loss': Array(0.10937369, dtype=float32), 'training/policy_loss': Array(0.2698282, dtype=float32), 'training/total_loss': Array(0.3792019, dtype=float32), 'training/v_loss': Array(2.611104e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101655, dtype=float32), 'eval/episode_forward_reward': Array(-0.03721767, dtype=float32), 'eval/episode_reward': Array(-2.034028, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03721767, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995694, dtype=float32), 'eval/episode_train_reward': Array(-0.00111653, dtype=float32), 'eval/episode_x_position': Array(1.0082917, dtype=float32), 'eval/episode_x_velocity': Array(-0.03721767, dtype=float32), 'eval/episode_y_position': Array(-0.00040548, dtype=float32), 'eval/episode_y_velocity': Array(-0.00191551, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568101, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04279513, dtype=float32), 'eval/episode_reward_std': Array(0.04666397, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04279513, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01628109, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128385, dtype=float32), 'eval/episode_x_position_std': Array(0.00566744, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04279513, dtype=float32), 'eval/episode_y_position_std': Array(0.00610126, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01507114, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.710567951202393, 'eval/sps': 6180.419595521943, 'num_steps': 3481600}
{'eval/walltime': 14204.210044145584, 'training/sps': 127.36118072702206, 'training/walltime': 27491.413683891296, 'training/entropy_loss': Array(0.10836934, dtype=float32), 'training/policy_loss': Array(0.27271473, dtype=float32), 'training/total_loss': Array(0.38108405, dtype=float32), 'training/v_loss': Array(3.22058e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085099, dtype=float32), 'eval/episode_forward_reward': Array(-0.03972572, dtype=float32), 'eval/episode_reward': Array(-2.0382915, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03972572, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997374, dtype=float32), 'eval/episode_train_reward': Array(-0.00119177, dtype=float32), 'eval/episode_x_position': Array(1.0066345, dtype=float32), 'eval/episode_x_velocity': Array(-0.03972572, dtype=float32), 'eval/episode_y_position': Array(-0.00039163, dtype=float32), 'eval/episode_y_velocity': Array(-0.0022134, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00552655, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04327841, dtype=float32), 'eval/episode_reward_std': Array(0.0454988, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04327841, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01060822, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129835, dtype=float32), 'eval/episode_x_position_std': Array(0.00551443, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04327841, dtype=float32), 'eval/episode_y_position_std': Array(0.00539296, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01392842, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70737862586975, 'eval/sps': 6181.371496249625, 'num_steps': 3486720}
{'eval/walltime': 14224.896809101105, 'training/sps': 127.21282156247383, 'training/walltime': 27531.661199331284, 'training/entropy_loss': Array(0.10820163, dtype=float32), 'training/policy_loss': Array(0.26800543, dtype=float32), 'training/total_loss': Array(0.37620705, dtype=float32), 'training/v_loss': Array(3.9282977e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095484, dtype=float32), 'eval/episode_forward_reward': Array(-0.04320887, dtype=float32), 'eval/episode_reward': Array(-2.039772, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04320887, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952672, dtype=float32), 'eval/episode_train_reward': Array(-0.00129627, dtype=float32), 'eval/episode_x_position': Array(1.0077021, dtype=float32), 'eval/episode_x_velocity': Array(-0.04320887, dtype=float32), 'eval/episode_y_position': Array(-0.00022217, dtype=float32), 'eval/episode_y_velocity': Array(-0.00026494, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00564317, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04501929, dtype=float32), 'eval/episode_reward_std': Array(0.05475215, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04501929, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02526017, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135058, dtype=float32), 'eval/episode_x_position_std': Array(0.0055854, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04501929, dtype=float32), 'eval/episode_y_position_std': Array(0.00635309, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01016462, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68676495552063, 'eval/sps': 6187.531026490487, 'num_steps': 3491840}
{'eval/walltime': 14245.629588365555, 'training/sps': 127.5083660820556, 'training/walltime': 27571.815427303314, 'training/entropy_loss': Array(0.10684071, dtype=float32), 'training/policy_loss': Array(0.27026737, dtype=float32), 'training/total_loss': Array(0.3771081, dtype=float32), 'training/v_loss': Array(2.352325e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092015, dtype=float32), 'eval/episode_forward_reward': Array(-0.04063958, dtype=float32), 'eval/episode_reward': Array(-2.038836, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04063958, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969773, dtype=float32), 'eval/episode_train_reward': Array(-0.00121919, dtype=float32), 'eval/episode_x_position': Array(1.0073342, dtype=float32), 'eval/episode_x_velocity': Array(-0.04063958, dtype=float32), 'eval/episode_y_position': Array(-0.00056391, dtype=float32), 'eval/episode_y_velocity': Array(-0.00037522, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058387, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04237438, dtype=float32), 'eval/episode_reward_std': Array(0.04444489, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04237438, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0125627, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127123, dtype=float32), 'eval/episode_x_position_std': Array(0.00579655, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04237438, dtype=float32), 'eval/episode_y_position_std': Array(0.00605724, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01436784, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.732779264450073, 'eval/sps': 6173.798426508021, 'num_steps': 3496960}
{'eval/walltime': 14266.322459459305, 'training/sps': 126.90485027944277, 'training/walltime': 27612.160614967346, 'training/entropy_loss': Array(0.10498217, dtype=float32), 'training/policy_loss': Array(0.26595226, dtype=float32), 'training/total_loss': Array(0.37093443, dtype=float32), 'training/v_loss': Array(2.8323838e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.007519, dtype=float32), 'eval/episode_forward_reward': Array(-0.04429192, dtype=float32), 'eval/episode_reward': Array(-2.0409908, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04429192, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99537, dtype=float32), 'eval/episode_train_reward': Array(-0.00132876, dtype=float32), 'eval/episode_x_position': Array(1.0056946, dtype=float32), 'eval/episode_x_velocity': Array(-0.04429192, dtype=float32), 'eval/episode_y_position': Array(0.00022155, dtype=float32), 'eval/episode_y_velocity': Array(-0.00012392, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572122, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0462794, dtype=float32), 'eval/episode_reward_std': Array(0.04681831, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0462794, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01784647, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138838, dtype=float32), 'eval/episode_x_position_std': Array(0.00573292, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0462794, dtype=float32), 'eval/episode_y_position_std': Array(0.00585681, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01374883, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69287109375, 'eval/sps': 6185.705184171406, 'num_steps': 3502080}
{'eval/walltime': 14287.008722543716, 'training/sps': 127.33670778079578, 'training/walltime': 27652.368973493576, 'training/entropy_loss': Array(0.10903756, dtype=float32), 'training/policy_loss': Array(0.2697509, dtype=float32), 'training/total_loss': Array(0.37878847, dtype=float32), 'training/v_loss': Array(2.3165303e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016521, dtype=float32), 'eval/episode_forward_reward': Array(-0.0412201, dtype=float32), 'eval/episode_reward': Array(-2.0554433, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0412201, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0207992, dtype=float32), 'eval/episode_train_reward': Array(-0.0012366, dtype=float32), 'eval/episode_x_position': Array(1.0146602, dtype=float32), 'eval/episode_x_velocity': Array(-0.0412201, dtype=float32), 'eval/episode_y_position': Array(0.00026575, dtype=float32), 'eval/episode_y_velocity': Array(-0.00143778, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09028495, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04313461, dtype=float32), 'eval/episode_reward_std': Array(0.17852275, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04313461, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2646904, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129404, dtype=float32), 'eval/episode_x_position_std': Array(0.09001718, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04313461, dtype=float32), 'eval/episode_y_position_std': Array(0.00596898, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01554198, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.68626308441162, 'eval/sps': 6187.681142683326, 'num_steps': 3507200}
{'eval/walltime': 14307.728121757507, 'training/sps': 126.97044242763327, 'training/walltime': 27692.69331908226, 'training/entropy_loss': Array(0.09980327, dtype=float32), 'training/policy_loss': Array(0.27001515, dtype=float32), 'training/total_loss': Array(0.3698184, dtype=float32), 'training/v_loss': Array(1.2208619e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088246, dtype=float32), 'eval/episode_forward_reward': Array(-0.03752586, dtype=float32), 'eval/episode_reward': Array(-2.0348787, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03752586, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962273, dtype=float32), 'eval/episode_train_reward': Array(-0.00112578, dtype=float32), 'eval/episode_x_position': Array(1.006921, dtype=float32), 'eval/episode_x_velocity': Array(-0.03752586, dtype=float32), 'eval/episode_y_position': Array(0.00036951, dtype=float32), 'eval/episode_y_velocity': Array(-0.00193536, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578567, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04411708, dtype=float32), 'eval/episode_reward_std': Array(0.04668023, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04411708, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01468765, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132351, dtype=float32), 'eval/episode_x_position_std': Array(0.00575033, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04411708, dtype=float32), 'eval/episode_y_position_std': Array(0.00517278, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01517171, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.719399213790894, 'eval/sps': 6177.785305415749, 'num_steps': 3512320}
{'eval/walltime': 14328.431069850922, 'training/sps': 127.25716133943392, 'training/walltime': 27732.92681121826, 'training/entropy_loss': Array(0.09492249, dtype=float32), 'training/policy_loss': Array(-0.07546826, dtype=float32), 'training/total_loss': Array(0.01945423, dtype=float32), 'training/v_loss': Array(2.2311267e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089356, dtype=float32), 'eval/episode_forward_reward': Array(-0.04268973, dtype=float32), 'eval/episode_reward': Array(-2.0396743, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04268973, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995704, dtype=float32), 'eval/episode_train_reward': Array(-0.00128069, dtype=float32), 'eval/episode_x_position': Array(1.0071049, dtype=float32), 'eval/episode_x_velocity': Array(-0.04268973, dtype=float32), 'eval/episode_y_position': Array(-0.00091213, dtype=float32), 'eval/episode_y_velocity': Array(-0.0017428, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594975, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04514389, dtype=float32), 'eval/episode_reward_std': Array(0.04890303, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04514389, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01511662, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135432, dtype=float32), 'eval/episode_x_position_std': Array(0.00593753, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04514389, dtype=float32), 'eval/episode_y_position_std': Array(0.00575994, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01186136, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.702948093414307, 'eval/sps': 6182.694340074076, 'num_steps': 3517440}
{'eval/walltime': 14349.14881849289, 'training/sps': 127.14264582183971, 'training/walltime': 27773.196541070938, 'training/entropy_loss': Array(0.09677378, dtype=float32), 'training/policy_loss': Array(-0.04450586, dtype=float32), 'training/total_loss': Array(0.05226791, dtype=float32), 'training/v_loss': Array(2.7674035e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100878, dtype=float32), 'eval/episode_forward_reward': Array(-0.03560051, dtype=float32), 'eval/episode_reward': Array(-2.0316246, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03560051, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.994956, dtype=float32), 'eval/episode_train_reward': Array(-0.00106802, dtype=float32), 'eval/episode_x_position': Array(1.0081799, dtype=float32), 'eval/episode_x_velocity': Array(-0.03560051, dtype=float32), 'eval/episode_y_position': Array(0.00028651, dtype=float32), 'eval/episode_y_velocity': Array(-0.00077738, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00543461, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04376961, dtype=float32), 'eval/episode_reward_std': Array(0.0477151, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04376961, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01993959, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131309, dtype=float32), 'eval/episode_x_position_std': Array(0.00543136, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04376961, dtype=float32), 'eval/episode_y_position_std': Array(0.00607153, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01305491, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.717748641967773, 'eval/sps': 6178.277486227989, 'num_steps': 3522560}
{'eval/walltime': 14369.85345339775, 'training/sps': 126.86293947384803, 'training/walltime': 27813.555057287216, 'training/entropy_loss': Array(0.09944148, dtype=float32), 'training/policy_loss': Array(0.02598787, dtype=float32), 'training/total_loss': Array(0.12542935, dtype=float32), 'training/v_loss': Array(1.978888e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098331, dtype=float32), 'eval/episode_forward_reward': Array(-0.03158736, dtype=float32), 'eval/episode_reward': Array(-2.0284164, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03158736, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958816, dtype=float32), 'eval/episode_train_reward': Array(-0.00094762, dtype=float32), 'eval/episode_x_position': Array(1.0079306, dtype=float32), 'eval/episode_x_velocity': Array(-0.03158736, dtype=float32), 'eval/episode_y_position': Array(3.4003897e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00041832, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571135, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04111771, dtype=float32), 'eval/episode_reward_std': Array(0.04524877, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04111771, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01565532, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123353, dtype=float32), 'eval/episode_x_position_std': Array(0.00576529, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04111771, dtype=float32), 'eval/episode_y_position_std': Array(0.00591856, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01186683, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70463490486145, 'eval/sps': 6182.190634520466, 'num_steps': 3527680}
{'eval/walltime': 14390.579269170761, 'training/sps': 127.0860632189775, 'training/walltime': 27853.84271645546, 'training/entropy_loss': Array(0.10442063, dtype=float32), 'training/policy_loss': Array(0.2621223, dtype=float32), 'training/total_loss': Array(0.36654294, dtype=float32), 'training/v_loss': Array(1.5131074e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0175523, dtype=float32), 'eval/episode_forward_reward': Array(-0.03846106, dtype=float32), 'eval/episode_reward': Array(-2.0504856, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03846106, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0186834, dtype=float32), 'eval/episode_train_reward': Array(-0.00115383, dtype=float32), 'eval/episode_x_position': Array(1.0156724, dtype=float32), 'eval/episode_x_velocity': Array(-0.03846106, dtype=float32), 'eval/episode_y_position': Array(-0.00045829, dtype=float32), 'eval/episode_y_velocity': Array(-0.00082698, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08839893, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04373114, dtype=float32), 'eval/episode_reward_std': Array(0.18017633, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04373114, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26532337, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131193, dtype=float32), 'eval/episode_x_position_std': Array(0.08811544, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04373114, dtype=float32), 'eval/episode_y_position_std': Array(0.00587988, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01362472, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.725815773010254, 'eval/sps': 6175.872708792734, 'num_steps': 3532800}
{'eval/walltime': 14411.27594423294, 'training/sps': 127.17524538184082, 'training/walltime': 27894.102123737335, 'training/entropy_loss': Array(0.10744908, dtype=float32), 'training/policy_loss': Array(0.11508879, dtype=float32), 'training/total_loss': Array(0.2225379, dtype=float32), 'training/v_loss': Array(2.4477412e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090961, dtype=float32), 'eval/episode_forward_reward': Array(-0.03762194, dtype=float32), 'eval/episode_reward': Array(-2.0365334, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03762194, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997783, dtype=float32), 'eval/episode_train_reward': Array(-0.00112866, dtype=float32), 'eval/episode_x_position': Array(1.0071943, dtype=float32), 'eval/episode_x_velocity': Array(-0.03762194, dtype=float32), 'eval/episode_y_position': Array(-0.00016743, dtype=float32), 'eval/episode_y_velocity': Array(-0.00233772, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569364, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04191827, dtype=float32), 'eval/episode_reward_std': Array(0.04431503, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04191827, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01038322, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125755, dtype=float32), 'eval/episode_x_position_std': Array(0.00569748, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04191827, dtype=float32), 'eval/episode_y_position_std': Array(0.00582114, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01262559, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.696675062179565, 'eval/sps': 6184.568275602059, 'num_steps': 3537920}
{'eval/walltime': 14431.953529119492, 'training/sps': 127.25835887710019, 'training/walltime': 27934.335237264633, 'training/entropy_loss': Array(0.1061044, dtype=float32), 'training/policy_loss': Array(0.14948308, dtype=float32), 'training/total_loss': Array(0.2555875, dtype=float32), 'training/v_loss': Array(7.5372647e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086107, dtype=float32), 'eval/episode_forward_reward': Array(-0.0433349, dtype=float32), 'eval/episode_reward': Array(-2.0382996, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0433349, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9936647, dtype=float32), 'eval/episode_train_reward': Array(-0.00130005, dtype=float32), 'eval/episode_x_position': Array(1.0067582, dtype=float32), 'eval/episode_x_velocity': Array(-0.0433349, dtype=float32), 'eval/episode_y_position': Array(6.276823e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00083241, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581758, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04438437, dtype=float32), 'eval/episode_reward_std': Array(0.05157353, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04438437, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02205542, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133153, dtype=float32), 'eval/episode_x_position_std': Array(0.00581119, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04438437, dtype=float32), 'eval/episode_y_position_std': Array(0.0057938, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01296989, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677584886550903, 'eval/sps': 6190.278057243216, 'num_steps': 3543040}
{'eval/walltime': 14452.661989212036, 'training/sps': 127.47144516976596, 'training/walltime': 27974.50109553337, 'training/entropy_loss': Array(0.10661313, dtype=float32), 'training/policy_loss': Array(0.2689368, dtype=float32), 'training/total_loss': Array(0.3755499, dtype=float32), 'training/v_loss': Array(3.4697623e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094888, dtype=float32), 'eval/episode_forward_reward': Array(-0.03714627, dtype=float32), 'eval/episode_reward': Array(-2.0334597, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03714627, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9951987, dtype=float32), 'eval/episode_train_reward': Array(-0.00111439, dtype=float32), 'eval/episode_x_position': Array(1.0075967, dtype=float32), 'eval/episode_x_velocity': Array(-0.03714627, dtype=float32), 'eval/episode_y_position': Array(0.00028697, dtype=float32), 'eval/episode_y_velocity': Array(-0.00334907, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568927, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04333144, dtype=float32), 'eval/episode_reward_std': Array(0.05020308, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04333144, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0174929, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129994, dtype=float32), 'eval/episode_x_position_std': Array(0.00572334, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04333144, dtype=float32), 'eval/episode_y_position_std': Array(0.00559687, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01436357, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.708460092544556, 'eval/sps': 6181.048683870147, 'num_steps': 3548160}
{'eval/walltime': 14473.324212789536, 'training/sps': 127.14219642975362, 'training/walltime': 28014.77096772194, 'training/entropy_loss': Array(0.10569228, dtype=float32), 'training/policy_loss': Array(0.26251128, dtype=float32), 'training/total_loss': Array(0.36820358, dtype=float32), 'training/v_loss': Array(1.5214194e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094674, dtype=float32), 'eval/episode_forward_reward': Array(-0.04036282, dtype=float32), 'eval/episode_reward': Array(-2.0393987, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04036282, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978251, dtype=float32), 'eval/episode_train_reward': Array(-0.00121088, dtype=float32), 'eval/episode_x_position': Array(1.0075767, dtype=float32), 'eval/episode_x_velocity': Array(-0.04036282, dtype=float32), 'eval/episode_y_position': Array(0.0006316, dtype=float32), 'eval/episode_y_velocity': Array(-0.00084309, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0054989, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04386884, dtype=float32), 'eval/episode_reward_std': Array(0.04672405, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04386884, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0098786, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131607, dtype=float32), 'eval/episode_x_position_std': Array(0.00550366, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04386884, dtype=float32), 'eval/episode_y_position_std': Array(0.00594055, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01207085, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66222357749939, 'eval/sps': 6194.880213153273, 'num_steps': 3553280}
{'eval/walltime': 14494.015872478485, 'training/sps': 127.0989680236862, 'training/walltime': 28055.05453634262, 'training/entropy_loss': Array(0.10898334, dtype=float32), 'training/policy_loss': Array(0.16283216, dtype=float32), 'training/total_loss': Array(0.2718155, dtype=float32), 'training/v_loss': Array(5.30582e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099638, dtype=float32), 'eval/episode_forward_reward': Array(-0.04161871, dtype=float32), 'eval/episode_reward': Array(-2.0408902, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04161871, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980235, dtype=float32), 'eval/episode_train_reward': Array(-0.00124856, dtype=float32), 'eval/episode_x_position': Array(1.0080922, dtype=float32), 'eval/episode_x_velocity': Array(-0.04161871, dtype=float32), 'eval/episode_y_position': Array(-0.00040472, dtype=float32), 'eval/episode_y_velocity': Array(-0.00195398, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00536064, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04540602, dtype=float32), 'eval/episode_reward_std': Array(0.04799647, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04540602, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00872694, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136218, dtype=float32), 'eval/episode_x_position_std': Array(0.00535921, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04540602, dtype=float32), 'eval/episode_y_position_std': Array(0.00546455, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01273854, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.691659688949585, 'eval/sps': 6186.06732974439, 'num_steps': 3558400}
{'eval/walltime': 14514.680845499039, 'training/sps': 127.26518632808168, 'training/walltime': 28095.285491466522, 'training/entropy_loss': Array(0.10824512, dtype=float32), 'training/policy_loss': Array(0.26315475, dtype=float32), 'training/total_loss': Array(0.37139988, dtype=float32), 'training/v_loss': Array(1.6700866e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087268, dtype=float32), 'eval/episode_forward_reward': Array(-0.03832362, dtype=float32), 'eval/episode_reward': Array(-2.0381315, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03832362, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986582, dtype=float32), 'eval/episode_train_reward': Array(-0.00114971, dtype=float32), 'eval/episode_x_position': Array(1.0068201, dtype=float32), 'eval/episode_x_velocity': Array(-0.03832362, dtype=float32), 'eval/episode_y_position': Array(0.00138044, dtype=float32), 'eval/episode_y_velocity': Array(-0.00145, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00592198, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04227642, dtype=float32), 'eval/episode_reward_std': Array(0.04364572, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04227642, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00757828, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126829, dtype=float32), 'eval/episode_x_position_std': Array(0.00590353, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04227642, dtype=float32), 'eval/episode_y_position_std': Array(0.00628154, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01379427, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66497302055359, 'eval/sps': 6194.055993815715, 'num_steps': 3563520}
{'eval/walltime': 14535.405049562454, 'training/sps': 127.01193076064722, 'training/walltime': 28135.596665143967, 'training/entropy_loss': Array(0.10542662, dtype=float32), 'training/policy_loss': Array(0.26182202, dtype=float32), 'training/total_loss': Array(0.36724865, dtype=float32), 'training/v_loss': Array(2.6520732e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088573, dtype=float32), 'eval/episode_forward_reward': Array(-0.03501043, dtype=float32), 'eval/episode_reward': Array(-2.033656, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03501043, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997595, dtype=float32), 'eval/episode_train_reward': Array(-0.00105031, dtype=float32), 'eval/episode_x_position': Array(1.0069698, dtype=float32), 'eval/episode_x_velocity': Array(-0.03501043, dtype=float32), 'eval/episode_y_position': Array(0.00027232, dtype=float32), 'eval/episode_y_velocity': Array(-0.00155975, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560973, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04270708, dtype=float32), 'eval/episode_reward_std': Array(0.046602, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04270708, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0124342, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128121, dtype=float32), 'eval/episode_x_position_std': Array(0.00562169, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04270708, dtype=float32), 'eval/episode_y_position_std': Array(0.00611533, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01323407, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.724204063415527, 'eval/sps': 6176.353002910188, 'num_steps': 3568640}
{'eval/walltime': 14556.088052034378, 'training/sps': 127.21424283854925, 'training/walltime': 28175.843730926514, 'training/entropy_loss': Array(0.10516669, dtype=float32), 'training/policy_loss': Array(0.26063138, dtype=float32), 'training/total_loss': Array(0.36579806, dtype=float32), 'training/v_loss': Array(2.5904545e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094101, dtype=float32), 'eval/episode_forward_reward': Array(-0.03869149, dtype=float32), 'eval/episode_reward': Array(-2.0358124, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03869149, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99596, dtype=float32), 'eval/episode_train_reward': Array(-0.00116074, dtype=float32), 'eval/episode_x_position': Array(1.0075754, dtype=float32), 'eval/episode_x_velocity': Array(-0.03869149, dtype=float32), 'eval/episode_y_position': Array(-0.00012919, dtype=float32), 'eval/episode_y_velocity': Array(2.268207e-06, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00555609, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04359195, dtype=float32), 'eval/episode_reward_std': Array(0.04889839, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04359195, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01736483, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130776, dtype=float32), 'eval/episode_x_position_std': Array(0.00557329, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04359195, dtype=float32), 'eval/episode_y_position_std': Array(0.0057676, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01187522, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.683002471923828, 'eval/sps': 6188.6566118122255, 'num_steps': 3573760}
{'eval/walltime': 14576.807162046432, 'training/sps': 127.2871148432985, 'training/walltime': 28216.06775522232, 'training/entropy_loss': Array(0.10719442, dtype=float32), 'training/policy_loss': Array(0.16048026, dtype=float32), 'training/total_loss': Array(0.26767468, dtype=float32), 'training/v_loss': Array(2.9929761e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0168506, dtype=float32), 'eval/episode_forward_reward': Array(-0.04375617, dtype=float32), 'eval/episode_reward': Array(-2.0574038, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04375617, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0201473, dtype=float32), 'eval/episode_train_reward': Array(-0.00131269, dtype=float32), 'eval/episode_x_position': Array(1.0149904, dtype=float32), 'eval/episode_x_velocity': Array(-0.04375617, dtype=float32), 'eval/episode_y_position': Array(0.00020149, dtype=float32), 'eval/episode_y_velocity': Array(-0.00327425, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.090193, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04396425, dtype=float32), 'eval/episode_reward_std': Array(0.17746529, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04396425, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2648963, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131893, dtype=float32), 'eval/episode_x_position_std': Array(0.08991815, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04396425, dtype=float32), 'eval/episode_y_position_std': Array(0.00624029, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01041157, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.719110012054443, 'eval/sps': 6177.871536254655, 'num_steps': 3578880}
{'eval/walltime': 14597.47369146347, 'training/sps': 127.19227764818545, 'training/walltime': 28256.321771383286, 'training/entropy_loss': Array(0.11080242, dtype=float32), 'training/policy_loss': Array(0.2674864, dtype=float32), 'training/total_loss': Array(0.3782888, dtype=float32), 'training/v_loss': Array(1.9396769e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093155, dtype=float32), 'eval/episode_forward_reward': Array(-0.04389595, dtype=float32), 'eval/episode_reward': Array(-2.0394802, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04389595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9942675, dtype=float32), 'eval/episode_train_reward': Array(-0.00131688, dtype=float32), 'eval/episode_x_position': Array(1.0074396, dtype=float32), 'eval/episode_x_velocity': Array(-0.04389595, dtype=float32), 'eval/episode_y_position': Array(0.00050724, dtype=float32), 'eval/episode_y_velocity': Array(-0.00049004, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583802, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04604691, dtype=float32), 'eval/episode_reward_std': Array(0.05213685, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04604691, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0206633, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138141, dtype=float32), 'eval/episode_x_position_std': Array(0.00585305, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04604691, dtype=float32), 'eval/episode_y_position_std': Array(0.00584602, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01681784, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666529417037964, 'eval/sps': 6193.5895194126715, 'num_steps': 3584000}
{'eval/walltime': 14618.153484106064, 'training/sps': 127.42975898039656, 'training/walltime': 28296.500769138336, 'training/entropy_loss': Array(0.11087805, dtype=float32), 'training/policy_loss': Array(0.26871672, dtype=float32), 'training/total_loss': Array(0.3795948, dtype=float32), 'training/v_loss': Array(1.282285e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.024788, dtype=float32), 'eval/episode_forward_reward': Array(-0.04339754, dtype=float32), 'eval/episode_reward': Array(-2.0710893, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04339754, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0420148, dtype=float32), 'eval/episode_train_reward': Array(-0.00130193, dtype=float32), 'eval/episode_x_position': Array(1.0228909, dtype=float32), 'eval/episode_x_velocity': Array(-0.04339754, dtype=float32), 'eval/episode_y_position': Array(0.00038894, dtype=float32), 'eval/episode_y_velocity': Array(-0.00071084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12524526, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04468713, dtype=float32), 'eval/episode_reward_std': Array(0.23973857, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04468713, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.36590827, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134061, dtype=float32), 'eval/episode_x_position_std': Array(0.12485912, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04468713, dtype=float32), 'eval/episode_y_position_std': Array(0.00589471, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01172904, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.679792642593384, 'eval/sps': 6189.617188731538, 'num_steps': 3589120}
{'eval/walltime': 14638.818323612213, 'training/sps': 127.07819766581581, 'training/walltime': 28336.7909219265, 'training/entropy_loss': Array(0.11005461, dtype=float32), 'training/policy_loss': Array(0.26728934, dtype=float32), 'training/total_loss': Array(0.37734395, dtype=float32), 'training/v_loss': Array(1.1545955e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100753, dtype=float32), 'eval/episode_forward_reward': Array(-0.03941675, dtype=float32), 'eval/episode_reward': Array(-2.0351129, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03941675, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9945135, dtype=float32), 'eval/episode_train_reward': Array(-0.0011825, dtype=float32), 'eval/episode_x_position': Array(1.0082234, dtype=float32), 'eval/episode_x_velocity': Array(-0.03941675, dtype=float32), 'eval/episode_y_position': Array(-4.736401e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.0005009, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059948, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04441723, dtype=float32), 'eval/episode_reward_std': Array(0.05116936, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04441723, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01893859, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133252, dtype=float32), 'eval/episode_x_position_std': Array(0.00597488, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04441723, dtype=float32), 'eval/episode_y_position_std': Array(0.00621488, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01625377, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.664839506149292, 'eval/sps': 6194.096013274659, 'num_steps': 3594240}
{'eval/walltime': 14659.531690597534, 'training/sps': 127.09377630206494, 'training/walltime': 28377.076136112213, 'training/entropy_loss': Array(0.11056601, dtype=float32), 'training/policy_loss': Array(0.26840603, dtype=float32), 'training/total_loss': Array(0.37897202, dtype=float32), 'training/v_loss': Array(4.112602e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089691, dtype=float32), 'eval/episode_forward_reward': Array(-0.0417834, dtype=float32), 'eval/episode_reward': Array(-2.038538, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0417834, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995501, dtype=float32), 'eval/episode_train_reward': Array(-0.0012535, dtype=float32), 'eval/episode_x_position': Array(1.0070901, dtype=float32), 'eval/episode_x_velocity': Array(-0.0417834, dtype=float32), 'eval/episode_y_position': Array(-7.1005925e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.0037888, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560736, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04532248, dtype=float32), 'eval/episode_reward_std': Array(0.05130677, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04532248, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01901498, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135967, dtype=float32), 'eval/episode_x_position_std': Array(0.0055702, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04532248, dtype=float32), 'eval/episode_y_position_std': Array(0.00570466, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01242133, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.713366985321045, 'eval/sps': 6179.584424430362, 'num_steps': 3599360}
{'eval/walltime': 14680.247691869736, 'training/sps': 127.26080756489274, 'training/walltime': 28417.308475494385, 'training/entropy_loss': Array(0.10996345, dtype=float32), 'training/policy_loss': Array(0.26690972, dtype=float32), 'training/total_loss': Array(0.37687317, dtype=float32), 'training/v_loss': Array(8.96278e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101801, dtype=float32), 'eval/episode_forward_reward': Array(-0.03877313, dtype=float32), 'eval/episode_reward': Array(-2.038841, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03877313, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9989047, dtype=float32), 'eval/episode_train_reward': Array(-0.00116319, dtype=float32), 'eval/episode_x_position': Array(1.0082729, dtype=float32), 'eval/episode_x_velocity': Array(-0.03877313, dtype=float32), 'eval/episode_y_position': Array(0.00030469, dtype=float32), 'eval/episode_y_velocity': Array(1.2652985e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588494, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04278955, dtype=float32), 'eval/episode_reward_std': Array(0.0454471, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04278955, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00722249, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128369, dtype=float32), 'eval/episode_x_position_std': Array(0.00585186, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04278955, dtype=float32), 'eval/episode_y_position_std': Array(0.00568429, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01246637, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.716001272201538, 'eval/sps': 6178.798616495602, 'num_steps': 3604480}
{'eval/walltime': 14700.958196401596, 'training/sps': 127.51999150137362, 'training/walltime': 28457.459042787552, 'training/entropy_loss': Array(0.11032005, dtype=float32), 'training/policy_loss': Array(0.2686177, dtype=float32), 'training/total_loss': Array(0.37893772, dtype=float32), 'training/v_loss': Array(3.306515e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095041, dtype=float32), 'eval/episode_forward_reward': Array(-0.03592515, dtype=float32), 'eval/episode_reward': Array(-2.0327153, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03592515, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9957123, dtype=float32), 'eval/episode_train_reward': Array(-0.00107775, dtype=float32), 'eval/episode_x_position': Array(1.007575, dtype=float32), 'eval/episode_x_velocity': Array(-0.03592515, dtype=float32), 'eval/episode_y_position': Array(-0.00091071, dtype=float32), 'eval/episode_y_velocity': Array(-0.00063023, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575966, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04320787, dtype=float32), 'eval/episode_reward_std': Array(0.05213621, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04320787, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02134793, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129624, dtype=float32), 'eval/episode_x_position_std': Array(0.00571388, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04320787, dtype=float32), 'eval/episode_y_position_std': Array(0.00576659, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01156691, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71050453186035, 'eval/sps': 6180.438521093924, 'num_steps': 3609600}
{'eval/walltime': 14721.624403715134, 'training/sps': 127.16462173344316, 'training/walltime': 28497.721813440323, 'training/entropy_loss': Array(0.11039687, dtype=float32), 'training/policy_loss': Array(0.27278426, dtype=float32), 'training/total_loss': Array(0.38318115, dtype=float32), 'training/v_loss': Array(1.7120929e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094392, dtype=float32), 'eval/episode_forward_reward': Array(-0.03729381, dtype=float32), 'eval/episode_reward': Array(-2.034513, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03729381, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961004, dtype=float32), 'eval/episode_train_reward': Array(-0.00111881, dtype=float32), 'eval/episode_x_position': Array(1.0075443, dtype=float32), 'eval/episode_x_velocity': Array(-0.03729381, dtype=float32), 'eval/episode_y_position': Array(0.00013035, dtype=float32), 'eval/episode_y_velocity': Array(-0.00266306, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593801, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04275233, dtype=float32), 'eval/episode_reward_std': Array(0.04695054, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04275233, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01644433, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128257, dtype=float32), 'eval/episode_x_position_std': Array(0.00589411, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04275233, dtype=float32), 'eval/episode_y_position_std': Array(0.00580175, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00950162, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666207313537598, 'eval/sps': 6193.686052696877, 'num_steps': 3614720}
{'eval/walltime': 14742.314972877502, 'training/sps': 127.29592684846371, 'training/walltime': 28537.943053245544, 'training/entropy_loss': Array(0.10898288, dtype=float32), 'training/policy_loss': Array(0.27107605, dtype=float32), 'training/total_loss': Array(0.38005894, dtype=float32), 'training/v_loss': Array(6.9961006e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086586, dtype=float32), 'eval/episode_forward_reward': Array(-0.04184091, dtype=float32), 'eval/episode_reward': Array(-2.0408146, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04184091, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977183, dtype=float32), 'eval/episode_train_reward': Array(-0.00125523, dtype=float32), 'eval/episode_x_position': Array(1.0067844, dtype=float32), 'eval/episode_x_velocity': Array(-0.04184091, dtype=float32), 'eval/episode_y_position': Array(-2.6011738e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00111797, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577788, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04465804, dtype=float32), 'eval/episode_reward_std': Array(0.04595475, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04465804, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00962429, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133974, dtype=float32), 'eval/episode_x_position_std': Array(0.00576303, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04465804, dtype=float32), 'eval/episode_y_position_std': Array(0.00553745, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01071325, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.690569162368774, 'eval/sps': 6186.393375432202, 'num_steps': 3619840}
{'eval/walltime': 14762.980243444443, 'training/sps': 127.28519551362353, 'training/walltime': 28578.167684078217, 'training/entropy_loss': Array(0.10845592, dtype=float32), 'training/policy_loss': Array(0.27074364, dtype=float32), 'training/total_loss': Array(0.37919956, dtype=float32), 'training/v_loss': Array(5.516e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0166712, dtype=float32), 'eval/episode_forward_reward': Array(-0.03668713, dtype=float32), 'eval/episode_reward': Array(-2.0492718, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03668713, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0192966, dtype=float32), 'eval/episode_train_reward': Array(-0.00110061, dtype=float32), 'eval/episode_x_position': Array(1.0147753, dtype=float32), 'eval/episode_x_velocity': Array(-0.03668713, dtype=float32), 'eval/episode_y_position': Array(-0.0003837, dtype=float32), 'eval/episode_y_velocity': Array(-0.00200397, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08763162, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04164769, dtype=float32), 'eval/episode_reward_std': Array(0.1723615, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04164769, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25948116, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124943, dtype=float32), 'eval/episode_x_position_std': Array(0.08736018, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04164769, dtype=float32), 'eval/episode_y_position_std': Array(0.00565703, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0128878, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.665270566940308, 'eval/sps': 6193.966809453278, 'num_steps': 3624960}
{'eval/walltime': 14783.67656326294, 'training/sps': 127.19136234541735, 'training/walltime': 28618.421989917755, 'training/entropy_loss': Array(0.10879211, dtype=float32), 'training/policy_loss': Array(0.26842523, dtype=float32), 'training/total_loss': Array(0.37721735, dtype=float32), 'training/v_loss': Array(9.588001e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099363, dtype=float32), 'eval/episode_forward_reward': Array(-0.0383358, dtype=float32), 'eval/episode_reward': Array(-2.0379791, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0383358, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984932, dtype=float32), 'eval/episode_train_reward': Array(-0.00115007, dtype=float32), 'eval/episode_x_position': Array(1.0080546, dtype=float32), 'eval/episode_x_velocity': Array(-0.0383358, dtype=float32), 'eval/episode_y_position': Array(-0.00071353, dtype=float32), 'eval/episode_y_velocity': Array(-0.00090801, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00538351, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04243102, dtype=float32), 'eval/episode_reward_std': Array(0.04463972, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04243102, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01038923, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127293, dtype=float32), 'eval/episode_x_position_std': Array(0.0054041, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04243102, dtype=float32), 'eval/episode_y_position_std': Array(0.00577178, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01393656, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.696319818496704, 'eval/sps': 6184.6744311326265, 'num_steps': 3630080}
{'eval/walltime': 14804.360309123993, 'training/sps': 127.21635220341881, 'training/walltime': 28658.6683883667, 'training/entropy_loss': Array(0.1096357, dtype=float32), 'training/policy_loss': Array(0.2670049, dtype=float32), 'training/total_loss': Array(0.37664062, dtype=float32), 'training/v_loss': Array(1.4646512e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092026, dtype=float32), 'eval/episode_forward_reward': Array(-0.04429712, dtype=float32), 'eval/episode_reward': Array(-2.0415335, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04429712, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959073, dtype=float32), 'eval/episode_train_reward': Array(-0.00132891, dtype=float32), 'eval/episode_x_position': Array(1.007312, dtype=float32), 'eval/episode_x_velocity': Array(-0.04429712, dtype=float32), 'eval/episode_y_position': Array(-2.7368704e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00397549, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589885, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04604878, dtype=float32), 'eval/episode_reward_std': Array(0.04924415, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04604878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01696629, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138146, dtype=float32), 'eval/episode_x_position_std': Array(0.00591939, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04604878, dtype=float32), 'eval/episode_y_position_std': Array(0.00656502, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0119867, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.683745861053467, 'eval/sps': 6188.434186914763, 'num_steps': 3635200}
{'eval/walltime': 14825.061802864075, 'training/sps': 126.90359489213367, 'training/walltime': 28699.013975143433, 'training/entropy_loss': Array(0.11203465, dtype=float32), 'training/policy_loss': Array(0.2667093, dtype=float32), 'training/total_loss': Array(0.37874395, dtype=float32), 'training/v_loss': Array(3.1703476e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091206, dtype=float32), 'eval/episode_forward_reward': Array(-0.04372715, dtype=float32), 'eval/episode_reward': Array(-2.0414555, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04372715, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964166, dtype=float32), 'eval/episode_train_reward': Array(-0.00131181, dtype=float32), 'eval/episode_x_position': Array(1.0072596, dtype=float32), 'eval/episode_x_velocity': Array(-0.04372715, dtype=float32), 'eval/episode_y_position': Array(8.859824e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.00186596, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567551, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04615984, dtype=float32), 'eval/episode_reward_std': Array(0.04812496, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04615984, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0160247, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013848, dtype=float32), 'eval/episode_x_position_std': Array(0.00561822, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04615984, dtype=float32), 'eval/episode_y_position_std': Array(0.0063005, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01272735, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.701493740081787, 'eval/sps': 6183.128696272248, 'num_steps': 3640320}
{'eval/walltime': 14845.711319446564, 'training/sps': 127.27683307224345, 'training/walltime': 28739.241248846054, 'training/entropy_loss': Array(0.11320794, dtype=float32), 'training/policy_loss': Array(0.26748294, dtype=float32), 'training/total_loss': Array(0.38069084, dtype=float32), 'training/v_loss': Array(5.672678e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0168965, dtype=float32), 'eval/episode_forward_reward': Array(-0.04023243, dtype=float32), 'eval/episode_reward': Array(-2.0553837, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04023243, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0217566, dtype=float32), 'eval/episode_train_reward': Array(-0.00120697, dtype=float32), 'eval/episode_x_position': Array(1.0150084, dtype=float32), 'eval/episode_x_velocity': Array(-0.04023243, dtype=float32), 'eval/episode_y_position': Array(0.00112071, dtype=float32), 'eval/episode_y_velocity': Array(-0.00203538, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08932016, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04476492, dtype=float32), 'eval/episode_reward_std': Array(0.177477, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04476492, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26444167, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134295, dtype=float32), 'eval/episode_x_position_std': Array(0.0890451, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04476492, dtype=float32), 'eval/episode_y_position_std': Array(0.00601409, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01212511, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.649516582489014, 'eval/sps': 6198.692327187224, 'num_steps': 3645440}
{'eval/walltime': 14866.423043727875, 'training/sps': 126.95952796212225, 'training/walltime': 28779.56906104088, 'training/entropy_loss': Array(0.11302766, dtype=float32), 'training/policy_loss': Array(0.27078432, dtype=float32), 'training/total_loss': Array(0.38381198, dtype=float32), 'training/v_loss': Array(3.3996987e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094199, dtype=float32), 'eval/episode_forward_reward': Array(-0.03359871, dtype=float32), 'eval/episode_reward': Array(-2.032215, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03359871, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976084, dtype=float32), 'eval/episode_train_reward': Array(-0.00100796, dtype=float32), 'eval/episode_x_position': Array(1.0074993, dtype=float32), 'eval/episode_x_velocity': Array(-0.03359871, dtype=float32), 'eval/episode_y_position': Array(0.00120417, dtype=float32), 'eval/episode_y_velocity': Array(-0.00121018, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573705, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04290648, dtype=float32), 'eval/episode_reward_std': Array(0.04362923, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04290648, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00884148, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128719, dtype=float32), 'eval/episode_x_position_std': Array(0.0057283, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04290648, dtype=float32), 'eval/episode_y_position_std': Array(0.00612512, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0150375, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.711724281311035, 'eval/sps': 6180.074544324598, 'num_steps': 3650560}
{'eval/walltime': 14887.11841917038, 'training/sps': 127.16007218886375, 'training/walltime': 28819.833272218704, 'training/entropy_loss': Array(0.11094117, dtype=float32), 'training/policy_loss': Array(0.27278882, dtype=float32), 'training/total_loss': Array(0.38373, dtype=float32), 'training/v_loss': Array(9.178908e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092652, dtype=float32), 'eval/episode_forward_reward': Array(-0.0374422, dtype=float32), 'eval/episode_reward': Array(-2.0318782, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0374422, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9933128, dtype=float32), 'eval/episode_train_reward': Array(-0.00112327, dtype=float32), 'eval/episode_x_position': Array(1.0073764, dtype=float32), 'eval/episode_x_velocity': Array(-0.0374422, dtype=float32), 'eval/episode_y_position': Array(-0.00042627, dtype=float32), 'eval/episode_y_velocity': Array(-0.00244619, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0060353, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04189881, dtype=float32), 'eval/episode_reward_std': Array(0.04873761, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04189881, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02318873, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125696, dtype=float32), 'eval/episode_x_position_std': Array(0.00601607, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04189881, dtype=float32), 'eval/episode_y_position_std': Array(0.00588227, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01150501, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.695375442504883, 'eval/sps': 6184.956651576813, 'num_steps': 3655680}
{'eval/walltime': 14907.842647790909, 'training/sps': 127.08909945209356, 'training/walltime': 28860.119968891144, 'training/entropy_loss': Array(0.10990807, dtype=float32), 'training/policy_loss': Array(0.2712876, dtype=float32), 'training/total_loss': Array(0.3811957, dtype=float32), 'training/v_loss': Array(2.0346214e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093008, dtype=float32), 'eval/episode_forward_reward': Array(-0.03567385, dtype=float32), 'eval/episode_reward': Array(-2.0338187, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03567385, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970748, dtype=float32), 'eval/episode_train_reward': Array(-0.00107022, dtype=float32), 'eval/episode_x_position': Array(1.0074239, dtype=float32), 'eval/episode_x_velocity': Array(-0.03567385, dtype=float32), 'eval/episode_y_position': Array(0.00040856, dtype=float32), 'eval/episode_y_velocity': Array(-0.00239738, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560415, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04197705, dtype=float32), 'eval/episode_reward_std': Array(0.04490197, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04197705, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01361395, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125931, dtype=float32), 'eval/episode_x_position_std': Array(0.00556894, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04197705, dtype=float32), 'eval/episode_y_position_std': Array(0.00568633, dtype=float32), 'eval/episode_y_velocity_std': Array(0.013101, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.724228620529175, 'eval/sps': 6176.345684258893, 'num_steps': 3660800}
{'eval/walltime': 14928.531753778458, 'training/sps': 127.2395281707883, 'training/walltime': 28900.359036684036, 'training/entropy_loss': Array(0.10723288, dtype=float32), 'training/policy_loss': Array(0.27025986, dtype=float32), 'training/total_loss': Array(0.37749273, dtype=float32), 'training/v_loss': Array(6.9693024e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087354, dtype=float32), 'eval/episode_forward_reward': Array(-0.04248259, dtype=float32), 'eval/episode_reward': Array(-2.0394301, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04248259, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956732, dtype=float32), 'eval/episode_train_reward': Array(-0.00127448, dtype=float32), 'eval/episode_x_position': Array(1.0069062, dtype=float32), 'eval/episode_x_velocity': Array(-0.04248259, dtype=float32), 'eval/episode_y_position': Array(-0.00048811, dtype=float32), 'eval/episode_y_velocity': Array(-0.00209412, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00605319, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04456754, dtype=float32), 'eval/episode_reward_std': Array(0.04625686, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04456754, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01728386, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133703, dtype=float32), 'eval/episode_x_position_std': Array(0.00604178, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04456754, dtype=float32), 'eval/episode_y_position_std': Array(0.00575004, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01468097, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.689105987548828, 'eval/sps': 6186.830889504519, 'num_steps': 3665920}
{'eval/walltime': 14949.250852108002, 'training/sps': 127.39228882167785, 'training/walltime': 28940.549852371216, 'training/entropy_loss': Array(0.10589641, dtype=float32), 'training/policy_loss': Array(0.1534301, dtype=float32), 'training/total_loss': Array(0.25932652, dtype=float32), 'training/v_loss': Array(1.0852228e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094311, dtype=float32), 'eval/episode_forward_reward': Array(-0.04028444, dtype=float32), 'eval/episode_reward': Array(-2.0365982, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04028444, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9951053, dtype=float32), 'eval/episode_train_reward': Array(-0.00120853, dtype=float32), 'eval/episode_x_position': Array(1.007545, dtype=float32), 'eval/episode_x_velocity': Array(-0.04028444, dtype=float32), 'eval/episode_y_position': Array(-0.00073454, dtype=float32), 'eval/episode_y_velocity': Array(-0.00334199, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593175, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04393696, dtype=float32), 'eval/episode_reward_std': Array(0.04896446, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04393696, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01835642, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131811, dtype=float32), 'eval/episode_x_position_std': Array(0.00587691, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04393696, dtype=float32), 'eval/episode_y_position_std': Array(0.00561848, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01431971, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.719098329544067, 'eval/sps': 6177.875019661471, 'num_steps': 3671040}
{'eval/walltime': 14969.945966959, 'training/sps': 127.16415938485689, 'training/walltime': 28980.812769412994, 'training/entropy_loss': Array(0.10965252, dtype=float32), 'training/policy_loss': Array(0.26670265, dtype=float32), 'training/total_loss': Array(0.37635517, dtype=float32), 'training/v_loss': Array(2.467649e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009587, dtype=float32), 'eval/episode_forward_reward': Array(-0.03536674, dtype=float32), 'eval/episode_reward': Array(-2.033087, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03536674, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966593, dtype=float32), 'eval/episode_train_reward': Array(-0.001061, dtype=float32), 'eval/episode_x_position': Array(1.0077006, dtype=float32), 'eval/episode_x_velocity': Array(-0.03536674, dtype=float32), 'eval/episode_y_position': Array(-0.00058694, dtype=float32), 'eval/episode_y_velocity': Array(-0.00111305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580939, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04207097, dtype=float32), 'eval/episode_reward_std': Array(0.0451103, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04207097, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01412904, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126213, dtype=float32), 'eval/episode_x_position_std': Array(0.00578081, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04207097, dtype=float32), 'eval/episode_y_position_std': Array(0.00556758, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01275162, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.695114850997925, 'eval/sps': 6185.034532138767, 'num_steps': 3676160}
{'eval/walltime': 14990.647526025772, 'training/sps': 127.1198174106297, 'training/walltime': 29021.089730978012, 'training/entropy_loss': Array(0.11091048, dtype=float32), 'training/policy_loss': Array(0.26617232, dtype=float32), 'training/total_loss': Array(0.37708277, dtype=float32), 'training/v_loss': Array(2.4634144e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089865, dtype=float32), 'eval/episode_forward_reward': Array(-0.04734534, dtype=float32), 'eval/episode_reward': Array(-2.0460978, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04734534, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973316, dtype=float32), 'eval/episode_train_reward': Array(-0.00142036, dtype=float32), 'eval/episode_x_position': Array(1.0071658, dtype=float32), 'eval/episode_x_velocity': Array(-0.04734534, dtype=float32), 'eval/episode_y_position': Array(0.00016554, dtype=float32), 'eval/episode_y_velocity': Array(-8.73316e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588077, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04664323, dtype=float32), 'eval/episode_reward_std': Array(0.0491224, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04664323, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01371699, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013993, dtype=float32), 'eval/episode_x_position_std': Array(0.0059072, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04664323, dtype=float32), 'eval/episode_y_position_std': Array(0.00598386, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01534195, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70155906677246, 'eval/sps': 6183.109184537193, 'num_steps': 3681280}
{'eval/walltime': 15011.33880519867, 'training/sps': 126.98422631026176, 'training/walltime': 29061.409699440002, 'training/entropy_loss': Array(0.11079915, dtype=float32), 'training/policy_loss': Array(0.27083367, dtype=float32), 'training/total_loss': Array(0.3816328, dtype=float32), 'training/v_loss': Array(4.831994e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0162722, dtype=float32), 'eval/episode_forward_reward': Array(-0.03450837, dtype=float32), 'eval/episode_reward': Array(-2.04793, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03450837, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.020199, dtype=float32), 'eval/episode_train_reward': Array(-0.00103525, dtype=float32), 'eval/episode_x_position': Array(1.0143505, dtype=float32), 'eval/episode_x_velocity': Array(-0.03450837, dtype=float32), 'eval/episode_y_position': Array(-0.00017593, dtype=float32), 'eval/episode_y_velocity': Array(-0.00158407, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08772786, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04284437, dtype=float32), 'eval/episode_reward_std': Array(0.18035895, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04284437, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26476675, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128533, dtype=float32), 'eval/episode_x_position_std': Array(0.08745714, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04284437, dtype=float32), 'eval/episode_y_position_std': Array(0.00571301, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01094597, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.69127917289734, 'eval/sps': 6186.181092547529, 'num_steps': 3686400}
{'eval/walltime': 15032.072307825089, 'training/sps': 126.98891271613914, 'training/walltime': 29101.72817993164, 'training/entropy_loss': Array(0.10931052, dtype=float32), 'training/policy_loss': Array(0.26791382, dtype=float32), 'training/total_loss': Array(0.37722433, dtype=float32), 'training/v_loss': Array(1.4847622e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0251349, dtype=float32), 'eval/episode_forward_reward': Array(-0.04141677, dtype=float32), 'eval/episode_reward': Array(-2.071472, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04141677, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0444376, dtype=float32), 'eval/episode_train_reward': Array(-0.0012425, dtype=float32), 'eval/episode_x_position': Array(1.023247, dtype=float32), 'eval/episode_x_velocity': Array(-0.04141677, dtype=float32), 'eval/episode_y_position': Array(0.00025194, dtype=float32), 'eval/episode_y_velocity': Array(0.00031333, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12659627, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04343483, dtype=float32), 'eval/episode_reward_std': Array(0.24735197, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04343483, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37251878, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130304, dtype=float32), 'eval/episode_x_position_std': Array(0.12621695, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04343483, dtype=float32), 'eval/episode_y_position_std': Array(0.00598202, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01341761, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.733502626419067, 'eval/sps': 6173.583031595428, 'num_steps': 3691520}
{'eval/walltime': 15052.769340991974, 'training/sps': 126.99351310421594, 'training/walltime': 29142.045199871063, 'training/entropy_loss': Array(0.10979436, dtype=float32), 'training/policy_loss': Array(0.27050853, dtype=float32), 'training/total_loss': Array(0.3803029, dtype=float32), 'training/v_loss': Array(9.063537e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169144, dtype=float32), 'eval/episode_forward_reward': Array(-0.041651, dtype=float32), 'eval/episode_reward': Array(-2.056264, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.041651, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.021176, dtype=float32), 'eval/episode_train_reward': Array(-0.00124953, dtype=float32), 'eval/episode_x_position': Array(1.0150279, dtype=float32), 'eval/episode_x_velocity': Array(-0.041651, dtype=float32), 'eval/episode_y_position': Array(0.00020365, dtype=float32), 'eval/episode_y_velocity': Array(-0.00100452, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08902218, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04477234, dtype=float32), 'eval/episode_reward_std': Array(0.17826396, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04477234, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2646105, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134317, dtype=float32), 'eval/episode_x_position_std': Array(0.08874578, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04477234, dtype=float32), 'eval/episode_y_position_std': Array(0.00595689, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01616635, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.697033166885376, 'eval/sps': 6184.461268815866, 'num_steps': 3696640}
{'eval/walltime': 15073.4810359478, 'training/sps': 127.18145833132961, 'training/walltime': 29182.30264043808, 'training/entropy_loss': Array(0.10826206, dtype=float32), 'training/policy_loss': Array(0.26807553, dtype=float32), 'training/total_loss': Array(0.3763376, dtype=float32), 'training/v_loss': Array(1.85347e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097235, dtype=float32), 'eval/episode_forward_reward': Array(-0.04241747, dtype=float32), 'eval/episode_reward': Array(-2.0396323, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04241747, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959424, dtype=float32), 'eval/episode_train_reward': Array(-0.00127252, dtype=float32), 'eval/episode_x_position': Array(1.0078893, dtype=float32), 'eval/episode_x_velocity': Array(-0.04241747, dtype=float32), 'eval/episode_y_position': Array(-0.00034257, dtype=float32), 'eval/episode_y_velocity': Array(-0.00106893, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00546548, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04432013, dtype=float32), 'eval/episode_reward_std': Array(0.05027164, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04432013, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01660469, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013296, dtype=float32), 'eval/episode_x_position_std': Array(0.00540436, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04432013, dtype=float32), 'eval/episode_y_position_std': Array(0.00555527, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01651006, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.711694955825806, 'eval/sps': 6180.083294631376, 'num_steps': 3701760}
{'eval/walltime': 15094.181001901627, 'training/sps': 127.23333517672486, 'training/walltime': 29222.5436668396, 'training/entropy_loss': Array(0.11003011, dtype=float32), 'training/policy_loss': Array(0.26775387, dtype=float32), 'training/total_loss': Array(0.377784, dtype=float32), 'training/v_loss': Array(4.3648263e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169632, dtype=float32), 'eval/episode_forward_reward': Array(-0.03787223, dtype=float32), 'eval/episode_reward': Array(-2.052143, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03787223, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0209475, dtype=float32), 'eval/episode_train_reward': Array(-0.00113617, dtype=float32), 'eval/episode_x_position': Array(1.0150847, dtype=float32), 'eval/episode_x_velocity': Array(-0.03787223, dtype=float32), 'eval/episode_y_position': Array(0.0002983, dtype=float32), 'eval/episode_y_velocity': Array(-3.8540573e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08829882, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04239061, dtype=float32), 'eval/episode_reward_std': Array(0.17887868, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04239061, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26452333, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127172, dtype=float32), 'eval/episode_x_position_std': Array(0.08803231, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04239061, dtype=float32), 'eval/episode_y_position_std': Array(0.00637209, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01183102, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.699965953826904, 'eval/sps': 6183.585049633186, 'num_steps': 3706880}
{'eval/walltime': 15114.881953239441, 'training/sps': 127.22867895486843, 'training/walltime': 29262.786165952682, 'training/entropy_loss': Array(0.10953895, dtype=float32), 'training/policy_loss': Array(0.2684303, dtype=float32), 'training/total_loss': Array(0.37796924, dtype=float32), 'training/v_loss': Array(1.4001403e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092258, dtype=float32), 'eval/episode_forward_reward': Array(-0.03637413, dtype=float32), 'eval/episode_reward': Array(-2.031062, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03637413, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9935966, dtype=float32), 'eval/episode_train_reward': Array(-0.00109122, dtype=float32), 'eval/episode_x_position': Array(1.0073248, dtype=float32), 'eval/episode_x_velocity': Array(-0.03637413, dtype=float32), 'eval/episode_y_position': Array(0.00076435, dtype=float32), 'eval/episode_y_velocity': Array(-0.00029171, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576151, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04272144, dtype=float32), 'eval/episode_reward_std': Array(0.04893035, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04272144, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02178123, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128164, dtype=float32), 'eval/episode_x_position_std': Array(0.00578186, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04272144, dtype=float32), 'eval/episode_y_position_std': Array(0.00578148, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01138794, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70095133781433, 'eval/sps': 6183.290705397824, 'num_steps': 3712000}
{'eval/walltime': 15135.562257766724, 'training/sps': 127.07826459298607, 'training/walltime': 29303.07629752159, 'training/entropy_loss': Array(0.10971701, dtype=float32), 'training/policy_loss': Array(0.2680431, dtype=float32), 'training/total_loss': Array(0.3777601, dtype=float32), 'training/v_loss': Array(2.7592075e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008349, dtype=float32), 'eval/episode_forward_reward': Array(-0.03706571, dtype=float32), 'eval/episode_reward': Array(-2.036246, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03706571, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980683, dtype=float32), 'eval/episode_train_reward': Array(-0.00111197, dtype=float32), 'eval/episode_x_position': Array(1.0064458, dtype=float32), 'eval/episode_x_velocity': Array(-0.03706571, dtype=float32), 'eval/episode_y_position': Array(-0.00044784, dtype=float32), 'eval/episode_y_velocity': Array(-0.0013466, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00543018, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04336146, dtype=float32), 'eval/episode_reward_std': Array(0.04723808, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04336146, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01052848, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130084, dtype=float32), 'eval/episode_x_position_std': Array(0.00536652, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04336146, dtype=float32), 'eval/episode_y_position_std': Array(0.00602422, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01098122, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680304527282715, 'eval/sps': 6189.463981593434, 'num_steps': 3717120}
{'eval/walltime': 15156.252363204956, 'training/sps': 127.38714489665772, 'training/walltime': 29343.26873612404, 'training/entropy_loss': Array(0.11097744, dtype=float32), 'training/policy_loss': Array(0.26578173, dtype=float32), 'training/total_loss': Array(0.37675917, dtype=float32), 'training/v_loss': Array(4.2576334e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094366, dtype=float32), 'eval/episode_forward_reward': Array(-0.03711887, dtype=float32), 'eval/episode_reward': Array(-2.0357475, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03711887, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997515, dtype=float32), 'eval/episode_train_reward': Array(-0.00111357, dtype=float32), 'eval/episode_x_position': Array(1.007539, dtype=float32), 'eval/episode_x_velocity': Array(-0.03711887, dtype=float32), 'eval/episode_y_position': Array(0.00053603, dtype=float32), 'eval/episode_y_velocity': Array(-0.00235008, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00606809, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04163939, dtype=float32), 'eval/episode_reward_std': Array(0.04524293, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04163939, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01240166, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124918, dtype=float32), 'eval/episode_x_position_std': Array(0.0059992, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04163939, dtype=float32), 'eval/episode_y_position_std': Array(0.00592855, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0134559, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.690105438232422, 'eval/sps': 6186.532030111064, 'num_steps': 3722240}
{'eval/walltime': 15176.927479505539, 'training/sps': 126.99749121420527, 'training/walltime': 29383.584493160248, 'training/entropy_loss': Array(0.11022507, dtype=float32), 'training/policy_loss': Array(0.27179334, dtype=float32), 'training/total_loss': Array(0.3820184, dtype=float32), 'training/v_loss': Array(2.7449056e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0164173, dtype=float32), 'eval/episode_forward_reward': Array(-0.03486088, dtype=float32), 'eval/episode_reward': Array(-2.0478077, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03486088, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0197134, dtype=float32), 'eval/episode_train_reward': Array(-0.00104583, dtype=float32), 'eval/episode_x_position': Array(1.0145032, dtype=float32), 'eval/episode_x_velocity': Array(-0.03486088, dtype=float32), 'eval/episode_y_position': Array(-0.00075421, dtype=float32), 'eval/episode_y_velocity': Array(-0.00164027, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09069884, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04213923, dtype=float32), 'eval/episode_reward_std': Array(0.17999224, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04213923, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26496586, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126418, dtype=float32), 'eval/episode_x_position_std': Array(0.0904407, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04213923, dtype=float32), 'eval/episode_y_position_std': Array(0.00557967, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01455558, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.675116300582886, 'eval/sps': 6191.017169581355, 'num_steps': 3727360}
{'eval/walltime': 15197.63042640686, 'training/sps': 127.23994658713735, 'training/walltime': 29423.82342863083, 'training/entropy_loss': Array(0.10869408, dtype=float32), 'training/policy_loss': Array(0.2664836, dtype=float32), 'training/total_loss': Array(0.37517768, dtype=float32), 'training/v_loss': Array(3.3123366e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095952, dtype=float32), 'eval/episode_forward_reward': Array(-0.03727075, dtype=float32), 'eval/episode_reward': Array(-2.0348954, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03727075, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965067, dtype=float32), 'eval/episode_train_reward': Array(-0.00111812, dtype=float32), 'eval/episode_x_position': Array(1.0076833, dtype=float32), 'eval/episode_x_velocity': Array(-0.03727075, dtype=float32), 'eval/episode_y_position': Array(0.00084689, dtype=float32), 'eval/episode_y_velocity': Array(-0.00064991, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599024, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04301991, dtype=float32), 'eval/episode_reward_std': Array(0.04528463, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04301991, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01494442, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012906, dtype=float32), 'eval/episode_x_position_std': Array(0.00598146, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04301991, dtype=float32), 'eval/episode_y_position_std': Array(0.00565827, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01251892, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70294690132141, 'eval/sps': 6182.694696078755, 'num_steps': 3732480}
{'eval/walltime': 15218.332439184189, 'training/sps': 126.91216936697731, 'training/walltime': 29464.166289567947, 'training/entropy_loss': Array(0.1087172, dtype=float32), 'training/policy_loss': Array(0.26857644, dtype=float32), 'training/total_loss': Array(0.37729365, dtype=float32), 'training/v_loss': Array(5.925904e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084183, dtype=float32), 'eval/episode_forward_reward': Array(-0.03692671, dtype=float32), 'eval/episode_reward': Array(-2.0367231, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03692671, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986885, dtype=float32), 'eval/episode_train_reward': Array(-0.0011078, dtype=float32), 'eval/episode_x_position': Array(1.0065293, dtype=float32), 'eval/episode_x_velocity': Array(-0.03692671, dtype=float32), 'eval/episode_y_position': Array(0.00046508, dtype=float32), 'eval/episode_y_velocity': Array(-9.410328e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573231, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04386872, dtype=float32), 'eval/episode_reward_std': Array(0.04554547, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04386872, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00701634, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131606, dtype=float32), 'eval/episode_x_position_std': Array(0.00576361, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04386872, dtype=float32), 'eval/episode_y_position_std': Array(0.00584943, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01258444, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70201277732849, 'eval/sps': 6182.973673950069, 'num_steps': 3737600}
{'eval/walltime': 15239.030407905579, 'training/sps': 127.30362844898463, 'training/walltime': 29504.38509607315, 'training/entropy_loss': Array(0.11235853, dtype=float32), 'training/policy_loss': Array(0.27296525, dtype=float32), 'training/total_loss': Array(0.38532376, dtype=float32), 'training/v_loss': Array(5.2342554e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009162, dtype=float32), 'eval/episode_forward_reward': Array(-0.04124393, dtype=float32), 'eval/episode_reward': Array(-2.0377357, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04124393, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9952545, dtype=float32), 'eval/episode_train_reward': Array(-0.00123732, dtype=float32), 'eval/episode_x_position': Array(1.0073137, dtype=float32), 'eval/episode_x_velocity': Array(-0.04124393, dtype=float32), 'eval/episode_y_position': Array(-0.00029641, dtype=float32), 'eval/episode_y_velocity': Array(-0.00030306, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00620395, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04465196, dtype=float32), 'eval/episode_reward_std': Array(0.04808668, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04465196, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01603116, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133956, dtype=float32), 'eval/episode_x_position_std': Array(0.00617905, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04465196, dtype=float32), 'eval/episode_y_position_std': Array(0.00553093, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0154597, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69796872138977, 'eval/sps': 6184.181729278669, 'num_steps': 3742720}
{'eval/walltime': 15259.745640039444, 'training/sps': 126.87914004321262, 'training/walltime': 29544.73845911026, 'training/entropy_loss': Array(0.10645667, dtype=float32), 'training/policy_loss': Array(0.27198255, dtype=float32), 'training/total_loss': Array(0.37843925, dtype=float32), 'training/v_loss': Array(2.5254806e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086522, dtype=float32), 'eval/episode_forward_reward': Array(-0.0399861, dtype=float32), 'eval/episode_reward': Array(-2.0393195, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0399861, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998134, dtype=float32), 'eval/episode_train_reward': Array(-0.00119958, dtype=float32), 'eval/episode_x_position': Array(1.0068059, dtype=float32), 'eval/episode_x_velocity': Array(-0.0399861, dtype=float32), 'eval/episode_y_position': Array(-0.00082157, dtype=float32), 'eval/episode_y_velocity': Array(-0.00199002, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579242, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04270306, dtype=float32), 'eval/episode_reward_std': Array(0.04487899, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04270306, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00985352, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128109, dtype=float32), 'eval/episode_x_position_std': Array(0.00576565, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04270306, dtype=float32), 'eval/episode_y_position_std': Array(0.00617198, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01043688, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.715232133865356, 'eval/sps': 6179.028029849833, 'num_steps': 3747840}
{'eval/walltime': 15280.464145183563, 'training/sps': 127.10521038558392, 'training/walltime': 29585.020049333572, 'training/entropy_loss': Array(0.10486805, dtype=float32), 'training/policy_loss': Array(0.26236326, dtype=float32), 'training/total_loss': Array(0.36723128, dtype=float32), 'training/v_loss': Array(1.4905025e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0162125, dtype=float32), 'eval/episode_forward_reward': Array(-0.04188002, dtype=float32), 'eval/episode_reward': Array(-2.0554032, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04188002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0200794, dtype=float32), 'eval/episode_train_reward': Array(-0.0012564, dtype=float32), 'eval/episode_x_position': Array(1.014324, dtype=float32), 'eval/episode_x_velocity': Array(-0.04188002, dtype=float32), 'eval/episode_y_position': Array(0.00028742, dtype=float32), 'eval/episode_y_velocity': Array(-0.0030127, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08865924, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04397514, dtype=float32), 'eval/episode_reward_std': Array(0.17903596, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04397514, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26485103, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131925, dtype=float32), 'eval/episode_x_position_std': Array(0.08838616, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04397514, dtype=float32), 'eval/episode_y_position_std': Array(0.00621251, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01118623, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.718505144119263, 'eval/sps': 6178.051896583451, 'num_steps': 3752960}
{'eval/walltime': 15301.162822723389, 'training/sps': 126.90890983506273, 'training/walltime': 29625.363946437836, 'training/entropy_loss': Array(0.10673526, dtype=float32), 'training/policy_loss': Array(0.03032609, dtype=float32), 'training/total_loss': Array(0.13706134, dtype=float32), 'training/v_loss': Array(1.0766288e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092316, dtype=float32), 'eval/episode_forward_reward': Array(-0.03935692, dtype=float32), 'eval/episode_reward': Array(-2.036716, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03935692, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961784, dtype=float32), 'eval/episode_train_reward': Array(-0.00118071, dtype=float32), 'eval/episode_x_position': Array(1.0073818, dtype=float32), 'eval/episode_x_velocity': Array(-0.03935692, dtype=float32), 'eval/episode_y_position': Array(-0.00030914, dtype=float32), 'eval/episode_y_velocity': Array(-0.00115817, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00618855, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04273083, dtype=float32), 'eval/episode_reward_std': Array(0.04820717, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04273083, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01718047, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128192, dtype=float32), 'eval/episode_x_position_std': Array(0.00617334, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04273083, dtype=float32), 'eval/episode_y_position_std': Array(0.00590873, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01313231, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69867753982544, 'eval/sps': 6183.969954298804, 'num_steps': 3758080}
{'eval/walltime': 15321.863317728043, 'training/sps': 127.38166363914182, 'training/walltime': 29665.558114528656, 'training/entropy_loss': Array(0.10974257, dtype=float32), 'training/policy_loss': Array(0.2684045, dtype=float32), 'training/total_loss': Array(0.37814707, dtype=float32), 'training/v_loss': Array(1.9801771e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0174664, dtype=float32), 'eval/episode_forward_reward': Array(-0.04296828, dtype=float32), 'eval/episode_reward': Array(-2.054336, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04296828, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0178914, dtype=float32), 'eval/episode_train_reward': Array(-0.00128905, dtype=float32), 'eval/episode_x_position': Array(1.0156171, dtype=float32), 'eval/episode_x_velocity': Array(-0.04296828, dtype=float32), 'eval/episode_y_position': Array(-0.00023254, dtype=float32), 'eval/episode_y_velocity': Array(-0.00167766, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09002879, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04387136, dtype=float32), 'eval/episode_reward_std': Array(0.18059829, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04387136, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26522216, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131614, dtype=float32), 'eval/episode_x_position_std': Array(0.08975337, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04387136, dtype=float32), 'eval/episode_y_position_std': Array(0.00541443, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00741868, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.70049500465393, 'eval/sps': 6183.427013277835, 'num_steps': 3763200}
{'eval/walltime': 15342.525580406189, 'training/sps': 127.00985671416593, 'training/walltime': 29705.869946479797, 'training/entropy_loss': Array(0.10967011, dtype=float32), 'training/policy_loss': Array(0.26526177, dtype=float32), 'training/total_loss': Array(0.37493187, dtype=float32), 'training/v_loss': Array(4.203508e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089123, dtype=float32), 'eval/episode_forward_reward': Array(-0.03964834, dtype=float32), 'eval/episode_reward': Array(-2.0388927, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03964834, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998055, dtype=float32), 'eval/episode_train_reward': Array(-0.00118945, dtype=float32), 'eval/episode_x_position': Array(1.0070355, dtype=float32), 'eval/episode_x_velocity': Array(-0.03964834, dtype=float32), 'eval/episode_y_position': Array(-0.00047043, dtype=float32), 'eval/episode_y_velocity': Array(-0.001505, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00609354, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04339281, dtype=float32), 'eval/episode_reward_std': Array(0.04561256, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04339281, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00867271, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130178, dtype=float32), 'eval/episode_x_position_std': Array(0.00615316, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04339281, dtype=float32), 'eval/episode_y_position_std': Array(0.00550591, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01213668, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.662262678146362, 'eval/sps': 6194.86849014752, 'num_steps': 3768320}
{'eval/walltime': 15363.221984863281, 'training/sps': 127.11629664049343, 'training/walltime': 29746.148023605347, 'training/entropy_loss': Array(0.11163364, dtype=float32), 'training/policy_loss': Array(0.26672202, dtype=float32), 'training/total_loss': Array(0.37835568, dtype=float32), 'training/v_loss': Array(1.3178122e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0250084, dtype=float32), 'eval/episode_forward_reward': Array(-0.03663257, dtype=float32), 'eval/episode_reward': Array(-2.0660236, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03663257, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0439172, dtype=float32), 'eval/episode_train_reward': Array(-0.00109898, dtype=float32), 'eval/episode_x_position': Array(1.0230973, dtype=float32), 'eval/episode_x_velocity': Array(-0.03663257, dtype=float32), 'eval/episode_y_position': Array(-0.00026603, dtype=float32), 'eval/episode_y_velocity': Array(-0.00061186, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12619631, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0438121, dtype=float32), 'eval/episode_reward_std': Array(0.24827337, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0438121, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37269062, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131436, dtype=float32), 'eval/episode_x_position_std': Array(0.12581567, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0438121, dtype=float32), 'eval/episode_y_position_std': Array(0.00590465, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01099223, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.696404457092285, 'eval/sps': 6184.649138712435, 'num_steps': 3773440}
{'eval/walltime': 15383.869710683823, 'training/sps': 127.16650655408138, 'training/walltime': 29786.410197496414, 'training/entropy_loss': Array(0.11069559, dtype=float32), 'training/policy_loss': Array(0.26954973, dtype=float32), 'training/total_loss': Array(0.38024533, dtype=float32), 'training/v_loss': Array(1.2863302e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087032, dtype=float32), 'eval/episode_forward_reward': Array(-0.03778321, dtype=float32), 'eval/episode_reward': Array(-2.0364532, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03778321, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975367, dtype=float32), 'eval/episode_train_reward': Array(-0.0011335, dtype=float32), 'eval/episode_x_position': Array(1.0067773, dtype=float32), 'eval/episode_x_velocity': Array(-0.03778321, dtype=float32), 'eval/episode_y_position': Array(0.00055505, dtype=float32), 'eval/episode_y_velocity': Array(-0.00013412, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558436, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04298367, dtype=float32), 'eval/episode_reward_std': Array(0.04506929, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04298367, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01194197, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128951, dtype=float32), 'eval/episode_x_position_std': Array(0.00556311, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04298367, dtype=float32), 'eval/episode_y_position_std': Array(0.00582526, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00894223, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647725820541382, 'eval/sps': 6199.229935175682, 'num_steps': 3778560}
{'eval/walltime': 15404.551233291626, 'training/sps': 127.323415707418, 'training/walltime': 29826.622753620148, 'training/entropy_loss': Array(0.10992026, dtype=float32), 'training/policy_loss': Array(0.26868993, dtype=float32), 'training/total_loss': Array(0.37861022, dtype=float32), 'training/v_loss': Array(1.7432333e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097629, dtype=float32), 'eval/episode_forward_reward': Array(-0.03945882, dtype=float32), 'eval/episode_reward': Array(-2.0380862, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03945882, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974437, dtype=float32), 'eval/episode_train_reward': Array(-0.00118376, dtype=float32), 'eval/episode_x_position': Array(1.0078595, dtype=float32), 'eval/episode_x_velocity': Array(-0.03945882, dtype=float32), 'eval/episode_y_position': Array(-0.00017833, dtype=float32), 'eval/episode_y_velocity': Array(-0.00071404, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580019, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04570369, dtype=float32), 'eval/episode_reward_std': Array(0.04727954, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04570369, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01187638, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137111, dtype=float32), 'eval/episode_x_position_std': Array(0.00578733, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04570369, dtype=float32), 'eval/episode_y_position_std': Array(0.00540853, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01647772, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.681522607803345, 'eval/sps': 6189.099440468872, 'num_steps': 3783680}
{'eval/walltime': 15425.197746753693, 'training/sps': 127.01142895688047, 'training/walltime': 29866.934086561203, 'training/entropy_loss': Array(0.11031538, dtype=float32), 'training/policy_loss': Array(0.2684185, dtype=float32), 'training/total_loss': Array(0.37873387, dtype=float32), 'training/v_loss': Array(7.464573e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095725, dtype=float32), 'eval/episode_forward_reward': Array(-0.03965083, dtype=float32), 'eval/episode_reward': Array(-2.0342615, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03965083, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9934213, dtype=float32), 'eval/episode_train_reward': Array(-0.00118952, dtype=float32), 'eval/episode_x_position': Array(1.0077212, dtype=float32), 'eval/episode_x_velocity': Array(-0.03965083, dtype=float32), 'eval/episode_y_position': Array(0.00110427, dtype=float32), 'eval/episode_y_velocity': Array(-0.00060265, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00603404, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04521437, dtype=float32), 'eval/episode_reward_std': Array(0.05250926, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04521437, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02292572, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135643, dtype=float32), 'eval/episode_x_position_std': Array(0.00600636, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04521437, dtype=float32), 'eval/episode_y_position_std': Array(0.00572778, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01400943, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64651346206665, 'eval/sps': 6199.593952517522, 'num_steps': 3788800}
{'eval/walltime': 15445.924731254578, 'training/sps': 127.16611045849118, 'training/walltime': 29907.196385860443, 'training/entropy_loss': Array(0.11173762, dtype=float32), 'training/policy_loss': Array(0.2711619, dtype=float32), 'training/total_loss': Array(0.38289955, dtype=float32), 'training/v_loss': Array(3.3196768e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008603, dtype=float32), 'eval/episode_forward_reward': Array(-0.04170044, dtype=float32), 'eval/episode_reward': Array(-2.0360694, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04170044, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9931178, dtype=float32), 'eval/episode_train_reward': Array(-0.00125101, dtype=float32), 'eval/episode_x_position': Array(1.0067699, dtype=float32), 'eval/episode_x_velocity': Array(-0.04170044, dtype=float32), 'eval/episode_y_position': Array(-0.00038062, dtype=float32), 'eval/episode_y_velocity': Array(-0.0027688, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582479, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04165506, dtype=float32), 'eval/episode_reward_std': Array(0.04893142, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04165506, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02252533, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124965, dtype=float32), 'eval/episode_x_position_std': Array(0.00578138, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04165506, dtype=float32), 'eval/episode_y_position_std': Array(0.00605844, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01700817, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72698450088501, 'eval/sps': 6175.5244712290205, 'num_steps': 3793920}
{'eval/walltime': 15466.599361419678, 'training/sps': 127.15000817466802, 'training/walltime': 29947.463783979416, 'training/entropy_loss': Array(0.1095597, dtype=float32), 'training/policy_loss': Array(0.27136657, dtype=float32), 'training/total_loss': Array(0.38092625, dtype=float32), 'training/v_loss': Array(3.827016e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099852, dtype=float32), 'eval/episode_forward_reward': Array(-0.03645919, dtype=float32), 'eval/episode_reward': Array(-2.0341735, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03645919, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966204, dtype=float32), 'eval/episode_train_reward': Array(-0.00109378, dtype=float32), 'eval/episode_x_position': Array(1.0080758, dtype=float32), 'eval/episode_x_velocity': Array(-0.03645919, dtype=float32), 'eval/episode_y_position': Array(-0.0008195, dtype=float32), 'eval/episode_y_velocity': Array(0.00041135, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00591941, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04205761, dtype=float32), 'eval/episode_reward_std': Array(0.04573186, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04205761, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.013813, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126173, dtype=float32), 'eval/episode_x_position_std': Array(0.00586433, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04205761, dtype=float32), 'eval/episode_y_position_std': Array(0.00604424, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01003292, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.674630165100098, 'eval/sps': 6191.162742832081, 'num_steps': 3799040}
{'eval/walltime': 15487.297009944916, 'training/sps': 126.88987049447347, 'training/walltime': 29987.813734531403, 'training/entropy_loss': Array(0.10920791, dtype=float32), 'training/policy_loss': Array(0.27324474, dtype=float32), 'training/total_loss': Array(0.38245267, dtype=float32), 'training/v_loss': Array(2.664755e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097153, dtype=float32), 'eval/episode_forward_reward': Array(-0.03767502, dtype=float32), 'eval/episode_reward': Array(-2.0358682, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03767502, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970632, dtype=float32), 'eval/episode_train_reward': Array(-0.00113025, dtype=float32), 'eval/episode_x_position': Array(1.0078409, dtype=float32), 'eval/episode_x_velocity': Array(-0.03767502, dtype=float32), 'eval/episode_y_position': Array(-0.00016675, dtype=float32), 'eval/episode_y_velocity': Array(-0.00039656, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0062919, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04221258, dtype=float32), 'eval/episode_reward_std': Array(0.04614861, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04221258, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01262829, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126638, dtype=float32), 'eval/episode_x_position_std': Array(0.00631031, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04221258, dtype=float32), 'eval/episode_y_position_std': Array(0.00576192, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01275849, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.697648525238037, 'eval/sps': 6184.277399624454, 'num_steps': 3804160}
{'eval/walltime': 15507.98179936409, 'training/sps': 127.11575714240466, 'training/walltime': 30028.091982603073, 'training/entropy_loss': Array(0.10937083, dtype=float32), 'training/policy_loss': Array(0.26929516, dtype=float32), 'training/total_loss': Array(0.37866598, dtype=float32), 'training/v_loss': Array(3.799717e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008471, dtype=float32), 'eval/episode_forward_reward': Array(-0.04577024, dtype=float32), 'eval/episode_reward': Array(-2.0444205, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04577024, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972773, dtype=float32), 'eval/episode_train_reward': Array(-0.00137311, dtype=float32), 'eval/episode_x_position': Array(1.0066351, dtype=float32), 'eval/episode_x_velocity': Array(-0.04577024, dtype=float32), 'eval/episode_y_position': Array(-0.00050226, dtype=float32), 'eval/episode_y_velocity': Array(-0.00257396, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00562512, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04420827, dtype=float32), 'eval/episode_reward_std': Array(0.04753523, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04420827, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01320463, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132625, dtype=float32), 'eval/episode_x_position_std': Array(0.00565633, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04420827, dtype=float32), 'eval/episode_y_position_std': Array(0.00602784, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01276536, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.684789419174194, 'eval/sps': 6188.1219772703, 'num_steps': 3809280}
{'eval/walltime': 15528.672443628311, 'training/sps': 127.39548783161833, 'training/walltime': 30068.281789064407, 'training/entropy_loss': Array(0.10972501, dtype=float32), 'training/policy_loss': Array(0.27272844, dtype=float32), 'training/total_loss': Array(0.3824535, dtype=float32), 'training/v_loss': Array(2.749052e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097308, dtype=float32), 'eval/episode_forward_reward': Array(-0.03460438, dtype=float32), 'eval/episode_reward': Array(-2.0342877, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03460438, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986453, dtype=float32), 'eval/episode_train_reward': Array(-0.00103813, dtype=float32), 'eval/episode_x_position': Array(1.0078285, dtype=float32), 'eval/episode_x_velocity': Array(-0.03460438, dtype=float32), 'eval/episode_y_position': Array(-0.00032884, dtype=float32), 'eval/episode_y_velocity': Array(-0.00039263, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00612924, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04191511, dtype=float32), 'eval/episode_reward_std': Array(0.044185, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04191511, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00958134, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125745, dtype=float32), 'eval/episode_x_position_std': Array(0.00611041, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04191511, dtype=float32), 'eval/episode_y_position_std': Array(0.00593773, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00905407, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69064426422119, 'eval/sps': 6186.370920374915, 'num_steps': 3814400}
{'eval/walltime': 15549.369102954865, 'training/sps': 127.12664806524732, 'training/walltime': 30108.556586503983, 'training/entropy_loss': Array(0.10759363, dtype=float32), 'training/policy_loss': Array(0.269724, dtype=float32), 'training/total_loss': Array(0.37731764, dtype=float32), 'training/v_loss': Array(2.7379206e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088813, dtype=float32), 'eval/episode_forward_reward': Array(-0.03493508, dtype=float32), 'eval/episode_reward': Array(-2.0324855, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03493508, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965026, dtype=float32), 'eval/episode_train_reward': Array(-0.00104805, dtype=float32), 'eval/episode_x_position': Array(1.0069731, dtype=float32), 'eval/episode_x_velocity': Array(-0.03493508, dtype=float32), 'eval/episode_y_position': Array(-0.00141275, dtype=float32), 'eval/episode_y_velocity': Array(-7.13522e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059759, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0422312, dtype=float32), 'eval/episode_reward_std': Array(0.0458402, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0422312, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01799355, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126694, dtype=float32), 'eval/episode_x_position_std': Array(0.00598272, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0422312, dtype=float32), 'eval/episode_y_position_std': Array(0.00559256, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01145182, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.696659326553345, 'eval/sps': 6184.5729777162105, 'num_steps': 3819520}
{'eval/walltime': 15570.088523864746, 'training/sps': 127.35138014869761, 'training/walltime': 30148.76031255722, 'training/entropy_loss': Array(0.10774785, dtype=float32), 'training/policy_loss': Array(0.26960647, dtype=float32), 'training/total_loss': Array(0.37735432, dtype=float32), 'training/v_loss': Array(1.7235571e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093164, dtype=float32), 'eval/episode_forward_reward': Array(-0.0424649, dtype=float32), 'eval/episode_reward': Array(-2.0416143, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0424649, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978755, dtype=float32), 'eval/episode_train_reward': Array(-0.00127395, dtype=float32), 'eval/episode_x_position': Array(1.00747, dtype=float32), 'eval/episode_x_velocity': Array(-0.0424649, dtype=float32), 'eval/episode_y_position': Array(-0.00012715, dtype=float32), 'eval/episode_y_velocity': Array(-0.00118024, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588967, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04410717, dtype=float32), 'eval/episode_reward_std': Array(0.04666187, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04410717, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01090102, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132322, dtype=float32), 'eval/episode_x_position_std': Array(0.00591516, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04410717, dtype=float32), 'eval/episode_y_position_std': Array(0.005874, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01305284, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.719420909881592, 'eval/sps': 6177.778836422678, 'num_steps': 3824640}
{'eval/walltime': 15590.769332170486, 'training/sps': 127.21075300690599, 'training/walltime': 30189.008482456207, 'training/entropy_loss': Array(0.10747731, dtype=float32), 'training/policy_loss': Array(0.26652634, dtype=float32), 'training/total_loss': Array(0.37400365, dtype=float32), 'training/v_loss': Array(1.1017853e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095186, dtype=float32), 'eval/episode_forward_reward': Array(-0.04139667, dtype=float32), 'eval/episode_reward': Array(-2.0400815, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04139667, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997443, dtype=float32), 'eval/episode_train_reward': Array(-0.0012419, dtype=float32), 'eval/episode_x_position': Array(1.0076566, dtype=float32), 'eval/episode_x_velocity': Array(-0.04139667, dtype=float32), 'eval/episode_y_position': Array(0.00041505, dtype=float32), 'eval/episode_y_velocity': Array(-0.00034335, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00542391, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04388397, dtype=float32), 'eval/episode_reward_std': Array(0.04648859, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04388397, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01011129, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131652, dtype=float32), 'eval/episode_x_position_std': Array(0.00535415, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04388397, dtype=float32), 'eval/episode_y_position_std': Array(0.00551673, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01473962, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680808305740356, 'eval/sps': 6189.313208056337, 'num_steps': 3829760}
{'eval/walltime': 15611.489691734314, 'training/sps': 127.24493160765415, 'training/walltime': 30229.245841503143, 'training/entropy_loss': Array(0.10841388, dtype=float32), 'training/policy_loss': Array(0.2671994, dtype=float32), 'training/total_loss': Array(0.37561327, dtype=float32), 'training/v_loss': Array(8.9085267e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099757, dtype=float32), 'eval/episode_forward_reward': Array(-0.04203757, dtype=float32), 'eval/episode_reward': Array(-2.0402699, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04203757, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996971, dtype=float32), 'eval/episode_train_reward': Array(-0.00126113, dtype=float32), 'eval/episode_x_position': Array(1.0081301, dtype=float32), 'eval/episode_x_velocity': Array(-0.04203757, dtype=float32), 'eval/episode_y_position': Array(0.00041643, dtype=float32), 'eval/episode_y_velocity': Array(-0.00262603, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00587998, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04576936, dtype=float32), 'eval/episode_reward_std': Array(0.049254, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04576936, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01410464, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137308, dtype=float32), 'eval/episode_x_position_std': Array(0.00586242, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04576936, dtype=float32), 'eval/episode_y_position_std': Array(0.00544643, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01406032, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.720359563827515, 'eval/sps': 6177.4989765841465, 'num_steps': 3834880}
{'eval/walltime': 15632.208742380142, 'training/sps': 127.19156499156144, 'training/walltime': 30269.500083208084, 'training/entropy_loss': Array(0.11027529, dtype=float32), 'training/policy_loss': Array(0.26751673, dtype=float32), 'training/total_loss': Array(0.37779203, dtype=float32), 'training/v_loss': Array(1.563023e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171762, dtype=float32), 'eval/episode_forward_reward': Array(-0.03279591, dtype=float32), 'eval/episode_reward': Array(-2.0476112, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03279591, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.021644, dtype=float32), 'eval/episode_train_reward': Array(-0.00098388, dtype=float32), 'eval/episode_x_position': Array(1.0152094, dtype=float32), 'eval/episode_x_velocity': Array(-0.03279591, dtype=float32), 'eval/episode_y_position': Array(0.00012772, dtype=float32), 'eval/episode_y_velocity': Array(-0.00150073, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08794041, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03997093, dtype=float32), 'eval/episode_reward_std': Array(0.17853442, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03997093, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26448736, dtype=float32), 'eval/episode_train_reward_std': Array(0.00119913, dtype=float32), 'eval/episode_x_position_std': Array(0.08767416, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03997093, dtype=float32), 'eval/episode_y_position_std': Array(0.0058861, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00965772, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.719050645828247, 'eval/sps': 6177.88923768921, 'num_steps': 3840000}
{'eval/walltime': 15652.93150472641, 'training/sps': 127.0613139675309, 'training/walltime': 30309.79558968544, 'training/entropy_loss': Array(0.11168505, dtype=float32), 'training/policy_loss': Array(0.27053502, dtype=float32), 'training/total_loss': Array(0.38222006, dtype=float32), 'training/v_loss': Array(1.7882249e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089369, dtype=float32), 'eval/episode_forward_reward': Array(-0.03969708, dtype=float32), 'eval/episode_reward': Array(-2.0375228, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03969708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966345, dtype=float32), 'eval/episode_train_reward': Array(-0.00119091, dtype=float32), 'eval/episode_x_position': Array(1.0070865, dtype=float32), 'eval/episode_x_velocity': Array(-0.03969708, dtype=float32), 'eval/episode_y_position': Array(3.2350858e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00228644, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00556206, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04445887, dtype=float32), 'eval/episode_reward_std': Array(0.04745029, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04445887, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01323405, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133377, dtype=float32), 'eval/episode_x_position_std': Array(0.00558897, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04445887, dtype=float32), 'eval/episode_y_position_std': Array(0.00607079, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01184624, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7227623462677, 'eval/sps': 6176.782702092494, 'num_steps': 3845120}
{'eval/walltime': 15673.664516210556, 'training/sps': 127.21728670682083, 'training/walltime': 30350.041692495346, 'training/entropy_loss': Array(0.10982255, dtype=float32), 'training/policy_loss': Array(0.26899815, dtype=float32), 'training/total_loss': Array(0.37882072, dtype=float32), 'training/v_loss': Array(3.7871764e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099375, dtype=float32), 'eval/episode_forward_reward': Array(-0.03351038, dtype=float32), 'eval/episode_reward': Array(-2.0290914, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03351038, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9945755, dtype=float32), 'eval/episode_train_reward': Array(-0.00100531, dtype=float32), 'eval/episode_x_position': Array(1.0080245, dtype=float32), 'eval/episode_x_velocity': Array(-0.03351038, dtype=float32), 'eval/episode_y_position': Array(0.00018309, dtype=float32), 'eval/episode_y_velocity': Array(-0.00274931, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00591409, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0405172, dtype=float32), 'eval/episode_reward_std': Array(0.04557291, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0405172, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01945511, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121552, dtype=float32), 'eval/episode_x_position_std': Array(0.005917, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0405172, dtype=float32), 'eval/episode_y_position_std': Array(0.00570713, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01232195, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.733011484146118, 'eval/sps': 6173.729276997583, 'num_steps': 3850240}
{'eval/walltime': 15694.391649007797, 'training/sps': 127.28453387133028, 'training/walltime': 30390.266532421112, 'training/entropy_loss': Array(0.10971239, dtype=float32), 'training/policy_loss': Array(0.2696675, dtype=float32), 'training/total_loss': Array(0.3793799, dtype=float32), 'training/v_loss': Array(5.147835e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.01598, dtype=float32), 'eval/episode_forward_reward': Array(-0.04193086, dtype=float32), 'eval/episode_reward': Array(-2.0541806, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04193086, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0188046, dtype=float32), 'eval/episode_train_reward': Array(-0.00125793, dtype=float32), 'eval/episode_x_position': Array(1.0141032, dtype=float32), 'eval/episode_x_velocity': Array(-0.04193086, dtype=float32), 'eval/episode_y_position': Array(0.00011061, dtype=float32), 'eval/episode_y_velocity': Array(-0.00219774, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09077456, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04556151, dtype=float32), 'eval/episode_reward_std': Array(0.17965299, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04556151, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26544288, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136685, dtype=float32), 'eval/episode_x_position_std': Array(0.09050509, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04556151, dtype=float32), 'eval/episode_y_position_std': Array(0.00589035, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01231684, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.72713279724121, 'eval/sps': 6175.480287222208, 'num_steps': 3855360}
{'eval/walltime': 15715.11224412918, 'training/sps': 127.12372893728022, 'training/walltime': 30430.542254686356, 'training/entropy_loss': Array(0.10683069, dtype=float32), 'training/policy_loss': Array(0.27045438, dtype=float32), 'training/total_loss': Array(0.37728506, dtype=float32), 'training/v_loss': Array(1.5697039e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096778, dtype=float32), 'eval/episode_forward_reward': Array(-0.0427207, dtype=float32), 'eval/episode_reward': Array(-2.0401921, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0427207, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961896, dtype=float32), 'eval/episode_train_reward': Array(-0.00128162, dtype=float32), 'eval/episode_x_position': Array(1.0078349, dtype=float32), 'eval/episode_x_velocity': Array(-0.0427207, dtype=float32), 'eval/episode_y_position': Array(-0.00057443, dtype=float32), 'eval/episode_y_velocity': Array(0.00149769, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594521, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04486942, dtype=float32), 'eval/episode_reward_std': Array(0.04901648, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04486942, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01674351, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134608, dtype=float32), 'eval/episode_x_position_std': Array(0.0059015, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04486942, dtype=float32), 'eval/episode_y_position_std': Array(0.00592585, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01685399, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.720595121383667, 'eval/sps': 6177.428749037421, 'num_steps': 3860480}
{'eval/walltime': 15735.836077928543, 'training/sps': 127.50516897125529, 'training/walltime': 30470.697489500046, 'training/entropy_loss': Array(0.1069085, dtype=float32), 'training/policy_loss': Array(0.26223797, dtype=float32), 'training/total_loss': Array(0.36914647, dtype=float32), 'training/v_loss': Array(3.9393777e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089037, dtype=float32), 'eval/episode_forward_reward': Array(-0.03447741, dtype=float32), 'eval/episode_reward': Array(-2.0345182, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03447741, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9990065, dtype=float32), 'eval/episode_train_reward': Array(-0.00103432, dtype=float32), 'eval/episode_x_position': Array(1.0070183, dtype=float32), 'eval/episode_x_velocity': Array(-0.03447741, dtype=float32), 'eval/episode_y_position': Array(-0.0002023, dtype=float32), 'eval/episode_y_velocity': Array(-0.00269797, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00631259, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04276468, dtype=float32), 'eval/episode_reward_std': Array(0.04525684, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04276468, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00782708, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128294, dtype=float32), 'eval/episode_x_position_std': Array(0.00628723, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04276468, dtype=float32), 'eval/episode_y_position_std': Array(0.00604481, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0129344, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.723833799362183, 'eval/sps': 6176.463353220844, 'num_steps': 3865600}
{'eval/walltime': 15756.542026519775, 'training/sps': 127.30670074658909, 'training/walltime': 30510.915325403214, 'training/entropy_loss': Array(0.10977089, dtype=float32), 'training/policy_loss': Array(0.26969525, dtype=float32), 'training/total_loss': Array(0.37946615, dtype=float32), 'training/v_loss': Array(6.868351e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092394, dtype=float32), 'eval/episode_forward_reward': Array(-0.03853549, dtype=float32), 'eval/episode_reward': Array(-2.0387278, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03853549, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9990363, dtype=float32), 'eval/episode_train_reward': Array(-0.00115606, dtype=float32), 'eval/episode_x_position': Array(1.0073684, dtype=float32), 'eval/episode_x_velocity': Array(-0.03853549, dtype=float32), 'eval/episode_y_position': Array(0.00026352, dtype=float32), 'eval/episode_y_velocity': Array(-0.00092013, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577848, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04188317, dtype=float32), 'eval/episode_reward_std': Array(0.04354806, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04188317, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00566333, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012565, dtype=float32), 'eval/episode_x_position_std': Array(0.0057598, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04188317, dtype=float32), 'eval/episode_y_position_std': Array(0.00567699, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01167416, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7059485912323, 'eval/sps': 6181.798406193288, 'num_steps': 3870720}
{'eval/walltime': 15777.254177808762, 'training/sps': 127.06429488669444, 'training/walltime': 30551.209886550903, 'training/entropy_loss': Array(0.10922648, dtype=float32), 'training/policy_loss': Array(0.27009654, dtype=float32), 'training/total_loss': Array(0.379323, dtype=float32), 'training/v_loss': Array(1.3759898e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093708, dtype=float32), 'eval/episode_forward_reward': Array(-0.04108964, dtype=float32), 'eval/episode_reward': Array(-2.0401573, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04108964, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978352, dtype=float32), 'eval/episode_train_reward': Array(-0.00123269, dtype=float32), 'eval/episode_x_position': Array(1.0075171, dtype=float32), 'eval/episode_x_velocity': Array(-0.04108964, dtype=float32), 'eval/episode_y_position': Array(-0.00045712, dtype=float32), 'eval/episode_y_velocity': Array(-0.00294112, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600105, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04416569, dtype=float32), 'eval/episode_reward_std': Array(0.04556463, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04416569, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01065819, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132497, dtype=float32), 'eval/episode_x_position_std': Array(0.00599649, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04416569, dtype=float32), 'eval/episode_y_position_std': Array(0.00596093, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01340186, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.712151288986206, 'eval/sps': 6179.9471341282, 'num_steps': 3875840}
{'eval/walltime': 15797.949709415436, 'training/sps': 127.13055549661888, 'training/walltime': 30591.483446121216, 'training/entropy_loss': Array(0.109767, dtype=float32), 'training/policy_loss': Array(0.26614803, dtype=float32), 'training/total_loss': Array(0.375915, dtype=float32), 'training/v_loss': Array(1.6951821e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0170183, dtype=float32), 'eval/episode_forward_reward': Array(-0.0366508, dtype=float32), 'eval/episode_reward': Array(-2.0445209, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0366508, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.014583, dtype=float32), 'eval/episode_train_reward': Array(-0.00109952, dtype=float32), 'eval/episode_x_position': Array(1.0151322, dtype=float32), 'eval/episode_x_velocity': Array(-0.0366508, dtype=float32), 'eval/episode_y_position': Array(3.1558826e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00178724, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08742264, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04465864, dtype=float32), 'eval/episode_reward_std': Array(0.18247427, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04465864, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26684996, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133976, dtype=float32), 'eval/episode_x_position_std': Array(0.08714616, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04465864, dtype=float32), 'eval/episode_y_position_std': Array(0.00576363, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01171813, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.695531606674194, 'eval/sps': 6184.909981182639, 'num_steps': 3880960}
{'eval/walltime': 15818.694383144379, 'training/sps': 127.27155062757413, 'training/walltime': 30631.712389469147, 'training/entropy_loss': Array(0.11073866, dtype=float32), 'training/policy_loss': Array(0.2691879, dtype=float32), 'training/total_loss': Array(0.37992656, dtype=float32), 'training/v_loss': Array(9.826943e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090005, dtype=float32), 'eval/episode_forward_reward': Array(-0.04217657, dtype=float32), 'eval/episode_reward': Array(-2.040498, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04217657, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997056, dtype=float32), 'eval/episode_train_reward': Array(-0.0012653, dtype=float32), 'eval/episode_x_position': Array(1.0071578, dtype=float32), 'eval/episode_x_velocity': Array(-0.04217657, dtype=float32), 'eval/episode_y_position': Array(0.00044093, dtype=float32), 'eval/episode_y_velocity': Array(-0.00148309, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576585, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04522072, dtype=float32), 'eval/episode_reward_std': Array(0.04932998, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04522072, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01198495, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135662, dtype=float32), 'eval/episode_x_position_std': Array(0.00578266, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04522072, dtype=float32), 'eval/episode_y_position_std': Array(0.0055037, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01235104, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.74467372894287, 'eval/sps': 6170.258528646561, 'num_steps': 3886080}
{'eval/walltime': 15839.39865064621, 'training/sps': 127.02922062250482, 'training/walltime': 30672.01807641983, 'training/entropy_loss': Array(0.10914899, dtype=float32), 'training/policy_loss': Array(0.2701258, dtype=float32), 'training/total_loss': Array(0.37927485, dtype=float32), 'training/v_loss': Array(2.817067e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096328, dtype=float32), 'eval/episode_forward_reward': Array(-0.04113908, dtype=float32), 'eval/episode_reward': Array(-2.0392148, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04113908, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968414, dtype=float32), 'eval/episode_train_reward': Array(-0.00123417, dtype=float32), 'eval/episode_x_position': Array(1.0077424, dtype=float32), 'eval/episode_x_velocity': Array(-0.04113908, dtype=float32), 'eval/episode_y_position': Array(0.00026168, dtype=float32), 'eval/episode_y_velocity': Array(-2.1288768e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00548579, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0428299, dtype=float32), 'eval/episode_reward_std': Array(0.04528971, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0428299, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01520388, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012849, dtype=float32), 'eval/episode_x_position_std': Array(0.00552986, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0428299, dtype=float32), 'eval/episode_y_position_std': Array(0.0061171, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00795942, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.704267501831055, 'eval/sps': 6182.300339226194, 'num_steps': 3891200}
{'eval/walltime': 15860.121985673904, 'training/sps': 127.23446291261058, 'training/walltime': 30712.258746147156, 'training/entropy_loss': Array(0.10767883, dtype=float32), 'training/policy_loss': Array(0.26981014, dtype=float32), 'training/total_loss': Array(0.37748897, dtype=float32), 'training/v_loss': Array(1.3987705e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097604, dtype=float32), 'eval/episode_forward_reward': Array(-0.03960519, dtype=float32), 'eval/episode_reward': Array(-2.0369413, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03960519, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996148, dtype=float32), 'eval/episode_train_reward': Array(-0.00118816, dtype=float32), 'eval/episode_x_position': Array(1.0078723, dtype=float32), 'eval/episode_x_velocity': Array(-0.03960519, dtype=float32), 'eval/episode_y_position': Array(-0.0001885, dtype=float32), 'eval/episode_y_velocity': Array(0.00056127, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00533343, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04243276, dtype=float32), 'eval/episode_reward_std': Array(0.04591643, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04243276, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01714004, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127298, dtype=float32), 'eval/episode_x_position_std': Array(0.00533569, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04243276, dtype=float32), 'eval/episode_y_position_std': Array(0.00600958, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01264541, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.723335027694702, 'eval/sps': 6176.612009068066, 'num_steps': 3896320}
{'eval/walltime': 15880.800803661346, 'training/sps': 127.12081521083319, 'training/walltime': 30752.535391569138, 'training/entropy_loss': Array(0.10846318, dtype=float32), 'training/policy_loss': Array(0.2667307, dtype=float32), 'training/total_loss': Array(0.37519386, dtype=float32), 'training/v_loss': Array(9.494285e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092423, dtype=float32), 'eval/episode_forward_reward': Array(-0.04007962, dtype=float32), 'eval/episode_reward': Array(-2.0396378, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04007962, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983556, dtype=float32), 'eval/episode_train_reward': Array(-0.00120239, dtype=float32), 'eval/episode_x_position': Array(1.0073743, dtype=float32), 'eval/episode_x_velocity': Array(-0.04007962, dtype=float32), 'eval/episode_y_position': Array(-4.7557012e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00201064, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570317, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04186068, dtype=float32), 'eval/episode_reward_std': Array(0.04482599, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04186068, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00955969, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125582, dtype=float32), 'eval/episode_x_position_std': Array(0.00569325, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04186068, dtype=float32), 'eval/episode_y_position_std': Array(0.00568173, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00963054, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.678817987442017, 'eval/sps': 6189.908924085157, 'num_steps': 3901440}
{'eval/walltime': 15901.503118991852, 'training/sps': 127.32389129320585, 'training/walltime': 30792.747797489166, 'training/entropy_loss': Array(0.10805151, dtype=float32), 'training/policy_loss': Array(0.27001822, dtype=float32), 'training/total_loss': Array(0.37806973, dtype=float32), 'training/v_loss': Array(1.856773e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086119, dtype=float32), 'eval/episode_forward_reward': Array(-0.03789583, dtype=float32), 'eval/episode_reward': Array(-2.0361605, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03789583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971278, dtype=float32), 'eval/episode_train_reward': Array(-0.00113687, dtype=float32), 'eval/episode_x_position': Array(1.0067258, dtype=float32), 'eval/episode_x_velocity': Array(-0.03789583, dtype=float32), 'eval/episode_y_position': Array(-8.471988e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00094202, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586859, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04346898, dtype=float32), 'eval/episode_reward_std': Array(0.04553567, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04346898, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01178104, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130407, dtype=float32), 'eval/episode_x_position_std': Array(0.00587807, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04346898, dtype=float32), 'eval/episode_y_position_std': Array(0.00588315, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01100742, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70231533050537, 'eval/sps': 6182.8833131233805, 'num_steps': 3906560}
{'eval/walltime': 15922.168026924133, 'training/sps': 127.27512526264289, 'training/walltime': 30832.97561097145, 'training/entropy_loss': Array(0.10994893, dtype=float32), 'training/policy_loss': Array(0.26827, dtype=float32), 'training/total_loss': Array(0.37821892, dtype=float32), 'training/v_loss': Array(1.0160057e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016571, dtype=float32), 'eval/episode_forward_reward': Array(-0.04176881, dtype=float32), 'eval/episode_reward': Array(-2.0560951, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04176881, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0208855, dtype=float32), 'eval/episode_train_reward': Array(-0.00125306, dtype=float32), 'eval/episode_x_position': Array(1.0146866, dtype=float32), 'eval/episode_x_velocity': Array(-0.04176881, dtype=float32), 'eval/episode_y_position': Array(-0.00026498, dtype=float32), 'eval/episode_y_velocity': Array(-0.00080371, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08838038, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04406088, dtype=float32), 'eval/episode_reward_std': Array(0.17996442, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04406088, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26470116, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132183, dtype=float32), 'eval/episode_x_position_std': Array(0.08811125, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04406088, dtype=float32), 'eval/episode_y_position_std': Array(0.006105, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01240679, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.664907932281494, 'eval/sps': 6194.07550323735, 'num_steps': 3911680}
{'eval/walltime': 15942.86137676239, 'training/sps': 127.30593850711769, 'training/walltime': 30873.193687677383, 'training/entropy_loss': Array(0.10595648, dtype=float32), 'training/policy_loss': Array(0.26960826, dtype=float32), 'training/total_loss': Array(0.37556475, dtype=float32), 'training/v_loss': Array(5.294841e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092621, dtype=float32), 'eval/episode_forward_reward': Array(-0.03823731, dtype=float32), 'eval/episode_reward': Array(-2.0377975, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03823731, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998413, dtype=float32), 'eval/episode_train_reward': Array(-0.00114712, dtype=float32), 'eval/episode_x_position': Array(1.0073712, dtype=float32), 'eval/episode_x_velocity': Array(-0.03823731, dtype=float32), 'eval/episode_y_position': Array(0.00078778, dtype=float32), 'eval/episode_y_velocity': Array(0.00028709, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573571, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04450718, dtype=float32), 'eval/episode_reward_std': Array(0.04734621, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04450718, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00961924, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133522, dtype=float32), 'eval/episode_x_position_std': Array(0.00573107, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04450718, dtype=float32), 'eval/episode_y_position_std': Array(0.00504596, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01201881, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.693349838256836, 'eval/sps': 6185.562076728629, 'num_steps': 3916800}
{'eval/walltime': 15963.559051275253, 'training/sps': 127.21152541049577, 'training/walltime': 30913.441613197327, 'training/entropy_loss': Array(0.10819132, dtype=float32), 'training/policy_loss': Array(0.264566, dtype=float32), 'training/total_loss': Array(0.37275732, dtype=float32), 'training/v_loss': Array(3.3322056e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0172267, dtype=float32), 'eval/episode_forward_reward': Array(-0.03313079, dtype=float32), 'eval/episode_reward': Array(-2.0465112, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03313079, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0201988, dtype=float32), 'eval/episode_train_reward': Array(-0.00099392, dtype=float32), 'eval/episode_x_position': Array(1.0153011, dtype=float32), 'eval/episode_x_velocity': Array(-0.03313079, dtype=float32), 'eval/episode_y_position': Array(-0.00091821, dtype=float32), 'eval/episode_y_velocity': Array(-0.00071178, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08801974, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04036408, dtype=float32), 'eval/episode_reward_std': Array(0.17768954, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04036408, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26485935, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121092, dtype=float32), 'eval/episode_x_position_std': Array(0.08775061, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04036408, dtype=float32), 'eval/episode_y_position_std': Array(0.00567315, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01050331, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.69767451286316, 'eval/sps': 6184.269634757797, 'num_steps': 3921920}
{'eval/walltime': 15984.273305416107, 'training/sps': 127.02373255553088, 'training/walltime': 30953.749041557312, 'training/entropy_loss': Array(0.10964443, dtype=float32), 'training/policy_loss': Array(0.26565135, dtype=float32), 'training/total_loss': Array(0.37529576, dtype=float32), 'training/v_loss': Array(2.6363236e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099555, dtype=float32), 'eval/episode_forward_reward': Array(-0.04202997, dtype=float32), 'eval/episode_reward': Array(-2.0397184, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04202997, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964275, dtype=float32), 'eval/episode_train_reward': Array(-0.0012609, dtype=float32), 'eval/episode_x_position': Array(1.0080892, dtype=float32), 'eval/episode_x_velocity': Array(-0.04202997, dtype=float32), 'eval/episode_y_position': Array(0.00067859, dtype=float32), 'eval/episode_y_velocity': Array(-0.0005828, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574715, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04451438, dtype=float32), 'eval/episode_reward_std': Array(0.04600697, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04451438, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01438822, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133543, dtype=float32), 'eval/episode_x_position_std': Array(0.00577429, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04451438, dtype=float32), 'eval/episode_y_position_std': Array(0.00600284, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0137468, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.714254140853882, 'eval/sps': 6179.319763560823, 'num_steps': 3927040}
{'eval/walltime': 16004.975972175598, 'training/sps': 127.15645959141224, 'training/walltime': 30994.01439666748, 'training/entropy_loss': Array(0.11213841, dtype=float32), 'training/policy_loss': Array(0.2706627, dtype=float32), 'training/total_loss': Array(0.38280112, dtype=float32), 'training/v_loss': Array(2.848445e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093629, dtype=float32), 'eval/episode_forward_reward': Array(-0.04531327, dtype=float32), 'eval/episode_reward': Array(-2.0436692, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04531327, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969969, dtype=float32), 'eval/episode_train_reward': Array(-0.0013594, dtype=float32), 'eval/episode_x_position': Array(1.0075271, dtype=float32), 'eval/episode_x_velocity': Array(-0.04531327, dtype=float32), 'eval/episode_y_position': Array(0.0006038, dtype=float32), 'eval/episode_y_velocity': Array(-0.00223273, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574406, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04632577, dtype=float32), 'eval/episode_reward_std': Array(0.05059073, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04632577, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01374392, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138977, dtype=float32), 'eval/episode_x_position_std': Array(0.00573541, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04632577, dtype=float32), 'eval/episode_y_position_std': Array(0.00615698, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01635211, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.702666759490967, 'eval/sps': 6182.778358315576, 'num_steps': 3932160}
{'eval/walltime': 16025.681958198547, 'training/sps': 127.31207592602618, 'training/walltime': 31034.230534553528, 'training/entropy_loss': Array(0.11154051, dtype=float32), 'training/policy_loss': Array(0.27022105, dtype=float32), 'training/total_loss': Array(0.38176158, dtype=float32), 'training/v_loss': Array(4.140024e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009615, dtype=float32), 'eval/episode_forward_reward': Array(-0.033128, dtype=float32), 'eval/episode_reward': Array(-2.0296004, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.033128, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9954786, dtype=float32), 'eval/episode_train_reward': Array(-0.00099384, dtype=float32), 'eval/episode_x_position': Array(1.0076946, dtype=float32), 'eval/episode_x_velocity': Array(-0.033128, dtype=float32), 'eval/episode_y_position': Array(0.00047106, dtype=float32), 'eval/episode_y_velocity': Array(-0.00106597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579838, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04358784, dtype=float32), 'eval/episode_reward_std': Array(0.05157005, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04358784, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02167446, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130764, dtype=float32), 'eval/episode_x_position_std': Array(0.00574878, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04358784, dtype=float32), 'eval/episode_y_position_std': Array(0.00578048, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01119697, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70598602294922, 'eval/sps': 6181.787230906696, 'num_steps': 3937280}
{'eval/walltime': 16046.38733625412, 'training/sps': 127.24455161048685, 'training/walltime': 31074.468013763428, 'training/entropy_loss': Array(0.10900645, dtype=float32), 'training/policy_loss': Array(0.26954058, dtype=float32), 'training/total_loss': Array(0.37854704, dtype=float32), 'training/v_loss': Array(4.1607167e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088564, dtype=float32), 'eval/episode_forward_reward': Array(-0.04036406, dtype=float32), 'eval/episode_reward': Array(-2.036412, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04036406, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9948373, dtype=float32), 'eval/episode_train_reward': Array(-0.00121092, dtype=float32), 'eval/episode_x_position': Array(1.0069854, dtype=float32), 'eval/episode_x_velocity': Array(-0.04036406, dtype=float32), 'eval/episode_y_position': Array(0.0004028, dtype=float32), 'eval/episode_y_velocity': Array(-0.0010195, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00528954, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04354576, dtype=float32), 'eval/episode_reward_std': Array(0.04864823, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04354576, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01911314, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130637, dtype=float32), 'eval/episode_x_position_std': Array(0.00534091, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04354576, dtype=float32), 'eval/episode_y_position_std': Array(0.00586945, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01246715, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70537805557251, 'eval/sps': 6181.968745340098, 'num_steps': 3942400}
{'eval/walltime': 16067.07040143013, 'training/sps': 127.29638638284507, 'training/walltime': 31114.689108371735, 'training/entropy_loss': Array(0.10864288, dtype=float32), 'training/policy_loss': Array(0.2687812, dtype=float32), 'training/total_loss': Array(0.3774241, dtype=float32), 'training/v_loss': Array(6.110731e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096576, dtype=float32), 'eval/episode_forward_reward': Array(-0.03875249, dtype=float32), 'eval/episode_reward': Array(-2.036016, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03875249, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996101, dtype=float32), 'eval/episode_train_reward': Array(-0.00116257, dtype=float32), 'eval/episode_x_position': Array(1.0077837, dtype=float32), 'eval/episode_x_velocity': Array(-0.03875249, dtype=float32), 'eval/episode_y_position': Array(0.00080579, dtype=float32), 'eval/episode_y_velocity': Array(-0.00129976, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058827, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04350214, dtype=float32), 'eval/episode_reward_std': Array(0.0486681, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04350214, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01602347, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130506, dtype=float32), 'eval/episode_x_position_std': Array(0.00582741, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04350214, dtype=float32), 'eval/episode_y_position_std': Array(0.00583602, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01633766, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.683065176010132, 'eval/sps': 6188.637849890093, 'num_steps': 3947520}
{'eval/walltime': 16087.754307508469, 'training/sps': 127.23603016700076, 'training/walltime': 31154.929282426834, 'training/entropy_loss': Array(0.10953364, dtype=float32), 'training/policy_loss': Array(0.26590663, dtype=float32), 'training/total_loss': Array(0.37544024, dtype=float32), 'training/v_loss': Array(1.3302962e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0170629, dtype=float32), 'eval/episode_forward_reward': Array(-0.03963041, dtype=float32), 'eval/episode_reward': Array(-2.054587, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03963041, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0215802, dtype=float32), 'eval/episode_train_reward': Array(-0.00118891, dtype=float32), 'eval/episode_x_position': Array(1.0151848, dtype=float32), 'eval/episode_x_velocity': Array(-0.03963041, dtype=float32), 'eval/episode_y_position': Array(-0.00058619, dtype=float32), 'eval/episode_y_velocity': Array(-0.00023119, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08903143, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04480045, dtype=float32), 'eval/episode_reward_std': Array(0.17888184, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04480045, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26455832, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134401, dtype=float32), 'eval/episode_x_position_std': Array(0.08875412, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04480045, dtype=float32), 'eval/episode_y_position_std': Array(0.00539529, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01280921, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.683906078338623, 'eval/sps': 6188.386251378745, 'num_steps': 3952640}
{'eval/walltime': 16108.457786083221, 'training/sps': 127.65155310502864, 'training/walltime': 31195.038469314575, 'training/entropy_loss': Array(0.11202833, dtype=float32), 'training/policy_loss': Array(0.2674827, dtype=float32), 'training/total_loss': Array(0.37951106, dtype=float32), 'training/v_loss': Array(1.7180764e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167135, dtype=float32), 'eval/episode_forward_reward': Array(-0.0365645, dtype=float32), 'eval/episode_reward': Array(-2.049451, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0365645, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0196023, dtype=float32), 'eval/episode_train_reward': Array(-0.00109694, dtype=float32), 'eval/episode_x_position': Array(1.014843, dtype=float32), 'eval/episode_x_velocity': Array(-0.0365645, dtype=float32), 'eval/episode_y_position': Array(-0.00043745, dtype=float32), 'eval/episode_y_velocity': Array(-0.00163117, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0896156, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04148806, dtype=float32), 'eval/episode_reward_std': Array(0.18103865, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04148806, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26491648, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124464, dtype=float32), 'eval/episode_x_position_std': Array(0.08934337, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04148806, dtype=float32), 'eval/episode_y_position_std': Array(0.00605017, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01536258, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.703478574752808, 'eval/sps': 6182.535922059575, 'num_steps': 3957760}
{'eval/walltime': 16129.134097576141, 'training/sps': 127.24206132808317, 'training/walltime': 31235.276736021042, 'training/entropy_loss': Array(0.11179916, dtype=float32), 'training/policy_loss': Array(0.26855263, dtype=float32), 'training/total_loss': Array(0.3803518, dtype=float32), 'training/v_loss': Array(1.2097653e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0077324, dtype=float32), 'eval/episode_forward_reward': Array(-0.03897352, dtype=float32), 'eval/episode_reward': Array(-2.0363407, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03897352, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961977, dtype=float32), 'eval/episode_train_reward': Array(-0.00116921, dtype=float32), 'eval/episode_x_position': Array(1.005879, dtype=float32), 'eval/episode_x_velocity': Array(-0.03897352, dtype=float32), 'eval/episode_y_position': Array(-0.00015121, dtype=float32), 'eval/episode_y_velocity': Array(0.00204243, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560247, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04239642, dtype=float32), 'eval/episode_reward_std': Array(0.04616363, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04239642, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01595516, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127189, dtype=float32), 'eval/episode_x_position_std': Array(0.00563015, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04239642, dtype=float32), 'eval/episode_y_position_std': Array(0.00564935, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01361575, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.676311492919922, 'eval/sps': 6190.65929838745, 'num_steps': 3962880}
{'eval/walltime': 16149.830996751785, 'training/sps': 127.02491819030199, 'training/walltime': 31275.58378815651, 'training/entropy_loss': Array(0.10785536, dtype=float32), 'training/policy_loss': Array(0.27117622, dtype=float32), 'training/total_loss': Array(0.3790316, dtype=float32), 'training/v_loss': Array(1.0360809e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085714, dtype=float32), 'eval/episode_forward_reward': Array(-0.0448764, dtype=float32), 'eval/episode_reward': Array(-2.0452063, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0448764, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9989836, dtype=float32), 'eval/episode_train_reward': Array(-0.00134629, dtype=float32), 'eval/episode_x_position': Array(1.0067656, dtype=float32), 'eval/episode_x_velocity': Array(-0.0448764, dtype=float32), 'eval/episode_y_position': Array(0.000503, dtype=float32), 'eval/episode_y_velocity': Array(-0.00252777, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595526, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04328191, dtype=float32), 'eval/episode_reward_std': Array(0.04482671, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04328191, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00638508, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129846, dtype=float32), 'eval/episode_x_position_std': Array(0.00597326, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04328191, dtype=float32), 'eval/episode_y_position_std': Array(0.00611032, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01349946, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69689917564392, 'eval/sps': 6184.501306873553, 'num_steps': 3968000}
{'eval/walltime': 16170.470080375671, 'training/sps': 127.16479040868298, 'training/walltime': 31315.84650540352, 'training/entropy_loss': Array(0.10561434, dtype=float32), 'training/policy_loss': Array(0.26473385, dtype=float32), 'training/total_loss': Array(0.3703482, dtype=float32), 'training/v_loss': Array(8.461603e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090915, dtype=float32), 'eval/episode_forward_reward': Array(-0.04538428, dtype=float32), 'eval/episode_reward': Array(-2.0419989, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04538428, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995253, dtype=float32), 'eval/episode_train_reward': Array(-0.00136153, dtype=float32), 'eval/episode_x_position': Array(1.0072592, dtype=float32), 'eval/episode_x_velocity': Array(-0.04538428, dtype=float32), 'eval/episode_y_position': Array(0.00042569, dtype=float32), 'eval/episode_y_velocity': Array(-0.00156979, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00546015, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04532928, dtype=float32), 'eval/episode_reward_std': Array(0.04869018, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04532928, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01709224, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135988, dtype=float32), 'eval/episode_x_position_std': Array(0.005484, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04532928, dtype=float32), 'eval/episode_y_position_std': Array(0.0057584, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01177855, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63908362388611, 'eval/sps': 6201.825736674788, 'num_steps': 3973120}
{'eval/walltime': 16191.146402597427, 'training/sps': 127.24922332052618, 'training/walltime': 31356.082507371902, 'training/entropy_loss': Array(0.1067241, dtype=float32), 'training/policy_loss': Array(0.26392245, dtype=float32), 'training/total_loss': Array(0.37064654, dtype=float32), 'training/v_loss': Array(2.690381e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093293, dtype=float32), 'eval/episode_forward_reward': Array(-0.03402021, dtype=float32), 'eval/episode_reward': Array(-2.033557, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03402021, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998516, dtype=float32), 'eval/episode_train_reward': Array(-0.00102061, dtype=float32), 'eval/episode_x_position': Array(1.007432, dtype=float32), 'eval/episode_x_velocity': Array(-0.03402021, dtype=float32), 'eval/episode_y_position': Array(0.00019293, dtype=float32), 'eval/episode_y_velocity': Array(-0.00291155, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566607, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04147698, dtype=float32), 'eval/episode_reward_std': Array(0.04351398, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04147698, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0095775, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124431, dtype=float32), 'eval/episode_x_position_std': Array(0.00568393, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04147698, dtype=float32), 'eval/episode_y_position_std': Array(0.00579556, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01618618, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67632222175598, 'eval/sps': 6190.656086086538, 'num_steps': 3978240}
{'eval/walltime': 16211.818666696548, 'training/sps': 127.29473539464212, 'training/walltime': 31396.30412364006, 'training/entropy_loss': Array(0.11118089, dtype=float32), 'training/policy_loss': Array(0.26473063, dtype=float32), 'training/total_loss': Array(0.37591153, dtype=float32), 'training/v_loss': Array(7.9046936e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094651, dtype=float32), 'eval/episode_forward_reward': Array(-0.03655116, dtype=float32), 'eval/episode_reward': Array(-2.0357447, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03655116, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998097, dtype=float32), 'eval/episode_train_reward': Array(-0.00109653, dtype=float32), 'eval/episode_x_position': Array(1.0075513, dtype=float32), 'eval/episode_x_velocity': Array(-0.03655116, dtype=float32), 'eval/episode_y_position': Array(-0.00027913, dtype=float32), 'eval/episode_y_velocity': Array(-0.00096775, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571025, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0441546, dtype=float32), 'eval/episode_reward_std': Array(0.04651414, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0441546, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.012436, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132464, dtype=float32), 'eval/episode_x_position_std': Array(0.00571473, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0441546, dtype=float32), 'eval/episode_y_position_std': Array(0.00619003, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01217252, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672264099121094, 'eval/sps': 6191.871358950086, 'num_steps': 3983360}
{'eval/walltime': 16232.510075330734, 'training/sps': 127.54336838655651, 'training/walltime': 31436.447331905365, 'training/entropy_loss': Array(0.11030318, dtype=float32), 'training/policy_loss': Array(0.26844162, dtype=float32), 'training/total_loss': Array(0.37874478, dtype=float32), 'training/v_loss': Array(2.0739028e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009784, dtype=float32), 'eval/episode_forward_reward': Array(-0.04292582, dtype=float32), 'eval/episode_reward': Array(-2.0430062, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04292582, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987926, dtype=float32), 'eval/episode_train_reward': Array(-0.00128777, dtype=float32), 'eval/episode_x_position': Array(1.0078914, dtype=float32), 'eval/episode_x_velocity': Array(-0.04292582, dtype=float32), 'eval/episode_y_position': Array(0.00053339, dtype=float32), 'eval/episode_y_velocity': Array(-0.00123349, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582206, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04524136, dtype=float32), 'eval/episode_reward_std': Array(0.04667546, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04524136, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00825089, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135724, dtype=float32), 'eval/episode_x_position_std': Array(0.00584831, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04524136, dtype=float32), 'eval/episode_y_position_std': Array(0.00615983, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01027749, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69140863418579, 'eval/sps': 6186.14238706406, 'num_steps': 3988480}
{'eval/walltime': 16253.157349586487, 'training/sps': 127.3499074732869, 'training/walltime': 31476.651522874832, 'training/entropy_loss': Array(0.11163698, dtype=float32), 'training/policy_loss': Array(0.27059, dtype=float32), 'training/total_loss': Array(0.382227, dtype=float32), 'training/v_loss': Array(6.957371e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169125, dtype=float32), 'eval/episode_forward_reward': Array(-0.03612632, dtype=float32), 'eval/episode_reward': Array(-2.0515664, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03612632, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0221686, dtype=float32), 'eval/episode_train_reward': Array(-0.00108379, dtype=float32), 'eval/episode_x_position': Array(1.0149769, dtype=float32), 'eval/episode_x_velocity': Array(-0.03612632, dtype=float32), 'eval/episode_y_position': Array(0.00031883, dtype=float32), 'eval/episode_y_velocity': Array(-0.00152624, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08801302, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04398027, dtype=float32), 'eval/episode_reward_std': Array(0.1796132, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04398027, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26433513, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131941, dtype=float32), 'eval/episode_x_position_std': Array(0.08774097, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04398027, dtype=float32), 'eval/episode_y_position_std': Array(0.00621776, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01372925, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.647274255752563, 'eval/sps': 6199.365515006793, 'num_steps': 3993600}
{'eval/walltime': 16273.832451581955, 'training/sps': 127.50217868594773, 'training/walltime': 31516.80769944191, 'training/entropy_loss': Array(0.10733385, dtype=float32), 'training/policy_loss': Array(0.27276003, dtype=float32), 'training/total_loss': Array(0.38009387, dtype=float32), 'training/v_loss': Array(2.5382406e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009282, dtype=float32), 'eval/episode_forward_reward': Array(-0.04113311, dtype=float32), 'eval/episode_reward': Array(-2.0393162, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04113311, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969494, dtype=float32), 'eval/episode_train_reward': Array(-0.00123399, dtype=float32), 'eval/episode_x_position': Array(1.0074377, dtype=float32), 'eval/episode_x_velocity': Array(-0.04113311, dtype=float32), 'eval/episode_y_position': Array(0.00052497, dtype=float32), 'eval/episode_y_velocity': Array(0.00026451, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574677, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0442586, dtype=float32), 'eval/episode_reward_std': Array(0.04852496, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0442586, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01606424, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132776, dtype=float32), 'eval/episode_x_position_std': Array(0.00573523, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0442586, dtype=float32), 'eval/episode_y_position_std': Array(0.00570476, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01722936, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67510199546814, 'eval/sps': 6191.021453149631, 'num_steps': 3998720}
{'eval/walltime': 16294.470920324326, 'training/sps': 127.36601812819826, 'training/walltime': 31557.006804943085, 'training/entropy_loss': Array(0.10784363, dtype=float32), 'training/policy_loss': Array(0.26691404, dtype=float32), 'training/total_loss': Array(0.37475768, dtype=float32), 'training/v_loss': Array(2.8130948e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009161, dtype=float32), 'eval/episode_forward_reward': Array(-0.04207964, dtype=float32), 'eval/episode_reward': Array(-2.0407975, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04207964, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974556, dtype=float32), 'eval/episode_train_reward': Array(-0.00126239, dtype=float32), 'eval/episode_x_position': Array(1.007292, dtype=float32), 'eval/episode_x_velocity': Array(-0.04207964, dtype=float32), 'eval/episode_y_position': Array(0.00046016, dtype=float32), 'eval/episode_y_velocity': Array(0.0008132, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573316, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04535852, dtype=float32), 'eval/episode_reward_std': Array(0.04764958, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04535852, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01380077, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136076, dtype=float32), 'eval/episode_x_position_std': Array(0.00575941, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04535852, dtype=float32), 'eval/episode_y_position_std': Array(0.00574776, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01024189, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.638468742370605, 'eval/sps': 6202.010507553647, 'num_steps': 4003840}
{'eval/walltime': 16315.149635076523, 'training/sps': 127.60692522678761, 'training/walltime': 31597.130019187927, 'training/entropy_loss': Array(0.10960172, dtype=float32), 'training/policy_loss': Array(0.26937658, dtype=float32), 'training/total_loss': Array(0.3789783, dtype=float32), 'training/v_loss': Array(5.2752425e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0166814, dtype=float32), 'eval/episode_forward_reward': Array(-0.03550838, dtype=float32), 'eval/episode_reward': Array(-2.0483851, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03550838, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0196238, dtype=float32), 'eval/episode_train_reward': Array(-0.00106525, dtype=float32), 'eval/episode_x_position': Array(1.0147612, dtype=float32), 'eval/episode_x_velocity': Array(-0.03550838, dtype=float32), 'eval/episode_y_position': Array(-0.00025131, dtype=float32), 'eval/episode_y_velocity': Array(0.00055495, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0904741, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04229684, dtype=float32), 'eval/episode_reward_std': Array(0.18009602, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04229684, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2651513, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126891, dtype=float32), 'eval/episode_x_position_std': Array(0.09021256, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04229684, dtype=float32), 'eval/episode_y_position_std': Array(0.00623941, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01388791, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.678714752197266, 'eval/sps': 6189.939826236012, 'num_steps': 4008960}
{'eval/walltime': 16335.788298845291, 'training/sps': 127.13493358014965, 'training/walltime': 31637.402191877365, 'training/entropy_loss': Array(0.10913365, dtype=float32), 'training/policy_loss': Array(0.2667355, dtype=float32), 'training/total_loss': Array(0.37586915, dtype=float32), 'training/v_loss': Array(4.5324622e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084317, dtype=float32), 'eval/episode_forward_reward': Array(-0.04098448, dtype=float32), 'eval/episode_reward': Array(-2.0381088, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04098448, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995895, dtype=float32), 'eval/episode_train_reward': Array(-0.00122953, dtype=float32), 'eval/episode_x_position': Array(1.0065513, dtype=float32), 'eval/episode_x_velocity': Array(-0.04098448, dtype=float32), 'eval/episode_y_position': Array(-0.00019915, dtype=float32), 'eval/episode_y_velocity': Array(0.00085852, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583374, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0446576, dtype=float32), 'eval/episode_reward_std': Array(0.04852453, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0446576, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01653454, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133973, dtype=float32), 'eval/episode_x_position_std': Array(0.00582104, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0446576, dtype=float32), 'eval/episode_y_position_std': Array(0.00579677, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01486924, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.63866376876831, 'eval/sps': 6201.951901251351, 'num_steps': 4014080}
{'eval/walltime': 16356.50535416603, 'training/sps': 127.31220121644162, 'training/walltime': 31677.61829018593, 'training/entropy_loss': Array(0.11701071, dtype=float32), 'training/policy_loss': Array(0.27368772, dtype=float32), 'training/total_loss': Array(0.39069843, dtype=float32), 'training/v_loss': Array(6.240589e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099156, dtype=float32), 'eval/episode_forward_reward': Array(-0.03290572, dtype=float32), 'eval/episode_reward': Array(-2.031159, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03290572, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997266, dtype=float32), 'eval/episode_train_reward': Array(-0.00098717, dtype=float32), 'eval/episode_x_position': Array(1.0079896, dtype=float32), 'eval/episode_x_velocity': Array(-0.03290572, dtype=float32), 'eval/episode_y_position': Array(0.00016156, dtype=float32), 'eval/episode_y_velocity': Array(-0.00279607, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566161, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04373756, dtype=float32), 'eval/episode_reward_std': Array(0.04613296, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04373756, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01365758, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131213, dtype=float32), 'eval/episode_x_position_std': Array(0.00561638, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04373756, dtype=float32), 'eval/episode_y_position_std': Array(0.00587301, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01024456, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.717055320739746, 'eval/sps': 6178.484249731177, 'num_steps': 4019200}
{'eval/walltime': 16377.257747650146, 'training/sps': 127.22146350193101, 'training/walltime': 31717.86307168007, 'training/entropy_loss': Array(0.1103033, dtype=float32), 'training/policy_loss': Array(0.26955485, dtype=float32), 'training/total_loss': Array(0.37985817, dtype=float32), 'training/v_loss': Array(3.6363623e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094763, dtype=float32), 'eval/episode_forward_reward': Array(-0.03437163, dtype=float32), 'eval/episode_reward': Array(-2.034815, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03437163, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.999412, dtype=float32), 'eval/episode_train_reward': Array(-0.00103115, dtype=float32), 'eval/episode_x_position': Array(1.0075862, dtype=float32), 'eval/episode_x_velocity': Array(-0.03437163, dtype=float32), 'eval/episode_y_position': Array(-0.00041017, dtype=float32), 'eval/episode_y_velocity': Array(0.00069699, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00576282, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04159454, dtype=float32), 'eval/episode_reward_std': Array(0.04320308, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04159454, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00474946, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124784, dtype=float32), 'eval/episode_x_position_std': Array(0.00573413, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04159454, dtype=float32), 'eval/episode_y_position_std': Array(0.00591207, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01227801, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7523934841156, 'eval/sps': 6167.96323267359, 'num_steps': 4024320}
{'eval/walltime': 16398.002014160156, 'training/sps': 127.31382095690496, 'training/walltime': 31758.07865834236, 'training/entropy_loss': Array(0.10550137, dtype=float32), 'training/policy_loss': Array(0.01271211, dtype=float32), 'training/total_loss': Array(0.11821348, dtype=float32), 'training/v_loss': Array(6.4728853e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169481, dtype=float32), 'eval/episode_forward_reward': Array(-0.03936709, dtype=float32), 'eval/episode_reward': Array(-2.0522141, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03936709, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0194788, dtype=float32), 'eval/episode_train_reward': Array(-0.00118101, dtype=float32), 'eval/episode_x_position': Array(1.0150533, dtype=float32), 'eval/episode_x_velocity': Array(-0.03936709, dtype=float32), 'eval/episode_y_position': Array(3.8403705e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00068502, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08768566, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04435907, dtype=float32), 'eval/episode_reward_std': Array(0.17609657, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04435907, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26159927, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133077, dtype=float32), 'eval/episode_x_position_std': Array(0.08741071, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04435907, dtype=float32), 'eval/episode_y_position_std': Array(0.00561508, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01555945, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.744266510009766, 'eval/sps': 6170.379653492976, 'num_steps': 4029440}
{'eval/walltime': 16418.71059513092, 'training/sps': 126.97171940759269, 'training/walltime': 31798.402598381042, 'training/entropy_loss': Array(0.10704949, dtype=float32), 'training/policy_loss': Array(0.03706028, dtype=float32), 'training/total_loss': Array(0.14410977, dtype=float32), 'training/v_loss': Array(1.131157e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086155, dtype=float32), 'eval/episode_forward_reward': Array(-0.03949948, dtype=float32), 'eval/episode_reward': Array(-2.0379336, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03949948, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972491, dtype=float32), 'eval/episode_train_reward': Array(-0.00118498, dtype=float32), 'eval/episode_x_position': Array(1.0067661, dtype=float32), 'eval/episode_x_velocity': Array(-0.03949948, dtype=float32), 'eval/episode_y_position': Array(0.00034851, dtype=float32), 'eval/episode_y_velocity': Array(-0.00013044, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058826, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04156661, dtype=float32), 'eval/episode_reward_std': Array(0.04578298, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04156661, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01441662, dtype=float32), 'eval/episode_train_reward_std': Array(0.001247, dtype=float32), 'eval/episode_x_position_std': Array(0.00591413, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04156661, dtype=float32), 'eval/episode_y_position_std': Array(0.0057634, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00945742, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70858097076416, 'eval/sps': 6181.012604422635, 'num_steps': 4034560}
{'eval/walltime': 16439.449059724808, 'training/sps': 127.35077370439068, 'training/walltime': 31838.6065158844, 'training/entropy_loss': Array(0.10767244, dtype=float32), 'training/policy_loss': Array(0.22532977, dtype=float32), 'training/total_loss': Array(0.3330022, dtype=float32), 'training/v_loss': Array(2.6241238e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096626, dtype=float32), 'eval/episode_forward_reward': Array(-0.03769994, dtype=float32), 'eval/episode_reward': Array(-2.0359068, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03769994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997076, dtype=float32), 'eval/episode_train_reward': Array(-0.001131, dtype=float32), 'eval/episode_x_position': Array(1.0077844, dtype=float32), 'eval/episode_x_velocity': Array(-0.03769994, dtype=float32), 'eval/episode_y_position': Array(0.00043694, dtype=float32), 'eval/episode_y_velocity': Array(-0.00049148, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584485, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04348002, dtype=float32), 'eval/episode_reward_std': Array(0.04690595, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04348002, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0140833, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013044, dtype=float32), 'eval/episode_x_position_std': Array(0.00590363, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04348002, dtype=float32), 'eval/episode_y_position_std': Array(0.00577062, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01497803, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.73846459388733, 'eval/sps': 6172.1059155810435, 'num_steps': 4039680}
{'eval/walltime': 16460.14840912819, 'training/sps': 126.86666732202636, 'training/walltime': 31878.963846206665, 'training/entropy_loss': Array(0.11160405, dtype=float32), 'training/policy_loss': Array(0.2719836, dtype=float32), 'training/total_loss': Array(0.38358766, dtype=float32), 'training/v_loss': Array(4.3471587e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093431, dtype=float32), 'eval/episode_forward_reward': Array(-0.04176547, dtype=float32), 'eval/episode_reward': Array(-2.0404253, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04176547, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997407, dtype=float32), 'eval/episode_train_reward': Array(-0.00125296, dtype=float32), 'eval/episode_x_position': Array(1.0074832, dtype=float32), 'eval/episode_x_velocity': Array(-0.04176547, dtype=float32), 'eval/episode_y_position': Array(-0.00041946, dtype=float32), 'eval/episode_y_velocity': Array(-0.00240194, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059257, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04428585, dtype=float32), 'eval/episode_reward_std': Array(0.04624166, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04428585, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01284938, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132858, dtype=float32), 'eval/episode_x_position_std': Array(0.00592798, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04428585, dtype=float32), 'eval/episode_y_position_std': Array(0.00567007, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01386076, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.699349403381348, 'eval/sps': 6183.769233785219, 'num_steps': 4044800}
{'eval/walltime': 16480.86607503891, 'training/sps': 127.44123847454352, 'training/walltime': 31919.139224767685, 'training/entropy_loss': Array(0.10914189, dtype=float32), 'training/policy_loss': Array(0.27194858, dtype=float32), 'training/total_loss': Array(0.38109046, dtype=float32), 'training/v_loss': Array(6.244766e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093334, dtype=float32), 'eval/episode_forward_reward': Array(-0.03901497, dtype=float32), 'eval/episode_reward': Array(-2.0372415, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03901497, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997056, dtype=float32), 'eval/episode_train_reward': Array(-0.00117045, dtype=float32), 'eval/episode_x_position': Array(1.007462, dtype=float32), 'eval/episode_x_velocity': Array(-0.03901497, dtype=float32), 'eval/episode_y_position': Array(-0.00056948, dtype=float32), 'eval/episode_y_velocity': Array(0.00043429, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00610877, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04342566, dtype=float32), 'eval/episode_reward_std': Array(0.0462074, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04342566, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01468393, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130277, dtype=float32), 'eval/episode_x_position_std': Array(0.00612022, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04342566, dtype=float32), 'eval/episode_y_position_std': Array(0.00579372, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01231421, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.717665910720825, 'eval/sps': 6178.302157762062, 'num_steps': 4049920}
{'eval/walltime': 16501.549391031265, 'training/sps': 127.17291747091689, 'training/walltime': 31959.39936900139, 'training/entropy_loss': Array(0.10758452, dtype=float32), 'training/policy_loss': Array(0.26675358, dtype=float32), 'training/total_loss': Array(0.3743381, dtype=float32), 'training/v_loss': Array(2.0429214e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095379, dtype=float32), 'eval/episode_forward_reward': Array(-0.03412583, dtype=float32), 'eval/episode_reward': Array(-2.0332727, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03412583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981234, dtype=float32), 'eval/episode_train_reward': Array(-0.00102377, dtype=float32), 'eval/episode_x_position': Array(1.0076389, dtype=float32), 'eval/episode_x_velocity': Array(-0.03412583, dtype=float32), 'eval/episode_y_position': Array(-0.00036006, dtype=float32), 'eval/episode_y_velocity': Array(-0.00436639, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059186, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04225818, dtype=float32), 'eval/episode_reward_std': Array(0.04506146, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04225818, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01172612, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126775, dtype=float32), 'eval/episode_x_position_std': Array(0.00588998, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04225818, dtype=float32), 'eval/episode_y_position_std': Array(0.00587201, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01647383, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.683315992355347, 'eval/sps': 6188.562803339146, 'num_steps': 4055040}
{'eval/walltime': 16522.267638921738, 'training/sps': 127.37820768202437, 'training/walltime': 31999.59462761879, 'training/entropy_loss': Array(0.10917534, dtype=float32), 'training/policy_loss': Array(0.0706372, dtype=float32), 'training/total_loss': Array(0.17981252, dtype=float32), 'training/v_loss': Array(7.4491896e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094492, dtype=float32), 'eval/episode_forward_reward': Array(-0.03797134, dtype=float32), 'eval/episode_reward': Array(-2.0369267, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03797134, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997816, dtype=float32), 'eval/episode_train_reward': Array(-0.00113914, dtype=float32), 'eval/episode_x_position': Array(1.0075631, dtype=float32), 'eval/episode_x_velocity': Array(-0.03797134, dtype=float32), 'eval/episode_y_position': Array(-0.00025621, dtype=float32), 'eval/episode_y_velocity': Array(0.00036403, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00631829, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04226323, dtype=float32), 'eval/episode_reward_std': Array(0.0443955, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04226323, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01178465, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012679, dtype=float32), 'eval/episode_x_position_std': Array(0.00625636, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04226323, dtype=float32), 'eval/episode_y_position_std': Array(0.00546594, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01127848, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.718247890472412, 'eval/sps': 6178.128608011427, 'num_steps': 4060160}
{'eval/walltime': 16542.954361200333, 'training/sps': 127.21684809141759, 'training/walltime': 32039.84086918831, 'training/entropy_loss': Array(0.11215727, dtype=float32), 'training/policy_loss': Array(0.26500118, dtype=float32), 'training/total_loss': Array(0.37715846, dtype=float32), 'training/v_loss': Array(3.159717e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085776, dtype=float32), 'eval/episode_forward_reward': Array(-0.04161095, dtype=float32), 'eval/episode_reward': Array(-2.0384762, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04161095, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995617, dtype=float32), 'eval/episode_train_reward': Array(-0.00124833, dtype=float32), 'eval/episode_x_position': Array(1.0067012, dtype=float32), 'eval/episode_x_velocity': Array(-0.04161095, dtype=float32), 'eval/episode_y_position': Array(-0.00052709, dtype=float32), 'eval/episode_y_velocity': Array(-0.00050104, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573021, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04643514, dtype=float32), 'eval/episode_reward_std': Array(0.0514721, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04643514, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01672632, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139305, dtype=float32), 'eval/episode_x_position_std': Array(0.00572149, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04643514, dtype=float32), 'eval/episode_y_position_std': Array(0.00620159, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01335942, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68672227859497, 'eval/sps': 6187.54379143208, 'num_steps': 4065280}
{'eval/walltime': 16563.678146839142, 'training/sps': 127.49477927909028, 'training/walltime': 32079.999376296997, 'training/entropy_loss': Array(0.11351372, dtype=float32), 'training/policy_loss': Array(0.2708162, dtype=float32), 'training/total_loss': Array(0.38432992, dtype=float32), 'training/v_loss': Array(1.4238403e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009797, dtype=float32), 'eval/episode_forward_reward': Array(-0.03636403, dtype=float32), 'eval/episode_reward': Array(-2.0356336, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03636403, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998179, dtype=float32), 'eval/episode_train_reward': Array(-0.00109092, dtype=float32), 'eval/episode_x_position': Array(1.0078874, dtype=float32), 'eval/episode_x_velocity': Array(-0.03636403, dtype=float32), 'eval/episode_y_position': Array(-6.596942e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00207573, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559708, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04217866, dtype=float32), 'eval/episode_reward_std': Array(0.04488126, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04217866, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00989671, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126536, dtype=float32), 'eval/episode_x_position_std': Array(0.00556381, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04217866, dtype=float32), 'eval/episode_y_position_std': Array(0.00570149, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01184188, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.723785638809204, 'eval/sps': 6176.477706867216, 'num_steps': 4070400}
{'eval/walltime': 16584.388750076294, 'training/sps': 127.17386715188175, 'training/walltime': 32120.259219884872, 'training/entropy_loss': Array(0.11284494, dtype=float32), 'training/policy_loss': Array(0.2716098, dtype=float32), 'training/total_loss': Array(0.38445476, dtype=float32), 'training/v_loss': Array(1.6986113e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087478, dtype=float32), 'eval/episode_forward_reward': Array(-0.04134816, dtype=float32), 'eval/episode_reward': Array(-2.041554, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04134816, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9989653, dtype=float32), 'eval/episode_train_reward': Array(-0.00124044, dtype=float32), 'eval/episode_x_position': Array(1.0068973, dtype=float32), 'eval/episode_x_velocity': Array(-0.04134816, dtype=float32), 'eval/episode_y_position': Array(-0.000485, dtype=float32), 'eval/episode_y_velocity': Array(-0.00080943, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00587019, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0444282, dtype=float32), 'eval/episode_reward_std': Array(0.04679908, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0444282, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00621379, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133285, dtype=float32), 'eval/episode_x_position_std': Array(0.00586072, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0444282, dtype=float32), 'eval/episode_y_position_std': Array(0.00576601, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01210538, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7106032371521, 'eval/sps': 6180.409065554634, 'num_steps': 4075520}
{'eval/walltime': 16605.09941458702, 'training/sps': 127.43024367874422, 'training/walltime': 32160.438064813614, 'training/entropy_loss': Array(0.11286519, dtype=float32), 'training/policy_loss': Array(0.26614586, dtype=float32), 'training/total_loss': Array(0.37901106, dtype=float32), 'training/v_loss': Array(4.353442e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016531, dtype=float32), 'eval/episode_forward_reward': Array(-0.0369486, dtype=float32), 'eval/episode_reward': Array(-2.0509868, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0369486, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0207424, dtype=float32), 'eval/episode_train_reward': Array(-0.00110846, dtype=float32), 'eval/episode_x_position': Array(1.0146354, dtype=float32), 'eval/episode_x_velocity': Array(-0.0369486, dtype=float32), 'eval/episode_y_position': Array(-0.00049647, dtype=float32), 'eval/episode_y_velocity': Array(-0.00192928, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09033331, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04230919, dtype=float32), 'eval/episode_reward_std': Array(0.17882055, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04230919, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2647537, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126928, dtype=float32), 'eval/episode_x_position_std': Array(0.09006538, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04230919, dtype=float32), 'eval/episode_y_position_std': Array(0.0056629, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01107376, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.71066451072693, 'eval/sps': 6180.390780493953, 'num_steps': 4080640}
{'eval/walltime': 16625.84044456482, 'training/sps': 127.29893538748846, 'training/walltime': 32200.65835404396, 'training/entropy_loss': Array(0.114559, dtype=float32), 'training/policy_loss': Array(0.27050403, dtype=float32), 'training/total_loss': Array(0.38506305, dtype=float32), 'training/v_loss': Array(2.1363391e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016757, dtype=float32), 'eval/episode_forward_reward': Array(-0.04443084, dtype=float32), 'eval/episode_reward': Array(-2.0584445, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04443084, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.020493, dtype=float32), 'eval/episode_train_reward': Array(-0.00133293, dtype=float32), 'eval/episode_x_position': Array(1.014909, dtype=float32), 'eval/episode_x_velocity': Array(-0.04443084, dtype=float32), 'eval/episode_y_position': Array(0.00082321, dtype=float32), 'eval/episode_y_velocity': Array(-0.00098201, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08864112, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04345969, dtype=float32), 'eval/episode_reward_std': Array(0.17732401, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04345969, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26477626, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130379, dtype=float32), 'eval/episode_x_position_std': Array(0.08837176, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04345969, dtype=float32), 'eval/episode_y_position_std': Array(0.00589311, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01212838, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.741029977798462, 'eval/sps': 6171.342509847066, 'num_steps': 4085760}
{'eval/walltime': 16646.558054447174, 'training/sps': 127.54118226260731, 'training/walltime': 32240.802250385284, 'training/entropy_loss': Array(0.11369486, dtype=float32), 'training/policy_loss': Array(0.2744801, dtype=float32), 'training/total_loss': Array(0.38817492, dtype=float32), 'training/v_loss': Array(4.537906e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0163656, dtype=float32), 'eval/episode_forward_reward': Array(-0.04000768, dtype=float32), 'eval/episode_reward': Array(-2.0558152, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04000768, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0224197, dtype=float32), 'eval/episode_train_reward': Array(-0.00120023, dtype=float32), 'eval/episode_x_position': Array(1.0144849, dtype=float32), 'eval/episode_x_velocity': Array(-0.04000768, dtype=float32), 'eval/episode_y_position': Array(4.7799083e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00137894, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08742878, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04255651, dtype=float32), 'eval/episode_reward_std': Array(0.17814599, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04255651, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26432446, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012767, dtype=float32), 'eval/episode_x_position_std': Array(0.08714727, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04255651, dtype=float32), 'eval/episode_y_position_std': Array(0.00562929, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01379493, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.717609882354736, 'eval/sps': 6178.3188662615985, 'num_steps': 4090880}
{'eval/walltime': 16667.250994443893, 'training/sps': 127.35491470865223, 'training/walltime': 32281.004860639572, 'training/entropy_loss': Array(0.11078024, dtype=float32), 'training/policy_loss': Array(0.27071744, dtype=float32), 'training/total_loss': Array(0.38149768, dtype=float32), 'training/v_loss': Array(7.940798e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094211, dtype=float32), 'eval/episode_forward_reward': Array(-0.03769823, dtype=float32), 'eval/episode_reward': Array(-2.0336227, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03769823, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947934, dtype=float32), 'eval/episode_train_reward': Array(-0.00113095, dtype=float32), 'eval/episode_x_position': Array(1.0075192, dtype=float32), 'eval/episode_x_velocity': Array(-0.03769823, dtype=float32), 'eval/episode_y_position': Array(0.0013024, dtype=float32), 'eval/episode_y_velocity': Array(-0.00180922, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00587058, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04298623, dtype=float32), 'eval/episode_reward_std': Array(0.04994377, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04298623, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01935336, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128959, dtype=float32), 'eval/episode_x_position_std': Array(0.00588584, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04298623, dtype=float32), 'eval/episode_y_position_std': Array(0.0056454, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00889129, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69293999671936, 'eval/sps': 6185.684587124546, 'num_steps': 4096000}
{'eval/walltime': 16687.950344085693, 'training/sps': 127.36902469322528, 'training/walltime': 32321.203017234802, 'training/entropy_loss': Array(0.10944542, dtype=float32), 'training/policy_loss': Array(0.26663113, dtype=float32), 'training/total_loss': Array(0.37607655, dtype=float32), 'training/v_loss': Array(8.4179197e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091004, dtype=float32), 'eval/episode_forward_reward': Array(-0.03838671, dtype=float32), 'eval/episode_reward': Array(-2.0368445, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03838671, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973063, dtype=float32), 'eval/episode_train_reward': Array(-0.0011516, dtype=float32), 'eval/episode_x_position': Array(1.0072218, dtype=float32), 'eval/episode_x_velocity': Array(-0.03838671, dtype=float32), 'eval/episode_y_position': Array(0.00017486, dtype=float32), 'eval/episode_y_velocity': Array(-0.00152397, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00536276, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04375301, dtype=float32), 'eval/episode_reward_std': Array(0.04666482, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04375301, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0147176, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131259, dtype=float32), 'eval/episode_x_position_std': Array(0.00534725, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04375301, dtype=float32), 'eval/episode_y_position_std': Array(0.00581488, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01210094, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.699349641799927, 'eval/sps': 6183.769162559528, 'num_steps': 4101120}
{'eval/walltime': 16708.627696037292, 'training/sps': 127.03894161575882, 'training/walltime': 32361.505620002747, 'training/entropy_loss': Array(0.11147125, dtype=float32), 'training/policy_loss': Array(0.26551372, dtype=float32), 'training/total_loss': Array(0.37698495, dtype=float32), 'training/v_loss': Array(8.0629525e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092664, dtype=float32), 'eval/episode_forward_reward': Array(-0.03952758, dtype=float32), 'eval/episode_reward': Array(-2.0384066, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03952758, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976933, dtype=float32), 'eval/episode_train_reward': Array(-0.00118583, dtype=float32), 'eval/episode_x_position': Array(1.0073706, dtype=float32), 'eval/episode_x_velocity': Array(-0.03952758, dtype=float32), 'eval/episode_y_position': Array(-0.00047995, dtype=float32), 'eval/episode_y_velocity': Array(0.00053455, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00534262, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04237009, dtype=float32), 'eval/episode_reward_std': Array(0.04488611, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04237009, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01179766, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012711, dtype=float32), 'eval/episode_x_position_std': Array(0.00537506, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04237009, dtype=float32), 'eval/episode_y_position_std': Array(0.00569699, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0137802, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67735195159912, 'eval/sps': 6190.34779209728, 'num_steps': 4106240}
{'eval/walltime': 16729.339265584946, 'training/sps': 127.45541373885455, 'training/walltime': 32401.676530361176, 'training/entropy_loss': Array(0.11172997, dtype=float32), 'training/policy_loss': Array(0.26725727, dtype=float32), 'training/total_loss': Array(0.37898725, dtype=float32), 'training/v_loss': Array(5.6917755e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095699, dtype=float32), 'eval/episode_forward_reward': Array(-0.03513865, dtype=float32), 'eval/episode_reward': Array(-2.0339694, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03513865, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977765, dtype=float32), 'eval/episode_train_reward': Array(-0.00105416, dtype=float32), 'eval/episode_x_position': Array(1.0076602, dtype=float32), 'eval/episode_x_velocity': Array(-0.03513865, dtype=float32), 'eval/episode_y_position': Array(-0.00029316, dtype=float32), 'eval/episode_y_velocity': Array(-0.00112137, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00593862, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04456874, dtype=float32), 'eval/episode_reward_std': Array(0.04590401, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04456874, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01272613, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133706, dtype=float32), 'eval/episode_x_position_std': Array(0.00592184, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04456874, dtype=float32), 'eval/episode_y_position_std': Array(0.00586347, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01418164, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7115695476532, 'eval/sps': 6180.120714922038, 'num_steps': 4111360}
{'eval/walltime': 16750.037559986115, 'training/sps': 127.1849013605915, 'training/walltime': 32441.932881116867, 'training/entropy_loss': Array(0.11410551, dtype=float32), 'training/policy_loss': Array(0.26707667, dtype=float32), 'training/total_loss': Array(0.3811822, dtype=float32), 'training/v_loss': Array(2.6091004e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092585, dtype=float32), 'eval/episode_forward_reward': Array(-0.03980962, dtype=float32), 'eval/episode_reward': Array(-2.0385075, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03980962, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975035, dtype=float32), 'eval/episode_train_reward': Array(-0.00119429, dtype=float32), 'eval/episode_x_position': Array(1.0073665, dtype=float32), 'eval/episode_x_velocity': Array(-0.03980962, dtype=float32), 'eval/episode_y_position': Array(-0.00014567, dtype=float32), 'eval/episode_y_velocity': Array(-0.00221415, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577077, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0463594, dtype=float32), 'eval/episode_reward_std': Array(0.05029871, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0463594, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01071317, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139078, dtype=float32), 'eval/episode_x_position_std': Array(0.00580389, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0463594, dtype=float32), 'eval/episode_y_position_std': Array(0.00588098, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01632606, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.698294401168823, 'eval/sps': 6184.084423534526, 'num_steps': 4116480}
{'eval/walltime': 16770.706647872925, 'training/sps': 127.46339263553229, 'training/walltime': 32482.101276874542, 'training/entropy_loss': Array(0.11223929, dtype=float32), 'training/policy_loss': Array(0.26737154, dtype=float32), 'training/total_loss': Array(0.37961087, dtype=float32), 'training/v_loss': Array(3.3638386e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0077999, dtype=float32), 'eval/episode_forward_reward': Array(-0.03930267, dtype=float32), 'eval/episode_reward': Array(-2.0386105, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03930267, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981287, dtype=float32), 'eval/episode_train_reward': Array(-0.00117908, dtype=float32), 'eval/episode_x_position': Array(1.005976, dtype=float32), 'eval/episode_x_velocity': Array(-0.03930267, dtype=float32), 'eval/episode_y_position': Array(0.00011916, dtype=float32), 'eval/episode_y_velocity': Array(-0.00172473, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581137, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04529719, dtype=float32), 'eval/episode_reward_std': Array(0.04860396, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04529719, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01123668, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135892, dtype=float32), 'eval/episode_x_position_std': Array(0.0058251, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04529719, dtype=float32), 'eval/episode_y_position_std': Array(0.00565909, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01168691, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.669087886810303, 'eval/sps': 6192.822861897136, 'num_steps': 4121600}
{'eval/walltime': 16791.407553434372, 'training/sps': 127.10747186971851, 'training/walltime': 32522.382150411606, 'training/entropy_loss': Array(0.11327881, dtype=float32), 'training/policy_loss': Array(0.26844567, dtype=float32), 'training/total_loss': Array(0.38172448, dtype=float32), 'training/v_loss': Array(1.0522247e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088844, dtype=float32), 'eval/episode_forward_reward': Array(-0.0479746, dtype=float32), 'eval/episode_reward': Array(-2.0462408, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0479746, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996827, dtype=float32), 'eval/episode_train_reward': Array(-0.00143924, dtype=float32), 'eval/episode_x_position': Array(1.0070469, dtype=float32), 'eval/episode_x_velocity': Array(-0.0479746, dtype=float32), 'eval/episode_y_position': Array(0.00058271, dtype=float32), 'eval/episode_y_velocity': Array(-0.0017583, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00631655, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04734211, dtype=float32), 'eval/episode_reward_std': Array(0.05251278, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04734211, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01740332, dtype=float32), 'eval/episode_train_reward_std': Array(0.00142026, dtype=float32), 'eval/episode_x_position_std': Array(0.0063439, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04734211, dtype=float32), 'eval/episode_y_position_std': Array(0.00565143, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01315585, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.700905561447144, 'eval/sps': 6183.304378644384, 'num_steps': 4126720}
{'eval/walltime': 16812.141233444214, 'training/sps': 127.22386328596687, 'training/walltime': 32562.62617278099, 'training/entropy_loss': Array(0.11003017, dtype=float32), 'training/policy_loss': Array(0.27133846, dtype=float32), 'training/total_loss': Array(0.3813686, dtype=float32), 'training/v_loss': Array(1.1599697e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096345, dtype=float32), 'eval/episode_forward_reward': Array(-0.03547563, dtype=float32), 'eval/episode_reward': Array(-2.0345657, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03547563, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998026, dtype=float32), 'eval/episode_train_reward': Array(-0.00106427, dtype=float32), 'eval/episode_x_position': Array(1.0077511, dtype=float32), 'eval/episode_x_velocity': Array(-0.03547563, dtype=float32), 'eval/episode_y_position': Array(6.5598026e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00123733, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00616221, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04057883, dtype=float32), 'eval/episode_reward_std': Array(0.04431674, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04057883, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01111458, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121737, dtype=float32), 'eval/episode_x_position_std': Array(0.0061107, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04057883, dtype=float32), 'eval/episode_y_position_std': Array(0.00608697, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01225034, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.73368000984192, 'eval/sps': 6173.530214570718, 'num_steps': 4131840}
{'eval/walltime': 16832.851015806198, 'training/sps': 127.1537566775474, 'training/walltime': 32602.892383813858, 'training/entropy_loss': Array(0.11078488, dtype=float32), 'training/policy_loss': Array(0.26953155, dtype=float32), 'training/total_loss': Array(0.38031644, dtype=float32), 'training/v_loss': Array(8.1539053e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093759, dtype=float32), 'eval/episode_forward_reward': Array(-0.04091828, dtype=float32), 'eval/episode_reward': Array(-2.038953, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04091828, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968073, dtype=float32), 'eval/episode_train_reward': Array(-0.00122755, dtype=float32), 'eval/episode_x_position': Array(1.007541, dtype=float32), 'eval/episode_x_velocity': Array(-0.04091828, dtype=float32), 'eval/episode_y_position': Array(0.00038734, dtype=float32), 'eval/episode_y_velocity': Array(-0.00075568, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00548841, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04253666, dtype=float32), 'eval/episode_reward_std': Array(0.0465753, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04253666, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01388524, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012761, dtype=float32), 'eval/episode_x_position_std': Array(0.00548073, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04253666, dtype=float32), 'eval/episode_y_position_std': Array(0.00578526, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00909053, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.709782361984253, 'eval/sps': 6180.654038883681, 'num_steps': 4136960}
{'eval/walltime': 16853.57718229294, 'training/sps': 127.26231588884275, 'training/walltime': 32643.12424635887, 'training/entropy_loss': Array(0.11108317, dtype=float32), 'training/policy_loss': Array(0.26874483, dtype=float32), 'training/total_loss': Array(0.37982798, dtype=float32), 'training/v_loss': Array(1.0771467e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099988, dtype=float32), 'eval/episode_forward_reward': Array(-0.03299381, dtype=float32), 'eval/episode_reward': Array(-2.0311286, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03299381, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971452, dtype=float32), 'eval/episode_train_reward': Array(-0.00098981, dtype=float32), 'eval/episode_x_position': Array(1.0080695, dtype=float32), 'eval/episode_x_velocity': Array(-0.03299381, dtype=float32), 'eval/episode_y_position': Array(0.00130391, dtype=float32), 'eval/episode_y_velocity': Array(-0.00284429, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557048, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04205347, dtype=float32), 'eval/episode_reward_std': Array(0.04605091, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04205347, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01381412, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012616, dtype=float32), 'eval/episode_x_position_std': Array(0.00557995, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04205347, dtype=float32), 'eval/episode_y_position_std': Array(0.00535281, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01398636, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.726166486740112, 'eval/sps': 6175.768204983299, 'num_steps': 4142080}
{'eval/walltime': 16874.31497979164, 'training/sps': 127.16726787781991, 'training/walltime': 32683.386179208755, 'training/entropy_loss': Array(0.11221737, dtype=float32), 'training/policy_loss': Array(0.26561427, dtype=float32), 'training/total_loss': Array(0.37783164, dtype=float32), 'training/v_loss': Array(1.1597093e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096083, dtype=float32), 'eval/episode_forward_reward': Array(-0.03857282, dtype=float32), 'eval/episode_reward': Array(-2.0358481, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03857282, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996118, dtype=float32), 'eval/episode_train_reward': Array(-0.00115718, dtype=float32), 'eval/episode_x_position': Array(1.0077467, dtype=float32), 'eval/episode_x_velocity': Array(-0.03857282, dtype=float32), 'eval/episode_y_position': Array(0.00010992, dtype=float32), 'eval/episode_y_velocity': Array(-0.00332881, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00643173, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04452685, dtype=float32), 'eval/episode_reward_std': Array(0.04932278, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04452685, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01777205, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133581, dtype=float32), 'eval/episode_x_position_std': Array(0.00641762, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04452685, dtype=float32), 'eval/episode_y_position_std': Array(0.00631519, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01059355, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.737797498703003, 'eval/sps': 6172.304460394382, 'num_steps': 4147200}
{'eval/walltime': 16894.997574090958, 'training/sps': 127.16741472172617, 'training/walltime': 32723.648065567017, 'training/entropy_loss': Array(0.11243156, dtype=float32), 'training/policy_loss': Array(0.2693969, dtype=float32), 'training/total_loss': Array(0.38182846, dtype=float32), 'training/v_loss': Array(1.03895705e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097423, dtype=float32), 'eval/episode_forward_reward': Array(-0.04209562, dtype=float32), 'eval/episode_reward': Array(-2.0388079, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04209562, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9954493, dtype=float32), 'eval/episode_train_reward': Array(-0.00126287, dtype=float32), 'eval/episode_x_position': Array(1.0078926, dtype=float32), 'eval/episode_x_velocity': Array(-0.04209562, dtype=float32), 'eval/episode_y_position': Array(9.1394526e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00214221, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00549706, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04379513, dtype=float32), 'eval/episode_reward_std': Array(0.04765416, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04379513, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01673198, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131385, dtype=float32), 'eval/episode_x_position_std': Array(0.00554644, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04379513, dtype=float32), 'eval/episode_y_position_std': Array(0.00569394, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01188501, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.682594299316406, 'eval/sps': 6188.778745431883, 'num_steps': 4152320}
{'eval/walltime': 16915.690598487854, 'training/sps': 127.03538098653394, 'training/walltime': 32763.95179796219, 'training/entropy_loss': Array(0.11434886, dtype=float32), 'training/policy_loss': Array(0.27118668, dtype=float32), 'training/total_loss': Array(0.38553554, dtype=float32), 'training/v_loss': Array(6.255679e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089698, dtype=float32), 'eval/episode_forward_reward': Array(-0.04127963, dtype=float32), 'eval/episode_reward': Array(-2.039095, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04127963, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965768, dtype=float32), 'eval/episode_train_reward': Array(-0.00123839, dtype=float32), 'eval/episode_x_position': Array(1.0071244, dtype=float32), 'eval/episode_x_velocity': Array(-0.04127963, dtype=float32), 'eval/episode_y_position': Array(-0.00039926, dtype=float32), 'eval/episode_y_velocity': Array(-0.00153526, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00532565, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04375676, dtype=float32), 'eval/episode_reward_std': Array(0.04951539, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04375676, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01634343, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013127, dtype=float32), 'eval/episode_x_position_std': Array(0.00537601, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04375676, dtype=float32), 'eval/episode_y_position_std': Array(0.00552491, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01314649, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.693024396896362, 'eval/sps': 6185.659357710806, 'num_steps': 4157440}
{'eval/walltime': 16936.40175795555, 'training/sps': 127.27651775765717, 'training/walltime': 32804.179171323776, 'training/entropy_loss': Array(0.11181197, dtype=float32), 'training/policy_loss': Array(0.2716694, dtype=float32), 'training/total_loss': Array(0.38348135, dtype=float32), 'training/v_loss': Array(4.075517e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0171645, dtype=float32), 'eval/episode_forward_reward': Array(-0.03655402, dtype=float32), 'eval/episode_reward': Array(-2.0500195, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03655402, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0201812, dtype=float32), 'eval/episode_train_reward': Array(-0.00109662, dtype=float32), 'eval/episode_x_position': Array(1.0152256, dtype=float32), 'eval/episode_x_velocity': Array(-0.03655402, dtype=float32), 'eval/episode_y_position': Array(0.00061064, dtype=float32), 'eval/episode_y_velocity': Array(-0.00126202, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09046584, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04506324, dtype=float32), 'eval/episode_reward_std': Array(0.17894138, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04506324, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2648198, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013519, dtype=float32), 'eval/episode_x_position_std': Array(0.09020631, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04506324, dtype=float32), 'eval/episode_y_position_std': Array(0.00591183, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01514837, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.711159467697144, 'eval/sps': 6180.243081013378, 'num_steps': 4162560}
{'eval/walltime': 16957.102634191513, 'training/sps': 127.40916308641226, 'training/walltime': 32844.36466407776, 'training/entropy_loss': Array(0.11009231, dtype=float32), 'training/policy_loss': Array(0.2695802, dtype=float32), 'training/total_loss': Array(0.37967247, dtype=float32), 'training/v_loss': Array(3.5412728e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083199, dtype=float32), 'eval/episode_forward_reward': Array(-0.04092045, dtype=float32), 'eval/episode_reward': Array(-2.038048, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04092045, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959, dtype=float32), 'eval/episode_train_reward': Array(-0.00122761, dtype=float32), 'eval/episode_x_position': Array(1.0064435, dtype=float32), 'eval/episode_x_velocity': Array(-0.04092045, dtype=float32), 'eval/episode_y_position': Array(-9.2373826e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00071556, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00609867, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04338943, dtype=float32), 'eval/episode_reward_std': Array(0.04706951, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04338943, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01638555, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130168, dtype=float32), 'eval/episode_x_position_std': Array(0.006091, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04338943, dtype=float32), 'eval/episode_y_position_std': Array(0.00567852, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01155257, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.700876235961914, 'eval/sps': 6183.31313809974, 'num_steps': 4167680}
{'eval/walltime': 16977.7967543602, 'training/sps': 127.51441703227461, 'training/walltime': 32884.516986608505, 'training/entropy_loss': Array(0.11130567, dtype=float32), 'training/policy_loss': Array(0.14986375, dtype=float32), 'training/total_loss': Array(0.26116943, dtype=float32), 'training/v_loss': Array(5.3927254e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095906, dtype=float32), 'eval/episode_forward_reward': Array(-0.03869203, dtype=float32), 'eval/episode_reward': Array(-2.037503, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03869203, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976501, dtype=float32), 'eval/episode_train_reward': Array(-0.00116076, dtype=float32), 'eval/episode_x_position': Array(1.0076941, dtype=float32), 'eval/episode_x_velocity': Array(-0.03869203, dtype=float32), 'eval/episode_y_position': Array(-0.00135338, dtype=float32), 'eval/episode_y_velocity': Array(-3.1625503e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00566838, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04404129, dtype=float32), 'eval/episode_reward_std': Array(0.04626076, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04404129, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01333401, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132124, dtype=float32), 'eval/episode_x_position_std': Array(0.00566675, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04404129, dtype=float32), 'eval/episode_y_position_std': Array(0.00583255, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01204205, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.694120168685913, 'eval/sps': 6185.331821629606, 'num_steps': 4172800}
{'eval/walltime': 16998.540744781494, 'training/sps': 127.14110947107534, 'training/walltime': 32924.7872030735, 'training/entropy_loss': Array(0.11353645, dtype=float32), 'training/policy_loss': Array(0.26910758, dtype=float32), 'training/total_loss': Array(0.38264406, dtype=float32), 'training/v_loss': Array(2.2651794e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091927, dtype=float32), 'eval/episode_forward_reward': Array(-0.04238201, dtype=float32), 'eval/episode_reward': Array(-2.0403996, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04238201, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996746, dtype=float32), 'eval/episode_train_reward': Array(-0.00127146, dtype=float32), 'eval/episode_x_position': Array(1.0073423, dtype=float32), 'eval/episode_x_velocity': Array(-0.04238201, dtype=float32), 'eval/episode_y_position': Array(-0.00023367, dtype=float32), 'eval/episode_y_velocity': Array(-0.00037064, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057413, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04561892, dtype=float32), 'eval/episode_reward_std': Array(0.04963703, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04561892, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01398198, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136857, dtype=float32), 'eval/episode_x_position_std': Array(0.00575961, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04561892, dtype=float32), 'eval/episode_y_position_std': Array(0.00574408, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01389489, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.743990421295166, 'eval/sps': 6170.461777141923, 'num_steps': 4177920}
{'eval/walltime': 17019.234841823578, 'training/sps': 127.28879807667089, 'training/walltime': 32965.01069545746, 'training/entropy_loss': Array(0.11340556, dtype=float32), 'training/policy_loss': Array(0.26927269, dtype=float32), 'training/total_loss': Array(0.38267824, dtype=float32), 'training/v_loss': Array(2.6663098e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096724, dtype=float32), 'eval/episode_forward_reward': Array(-0.04121545, dtype=float32), 'eval/episode_reward': Array(-2.0402353, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04121545, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977837, dtype=float32), 'eval/episode_train_reward': Array(-0.00123646, dtype=float32), 'eval/episode_x_position': Array(1.0078008, dtype=float32), 'eval/episode_x_velocity': Array(-0.04121545, dtype=float32), 'eval/episode_y_position': Array(0.00053834, dtype=float32), 'eval/episode_y_velocity': Array(-0.00028868, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581156, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04511657, dtype=float32), 'eval/episode_reward_std': Array(0.04872798, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04511657, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01066883, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013535, dtype=float32), 'eval/episode_x_position_std': Array(0.0057805, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04511657, dtype=float32), 'eval/episode_y_position_std': Array(0.00582804, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00953897, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69409704208374, 'eval/sps': 6185.338734021485, 'num_steps': 4183040}
{'eval/walltime': 17039.88016152382, 'training/sps': 127.21025791997697, 'training/walltime': 33005.25902199745, 'training/entropy_loss': Array(0.11266136, dtype=float32), 'training/policy_loss': Array(0.2694303, dtype=float32), 'training/total_loss': Array(0.38209167, dtype=float32), 'training/v_loss': Array(2.2366282e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085081, dtype=float32), 'eval/episode_forward_reward': Array(-0.03702582, dtype=float32), 'eval/episode_reward': Array(-2.0349476, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03702582, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9968112, dtype=float32), 'eval/episode_train_reward': Array(-0.00111077, dtype=float32), 'eval/episode_x_position': Array(1.0066361, dtype=float32), 'eval/episode_x_velocity': Array(-0.03702582, dtype=float32), 'eval/episode_y_position': Array(-0.00071278, dtype=float32), 'eval/episode_y_velocity': Array(-0.00057881, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584531, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04342114, dtype=float32), 'eval/episode_reward_std': Array(0.04725137, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04342114, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01393244, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130263, dtype=float32), 'eval/episode_x_position_std': Array(0.00578063, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04342114, dtype=float32), 'eval/episode_y_position_std': Array(0.00568625, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01091638, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64531970024109, 'eval/sps': 6199.952427886368, 'num_steps': 4188160}
{'eval/walltime': 17060.538526058197, 'training/sps': 127.36555280318, 'training/walltime': 33045.45827436447, 'training/entropy_loss': Array(0.11356902, dtype=float32), 'training/policy_loss': Array(0.2703387, dtype=float32), 'training/total_loss': Array(0.38390774, dtype=float32), 'training/v_loss': Array(3.5710075e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095868, dtype=float32), 'eval/episode_forward_reward': Array(-0.03816576, dtype=float32), 'eval/episode_reward': Array(-2.0373347, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03816576, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980237, dtype=float32), 'eval/episode_train_reward': Array(-0.00114497, dtype=float32), 'eval/episode_x_position': Array(1.0077283, dtype=float32), 'eval/episode_x_velocity': Array(-0.03816576, dtype=float32), 'eval/episode_y_position': Array(-0.00017372, dtype=float32), 'eval/episode_y_velocity': Array(0.00016654, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594944, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04237749, dtype=float32), 'eval/episode_reward_std': Array(0.04413883, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04237749, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01072621, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127132, dtype=float32), 'eval/episode_x_position_std': Array(0.00599149, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04237749, dtype=float32), 'eval/episode_y_position_std': Array(0.00548451, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01269555, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65836453437805, 'eval/sps': 6196.037434957269, 'num_steps': 4193280}
{'eval/walltime': 17081.210401535034, 'training/sps': 127.09606370639422, 'training/walltime': 33085.74276351929, 'training/entropy_loss': Array(0.11493232, dtype=float32), 'training/policy_loss': Array(0.27068427, dtype=float32), 'training/total_loss': Array(0.3856166, dtype=float32), 'training/v_loss': Array(3.539054e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086123, dtype=float32), 'eval/episode_forward_reward': Array(-0.04717933, dtype=float32), 'eval/episode_reward': Array(-2.0456781, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04717933, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970837, dtype=float32), 'eval/episode_train_reward': Array(-0.00141538, dtype=float32), 'eval/episode_x_position': Array(1.0068164, dtype=float32), 'eval/episode_x_velocity': Array(-0.04717933, dtype=float32), 'eval/episode_y_position': Array(0.00040263, dtype=float32), 'eval/episode_y_velocity': Array(-0.00351369, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00563434, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0441289, dtype=float32), 'eval/episode_reward_std': Array(0.04685833, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0441289, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01218976, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132387, dtype=float32), 'eval/episode_x_position_std': Array(0.00566295, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0441289, dtype=float32), 'eval/episode_y_position_std': Array(0.00590441, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01285262, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.671875476837158, 'eval/sps': 6191.987763443333, 'num_steps': 4198400}
{'eval/walltime': 17101.883554935455, 'training/sps': 127.39324782763939, 'training/walltime': 33125.93327665329, 'training/entropy_loss': Array(0.11161742, dtype=float32), 'training/policy_loss': Array(0.2711116, dtype=float32), 'training/total_loss': Array(0.38272905, dtype=float32), 'training/v_loss': Array(3.5227619e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086647, dtype=float32), 'eval/episode_forward_reward': Array(-0.04354663, dtype=float32), 'eval/episode_reward': Array(-2.043995, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04354663, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.999142, dtype=float32), 'eval/episode_train_reward': Array(-0.0013064, dtype=float32), 'eval/episode_x_position': Array(1.0068059, dtype=float32), 'eval/episode_x_velocity': Array(-0.04354663, dtype=float32), 'eval/episode_y_position': Array(-0.00052196, dtype=float32), 'eval/episode_y_velocity': Array(-0.00116756, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577805, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04391126, dtype=float32), 'eval/episode_reward_std': Array(0.04436241, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04391126, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00879284, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131734, dtype=float32), 'eval/episode_x_position_std': Array(0.00577732, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04391126, dtype=float32), 'eval/episode_y_position_std': Array(0.00574804, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01098683, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.673153400421143, 'eval/sps': 6191.605001943847, 'num_steps': 4203520}
{'eval/walltime': 17122.55211353302, 'training/sps': 127.12642605931262, 'training/walltime': 33166.208144426346, 'training/entropy_loss': Array(0.11025237, dtype=float32), 'training/policy_loss': Array(0.27016586, dtype=float32), 'training/total_loss': Array(0.3804182, dtype=float32), 'training/v_loss': Array(1.1653427e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094036, dtype=float32), 'eval/episode_forward_reward': Array(-0.03901931, dtype=float32), 'eval/episode_reward': Array(-2.0371807, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03901931, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969907, dtype=float32), 'eval/episode_train_reward': Array(-0.00117058, dtype=float32), 'eval/episode_x_position': Array(1.0075308, dtype=float32), 'eval/episode_x_velocity': Array(-0.03901931, dtype=float32), 'eval/episode_y_position': Array(9.338927e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00071416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00604645, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04435389, dtype=float32), 'eval/episode_reward_std': Array(0.04861359, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04435389, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01560151, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133062, dtype=float32), 'eval/episode_x_position_std': Array(0.00603179, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04435389, dtype=float32), 'eval/episode_y_position_std': Array(0.00570213, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01328589, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.668558597564697, 'eval/sps': 6192.981450340799, 'num_steps': 4208640}
{'eval/walltime': 17143.21163392067, 'training/sps': 127.3056736121713, 'training/walltime': 33206.4263048172, 'training/entropy_loss': Array(0.10947432, dtype=float32), 'training/policy_loss': Array(0.2682274, dtype=float32), 'training/total_loss': Array(0.37770173, dtype=float32), 'training/v_loss': Array(8.143603e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086012, dtype=float32), 'eval/episode_forward_reward': Array(-0.03235865, dtype=float32), 'eval/episode_reward': Array(-2.0305586, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03235865, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997229, dtype=float32), 'eval/episode_train_reward': Array(-0.00097076, dtype=float32), 'eval/episode_x_position': Array(1.0066903, dtype=float32), 'eval/episode_x_velocity': Array(-0.03235865, dtype=float32), 'eval/episode_y_position': Array(-0.00053057, dtype=float32), 'eval/episode_y_velocity': Array(-0.00020145, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00591252, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0410366, dtype=float32), 'eval/episode_reward_std': Array(0.04620354, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0410366, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01653708, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012311, dtype=float32), 'eval/episode_x_position_std': Array(0.00588032, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0410366, dtype=float32), 'eval/episode_y_position_std': Array(0.00588292, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00906684, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.659520387649536, 'eval/sps': 6195.690780726916, 'num_steps': 4213760}
{'eval/walltime': 17163.876983642578, 'training/sps': 127.25726842311873, 'training/walltime': 33246.65976309776, 'training/entropy_loss': Array(0.11084663, dtype=float32), 'training/policy_loss': Array(0.2219777, dtype=float32), 'training/total_loss': Array(0.33282432, dtype=float32), 'training/v_loss': Array(3.1883385e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090597, dtype=float32), 'eval/episode_forward_reward': Array(-0.03728247, dtype=float32), 'eval/episode_reward': Array(-2.0363479, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03728247, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979467, dtype=float32), 'eval/episode_train_reward': Array(-0.00111847, dtype=float32), 'eval/episode_x_position': Array(1.0071648, dtype=float32), 'eval/episode_x_velocity': Array(-0.03728247, dtype=float32), 'eval/episode_y_position': Array(9.95561e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00095941, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559802, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04392655, dtype=float32), 'eval/episode_reward_std': Array(0.04630392, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04392655, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00759062, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013178, dtype=float32), 'eval/episode_x_position_std': Array(0.00559748, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04392655, dtype=float32), 'eval/episode_y_position_std': Array(0.00604674, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01632761, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66534972190857, 'eval/sps': 6193.943084558572, 'num_steps': 4218880}
{'eval/walltime': 17184.548696279526, 'training/sps': 127.3913139604402, 'training/walltime': 33286.85088634491, 'training/entropy_loss': Array(0.10616073, dtype=float32), 'training/policy_loss': Array(0.2659113, dtype=float32), 'training/total_loss': Array(0.37207207, dtype=float32), 'training/v_loss': Array(4.9532986e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091598, dtype=float32), 'eval/episode_forward_reward': Array(-0.03164052, dtype=float32), 'eval/episode_reward': Array(-2.0299642, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03164052, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973745, dtype=float32), 'eval/episode_train_reward': Array(-0.00094922, dtype=float32), 'eval/episode_x_position': Array(1.0072207, dtype=float32), 'eval/episode_x_velocity': Array(-0.03164052, dtype=float32), 'eval/episode_y_position': Array(-0.00025967, dtype=float32), 'eval/episode_y_velocity': Array(0.00077669, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614337, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04293213, dtype=float32), 'eval/episode_reward_std': Array(0.0434294, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04293213, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01420585, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128796, dtype=float32), 'eval/episode_x_position_std': Array(0.00614894, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04293213, dtype=float32), 'eval/episode_y_position_std': Array(0.00605294, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01200382, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.671712636947632, 'eval/sps': 6192.036540369611, 'num_steps': 4224000}
{'eval/walltime': 17205.25365447998, 'training/sps': 127.30197651828252, 'training/walltime': 33327.07021474838, 'training/entropy_loss': Array(0.10440788, dtype=float32), 'training/policy_loss': Array(-0.08378562, dtype=float32), 'training/total_loss': Array(0.02062226, dtype=float32), 'training/v_loss': Array(2.782813e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0177922, dtype=float32), 'eval/episode_forward_reward': Array(-0.03807006, dtype=float32), 'eval/episode_reward': Array(-2.0545924, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03807006, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0231926, dtype=float32), 'eval/episode_train_reward': Array(-0.0011421, dtype=float32), 'eval/episode_x_position': Array(1.015891, dtype=float32), 'eval/episode_x_velocity': Array(-0.03807006, dtype=float32), 'eval/episode_y_position': Array(0.00049167, dtype=float32), 'eval/episode_y_velocity': Array(0.00056175, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09050985, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04164386, dtype=float32), 'eval/episode_reward_std': Array(0.17697243, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04164386, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2641536, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124932, dtype=float32), 'eval/episode_x_position_std': Array(0.09023999, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04164386, dtype=float32), 'eval/episode_y_position_std': Array(0.00610345, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01236899, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.704958200454712, 'eval/sps': 6182.094103294974, 'num_steps': 4229120}
{'eval/walltime': 17225.934402942657, 'training/sps': 127.3744648215088, 'training/walltime': 33367.266654491425, 'training/entropy_loss': Array(0.10503073, dtype=float32), 'training/policy_loss': Array(-0.03214298, dtype=float32), 'training/total_loss': Array(0.07288774, dtype=float32), 'training/v_loss': Array(1.4185599e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092998, dtype=float32), 'eval/episode_forward_reward': Array(-0.03816219, dtype=float32), 'eval/episode_reward': Array(-2.038157, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03816219, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9988499, dtype=float32), 'eval/episode_train_reward': Array(-0.00114487, dtype=float32), 'eval/episode_x_position': Array(1.0074131, dtype=float32), 'eval/episode_x_velocity': Array(-0.03816219, dtype=float32), 'eval/episode_y_position': Array(0.00050664, dtype=float32), 'eval/episode_y_velocity': Array(-0.00112781, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581376, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04382185, dtype=float32), 'eval/episode_reward_std': Array(0.04584602, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04382185, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00645894, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131466, dtype=float32), 'eval/episode_x_position_std': Array(0.00580391, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04382185, dtype=float32), 'eval/episode_y_position_std': Array(0.00552886, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01137467, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680748462677002, 'eval/sps': 6189.331117827016, 'num_steps': 4234240}
{'eval/walltime': 17246.66985297203, 'training/sps': 127.28821259914427, 'training/walltime': 33407.4903318882, 'training/entropy_loss': Array(0.10395408, dtype=float32), 'training/policy_loss': Array(0.16289203, dtype=float32), 'training/total_loss': Array(0.2668461, dtype=float32), 'training/v_loss': Array(1.5613033e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0172255, dtype=float32), 'eval/episode_forward_reward': Array(-0.03794651, dtype=float32), 'eval/episode_reward': Array(-2.0513458, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03794651, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0200734, dtype=float32), 'eval/episode_train_reward': Array(-0.0011384, dtype=float32), 'eval/episode_x_position': Array(1.0153033, dtype=float32), 'eval/episode_x_velocity': Array(-0.03794651, dtype=float32), 'eval/episode_y_position': Array(2.1919579e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00078968, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0886657, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04359327, dtype=float32), 'eval/episode_reward_std': Array(0.17611714, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04359327, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26212454, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013078, dtype=float32), 'eval/episode_x_position_std': Array(0.08839807, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04359327, dtype=float32), 'eval/episode_y_position_std': Array(0.00580979, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01061352, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.73545002937317, 'eval/sps': 6173.003229670894, 'num_steps': 4239360}
{'eval/walltime': 17267.398309469223, 'training/sps': 127.04551855811356, 'training/walltime': 33447.79084825516, 'training/entropy_loss': Array(0.10659258, dtype=float32), 'training/policy_loss': Array(0.2619039, dtype=float32), 'training/total_loss': Array(0.3684965, dtype=float32), 'training/v_loss': Array(1.6743217e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093896, dtype=float32), 'eval/episode_forward_reward': Array(-0.03518847, dtype=float32), 'eval/episode_reward': Array(-2.0331948, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03518847, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969509, dtype=float32), 'eval/episode_train_reward': Array(-0.00105565, dtype=float32), 'eval/episode_x_position': Array(1.0074663, dtype=float32), 'eval/episode_x_velocity': Array(-0.03518847, dtype=float32), 'eval/episode_y_position': Array(0.00046492, dtype=float32), 'eval/episode_y_velocity': Array(0.00068373, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570263, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04354606, dtype=float32), 'eval/episode_reward_std': Array(0.04474282, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04354606, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01414972, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130638, dtype=float32), 'eval/episode_x_position_std': Array(0.00566389, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04354606, dtype=float32), 'eval/episode_y_position_std': Array(0.00602237, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01368866, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.728456497192383, 'eval/sps': 6175.085926795238, 'num_steps': 4244480}
{'eval/walltime': 17288.135284423828, 'training/sps': 127.32840878044182, 'training/walltime': 33488.00182747841, 'training/entropy_loss': Array(0.10695465, dtype=float32), 'training/policy_loss': Array(-0.00156003, dtype=float32), 'training/total_loss': Array(0.10539462, dtype=float32), 'training/v_loss': Array(5.072112e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091703, dtype=float32), 'eval/episode_forward_reward': Array(-0.04499638, dtype=float32), 'eval/episode_reward': Array(-2.0450077, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04499638, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986613, dtype=float32), 'eval/episode_train_reward': Array(-0.00134989, dtype=float32), 'eval/episode_x_position': Array(1.0073218, dtype=float32), 'eval/episode_x_velocity': Array(-0.04499638, dtype=float32), 'eval/episode_y_position': Array(0.00017543, dtype=float32), 'eval/episode_y_velocity': Array(-0.00030683, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557489, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04469254, dtype=float32), 'eval/episode_reward_std': Array(0.04757705, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04469254, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00978343, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134078, dtype=float32), 'eval/episode_x_position_std': Array(0.00560152, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04469254, dtype=float32), 'eval/episode_y_position_std': Array(0.00575604, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01263973, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.736974954605103, 'eval/sps': 6172.5492884185005, 'num_steps': 4249600}
{'eval/walltime': 17308.834795475006, 'training/sps': 127.3730339192316, 'training/walltime': 33528.19871878624, 'training/entropy_loss': Array(0.10900797, dtype=float32), 'training/policy_loss': Array(0.2626515, dtype=float32), 'training/total_loss': Array(0.37165946, dtype=float32), 'training/v_loss': Array(4.2018593e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098915, dtype=float32), 'eval/episode_forward_reward': Array(-0.03525599, dtype=float32), 'eval/episode_reward': Array(-2.0313342, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03525599, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9950204, dtype=float32), 'eval/episode_train_reward': Array(-0.00105768, dtype=float32), 'eval/episode_x_position': Array(1.0080031, dtype=float32), 'eval/episode_x_velocity': Array(-0.03525599, dtype=float32), 'eval/episode_y_position': Array(-0.00036627, dtype=float32), 'eval/episode_y_velocity': Array(-0.00109619, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00545581, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04222606, dtype=float32), 'eval/episode_reward_std': Array(0.04794529, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04222606, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01906143, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126678, dtype=float32), 'eval/episode_x_position_std': Array(0.00547028, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04222606, dtype=float32), 'eval/episode_y_position_std': Array(0.00565795, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01131928, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69951105117798, 'eval/sps': 6183.720943143519, 'num_steps': 4254720}
{'eval/walltime': 17329.604029655457, 'training/sps': 127.10133911616968, 'training/walltime': 33568.48153591156, 'training/entropy_loss': Array(0.1133996, dtype=float32), 'training/policy_loss': Array(0.2612137, dtype=float32), 'training/total_loss': Array(0.37461329, dtype=float32), 'training/v_loss': Array(5.9751114e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085995, dtype=float32), 'eval/episode_forward_reward': Array(-0.03890274, dtype=float32), 'eval/episode_reward': Array(-2.0399375, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03890274, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9998674, dtype=float32), 'eval/episode_train_reward': Array(-0.00116708, dtype=float32), 'eval/episode_x_position': Array(1.0067213, dtype=float32), 'eval/episode_x_velocity': Array(-0.03890274, dtype=float32), 'eval/episode_y_position': Array(0.0005099, dtype=float32), 'eval/episode_y_velocity': Array(0.00038368, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596287, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04391006, dtype=float32), 'eval/episode_reward_std': Array(0.04523366, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04391006, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00086159, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013173, dtype=float32), 'eval/episode_x_position_std': Array(0.00589334, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04391006, dtype=float32), 'eval/episode_y_position_std': Array(0.00613922, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01084031, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.76923418045044, 'eval/sps': 6162.961950733995, 'num_steps': 4259840}
{'eval/walltime': 17350.307941436768, 'training/sps': 127.28231059237407, 'training/walltime': 33608.70707845688, 'training/entropy_loss': Array(0.11451214, dtype=float32), 'training/policy_loss': Array(0.2700516, dtype=float32), 'training/total_loss': Array(0.38456374, dtype=float32), 'training/v_loss': Array(3.2089872e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167806, dtype=float32), 'eval/episode_forward_reward': Array(-0.03998758, dtype=float32), 'eval/episode_reward': Array(-2.0536556, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03998758, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0202808, dtype=float32), 'eval/episode_train_reward': Array(-0.00119963, dtype=float32), 'eval/episode_x_position': Array(1.0149109, dtype=float32), 'eval/episode_x_velocity': Array(-0.03998758, dtype=float32), 'eval/episode_y_position': Array(0.00013318, dtype=float32), 'eval/episode_y_velocity': Array(-0.0008065, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08746856, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04336086, dtype=float32), 'eval/episode_reward_std': Array(0.17835216, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04336086, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26485813, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130083, dtype=float32), 'eval/episode_x_position_std': Array(0.0871914, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04336086, dtype=float32), 'eval/episode_y_position_std': Array(0.00568827, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01479132, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.703911781311035, 'eval/sps': 6182.4065593026135, 'num_steps': 4264960}
{'eval/walltime': 17371.028745651245, 'training/sps': 127.27894526765128, 'training/walltime': 33648.93368458748, 'training/entropy_loss': Array(0.11296535, dtype=float32), 'training/policy_loss': Array(0.27127194, dtype=float32), 'training/total_loss': Array(0.3842373, dtype=float32), 'training/v_loss': Array(6.7551587e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.010241, dtype=float32), 'eval/episode_forward_reward': Array(-0.03719345, dtype=float32), 'eval/episode_reward': Array(-2.0350585, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03719345, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9967494, dtype=float32), 'eval/episode_train_reward': Array(-0.0011158, dtype=float32), 'eval/episode_x_position': Array(1.0083567, dtype=float32), 'eval/episode_x_velocity': Array(-0.03719345, dtype=float32), 'eval/episode_y_position': Array(-0.00058159, dtype=float32), 'eval/episode_y_velocity': Array(-0.00362484, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00592041, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04434549, dtype=float32), 'eval/episode_reward_std': Array(0.04716508, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04434549, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01477525, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133036, dtype=float32), 'eval/episode_x_position_std': Array(0.00592011, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04434549, dtype=float32), 'eval/episode_y_position_std': Array(0.00556796, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01532663, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72080421447754, 'eval/sps': 6177.366412765337, 'num_steps': 4270080}
{'eval/walltime': 17391.711397886276, 'training/sps': 127.44061982984378, 'training/walltime': 33689.109258174896, 'training/entropy_loss': Array(0.11162868, dtype=float32), 'training/policy_loss': Array(0.2701453, dtype=float32), 'training/total_loss': Array(0.38177398, dtype=float32), 'training/v_loss': Array(2.1066404e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097556, dtype=float32), 'eval/episode_forward_reward': Array(-0.03389758, dtype=float32), 'eval/episode_reward': Array(-2.0325208, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03389758, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976063, dtype=float32), 'eval/episode_train_reward': Array(-0.00101693, dtype=float32), 'eval/episode_x_position': Array(1.0078413, dtype=float32), 'eval/episode_x_velocity': Array(-0.03389758, dtype=float32), 'eval/episode_y_position': Array(-0.000895, dtype=float32), 'eval/episode_y_velocity': Array(-0.00184649, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614062, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04316281, dtype=float32), 'eval/episode_reward_std': Array(0.04738365, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04316281, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01254915, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129488, dtype=float32), 'eval/episode_x_position_std': Array(0.0061089, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04316281, dtype=float32), 'eval/episode_y_position_std': Array(0.00590603, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00826239, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.682652235031128, 'eval/sps': 6188.761409583666, 'num_steps': 4275200}
{'eval/walltime': 17412.410948753357, 'training/sps': 127.24599319906909, 'training/walltime': 33729.34628152847, 'training/entropy_loss': Array(0.11125153, dtype=float32), 'training/policy_loss': Array(0.26423442, dtype=float32), 'training/total_loss': Array(0.375486, dtype=float32), 'training/v_loss': Array(3.2228523e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009579, dtype=float32), 'eval/episode_forward_reward': Array(-0.04252039, dtype=float32), 'eval/episode_reward': Array(-2.042811, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04252039, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9990149, dtype=float32), 'eval/episode_train_reward': Array(-0.00127561, dtype=float32), 'eval/episode_x_position': Array(1.0077391, dtype=float32), 'eval/episode_x_velocity': Array(-0.04252039, dtype=float32), 'eval/episode_y_position': Array(-0.00079689, dtype=float32), 'eval/episode_y_velocity': Array(-0.00107909, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058053, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04210586, dtype=float32), 'eval/episode_reward_std': Array(0.04349981, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04210586, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00458398, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126318, dtype=float32), 'eval/episode_x_position_std': Array(0.00575782, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04210586, dtype=float32), 'eval/episode_y_position_std': Array(0.00546821, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01268441, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69955086708069, 'eval/sps': 6183.709048661701, 'num_steps': 4280320}
{'eval/walltime': 17433.070755004883, 'training/sps': 127.37550666551464, 'training/walltime': 33769.542392492294, 'training/entropy_loss': Array(0.11408655, dtype=float32), 'training/policy_loss': Array(0.26864034, dtype=float32), 'training/total_loss': Array(0.3827269, dtype=float32), 'training/v_loss': Array(2.8262457e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094045, dtype=float32), 'eval/episode_forward_reward': Array(-0.03918307, dtype=float32), 'eval/episode_reward': Array(-2.0376418, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03918307, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972835, dtype=float32), 'eval/episode_train_reward': Array(-0.00117549, dtype=float32), 'eval/episode_x_position': Array(1.0075235, dtype=float32), 'eval/episode_x_velocity': Array(-0.03918307, dtype=float32), 'eval/episode_y_position': Array(-0.00019942, dtype=float32), 'eval/episode_y_velocity': Array(-0.00148391, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058956, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04486821, dtype=float32), 'eval/episode_reward_std': Array(0.04936746, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04486821, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01605463, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134605, dtype=float32), 'eval/episode_x_position_std': Array(0.00587873, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04486821, dtype=float32), 'eval/episode_y_position_std': Array(0.00572809, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01320239, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65980625152588, 'eval/sps': 6195.605052711772, 'num_steps': 4285440}
{'eval/walltime': 17453.764880895615, 'training/sps': 127.323153759303, 'training/walltime': 33809.755031347275, 'training/entropy_loss': Array(0.11338905, dtype=float32), 'training/policy_loss': Array(0.26911438, dtype=float32), 'training/total_loss': Array(0.38250342, dtype=float32), 'training/v_loss': Array(7.348123e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097933, dtype=float32), 'eval/episode_forward_reward': Array(-0.03583799, dtype=float32), 'eval/episode_reward': Array(-2.034377, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03583799, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974642, dtype=float32), 'eval/episode_train_reward': Array(-0.00107514, dtype=float32), 'eval/episode_x_position': Array(1.007923, dtype=float32), 'eval/episode_x_velocity': Array(-0.03583799, dtype=float32), 'eval/episode_y_position': Array(0.00042908, dtype=float32), 'eval/episode_y_velocity': Array(-0.00030897, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00608342, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04274897, dtype=float32), 'eval/episode_reward_std': Array(0.04417292, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04274897, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01345172, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128247, dtype=float32), 'eval/episode_x_position_std': Array(0.00607703, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04274897, dtype=float32), 'eval/episode_y_position_std': Array(0.00579249, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01264158, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69412589073181, 'eval/sps': 6185.330111349463, 'num_steps': 4290560}
{'eval/walltime': 17474.413104772568, 'training/sps': 127.42672005872058, 'training/walltime': 33849.934987306595, 'training/entropy_loss': Array(0.1138422, dtype=float32), 'training/policy_loss': Array(0.2679268, dtype=float32), 'training/total_loss': Array(0.381769, dtype=float32), 'training/v_loss': Array(1.0903454e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085464, dtype=float32), 'eval/episode_forward_reward': Array(-0.03770623, dtype=float32), 'eval/episode_reward': Array(-2.0360436, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03770623, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972062, dtype=float32), 'eval/episode_train_reward': Array(-0.00113119, dtype=float32), 'eval/episode_x_position': Array(1.006648, dtype=float32), 'eval/episode_x_velocity': Array(-0.03770623, dtype=float32), 'eval/episode_y_position': Array(-0.0010417, dtype=float32), 'eval/episode_y_velocity': Array(0.00064056, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00523995, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04444433, dtype=float32), 'eval/episode_reward_std': Array(0.04849773, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04444433, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01257501, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133333, dtype=float32), 'eval/episode_x_position_std': Array(0.00521535, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04444433, dtype=float32), 'eval/episode_y_position_std': Array(0.00578473, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01035701, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.648223876953125, 'eval/sps': 6199.080403369194, 'num_steps': 4295680}
{'eval/walltime': 17495.096497297287, 'training/sps': 127.06741203272053, 'training/walltime': 33890.228559970856, 'training/entropy_loss': Array(0.11450357, dtype=float32), 'training/policy_loss': Array(0.26770777, dtype=float32), 'training/total_loss': Array(0.38221133, dtype=float32), 'training/v_loss': Array(6.1906924e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089619, dtype=float32), 'eval/episode_forward_reward': Array(-0.04009406, dtype=float32), 'eval/episode_reward': Array(-2.0394535, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04009406, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981565, dtype=float32), 'eval/episode_train_reward': Array(-0.00120282, dtype=float32), 'eval/episode_x_position': Array(1.0071301, dtype=float32), 'eval/episode_x_velocity': Array(-0.04009406, dtype=float32), 'eval/episode_y_position': Array(0.00041253, dtype=float32), 'eval/episode_y_velocity': Array(-3.0776137e-06, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589064, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04259371, dtype=float32), 'eval/episode_reward_std': Array(0.04546798, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04259371, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01098491, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127781, dtype=float32), 'eval/episode_x_position_std': Array(0.00590592, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04259371, dtype=float32), 'eval/episode_y_position_std': Array(0.00574661, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01585087, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68339252471924, 'eval/sps': 6188.539904516341, 'num_steps': 4300800}
{'eval/walltime': 17515.76263308525, 'training/sps': 126.93348495247196, 'training/walltime': 33930.56464624405, 'training/entropy_loss': Array(0.11449916, dtype=float32), 'training/policy_loss': Array(0.26995236, dtype=float32), 'training/total_loss': Array(0.38445154, dtype=float32), 'training/v_loss': Array(6.515596e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088124, dtype=float32), 'eval/episode_forward_reward': Array(-0.03825004, dtype=float32), 'eval/episode_reward': Array(-2.0365295, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03825004, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997132, dtype=float32), 'eval/episode_train_reward': Array(-0.0011475, dtype=float32), 'eval/episode_x_position': Array(1.0069313, dtype=float32), 'eval/episode_x_velocity': Array(-0.03825004, dtype=float32), 'eval/episode_y_position': Array(-0.00056267, dtype=float32), 'eval/episode_y_velocity': Array(-0.0005288, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00582841, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0422848, dtype=float32), 'eval/episode_reward_std': Array(0.04333081, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0422848, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01310382, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126854, dtype=float32), 'eval/episode_x_position_std': Array(0.00583997, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0422848, dtype=float32), 'eval/episode_y_position_std': Array(0.00569729, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01333917, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666135787963867, 'eval/sps': 6193.707489067612, 'num_steps': 4305920}
{'eval/walltime': 17536.436371088028, 'training/sps': 127.21033628964507, 'training/walltime': 33970.81294798851, 'training/entropy_loss': Array(0.11440672, dtype=float32), 'training/policy_loss': Array(0.26975814, dtype=float32), 'training/total_loss': Array(0.38416487, dtype=float32), 'training/v_loss': Array(2.6602212e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093974, dtype=float32), 'eval/episode_forward_reward': Array(-0.04631087, dtype=float32), 'eval/episode_reward': Array(-2.0433278, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04631087, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9956279, dtype=float32), 'eval/episode_train_reward': Array(-0.00138933, dtype=float32), 'eval/episode_x_position': Array(1.0075498, dtype=float32), 'eval/episode_x_velocity': Array(-0.04631087, dtype=float32), 'eval/episode_y_position': Array(9.734082e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00164518, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00564209, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04423702, dtype=float32), 'eval/episode_reward_std': Array(0.0482079, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04423702, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01631749, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132711, dtype=float32), 'eval/episode_x_position_std': Array(0.00562231, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04423702, dtype=float32), 'eval/episode_y_position_std': Array(0.00601992, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01159086, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6737380027771, 'eval/sps': 6191.429918614901, 'num_steps': 4311040}
{'eval/walltime': 17557.128489732742, 'training/sps': 127.41387939835319, 'training/walltime': 34010.99695324898, 'training/entropy_loss': Array(0.11371543, dtype=float32), 'training/policy_loss': Array(0.27218154, dtype=float32), 'training/total_loss': Array(0.38589698, dtype=float32), 'training/v_loss': Array(1.5220876e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090103, dtype=float32), 'eval/episode_forward_reward': Array(-0.0338615, dtype=float32), 'eval/episode_reward': Array(-2.0310826, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0338615, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9962053, dtype=float32), 'eval/episode_train_reward': Array(-0.00101584, dtype=float32), 'eval/episode_x_position': Array(1.0071231, dtype=float32), 'eval/episode_x_velocity': Array(-0.0338615, dtype=float32), 'eval/episode_y_position': Array(-0.00012571, dtype=float32), 'eval/episode_y_velocity': Array(-0.00073659, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561265, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04176338, dtype=float32), 'eval/episode_reward_std': Array(0.04599409, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04176338, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01563535, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012529, dtype=float32), 'eval/episode_x_position_std': Array(0.00566761, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04176338, dtype=float32), 'eval/episode_y_position_std': Array(0.00564218, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01783442, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.692118644714355, 'eval/sps': 6185.930121403814, 'num_steps': 4316160}
{'eval/walltime': 17577.840035438538, 'training/sps': 127.11108469363897, 'training/walltime': 34051.276681900024, 'training/entropy_loss': Array(0.11298158, dtype=float32), 'training/policy_loss': Array(0.26954007, dtype=float32), 'training/total_loss': Array(0.38252166, dtype=float32), 'training/v_loss': Array(9.827522e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093818, dtype=float32), 'eval/episode_forward_reward': Array(-0.03501944, dtype=float32), 'eval/episode_reward': Array(-2.033329, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03501944, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997259, dtype=float32), 'eval/episode_train_reward': Array(-0.00105058, dtype=float32), 'eval/episode_x_position': Array(1.0075082, dtype=float32), 'eval/episode_x_velocity': Array(-0.03501944, dtype=float32), 'eval/episode_y_position': Array(-0.00046713, dtype=float32), 'eval/episode_y_velocity': Array(-0.00102327, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00605264, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04331231, dtype=float32), 'eval/episode_reward_std': Array(0.04623676, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04331231, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01380879, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129937, dtype=float32), 'eval/episode_x_position_std': Array(0.00602532, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04331231, dtype=float32), 'eval/episode_y_position_std': Array(0.00577306, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01294387, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.711545705795288, 'eval/sps': 6180.127829097004, 'num_steps': 4321280}
{'eval/walltime': 17598.532711029053, 'training/sps': 127.34203037102384, 'training/walltime': 34091.48335981369, 'training/entropy_loss': Array(0.11286952, dtype=float32), 'training/policy_loss': Array(0.2710536, dtype=float32), 'training/total_loss': Array(0.3839231, dtype=float32), 'training/v_loss': Array(6.573624e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092336, dtype=float32), 'eval/episode_forward_reward': Array(-0.03485545, dtype=float32), 'eval/episode_reward': Array(-2.0320978, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03485545, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9961967, dtype=float32), 'eval/episode_train_reward': Array(-0.00104566, dtype=float32), 'eval/episode_x_position': Array(1.0073692, dtype=float32), 'eval/episode_x_velocity': Array(-0.03485545, dtype=float32), 'eval/episode_y_position': Array(-0.00033767, dtype=float32), 'eval/episode_y_velocity': Array(0.00078333, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579287, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0405021, dtype=float32), 'eval/episode_reward_std': Array(0.0459161, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0405021, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01660208, dtype=float32), 'eval/episode_train_reward_std': Array(0.00121506, dtype=float32), 'eval/episode_x_position_std': Array(0.00581872, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0405021, dtype=float32), 'eval/episode_y_position_std': Array(0.00570108, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01317508, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.692675590515137, 'eval/sps': 6185.763626365994, 'num_steps': 4326400}
{'eval/walltime': 17619.22144818306, 'training/sps': 127.18247291716712, 'training/walltime': 34131.74047923088, 'training/entropy_loss': Array(0.11142111, dtype=float32), 'training/policy_loss': Array(0.26909322, dtype=float32), 'training/total_loss': Array(0.3805143, dtype=float32), 'training/v_loss': Array(9.911971e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097814, dtype=float32), 'eval/episode_forward_reward': Array(-0.03256951, dtype=float32), 'eval/episode_reward': Array(-2.0305455, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03256951, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996999, dtype=float32), 'eval/episode_train_reward': Array(-0.00097709, dtype=float32), 'eval/episode_x_position': Array(1.0078386, dtype=float32), 'eval/episode_x_velocity': Array(-0.03256951, dtype=float32), 'eval/episode_y_position': Array(0.00052008, dtype=float32), 'eval/episode_y_velocity': Array(-0.00078483, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583658, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04245784, dtype=float32), 'eval/episode_reward_std': Array(0.04700739, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04245784, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01471144, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127374, dtype=float32), 'eval/episode_x_position_std': Array(0.00587965, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04245784, dtype=float32), 'eval/episode_y_position_std': Array(0.0058174, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01509232, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.688737154006958, 'eval/sps': 6186.94118675142, 'num_steps': 4331520}
{'eval/walltime': 17639.940663814545, 'training/sps': 127.03012457606442, 'training/walltime': 34172.045879364014, 'training/entropy_loss': Array(0.11268567, dtype=float32), 'training/policy_loss': Array(0.26621038, dtype=float32), 'training/total_loss': Array(0.378896, dtype=float32), 'training/v_loss': Array(3.8563036e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.00888, dtype=float32), 'eval/episode_forward_reward': Array(-0.03204891, dtype=float32), 'eval/episode_reward': Array(-2.028027, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03204891, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9950166, dtype=float32), 'eval/episode_train_reward': Array(-0.00096147, dtype=float32), 'eval/episode_x_position': Array(1.0069543, dtype=float32), 'eval/episode_x_velocity': Array(-0.03204891, dtype=float32), 'eval/episode_y_position': Array(-4.7795496e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00025922, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570554, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04077036, dtype=float32), 'eval/episode_reward_std': Array(0.04641058, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04077036, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01801786, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122311, dtype=float32), 'eval/episode_x_position_std': Array(0.00565636, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04077036, dtype=float32), 'eval/episode_y_position_std': Array(0.00550846, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01221583, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.719215631484985, 'eval/sps': 6177.8400435917465, 'num_steps': 4336640}
{'eval/walltime': 17660.63864994049, 'training/sps': 127.3382556580168, 'training/walltime': 34212.25374913216, 'training/entropy_loss': Array(0.11345575, dtype=float32), 'training/policy_loss': Array(0.26600134, dtype=float32), 'training/total_loss': Array(0.37945706, dtype=float32), 'training/v_loss': Array(7.004205e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097435, dtype=float32), 'eval/episode_forward_reward': Array(-0.03908218, dtype=float32), 'eval/episode_reward': Array(-2.0380616, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03908218, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997807, dtype=float32), 'eval/episode_train_reward': Array(-0.00117247, dtype=float32), 'eval/episode_x_position': Array(1.0078545, dtype=float32), 'eval/episode_x_velocity': Array(-0.03908218, dtype=float32), 'eval/episode_y_position': Array(0.00048804, dtype=float32), 'eval/episode_y_velocity': Array(4.6721776e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567259, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04466081, dtype=float32), 'eval/episode_reward_std': Array(0.05098657, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04466081, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01734184, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133982, dtype=float32), 'eval/episode_x_position_std': Array(0.00566453, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04466081, dtype=float32), 'eval/episode_y_position_std': Array(0.00604015, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01740708, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.697986125946045, 'eval/sps': 6184.176529113867, 'num_steps': 4341760}
{'eval/walltime': 17681.351689577103, 'training/sps': 127.24082263172097, 'training/walltime': 34252.49240756035, 'training/entropy_loss': Array(0.11475386, dtype=float32), 'training/policy_loss': Array(0.27222314, dtype=float32), 'training/total_loss': Array(0.38697702, dtype=float32), 'training/v_loss': Array(2.0786706e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090418, dtype=float32), 'eval/episode_forward_reward': Array(-0.03940535, dtype=float32), 'eval/episode_reward': Array(-2.0385888, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03940535, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998001, dtype=float32), 'eval/episode_train_reward': Array(-0.00118216, dtype=float32), 'eval/episode_x_position': Array(1.0072018, dtype=float32), 'eval/episode_x_velocity': Array(-0.03940535, dtype=float32), 'eval/episode_y_position': Array(-0.00021051, dtype=float32), 'eval/episode_y_velocity': Array(-0.00277056, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0061681, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04562169, dtype=float32), 'eval/episode_reward_std': Array(0.04937531, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04562169, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01123537, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136865, dtype=float32), 'eval/episode_x_position_std': Array(0.00611733, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04562169, dtype=float32), 'eval/episode_y_position_std': Array(0.00605536, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0172821, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71303963661194, 'eval/sps': 6179.682086532092, 'num_steps': 4346880}
{'eval/walltime': 17702.073959350586, 'training/sps': 126.89251271453455, 'training/walltime': 34292.84151792526, 'training/entropy_loss': Array(0.11132045, dtype=float32), 'training/policy_loss': Array(0.27077907, dtype=float32), 'training/total_loss': Array(0.38209957, dtype=float32), 'training/v_loss': Array(9.1743315e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0175518, dtype=float32), 'eval/episode_forward_reward': Array(-0.0444556, dtype=float32), 'eval/episode_reward': Array(-2.059861, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0444556, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.021884, dtype=float32), 'eval/episode_train_reward': Array(-0.00133367, dtype=float32), 'eval/episode_x_position': Array(1.0157025, dtype=float32), 'eval/episode_x_velocity': Array(-0.0444556, dtype=float32), 'eval/episode_y_position': Array(-0.00032778, dtype=float32), 'eval/episode_y_velocity': Array(-0.00069894, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08861353, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04368116, dtype=float32), 'eval/episode_reward_std': Array(0.17927311, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04368116, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2644164, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131043, dtype=float32), 'eval/episode_x_position_std': Array(0.08833403, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04368116, dtype=float32), 'eval/episode_y_position_std': Array(0.00622221, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01152061, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.722269773483276, 'eval/sps': 6176.929525538362, 'num_steps': 4352000}
{'eval/walltime': 17722.78572368622, 'training/sps': 127.29686931253559, 'training/walltime': 34333.06245994568, 'training/entropy_loss': Array(0.11273452, dtype=float32), 'training/policy_loss': Array(0.26098064, dtype=float32), 'training/total_loss': Array(0.37371513, dtype=float32), 'training/v_loss': Array(1.1830199e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091664, dtype=float32), 'eval/episode_forward_reward': Array(-0.03956507, dtype=float32), 'eval/episode_reward': Array(-2.0378773, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03956507, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971251, dtype=float32), 'eval/episode_train_reward': Array(-0.00118695, dtype=float32), 'eval/episode_x_position': Array(1.0073227, dtype=float32), 'eval/episode_x_velocity': Array(-0.03956507, dtype=float32), 'eval/episode_y_position': Array(-0.00064674, dtype=float32), 'eval/episode_y_velocity': Array(-0.00066772, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594446, dtype=float32), 'eval/episode_forward_reward_std': Array(0.041951, dtype=float32), 'eval/episode_reward_std': Array(0.04398772, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.041951, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01409846, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125853, dtype=float32), 'eval/episode_x_position_std': Array(0.00590667, dtype=float32), 'eval/episode_x_velocity_std': Array(0.041951, dtype=float32), 'eval/episode_y_position_std': Array(0.0059856, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01422762, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.711764335632324, 'eval/sps': 6180.062592726106, 'num_steps': 4357120}
{'eval/walltime': 17743.491072416306, 'training/sps': 127.02022161355758, 'training/walltime': 34373.371002435684, 'training/entropy_loss': Array(0.11587127, dtype=float32), 'training/policy_loss': Array(0.2709844, dtype=float32), 'training/total_loss': Array(0.38685566, dtype=float32), 'training/v_loss': Array(1.536033e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094665, dtype=float32), 'eval/episode_forward_reward': Array(-0.0410773, dtype=float32), 'eval/episode_reward': Array(-2.0369895, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0410773, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9946797, dtype=float32), 'eval/episode_train_reward': Array(-0.00123232, dtype=float32), 'eval/episode_x_position': Array(1.0076224, dtype=float32), 'eval/episode_x_velocity': Array(-0.0410773, dtype=float32), 'eval/episode_y_position': Array(-0.00028468, dtype=float32), 'eval/episode_y_velocity': Array(-2.6507041e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570741, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04356671, dtype=float32), 'eval/episode_reward_std': Array(0.04854061, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04356671, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0194728, dtype=float32), 'eval/episode_train_reward_std': Array(0.001307, dtype=float32), 'eval/episode_x_position_std': Array(0.00567948, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04356671, dtype=float32), 'eval/episode_y_position_std': Array(0.00544489, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01161521, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70534873008728, 'eval/sps': 6181.977501011665, 'num_steps': 4362240}
{'eval/walltime': 17764.212250471115, 'training/sps': 127.23626763315538, 'training/walltime': 34413.61110138893, 'training/entropy_loss': Array(0.11162326, dtype=float32), 'training/policy_loss': Array(0.27370977, dtype=float32), 'training/total_loss': Array(0.38533303, dtype=float32), 'training/v_loss': Array(8.104203e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092226, dtype=float32), 'eval/episode_forward_reward': Array(-0.04171836, dtype=float32), 'eval/episode_reward': Array(-2.04209, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04171836, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9991202, dtype=float32), 'eval/episode_train_reward': Array(-0.00125155, dtype=float32), 'eval/episode_x_position': Array(1.0073776, dtype=float32), 'eval/episode_x_velocity': Array(-0.04171836, dtype=float32), 'eval/episode_y_position': Array(-0.00032323, dtype=float32), 'eval/episode_y_velocity': Array(-0.00119184, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572167, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0436287, dtype=float32), 'eval/episode_reward_std': Array(0.04499687, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0436287, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0061176, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130886, dtype=float32), 'eval/episode_x_position_std': Array(0.00569941, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0436287, dtype=float32), 'eval/episode_y_position_std': Array(0.00592613, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01236636, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72117805480957, 'eval/sps': 6177.254964048247, 'num_steps': 4367360}
{'eval/walltime': 17784.92657184601, 'training/sps': 127.1786029654249, 'training/walltime': 34453.86944580078, 'training/entropy_loss': Array(0.11074514, dtype=float32), 'training/policy_loss': Array(0.2631538, dtype=float32), 'training/total_loss': Array(0.37389895, dtype=float32), 'training/v_loss': Array(1.4423375e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.00887, dtype=float32), 'eval/episode_forward_reward': Array(-0.04955428, dtype=float32), 'eval/episode_reward': Array(-2.05085, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04955428, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9998093, dtype=float32), 'eval/episode_train_reward': Array(-0.00148663, dtype=float32), 'eval/episode_x_position': Array(1.0070736, dtype=float32), 'eval/episode_x_velocity': Array(-0.04955428, dtype=float32), 'eval/episode_y_position': Array(-0.00011384, dtype=float32), 'eval/episode_y_velocity': Array(-0.00041084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00567116, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04339603, dtype=float32), 'eval/episode_reward_std': Array(0.04485298, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04339603, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00142505, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130188, dtype=float32), 'eval/episode_x_position_std': Array(0.0056525, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04339603, dtype=float32), 'eval/episode_y_position_std': Array(0.00566634, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01232022, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71432137489319, 'eval/sps': 6179.299706875385, 'num_steps': 4372480}
{'eval/walltime': 17805.642516851425, 'training/sps': 127.45369810774419, 'training/walltime': 34494.04089689255, 'training/entropy_loss': Array(0.11397976, dtype=float32), 'training/policy_loss': Array(0.26322314, dtype=float32), 'training/total_loss': Array(0.3772029, dtype=float32), 'training/v_loss': Array(7.1988215e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009268, dtype=float32), 'eval/episode_forward_reward': Array(-0.0386599, dtype=float32), 'eval/episode_reward': Array(-2.0345554, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0386599, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9947357, dtype=float32), 'eval/episode_train_reward': Array(-0.0011598, dtype=float32), 'eval/episode_x_position': Array(1.0073917, dtype=float32), 'eval/episode_x_velocity': Array(-0.0386599, dtype=float32), 'eval/episode_y_position': Array(-0.00030375, dtype=float32), 'eval/episode_y_velocity': Array(0.001331, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00562257, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04278615, dtype=float32), 'eval/episode_reward_std': Array(0.04576795, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04278615, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01893839, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128358, dtype=float32), 'eval/episode_x_position_std': Array(0.00569361, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04278615, dtype=float32), 'eval/episode_y_position_std': Array(0.00552139, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0103098, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71594500541687, 'eval/sps': 6178.815398792098, 'num_steps': 4377600}
{'eval/walltime': 17826.34938287735, 'training/sps': 127.08915736530683, 'training/walltime': 34534.32757520676, 'training/entropy_loss': Array(0.11615956, dtype=float32), 'training/policy_loss': Array(0.26938635, dtype=float32), 'training/total_loss': Array(0.3855459, dtype=float32), 'training/v_loss': Array(1.2780379e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089588, dtype=float32), 'eval/episode_forward_reward': Array(-0.03592569, dtype=float32), 'eval/episode_reward': Array(-2.0365016, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03592569, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9994984, dtype=float32), 'eval/episode_train_reward': Array(-0.00107777, dtype=float32), 'eval/episode_x_position': Array(1.0070319, dtype=float32), 'eval/episode_x_velocity': Array(-0.03592569, dtype=float32), 'eval/episode_y_position': Array(0.00038586, dtype=float32), 'eval/episode_y_velocity': Array(-0.00063937, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00542626, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0416428, dtype=float32), 'eval/episode_reward_std': Array(0.04284724, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0416428, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00288552, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124928, dtype=float32), 'eval/episode_x_position_std': Array(0.00544545, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0416428, dtype=float32), 'eval/episode_y_position_std': Array(0.00578173, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01019723, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.706866025924683, 'eval/sps': 6181.524516541805, 'num_steps': 4382720}
{'eval/walltime': 17847.01540827751, 'training/sps': 127.24784424067398, 'training/walltime': 34574.56401324272, 'training/entropy_loss': Array(0.11480775, dtype=float32), 'training/policy_loss': Array(0.2707097, dtype=float32), 'training/total_loss': Array(0.38551748, dtype=float32), 'training/v_loss': Array(9.631444e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093839, dtype=float32), 'eval/episode_forward_reward': Array(-0.03991462, dtype=float32), 'eval/episode_reward': Array(-2.0395951, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03991462, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984832, dtype=float32), 'eval/episode_train_reward': Array(-0.00119744, dtype=float32), 'eval/episode_x_position': Array(1.0075262, dtype=float32), 'eval/episode_x_velocity': Array(-0.03991462, dtype=float32), 'eval/episode_y_position': Array(-0.00030677, dtype=float32), 'eval/episode_y_velocity': Array(-0.00077232, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579643, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04353071, dtype=float32), 'eval/episode_reward_std': Array(0.04608603, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04353071, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00981951, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130592, dtype=float32), 'eval/episode_x_position_std': Array(0.00576163, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04353071, dtype=float32), 'eval/episode_y_position_std': Array(0.00556001, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01594584, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666025400161743, 'eval/sps': 6193.740572824332, 'num_steps': 4387840}
{'eval/walltime': 17867.735823392868, 'training/sps': 127.38515680953411, 'training/walltime': 34614.75707912445, 'training/entropy_loss': Array(0.11407249, dtype=float32), 'training/policy_loss': Array(0.27001873, dtype=float32), 'training/total_loss': Array(0.3840912, dtype=float32), 'training/v_loss': Array(1.13680516e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087217, dtype=float32), 'eval/episode_forward_reward': Array(-0.03534075, dtype=float32), 'eval/episode_reward': Array(-2.0339036, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03534075, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975028, dtype=float32), 'eval/episode_train_reward': Array(-0.00106022, dtype=float32), 'eval/episode_x_position': Array(1.0068307, dtype=float32), 'eval/episode_x_velocity': Array(-0.03534075, dtype=float32), 'eval/episode_y_position': Array(-0.00106632, dtype=float32), 'eval/episode_y_velocity': Array(-0.00196886, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559592, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0414841, dtype=float32), 'eval/episode_reward_std': Array(0.04361213, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0414841, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01362716, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124452, dtype=float32), 'eval/episode_x_position_std': Array(0.00555016, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0414841, dtype=float32), 'eval/episode_y_position_std': Array(0.00544227, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01180608, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.720415115356445, 'eval/sps': 6177.482414680767, 'num_steps': 4392960}
{'eval/walltime': 17888.40688109398, 'training/sps': 127.30612491533337, 'training/walltime': 34654.975096940994, 'training/entropy_loss': Array(0.11329694, dtype=float32), 'training/policy_loss': Array(0.2706942, dtype=float32), 'training/total_loss': Array(0.38399112, dtype=float32), 'training/v_loss': Array(3.2183707e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093002, dtype=float32), 'eval/episode_forward_reward': Array(-0.04251899, dtype=float32), 'eval/episode_reward': Array(-2.0404422, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04251899, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966476, dtype=float32), 'eval/episode_train_reward': Array(-0.00127557, dtype=float32), 'eval/episode_x_position': Array(1.0074027, dtype=float32), 'eval/episode_x_velocity': Array(-0.04251899, dtype=float32), 'eval/episode_y_position': Array(0.00070372, dtype=float32), 'eval/episode_y_velocity': Array(-0.002454, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00559266, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04614299, dtype=float32), 'eval/episode_reward_std': Array(0.04817102, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04614299, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01490848, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138429, dtype=float32), 'eval/episode_x_position_std': Array(0.00556213, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04614299, dtype=float32), 'eval/episode_y_position_std': Array(0.00604174, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01071239, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67105770111084, 'eval/sps': 6192.232727071408, 'num_steps': 4398080}
{'eval/walltime': 17909.120027303696, 'training/sps': 127.14540622784078, 'training/walltime': 34695.24395251274, 'training/entropy_loss': Array(0.11278007, dtype=float32), 'training/policy_loss': Array(0.2692856, dtype=float32), 'training/total_loss': Array(0.38206565, dtype=float32), 'training/v_loss': Array(7.274477e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094231, dtype=float32), 'eval/episode_forward_reward': Array(-0.04428323, dtype=float32), 'eval/episode_reward': Array(-2.0431232, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04428323, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9975114, dtype=float32), 'eval/episode_train_reward': Array(-0.0013285, dtype=float32), 'eval/episode_x_position': Array(1.0075756, dtype=float32), 'eval/episode_x_velocity': Array(-0.04428323, dtype=float32), 'eval/episode_y_position': Array(0.00050216, dtype=float32), 'eval/episode_y_velocity': Array(-0.00229468, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588812, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04476467, dtype=float32), 'eval/episode_reward_std': Array(0.04696829, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04476467, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01352344, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134294, dtype=float32), 'eval/episode_x_position_std': Array(0.00584134, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04476467, dtype=float32), 'eval/episode_y_position_std': Array(0.00563289, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01673042, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.713146209716797, 'eval/sps': 6179.6502908840375, 'num_steps': 4403200}
{'eval/walltime': 17929.81696343422, 'training/sps': 127.27603573670407, 'training/walltime': 34735.4714782238, 'training/entropy_loss': Array(0.11167873, dtype=float32), 'training/policy_loss': Array(0.2690844, dtype=float32), 'training/total_loss': Array(0.3807631, dtype=float32), 'training/v_loss': Array(7.000881e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095097, dtype=float32), 'eval/episode_forward_reward': Array(-0.03718305, dtype=float32), 'eval/episode_reward': Array(-2.0364156, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03718305, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998117, dtype=float32), 'eval/episode_train_reward': Array(-0.00111549, dtype=float32), 'eval/episode_x_position': Array(1.0076258, dtype=float32), 'eval/episode_x_velocity': Array(-0.03718305, dtype=float32), 'eval/episode_y_position': Array(-0.00043248, dtype=float32), 'eval/episode_y_velocity': Array(-0.00115541, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00553302, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04372519, dtype=float32), 'eval/episode_reward_std': Array(0.04726693, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04372519, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01126355, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131176, dtype=float32), 'eval/episode_x_position_std': Array(0.00552903, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04372519, dtype=float32), 'eval/episode_y_position_std': Array(0.00576852, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00933117, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69693613052368, 'eval/sps': 6184.490264296975, 'num_steps': 4408320}
{'eval/walltime': 17950.518003940582, 'training/sps': 127.2676277362904, 'training/walltime': 34775.70166158676, 'training/entropy_loss': Array(0.11248378, dtype=float32), 'training/policy_loss': Array(0.2679634, dtype=float32), 'training/total_loss': Array(0.3804472, dtype=float32), 'training/v_loss': Array(2.1466224e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017981, dtype=float32), 'eval/episode_forward_reward': Array(-0.04966712, dtype=float32), 'eval/episode_reward': Array(-2.0629208, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04966712, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0195763, dtype=float32), 'eval/episode_train_reward': Array(-0.00149001, dtype=float32), 'eval/episode_x_position': Array(1.0161054, dtype=float32), 'eval/episode_x_velocity': Array(-0.04966712, dtype=float32), 'eval/episode_y_position': Array(0.00016676, dtype=float32), 'eval/episode_y_velocity': Array(-0.00222828, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08814668, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04784355, dtype=float32), 'eval/episode_reward_std': Array(0.18080625, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04784355, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.265097, dtype=float32), 'eval/episode_train_reward_std': Array(0.00143531, dtype=float32), 'eval/episode_x_position_std': Array(0.08787201, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04784355, dtype=float32), 'eval/episode_y_position_std': Array(0.00565659, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0120158, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.701040506362915, 'eval/sps': 6183.264071226585, 'num_steps': 4413440}
{'eval/walltime': 17971.22768354416, 'training/sps': 127.3737848744961, 'training/walltime': 34815.898315906525, 'training/entropy_loss': Array(0.11204468, dtype=float32), 'training/policy_loss': Array(0.26550132, dtype=float32), 'training/total_loss': Array(0.377546, dtype=float32), 'training/v_loss': Array(5.0224505e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0084825, dtype=float32), 'eval/episode_forward_reward': Array(-0.03503441, dtype=float32), 'eval/episode_reward': Array(-2.033918, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03503441, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978323, dtype=float32), 'eval/episode_train_reward': Array(-0.00105103, dtype=float32), 'eval/episode_x_position': Array(1.0066118, dtype=float32), 'eval/episode_x_velocity': Array(-0.03503441, dtype=float32), 'eval/episode_y_position': Array(-0.00091258, dtype=float32), 'eval/episode_y_velocity': Array(-0.00181039, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00535486, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04354541, dtype=float32), 'eval/episode_reward_std': Array(0.0475597, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04354541, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01068857, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130636, dtype=float32), 'eval/episode_x_position_std': Array(0.0053975, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04354541, dtype=float32), 'eval/episode_y_position_std': Array(0.00562658, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01211513, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70967960357666, 'eval/sps': 6180.684706386949, 'num_steps': 4418560}
{'eval/walltime': 17991.909996509552, 'training/sps': 127.26940021057483, 'training/walltime': 34856.127938985825, 'training/entropy_loss': Array(0.1144108, dtype=float32), 'training/policy_loss': Array(0.27081156, dtype=float32), 'training/total_loss': Array(0.38522238, dtype=float32), 'training/v_loss': Array(1.7331207e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097427, dtype=float32), 'eval/episode_forward_reward': Array(-0.03801736, dtype=float32), 'eval/episode_reward': Array(-2.0376544, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03801736, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984965, dtype=float32), 'eval/episode_train_reward': Array(-0.00114052, dtype=float32), 'eval/episode_x_position': Array(1.0078467, dtype=float32), 'eval/episode_x_velocity': Array(-0.03801736, dtype=float32), 'eval/episode_y_position': Array(0.00022753, dtype=float32), 'eval/episode_y_velocity': Array(-0.00206528, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00575995, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04138809, dtype=float32), 'eval/episode_reward_std': Array(0.0440364, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04138809, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00966548, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124164, dtype=float32), 'eval/episode_x_position_std': Array(0.00575615, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04138809, dtype=float32), 'eval/episode_y_position_std': Array(0.00578568, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00949506, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.682312965393066, 'eval/sps': 6188.862929121011, 'num_steps': 4423680}
{'eval/walltime': 18012.56399178505, 'training/sps': 127.53825315579256, 'training/walltime': 34896.272757291794, 'training/entropy_loss': Array(0.11227275, dtype=float32), 'training/policy_loss': Array(0.2707067, dtype=float32), 'training/total_loss': Array(0.38297945, dtype=float32), 'training/v_loss': Array(2.0474414e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090673, dtype=float32), 'eval/episode_forward_reward': Array(-0.03898222, dtype=float32), 'eval/episode_reward': Array(-2.0393672, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03898222, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9992156, dtype=float32), 'eval/episode_train_reward': Array(-0.00116947, dtype=float32), 'eval/episode_x_position': Array(1.0071906, dtype=float32), 'eval/episode_x_velocity': Array(-0.03898222, dtype=float32), 'eval/episode_y_position': Array(0.00019278, dtype=float32), 'eval/episode_y_velocity': Array(-0.00201739, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588639, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04345936, dtype=float32), 'eval/episode_reward_std': Array(0.04463443, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04345936, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00634491, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130378, dtype=float32), 'eval/episode_x_position_std': Array(0.00587242, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04345936, dtype=float32), 'eval/episode_y_position_std': Array(0.00603691, dtype=float32), 'eval/episode_y_velocity_std': Array(0.015431, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.653995275497437, 'eval/sps': 6197.348178531392, 'num_steps': 4428800}
{'eval/walltime': 18033.233225107193, 'training/sps': 127.3223860386155, 'training/walltime': 34936.48563861847, 'training/entropy_loss': Array(0.11306101, dtype=float32), 'training/policy_loss': Array(0.2699291, dtype=float32), 'training/total_loss': Array(0.38299012, dtype=float32), 'training/v_loss': Array(2.618491e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089911, dtype=float32), 'eval/episode_forward_reward': Array(-0.03689233, dtype=float32), 'eval/episode_reward': Array(-2.0362785, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03689233, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982793, dtype=float32), 'eval/episode_train_reward': Array(-0.00110677, dtype=float32), 'eval/episode_x_position': Array(1.0071123, dtype=float32), 'eval/episode_x_velocity': Array(-0.03689233, dtype=float32), 'eval/episode_y_position': Array(-0.00013776, dtype=float32), 'eval/episode_y_velocity': Array(-0.00227878, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00601711, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04199602, dtype=float32), 'eval/episode_reward_std': Array(0.04494852, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04199602, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00896975, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125988, dtype=float32), 'eval/episode_x_position_std': Array(0.00596413, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04199602, dtype=float32), 'eval/episode_y_position_std': Array(0.00571378, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00923705, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.669233322143555, 'eval/sps': 6192.779287215741, 'num_steps': 4433920}
{'eval/walltime': 18053.91673231125, 'training/sps': 127.42392322953673, 'training/walltime': 34976.66647648811, 'training/entropy_loss': Array(0.11336227, dtype=float32), 'training/policy_loss': Array(0.27124715, dtype=float32), 'training/total_loss': Array(0.38460943, dtype=float32), 'training/v_loss': Array(1.2330608e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0103481, dtype=float32), 'eval/episode_forward_reward': Array(-0.04215034, dtype=float32), 'eval/episode_reward': Array(-2.0405385, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04215034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9971237, dtype=float32), 'eval/episode_train_reward': Array(-0.00126451, dtype=float32), 'eval/episode_x_position': Array(1.0084814, dtype=float32), 'eval/episode_x_velocity': Array(-0.04215034, dtype=float32), 'eval/episode_y_position': Array(-9.999858e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00093543, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00556248, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04548354, dtype=float32), 'eval/episode_reward_std': Array(0.05127868, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04548354, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01435918, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136451, dtype=float32), 'eval/episode_x_position_std': Array(0.0055763, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04548354, dtype=float32), 'eval/episode_y_position_std': Array(0.00622214, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01016138, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.683507204055786, 'eval/sps': 6188.505592267289, 'num_steps': 4439040}
{'eval/walltime': 18074.596796035767, 'training/sps': 127.13242049172602, 'training/walltime': 35016.93944525719, 'training/entropy_loss': Array(0.11197522, dtype=float32), 'training/policy_loss': Array(0.27260068, dtype=float32), 'training/total_loss': Array(0.38457593, dtype=float32), 'training/v_loss': Array(1.5228427e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091226, dtype=float32), 'eval/episode_forward_reward': Array(-0.030252, dtype=float32), 'eval/episode_reward': Array(-2.0272567, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.030252, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996097, dtype=float32), 'eval/episode_train_reward': Array(-0.00090756, dtype=float32), 'eval/episode_x_position': Array(1.0071939, dtype=float32), 'eval/episode_x_velocity': Array(-0.030252, dtype=float32), 'eval/episode_y_position': Array(0.00027929, dtype=float32), 'eval/episode_y_velocity': Array(-0.00140684, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602114, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04009362, dtype=float32), 'eval/episode_reward_std': Array(0.04392591, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04009362, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01596126, dtype=float32), 'eval/episode_train_reward_std': Array(0.00120281, dtype=float32), 'eval/episode_x_position_std': Array(0.00605693, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04009362, dtype=float32), 'eval/episode_y_position_std': Array(0.00606552, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01096752, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680063724517822, 'eval/sps': 6189.536052940014, 'num_steps': 4444160}
{'eval/walltime': 18095.24457359314, 'training/sps': 127.51183819122697, 'training/walltime': 35057.092579841614, 'training/entropy_loss': Array(0.11105666, dtype=float32), 'training/policy_loss': Array(0.27147704, dtype=float32), 'training/total_loss': Array(0.38253373, dtype=float32), 'training/v_loss': Array(4.633508e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087929, dtype=float32), 'eval/episode_forward_reward': Array(-0.04179776, dtype=float32), 'eval/episode_reward': Array(-2.041736, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04179776, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998684, dtype=float32), 'eval/episode_train_reward': Array(-0.00125393, dtype=float32), 'eval/episode_x_position': Array(1.006884, dtype=float32), 'eval/episode_x_velocity': Array(-0.04179776, dtype=float32), 'eval/episode_y_position': Array(-0.00035236, dtype=float32), 'eval/episode_y_velocity': Array(-0.00171926, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00553834, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04408832, dtype=float32), 'eval/episode_reward_std': Array(0.04556623, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04408832, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00819005, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132265, dtype=float32), 'eval/episode_x_position_std': Array(0.00556307, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04408832, dtype=float32), 'eval/episode_y_position_std': Array(0.00588012, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01005468, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647777557373047, 'eval/sps': 6199.214401856673, 'num_steps': 4449280}
{'eval/walltime': 18115.954320430756, 'training/sps': 127.5470507280251, 'training/walltime': 35097.234629154205, 'training/entropy_loss': Array(0.109217, dtype=float32), 'training/policy_loss': Array(0.26646683, dtype=float32), 'training/total_loss': Array(0.37568384, dtype=float32), 'training/v_loss': Array(1.06967976e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087519, dtype=float32), 'eval/episode_forward_reward': Array(-0.03874193, dtype=float32), 'eval/episode_reward': Array(-2.0384994, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03874193, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998595, dtype=float32), 'eval/episode_train_reward': Array(-0.00116226, dtype=float32), 'eval/episode_x_position': Array(1.006882, dtype=float32), 'eval/episode_x_velocity': Array(-0.03874193, dtype=float32), 'eval/episode_y_position': Array(-2.2827153e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00151865, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00521648, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04278576, dtype=float32), 'eval/episode_reward_std': Array(0.04562495, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04278576, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00707924, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128357, dtype=float32), 'eval/episode_x_position_std': Array(0.00524874, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04278576, dtype=float32), 'eval/episode_y_position_std': Array(0.00577192, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01154722, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.709746837615967, 'eval/sps': 6180.664640839951, 'num_steps': 4454400}
{'eval/walltime': 18136.626857995987, 'training/sps': 127.31847963870612, 'training/walltime': 35137.44874429703, 'training/entropy_loss': Array(0.11280954, dtype=float32), 'training/policy_loss': Array(0.26694244, dtype=float32), 'training/total_loss': Array(0.37975198, dtype=float32), 'training/v_loss': Array(3.7570764e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098755, dtype=float32), 'eval/episode_forward_reward': Array(-0.03796452, dtype=float32), 'eval/episode_reward': Array(-2.0368323, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03796452, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977286, dtype=float32), 'eval/episode_train_reward': Array(-0.00113894, dtype=float32), 'eval/episode_x_position': Array(1.0079658, dtype=float32), 'eval/episode_x_velocity': Array(-0.03796452, dtype=float32), 'eval/episode_y_position': Array(0.00024666, dtype=float32), 'eval/episode_y_velocity': Array(0.00137462, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581134, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04442611, dtype=float32), 'eval/episode_reward_std': Array(0.04781419, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04442611, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01181935, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133278, dtype=float32), 'eval/episode_x_position_std': Array(0.00587805, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04442611, dtype=float32), 'eval/episode_y_position_std': Array(0.00583915, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01452277, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672537565231323, 'eval/sps': 6191.789449945435, 'num_steps': 4459520}
{'eval/walltime': 18157.32150197029, 'training/sps': 127.50914513240004, 'training/walltime': 35177.60272693634, 'training/entropy_loss': Array(0.11326155, dtype=float32), 'training/policy_loss': Array(0.27202332, dtype=float32), 'training/total_loss': Array(0.3852849, dtype=float32), 'training/v_loss': Array(4.8281847e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091614, dtype=float32), 'eval/episode_forward_reward': Array(-0.03687463, dtype=float32), 'eval/episode_reward': Array(-2.0345247, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03687463, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965436, dtype=float32), 'eval/episode_train_reward': Array(-0.00110624, dtype=float32), 'eval/episode_x_position': Array(1.0072961, dtype=float32), 'eval/episode_x_velocity': Array(-0.03687463, dtype=float32), 'eval/episode_y_position': Array(0.00065725, dtype=float32), 'eval/episode_y_velocity': Array(-0.0018223, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602056, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04291021, dtype=float32), 'eval/episode_reward_std': Array(0.04808454, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04291021, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01649266, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128731, dtype=float32), 'eval/episode_x_position_std': Array(0.00600493, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04291021, dtype=float32), 'eval/episode_y_position_std': Array(0.00563745, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01393968, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6946439743042, 'eval/sps': 6185.175263654356, 'num_steps': 4464640}
{'eval/walltime': 18178.056673765182, 'training/sps': 127.5805242566346, 'training/walltime': 35217.7342441082, 'training/entropy_loss': Array(0.11108951, dtype=float32), 'training/policy_loss': Array(0.26980388, dtype=float32), 'training/total_loss': Array(0.3808934, dtype=float32), 'training/v_loss': Array(6.338169e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087936, dtype=float32), 'eval/episode_forward_reward': Array(-0.04329401, dtype=float32), 'eval/episode_reward': Array(-2.0400784, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04329401, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9954853, dtype=float32), 'eval/episode_train_reward': Array(-0.00129882, dtype=float32), 'eval/episode_x_position': Array(1.0069575, dtype=float32), 'eval/episode_x_velocity': Array(-0.04329401, dtype=float32), 'eval/episode_y_position': Array(-0.00037202, dtype=float32), 'eval/episode_y_velocity': Array(-0.00203104, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580416, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04317122, dtype=float32), 'eval/episode_reward_std': Array(0.04743535, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04317122, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0199053, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129514, dtype=float32), 'eval/episode_x_position_std': Array(0.00578213, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04317122, dtype=float32), 'eval/episode_y_position_std': Array(0.00583108, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01440716, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.735171794891357, 'eval/sps': 6173.086061989421, 'num_steps': 4469760}
{'eval/walltime': 18198.78927707672, 'training/sps': 127.20979071819, 'training/walltime': 35257.98271846771, 'training/entropy_loss': Array(0.11021021, dtype=float32), 'training/policy_loss': Array(0.2683633, dtype=float32), 'training/total_loss': Array(0.37857348, dtype=float32), 'training/v_loss': Array(5.0082155e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0165839, dtype=float32), 'eval/episode_forward_reward': Array(-0.04061793, dtype=float32), 'eval/episode_reward': Array(-2.0544043, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04061793, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0203803, dtype=float32), 'eval/episode_train_reward': Array(-0.00121854, dtype=float32), 'eval/episode_x_position': Array(1.0146837, dtype=float32), 'eval/episode_x_velocity': Array(-0.04061793, dtype=float32), 'eval/episode_y_position': Array(0.00047015, dtype=float32), 'eval/episode_y_velocity': Array(0.00013983, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09012703, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04574827, dtype=float32), 'eval/episode_reward_std': Array(0.18049622, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04574827, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2647948, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137245, dtype=float32), 'eval/episode_x_position_std': Array(0.0898602, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04574827, dtype=float32), 'eval/episode_y_position_std': Array(0.00569139, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01285813, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.732603311538696, 'eval/sps': 6173.850822137797, 'num_steps': 4474880}
{'eval/walltime': 18219.493028640747, 'training/sps': 127.21587817428025, 'training/walltime': 35298.22926688194, 'training/entropy_loss': Array(0.11015346, dtype=float32), 'training/policy_loss': Array(0.2679744, dtype=float32), 'training/total_loss': Array(0.37812787, dtype=float32), 'training/v_loss': Array(1.6677104e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093913, dtype=float32), 'eval/episode_forward_reward': Array(-0.03751329, dtype=float32), 'eval/episode_reward': Array(-2.0373254, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03751329, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986868, dtype=float32), 'eval/episode_train_reward': Array(-0.0011254, dtype=float32), 'eval/episode_x_position': Array(1.0074911, dtype=float32), 'eval/episode_x_velocity': Array(-0.03751329, dtype=float32), 'eval/episode_y_position': Array(0.00038489, dtype=float32), 'eval/episode_y_velocity': Array(-0.0007514, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00626275, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04384228, dtype=float32), 'eval/episode_reward_std': Array(0.04604362, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04384228, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00900644, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131527, dtype=float32), 'eval/episode_x_position_std': Array(0.00628126, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04384228, dtype=float32), 'eval/episode_y_position_std': Array(0.00576137, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01455173, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70375156402588, 'eval/sps': 6182.454402245067, 'num_steps': 4480000}
{'eval/walltime': 18240.225773334503, 'training/sps': 127.12589023801351, 'training/walltime': 35338.50430440903, 'training/entropy_loss': Array(0.11401325, dtype=float32), 'training/policy_loss': Array(0.26612967, dtype=float32), 'training/total_loss': Array(0.38014293, dtype=float32), 'training/v_loss': Array(2.2046271e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093452, dtype=float32), 'eval/episode_forward_reward': Array(-0.03891198, dtype=float32), 'eval/episode_reward': Array(-2.036588, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03891198, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965086, dtype=float32), 'eval/episode_train_reward': Array(-0.00116736, dtype=float32), 'eval/episode_x_position': Array(1.0074904, dtype=float32), 'eval/episode_x_velocity': Array(-0.03891198, dtype=float32), 'eval/episode_y_position': Array(0.00072814, dtype=float32), 'eval/episode_y_velocity': Array(0.00013904, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0058884, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04167578, dtype=float32), 'eval/episode_reward_std': Array(0.04712354, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04167578, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01644663, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125027, dtype=float32), 'eval/episode_x_position_std': Array(0.00595997, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04167578, dtype=float32), 'eval/episode_y_position_std': Array(0.00576835, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01303041, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.732744693756104, 'eval/sps': 6173.808720972126, 'num_steps': 4485120}
{'eval/walltime': 18260.907015562057, 'training/sps': 127.26997570965123, 'training/walltime': 35378.73374557495, 'training/entropy_loss': Array(0.11390822, dtype=float32), 'training/policy_loss': Array(0.27080715, dtype=float32), 'training/total_loss': Array(0.38471535, dtype=float32), 'training/v_loss': Array(2.6646775e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167482, dtype=float32), 'eval/episode_forward_reward': Array(-0.03976678, dtype=float32), 'eval/episode_reward': Array(-2.0525708, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03976678, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.019424, dtype=float32), 'eval/episode_train_reward': Array(-0.001193, dtype=float32), 'eval/episode_x_position': Array(1.0148067, dtype=float32), 'eval/episode_x_velocity': Array(-0.03976678, dtype=float32), 'eval/episode_y_position': Array(-0.00066111, dtype=float32), 'eval/episode_y_velocity': Array(0.00085854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08845566, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04361474, dtype=float32), 'eval/episode_reward_std': Array(0.18027414, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04361474, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26502258, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130844, dtype=float32), 'eval/episode_x_position_std': Array(0.08819114, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04361474, dtype=float32), 'eval/episode_y_position_std': Array(0.0060065, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01499085, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.68124222755432, 'eval/sps': 6189.183347480996, 'num_steps': 4490240}
{'eval/walltime': 18281.59334039688, 'training/sps': 127.47206638375508, 'training/walltime': 35418.899408102036, 'training/entropy_loss': Array(0.11385782, dtype=float32), 'training/policy_loss': Array(0.27114624, dtype=float32), 'training/total_loss': Array(0.38500404, dtype=float32), 'training/v_loss': Array(9.288298e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092232, dtype=float32), 'eval/episode_forward_reward': Array(-0.03458288, dtype=float32), 'eval/episode_reward': Array(-2.0351562, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03458288, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.999536, dtype=float32), 'eval/episode_train_reward': Array(-0.00103749, dtype=float32), 'eval/episode_x_position': Array(1.0073264, dtype=float32), 'eval/episode_x_velocity': Array(-0.03458288, dtype=float32), 'eval/episode_y_position': Array(-0.00040284, dtype=float32), 'eval/episode_y_velocity': Array(0.00050543, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581787, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04157663, dtype=float32), 'eval/episode_reward_std': Array(0.04315326, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04157663, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00410324, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012473, dtype=float32), 'eval/episode_x_position_std': Array(0.00577863, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04157663, dtype=float32), 'eval/episode_y_position_std': Array(0.00594828, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01039021, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68632483482361, 'eval/sps': 6187.662671936934, 'num_steps': 4495360}
{'eval/walltime': 18302.314331531525, 'training/sps': 127.26674453455546, 'training/walltime': 35459.12987065315, 'training/entropy_loss': Array(0.11341414, dtype=float32), 'training/policy_loss': Array(0.27020386, dtype=float32), 'training/total_loss': Array(0.383618, dtype=float32), 'training/v_loss': Array(2.4199793e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089048, dtype=float32), 'eval/episode_forward_reward': Array(-0.03929731, dtype=float32), 'eval/episode_reward': Array(-2.0381703, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03929731, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997694, dtype=float32), 'eval/episode_train_reward': Array(-0.00117892, dtype=float32), 'eval/episode_x_position': Array(1.0070672, dtype=float32), 'eval/episode_x_velocity': Array(-0.03929731, dtype=float32), 'eval/episode_y_position': Array(6.356546e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00065857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574514, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04363179, dtype=float32), 'eval/episode_reward_std': Array(0.04716052, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04363179, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01329849, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130895, dtype=float32), 'eval/episode_x_position_std': Array(0.00569996, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04363179, dtype=float32), 'eval/episode_y_position_std': Array(0.0054309, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01196555, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.720991134643555, 'eval/sps': 6177.3106879041125, 'num_steps': 4500480}
{'eval/walltime': 18323.034453630447, 'training/sps': 127.07327457617619, 'training/walltime': 35499.42158436775, 'training/entropy_loss': Array(0.11039462, dtype=float32), 'training/policy_loss': Array(0.2709454, dtype=float32), 'training/total_loss': Array(0.38134003, dtype=float32), 'training/v_loss': Array(4.0356447e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090714, dtype=float32), 'eval/episode_forward_reward': Array(-0.04169384, dtype=float32), 'eval/episode_reward': Array(-2.04076, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04169384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978151, dtype=float32), 'eval/episode_train_reward': Array(-0.00125082, dtype=float32), 'eval/episode_x_position': Array(1.0072005, dtype=float32), 'eval/episode_x_velocity': Array(-0.04169384, dtype=float32), 'eval/episode_y_position': Array(-2.6839385e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00058869, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00598794, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04466763, dtype=float32), 'eval/episode_reward_std': Array(0.04715502, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04466763, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01124814, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134003, dtype=float32), 'eval/episode_x_position_std': Array(0.00593993, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04466763, dtype=float32), 'eval/episode_y_position_std': Array(0.00556195, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01403192, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72012209892273, 'eval/sps': 6177.569774391191, 'num_steps': 4505600}
{'eval/walltime': 18343.751358747482, 'training/sps': 127.05514281926226, 'training/walltime': 35539.719048023224, 'training/entropy_loss': Array(0.11012801, dtype=float32), 'training/policy_loss': Array(0.26775706, dtype=float32), 'training/total_loss': Array(0.3778851, dtype=float32), 'training/v_loss': Array(2.7660376e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092654, dtype=float32), 'eval/episode_forward_reward': Array(-0.03786199, dtype=float32), 'eval/episode_reward': Array(-2.0366626, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03786199, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997665, dtype=float32), 'eval/episode_train_reward': Array(-0.00113586, dtype=float32), 'eval/episode_x_position': Array(1.007386, dtype=float32), 'eval/episode_x_velocity': Array(-0.03786199, dtype=float32), 'eval/episode_y_position': Array(0.0001335, dtype=float32), 'eval/episode_y_velocity': Array(-0.00204961, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00595507, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04202593, dtype=float32), 'eval/episode_reward_std': Array(0.045284, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04202593, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01274785, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126078, dtype=float32), 'eval/episode_x_position_std': Array(0.00597537, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04202593, dtype=float32), 'eval/episode_y_position_std': Array(0.00580409, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01295268, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.716905117034912, 'eval/sps': 6178.52904557396, 'num_steps': 4510720}
{'eval/walltime': 18364.469841957092, 'training/sps': 127.1428121805198, 'training/walltime': 35579.988725185394, 'training/entropy_loss': Array(0.11389501, dtype=float32), 'training/policy_loss': Array(0.26630655, dtype=float32), 'training/total_loss': Array(0.38020158, dtype=float32), 'training/v_loss': Array(2.918355e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096911, dtype=float32), 'eval/episode_forward_reward': Array(-0.03400042, dtype=float32), 'eval/episode_reward': Array(-2.0307684, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03400042, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995748, dtype=float32), 'eval/episode_train_reward': Array(-0.00102001, dtype=float32), 'eval/episode_x_position': Array(1.0077742, dtype=float32), 'eval/episode_x_velocity': Array(-0.03400042, dtype=float32), 'eval/episode_y_position': Array(0.00031935, dtype=float32), 'eval/episode_y_velocity': Array(-0.00343648, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00587587, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04291476, dtype=float32), 'eval/episode_reward_std': Array(0.04955421, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04291476, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01742868, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128744, dtype=float32), 'eval/episode_x_position_std': Array(0.0059095, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04291476, dtype=float32), 'eval/episode_y_position_std': Array(0.00628915, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01141826, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.718483209609985, 'eval/sps': 6178.058437242595, 'num_steps': 4515840}
{'eval/walltime': 18385.13516306877, 'training/sps': 127.47320289566474, 'training/walltime': 35620.15402960777, 'training/entropy_loss': Array(0.11284122, dtype=float32), 'training/policy_loss': Array(0.27010745, dtype=float32), 'training/total_loss': Array(0.3829487, dtype=float32), 'training/v_loss': Array(3.6787162e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097159, dtype=float32), 'eval/episode_forward_reward': Array(-0.03306801, dtype=float32), 'eval/episode_reward': Array(-2.0315223, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03306801, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9974623, dtype=float32), 'eval/episode_train_reward': Array(-0.00099204, dtype=float32), 'eval/episode_x_position': Array(1.0078084, dtype=float32), 'eval/episode_x_velocity': Array(-0.03306801, dtype=float32), 'eval/episode_y_position': Array(0.00051407, dtype=float32), 'eval/episode_y_velocity': Array(0.00024991, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00552353, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04106171, dtype=float32), 'eval/episode_reward_std': Array(0.04331048, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04106171, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01130434, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123185, dtype=float32), 'eval/episode_x_position_std': Array(0.00555324, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04106171, dtype=float32), 'eval/episode_y_position_std': Array(0.00558857, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01170511, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.665321111679077, 'eval/sps': 6193.951659800745, 'num_steps': 4520960}
{'eval/walltime': 18405.82760334015, 'training/sps': 127.23807315878159, 'training/walltime': 35660.39355754852, 'training/entropy_loss': Array(0.11237855, dtype=float32), 'training/policy_loss': Array(0.26793414, dtype=float32), 'training/total_loss': Array(0.38031268, dtype=float32), 'training/v_loss': Array(2.5157654e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096228, dtype=float32), 'eval/episode_forward_reward': Array(-0.04067722, dtype=float32), 'eval/episode_reward': Array(-2.0392573, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04067722, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973598, dtype=float32), 'eval/episode_train_reward': Array(-0.00122032, dtype=float32), 'eval/episode_x_position': Array(1.0077488, dtype=float32), 'eval/episode_x_velocity': Array(-0.04067722, dtype=float32), 'eval/episode_y_position': Array(-0.00040553, dtype=float32), 'eval/episode_y_velocity': Array(-0.00088478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00529013, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04268771, dtype=float32), 'eval/episode_reward_std': Array(0.04843064, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04268771, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01812073, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128063, dtype=float32), 'eval/episode_x_position_std': Array(0.00529556, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04268771, dtype=float32), 'eval/episode_y_position_std': Array(0.00590663, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01233724, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.692440271377563, 'eval/sps': 6185.833972276998, 'num_steps': 4526080}
{'eval/walltime': 18426.55625462532, 'training/sps': 127.17682021559143, 'training/walltime': 35700.65246629715, 'training/entropy_loss': Array(0.11367616, dtype=float32), 'training/policy_loss': Array(0.2691081, dtype=float32), 'training/total_loss': Array(0.38278425, dtype=float32), 'training/v_loss': Array(2.9366625e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086308, dtype=float32), 'eval/episode_forward_reward': Array(-0.04349168, dtype=float32), 'eval/episode_reward': Array(-2.0412195, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04349168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996423, dtype=float32), 'eval/episode_train_reward': Array(-0.00130475, dtype=float32), 'eval/episode_x_position': Array(1.0067933, dtype=float32), 'eval/episode_x_velocity': Array(-0.04349168, dtype=float32), 'eval/episode_y_position': Array(0.00034029, dtype=float32), 'eval/episode_y_velocity': Array(0.0007982, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00550607, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04455465, dtype=float32), 'eval/episode_reward_std': Array(0.04767752, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04455465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01702237, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133664, dtype=float32), 'eval/episode_x_position_std': Array(0.0054599, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04455465, dtype=float32), 'eval/episode_y_position_std': Array(0.00529866, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0132102, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72865128517151, 'eval/sps': 6175.027899261654, 'num_steps': 4531200}
{'eval/walltime': 18447.287514686584, 'training/sps': 127.10319798816153, 'training/walltime': 35740.93469429016, 'training/entropy_loss': Array(0.11223577, dtype=float32), 'training/policy_loss': Array(0.2720619, dtype=float32), 'training/total_loss': Array(0.3842977, dtype=float32), 'training/v_loss': Array(2.243084e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.008985, dtype=float32), 'eval/episode_forward_reward': Array(-0.03717048, dtype=float32), 'eval/episode_reward': Array(-2.036245, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03717048, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9979596, dtype=float32), 'eval/episode_train_reward': Array(-0.00111511, dtype=float32), 'eval/episode_x_position': Array(1.0070953, dtype=float32), 'eval/episode_x_velocity': Array(-0.03717048, dtype=float32), 'eval/episode_y_position': Array(0.00015404, dtype=float32), 'eval/episode_y_velocity': Array(-0.00253419, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00537373, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04234281, dtype=float32), 'eval/episode_reward_std': Array(0.0455953, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04234281, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01119219, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127028, dtype=float32), 'eval/episode_x_position_std': Array(0.0053488, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04234281, dtype=float32), 'eval/episode_y_position_std': Array(0.00559606, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01143613, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.731260061264038, 'eval/sps': 6174.250847355176, 'num_steps': 4536320}
{'eval/walltime': 18468.00036072731, 'training/sps': 127.28501595665408, 'training/walltime': 35781.159381866455, 'training/entropy_loss': Array(0.10981071, dtype=float32), 'training/policy_loss': Array(0.27214658, dtype=float32), 'training/total_loss': Array(0.3819573, dtype=float32), 'training/v_loss': Array(7.056163e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097299, dtype=float32), 'eval/episode_forward_reward': Array(-0.03870251, dtype=float32), 'eval/episode_reward': Array(-2.0386057, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03870251, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9987419, dtype=float32), 'eval/episode_train_reward': Array(-0.00116108, dtype=float32), 'eval/episode_x_position': Array(1.0078667, dtype=float32), 'eval/episode_x_velocity': Array(-0.03870251, dtype=float32), 'eval/episode_y_position': Array(0.00082561, dtype=float32), 'eval/episode_y_velocity': Array(-0.00275278, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00608697, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04205504, dtype=float32), 'eval/episode_reward_std': Array(0.04479987, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04205504, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00833692, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126165, dtype=float32), 'eval/episode_x_position_std': Array(0.00606686, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04205504, dtype=float32), 'eval/episode_y_position_std': Array(0.00564889, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01360849, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.712846040725708, 'eval/sps': 6179.739845906532, 'num_steps': 4541440}
{'eval/walltime': 18488.734542131424, 'training/sps': 127.29728810609316, 'training/walltime': 35821.38019156456, 'training/entropy_loss': Array(0.1095048, dtype=float32), 'training/policy_loss': Array(0.26642907, dtype=float32), 'training/total_loss': Array(0.37593386, dtype=float32), 'training/v_loss': Array(2.8175944e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091195, dtype=float32), 'eval/episode_forward_reward': Array(-0.04280467, dtype=float32), 'eval/episode_reward': Array(-2.0416918, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04280467, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997603, dtype=float32), 'eval/episode_train_reward': Array(-0.00128414, dtype=float32), 'eval/episode_x_position': Array(1.0072968, dtype=float32), 'eval/episode_x_velocity': Array(-0.04280467, dtype=float32), 'eval/episode_y_position': Array(0.00036164, dtype=float32), 'eval/episode_y_velocity': Array(0.00188292, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00546482, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04506066, dtype=float32), 'eval/episode_reward_std': Array(0.04905412, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04506066, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01191697, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135182, dtype=float32), 'eval/episode_x_position_std': Array(0.0054474, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04506066, dtype=float32), 'eval/episode_y_position_std': Array(0.00568498, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0138326, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.73418140411377, 'eval/sps': 6173.380926174598, 'num_steps': 4546560}
{'eval/walltime': 18509.437134742737, 'training/sps': 127.53942417640648, 'training/walltime': 35861.524641275406, 'training/entropy_loss': Array(0.1136785, dtype=float32), 'training/policy_loss': Array(0.26818144, dtype=float32), 'training/total_loss': Array(0.38185996, dtype=float32), 'training/v_loss': Array(4.554265e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097835, dtype=float32), 'eval/episode_forward_reward': Array(-0.04228267, dtype=float32), 'eval/episode_reward': Array(-2.0401988, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04228267, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966478, dtype=float32), 'eval/episode_train_reward': Array(-0.00126848, dtype=float32), 'eval/episode_x_position': Array(1.0078958, dtype=float32), 'eval/episode_x_velocity': Array(-0.04228267, dtype=float32), 'eval/episode_y_position': Array(0.00061019, dtype=float32), 'eval/episode_y_velocity': Array(-0.0024569, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00569839, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04616106, dtype=float32), 'eval/episode_reward_std': Array(0.04958924, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04616106, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01360684, dtype=float32), 'eval/episode_train_reward_std': Array(0.00138483, dtype=float32), 'eval/episode_x_position_std': Array(0.00569242, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04616106, dtype=float32), 'eval/episode_y_position_std': Array(0.00585637, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01089229, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.702592611312866, 'eval/sps': 6182.800502486572, 'num_steps': 4551680}
{'eval/walltime': 18530.15547132492, 'training/sps': 127.1295929156304, 'training/walltime': 35901.79850578308, 'training/entropy_loss': Array(0.11208141, dtype=float32), 'training/policy_loss': Array(0.26944828, dtype=float32), 'training/total_loss': Array(0.3815297, dtype=float32), 'training/v_loss': Array(1.5021913e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091519, dtype=float32), 'eval/episode_forward_reward': Array(-0.03539616, dtype=float32), 'eval/episode_reward': Array(-2.033554, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03539616, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970963, dtype=float32), 'eval/episode_train_reward': Array(-0.00106188, dtype=float32), 'eval/episode_x_position': Array(1.0072496, dtype=float32), 'eval/episode_x_velocity': Array(-0.03539616, dtype=float32), 'eval/episode_y_position': Array(-0.00014863, dtype=float32), 'eval/episode_y_velocity': Array(-0.00014029, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00564267, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04247805, dtype=float32), 'eval/episode_reward_std': Array(0.04533324, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04247805, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01249395, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127434, dtype=float32), 'eval/episode_x_position_std': Array(0.00562727, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04247805, dtype=float32), 'eval/episode_y_position_std': Array(0.00566244, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01004063, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.718336582183838, 'eval/sps': 6178.102160482809, 'num_steps': 4556800}
{'eval/walltime': 18550.877792835236, 'training/sps': 127.63919283295988, 'training/walltime': 35941.911576747894, 'training/entropy_loss': Array(0.11340129, dtype=float32), 'training/policy_loss': Array(0.26710457, dtype=float32), 'training/total_loss': Array(0.3805059, dtype=float32), 'training/v_loss': Array(4.6452193e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093719, dtype=float32), 'eval/episode_forward_reward': Array(-0.03805113, dtype=float32), 'eval/episode_reward': Array(-2.0370884, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03805113, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978957, dtype=float32), 'eval/episode_train_reward': Array(-0.00114153, dtype=float32), 'eval/episode_x_position': Array(1.007488, dtype=float32), 'eval/episode_x_velocity': Array(-0.03805113, dtype=float32), 'eval/episode_y_position': Array(0.00035139, dtype=float32), 'eval/episode_y_velocity': Array(-0.00308309, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600214, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04384807, dtype=float32), 'eval/episode_reward_std': Array(0.04571436, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04384807, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01031752, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131544, dtype=float32), 'eval/episode_x_position_std': Array(0.00598479, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04384807, dtype=float32), 'eval/episode_y_position_std': Array(0.00560672, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01611635, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.72232151031494, 'eval/sps': 6176.914103773822, 'num_steps': 4561920}
{'eval/walltime': 18571.58929991722, 'training/sps': 126.7475430945223, 'training/walltime': 35982.30683708191, 'training/entropy_loss': Array(0.11346698, dtype=float32), 'training/policy_loss': Array(0.27009314, dtype=float32), 'training/total_loss': Array(0.38356012, dtype=float32), 'training/v_loss': Array(3.171942e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095721, dtype=float32), 'eval/episode_forward_reward': Array(-0.03525832, dtype=float32), 'eval/episode_reward': Array(-2.0323198, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03525832, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9960036, dtype=float32), 'eval/episode_train_reward': Array(-0.00105775, dtype=float32), 'eval/episode_x_position': Array(1.007692, dtype=float32), 'eval/episode_x_velocity': Array(-0.03525832, dtype=float32), 'eval/episode_y_position': Array(2.5818706e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00219352, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585861, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04277999, dtype=float32), 'eval/episode_reward_std': Array(0.04923534, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04277999, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01987827, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012834, dtype=float32), 'eval/episode_x_position_std': Array(0.00589346, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04277999, dtype=float32), 'eval/episode_y_position_std': Array(0.00587491, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01353236, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.711507081985474, 'eval/sps': 6180.139354095207, 'num_steps': 4567040}
{'eval/walltime': 18592.3108792305, 'training/sps': 127.33303304447519, 'training/walltime': 36022.51635599136, 'training/entropy_loss': Array(0.11372315, dtype=float32), 'training/policy_loss': Array(0.26852384, dtype=float32), 'training/total_loss': Array(0.38224697, dtype=float32), 'training/v_loss': Array(1.1684059e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017137, dtype=float32), 'eval/episode_forward_reward': Array(-0.04270494, dtype=float32), 'eval/episode_reward': Array(-2.057791, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04270494, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0216174, dtype=float32), 'eval/episode_train_reward': Array(-0.00128115, dtype=float32), 'eval/episode_x_position': Array(1.0152609, dtype=float32), 'eval/episode_x_velocity': Array(-0.04270494, dtype=float32), 'eval/episode_y_position': Array(-0.00017102, dtype=float32), 'eval/episode_y_velocity': Array(-0.00307857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08809859, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04425849, dtype=float32), 'eval/episode_reward_std': Array(0.17951769, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04425849, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26447785, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132775, dtype=float32), 'eval/episode_x_position_std': Array(0.08782191, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04425849, dtype=float32), 'eval/episode_y_position_std': Array(0.006034, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01334674, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.7215793132782, 'eval/sps': 6177.135345952071, 'num_steps': 4572160}
{'eval/walltime': 18613.028066158295, 'training/sps': 127.37832328053183, 'training/walltime': 36062.71157813072, 'training/entropy_loss': Array(0.11319869, dtype=float32), 'training/policy_loss': Array(0.26884252, dtype=float32), 'training/total_loss': Array(0.38204125, dtype=float32), 'training/v_loss': Array(5.3371414e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092616, dtype=float32), 'eval/episode_forward_reward': Array(-0.03868217, dtype=float32), 'eval/episode_reward': Array(-2.0350194, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03868217, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9951768, dtype=float32), 'eval/episode_train_reward': Array(-0.00116047, dtype=float32), 'eval/episode_x_position': Array(1.0073934, dtype=float32), 'eval/episode_x_velocity': Array(-0.03868217, dtype=float32), 'eval/episode_y_position': Array(-0.00062795, dtype=float32), 'eval/episode_y_velocity': Array(-0.00115799, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00629756, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04268123, dtype=float32), 'eval/episode_reward_std': Array(0.05023142, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04268123, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01858401, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128044, dtype=float32), 'eval/episode_x_position_std': Array(0.00629352, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04268123, dtype=float32), 'eval/episode_y_position_std': Array(0.00600004, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01257746, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71718692779541, 'eval/sps': 6178.445000574262, 'num_steps': 4577280}
{'eval/walltime': 18633.707517147064, 'training/sps': 127.46777475855416, 'training/walltime': 36102.87859296799, 'training/entropy_loss': Array(0.11281477, dtype=float32), 'training/policy_loss': Array(0.2708104, dtype=float32), 'training/total_loss': Array(0.38362515, dtype=float32), 'training/v_loss': Array(1.84487e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087649, dtype=float32), 'eval/episode_forward_reward': Array(-0.03848846, dtype=float32), 'eval/episode_reward': Array(-2.0361362, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03848846, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964933, dtype=float32), 'eval/episode_train_reward': Array(-0.00115465, dtype=float32), 'eval/episode_x_position': Array(1.0068817, dtype=float32), 'eval/episode_x_velocity': Array(-0.03848846, dtype=float32), 'eval/episode_y_position': Array(-0.000216, dtype=float32), 'eval/episode_y_velocity': Array(0.00060564, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00608711, dtype=float32), 'eval/episode_forward_reward_std': Array(0.043491, dtype=float32), 'eval/episode_reward_std': Array(0.05144187, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.043491, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02094601, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130473, dtype=float32), 'eval/episode_x_position_std': Array(0.00604449, dtype=float32), 'eval/episode_x_velocity_std': Array(0.043491, dtype=float32), 'eval/episode_y_position_std': Array(0.00617111, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01312768, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67945098876953, 'eval/sps': 6189.7194499754105, 'num_steps': 4582400}
{'eval/walltime': 18654.425451993942, 'training/sps': 127.02630221021889, 'training/walltime': 36143.18520593643, 'training/entropy_loss': Array(0.11221537, dtype=float32), 'training/policy_loss': Array(0.2669021, dtype=float32), 'training/total_loss': Array(0.37911743, dtype=float32), 'training/v_loss': Array(3.6499201e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085144, dtype=float32), 'eval/episode_forward_reward': Array(-0.04121041, dtype=float32), 'eval/episode_reward': Array(-2.0392156, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04121041, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996769, dtype=float32), 'eval/episode_train_reward': Array(-0.00123631, dtype=float32), 'eval/episode_x_position': Array(1.0066491, dtype=float32), 'eval/episode_x_velocity': Array(-0.04121041, dtype=float32), 'eval/episode_y_position': Array(-0.00036534, dtype=float32), 'eval/episode_y_velocity': Array(0.0011107, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00551721, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04539623, dtype=float32), 'eval/episode_reward_std': Array(0.04924704, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04539623, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01381111, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136189, dtype=float32), 'eval/episode_x_position_std': Array(0.00543024, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04539623, dtype=float32), 'eval/episode_y_position_std': Array(0.00575507, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01716668, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.71793484687805, 'eval/sps': 6178.221958222254, 'num_steps': 4587520}
{'eval/walltime': 18675.0747320652, 'training/sps': 127.25843956842094, 'training/walltime': 36183.41829395294, 'training/entropy_loss': Array(0.1126264, dtype=float32), 'training/policy_loss': Array(0.2647372, dtype=float32), 'training/total_loss': Array(0.37736362, dtype=float32), 'training/v_loss': Array(4.7738884e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.00951, dtype=float32), 'eval/episode_forward_reward': Array(-0.03761403, dtype=float32), 'eval/episode_reward': Array(-2.0369363, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03761403, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981937, dtype=float32), 'eval/episode_train_reward': Array(-0.00112842, dtype=float32), 'eval/episode_x_position': Array(1.0076479, dtype=float32), 'eval/episode_x_velocity': Array(-0.03761403, dtype=float32), 'eval/episode_y_position': Array(0.00047651, dtype=float32), 'eval/episode_y_velocity': Array(-0.00053301, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0059299, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04235681, dtype=float32), 'eval/episode_reward_std': Array(0.04577877, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04235681, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01104259, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012707, dtype=float32), 'eval/episode_x_position_std': Array(0.00591708, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04235681, dtype=float32), 'eval/episode_y_position_std': Array(0.00568855, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01008109, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.649280071258545, 'eval/sps': 6198.763325321035, 'num_steps': 4592640}
{'eval/walltime': 18695.712691307068, 'training/sps': 127.15824327633753, 'training/walltime': 36223.6830842495, 'training/entropy_loss': Array(0.11418187, dtype=float32), 'training/policy_loss': Array(0.2669594, dtype=float32), 'training/total_loss': Array(0.38114125, dtype=float32), 'training/v_loss': Array(5.7151145e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.00909, dtype=float32), 'eval/episode_forward_reward': Array(-0.03893813, dtype=float32), 'eval/episode_reward': Array(-2.03748, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03893813, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973738, dtype=float32), 'eval/episode_train_reward': Array(-0.00116814, dtype=float32), 'eval/episode_x_position': Array(1.0072013, dtype=float32), 'eval/episode_x_velocity': Array(-0.03893813, dtype=float32), 'eval/episode_y_position': Array(-0.00075296, dtype=float32), 'eval/episode_y_velocity': Array(0.00020973, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00527297, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04270307, dtype=float32), 'eval/episode_reward_std': Array(0.04816636, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04270307, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01344738, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128109, dtype=float32), 'eval/episode_x_position_std': Array(0.00526656, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04270307, dtype=float32), 'eval/episode_y_position_std': Array(0.00543175, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01459493, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.637959241867065, 'eval/sps': 6202.163619953934, 'num_steps': 4597760}
{'eval/walltime': 18716.38821554184, 'training/sps': 127.48716957277985, 'training/walltime': 36263.84398841858, 'training/entropy_loss': Array(0.11507963, dtype=float32), 'training/policy_loss': Array(0.27064288, dtype=float32), 'training/total_loss': Array(0.3857225, dtype=float32), 'training/v_loss': Array(1.3056569e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100253, dtype=float32), 'eval/episode_forward_reward': Array(-0.04663117, dtype=float32), 'eval/episode_reward': Array(-2.044433, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04663117, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964032, dtype=float32), 'eval/episode_train_reward': Array(-0.00139893, dtype=float32), 'eval/episode_x_position': Array(1.0081816, dtype=float32), 'eval/episode_x_velocity': Array(-0.04663117, dtype=float32), 'eval/episode_y_position': Array(0.00037728, dtype=float32), 'eval/episode_y_velocity': Array(-0.00010948, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568873, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04502133, dtype=float32), 'eval/episode_reward_std': Array(0.05152729, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04502133, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01714892, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135064, dtype=float32), 'eval/episode_x_position_std': Array(0.00567886, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04502133, dtype=float32), 'eval/episode_y_position_std': Array(0.00586704, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01353303, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67552423477173, 'eval/sps': 6190.895018987324, 'num_steps': 4602880}
{'eval/walltime': 18737.106654405594, 'training/sps': 127.27696809978087, 'training/walltime': 36304.071219444275, 'training/entropy_loss': Array(0.11320154, dtype=float32), 'training/policy_loss': Array(0.27242982, dtype=float32), 'training/total_loss': Array(0.38563138, dtype=float32), 'training/v_loss': Array(1.380285e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095046, dtype=float32), 'eval/episode_forward_reward': Array(-0.03597233, dtype=float32), 'eval/episode_reward': Array(-2.0353415, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03597233, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982898, dtype=float32), 'eval/episode_train_reward': Array(-0.00107917, dtype=float32), 'eval/episode_x_position': Array(1.0076265, dtype=float32), 'eval/episode_x_velocity': Array(-0.03597233, dtype=float32), 'eval/episode_y_position': Array(-0.0003199, dtype=float32), 'eval/episode_y_velocity': Array(-0.00165938, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589424, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0416676, dtype=float32), 'eval/episode_reward_std': Array(0.0439272, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0416676, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01026951, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125003, dtype=float32), 'eval/episode_x_position_std': Array(0.00587995, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0416676, dtype=float32), 'eval/episode_y_position_std': Array(0.00586861, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01516145, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.718438863754272, 'eval/sps': 6178.071660791426, 'num_steps': 4608000}
{'eval/walltime': 18757.758853912354, 'training/sps': 127.5837365173486, 'training/walltime': 36344.2017261982, 'training/entropy_loss': Array(0.1125655, dtype=float32), 'training/policy_loss': Array(0.26885694, dtype=float32), 'training/total_loss': Array(0.38142246, dtype=float32), 'training/v_loss': Array(9.718503e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095911, dtype=float32), 'eval/episode_forward_reward': Array(-0.0414267, dtype=float32), 'eval/episode_reward': Array(-2.040711, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0414267, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980416, dtype=float32), 'eval/episode_train_reward': Array(-0.0012428, dtype=float32), 'eval/episode_x_position': Array(1.0077482, dtype=float32), 'eval/episode_x_velocity': Array(-0.0414267, dtype=float32), 'eval/episode_y_position': Array(-3.5953417e-06, dtype=float32), 'eval/episode_y_velocity': Array(-0.001591, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00603583, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04511224, dtype=float32), 'eval/episode_reward_std': Array(0.04846489, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04511224, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01060417, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135337, dtype=float32), 'eval/episode_x_position_std': Array(0.00602872, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04511224, dtype=float32), 'eval/episode_y_position_std': Array(0.00537003, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01343384, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.652199506759644, 'eval/sps': 6197.887055957623, 'num_steps': 4613120}
{'eval/walltime': 18778.436799764633, 'training/sps': 127.28159994408695, 'training/walltime': 36384.42749333382, 'training/entropy_loss': Array(0.11323983, dtype=float32), 'training/policy_loss': Array(0.27245352, dtype=float32), 'training/total_loss': Array(0.38569334, dtype=float32), 'training/v_loss': Array(1.308911e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086017, dtype=float32), 'eval/episode_forward_reward': Array(-0.05072169, dtype=float32), 'eval/episode_reward': Array(-2.051418, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.05072169, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9991746, dtype=float32), 'eval/episode_train_reward': Array(-0.00152165, dtype=float32), 'eval/episode_x_position': Array(1.0068027, dtype=float32), 'eval/episode_x_velocity': Array(-0.05072169, dtype=float32), 'eval/episode_y_position': Array(0.00070425, dtype=float32), 'eval/episode_y_velocity': Array(-0.00010109, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00622607, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04389545, dtype=float32), 'eval/episode_reward_std': Array(0.04471906, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04389545, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00523527, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131686, dtype=float32), 'eval/episode_x_position_std': Array(0.00621338, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04389545, dtype=float32), 'eval/episode_y_position_std': Array(0.00576557, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01706617, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677945852279663, 'eval/sps': 6190.169996304952, 'num_steps': 4618240}
{'eval/walltime': 18799.11150455475, 'training/sps': 127.36338561180979, 'training/walltime': 36424.62742972374, 'training/entropy_loss': Array(0.1116962, dtype=float32), 'training/policy_loss': Array(0.27069807, dtype=float32), 'training/total_loss': Array(0.38239425, dtype=float32), 'training/v_loss': Array(4.055831e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094318, dtype=float32), 'eval/episode_forward_reward': Array(-0.04212155, dtype=float32), 'eval/episode_reward': Array(-2.0392299, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04212155, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958448, dtype=float32), 'eval/episode_train_reward': Array(-0.00126365, dtype=float32), 'eval/episode_x_position': Array(1.0075796, dtype=float32), 'eval/episode_x_velocity': Array(-0.04212155, dtype=float32), 'eval/episode_y_position': Array(-0.00019842, dtype=float32), 'eval/episode_y_velocity': Array(0.00172684, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589324, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04743953, dtype=float32), 'eval/episode_reward_std': Array(0.05158856, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04743953, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01651307, dtype=float32), 'eval/episode_train_reward_std': Array(0.00142319, dtype=float32), 'eval/episode_x_position_std': Array(0.00594692, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04743953, dtype=float32), 'eval/episode_y_position_std': Array(0.00553808, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01104413, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.674704790115356, 'eval/sps': 6191.140395929485, 'num_steps': 4623360}
{'eval/walltime': 18819.77689051628, 'training/sps': 127.30929620270797, 'training/walltime': 36464.844445705414, 'training/entropy_loss': Array(0.11190817, dtype=float32), 'training/policy_loss': Array(0.26477104, dtype=float32), 'training/total_loss': Array(0.37667924, dtype=float32), 'training/v_loss': Array(4.1415738e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096034, dtype=float32), 'eval/episode_forward_reward': Array(-0.04730739, dtype=float32), 'eval/episode_reward': Array(-2.0476637, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04730739, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9989371, dtype=float32), 'eval/episode_train_reward': Array(-0.00141922, dtype=float32), 'eval/episode_x_position': Array(1.0077999, dtype=float32), 'eval/episode_x_velocity': Array(-0.04730739, dtype=float32), 'eval/episode_y_position': Array(-0.00072481, dtype=float32), 'eval/episode_y_velocity': Array(0.00018952, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00610562, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04390731, dtype=float32), 'eval/episode_reward_std': Array(0.04474899, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04390731, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00737227, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131722, dtype=float32), 'eval/episode_x_position_std': Array(0.00609362, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04390731, dtype=float32), 'eval/episode_y_position_std': Array(0.00548937, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01101579, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.665385961532593, 'eval/sps': 6193.93222261924, 'num_steps': 4628480}
{'eval/walltime': 18840.486488103867, 'training/sps': 127.3051279773369, 'training/walltime': 36505.0627784729, 'training/entropy_loss': Array(0.11384439, dtype=float32), 'training/policy_loss': Array(0.26640344, dtype=float32), 'training/total_loss': Array(0.38024783, dtype=float32), 'training/v_loss': Array(2.2228722e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0102292, dtype=float32), 'eval/episode_forward_reward': Array(-0.03732989, dtype=float32), 'eval/episode_reward': Array(-2.036774, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03732989, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983244, dtype=float32), 'eval/episode_train_reward': Array(-0.0011199, dtype=float32), 'eval/episode_x_position': Array(1.0083585, dtype=float32), 'eval/episode_x_velocity': Array(-0.03732989, dtype=float32), 'eval/episode_y_position': Array(-0.00015721, dtype=float32), 'eval/episode_y_velocity': Array(-0.00174703, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00620579, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04339749, dtype=float32), 'eval/episode_reward_std': Array(0.04529215, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04339749, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0104197, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130192, dtype=float32), 'eval/episode_x_position_std': Array(0.00620373, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04339749, dtype=float32), 'eval/episode_y_position_std': Array(0.00580768, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00988849, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.70959758758545, 'eval/sps': 6180.709183684512, 'num_steps': 4633600}
{'eval/walltime': 18861.17603826523, 'training/sps': 127.30350543941935, 'training/walltime': 36545.28162384033, 'training/entropy_loss': Array(0.11193249, dtype=float32), 'training/policy_loss': Array(0.27184638, dtype=float32), 'training/total_loss': Array(0.38377887, dtype=float32), 'training/v_loss': Array(3.963648e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090048, dtype=float32), 'eval/episode_forward_reward': Array(-0.03759804, dtype=float32), 'eval/episode_reward': Array(-2.0372062, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03759804, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984803, dtype=float32), 'eval/episode_train_reward': Array(-0.00112794, dtype=float32), 'eval/episode_x_position': Array(1.0071259, dtype=float32), 'eval/episode_x_velocity': Array(-0.03759804, dtype=float32), 'eval/episode_y_position': Array(6.571383e-06, dtype=float32), 'eval/episode_y_velocity': Array(0.00036539, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00596425, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04354046, dtype=float32), 'eval/episode_reward_std': Array(0.045905, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04354046, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00926591, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130621, dtype=float32), 'eval/episode_x_position_std': Array(0.00593005, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04354046, dtype=float32), 'eval/episode_y_position_std': Array(0.00596838, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01249787, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.689550161361694, 'eval/sps': 6186.698067464199, 'num_steps': 4638720}
{'eval/walltime': 18881.829795598984, 'training/sps': 127.49189923068042, 'training/walltime': 36585.441038131714, 'training/entropy_loss': Array(0.1110892, dtype=float32), 'training/policy_loss': Array(0.27262944, dtype=float32), 'training/total_loss': Array(0.3837186, dtype=float32), 'training/v_loss': Array(4.8247717e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094705, dtype=float32), 'eval/episode_forward_reward': Array(-0.03664692, dtype=float32), 'eval/episode_reward': Array(-2.037199, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03664692, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9994526, dtype=float32), 'eval/episode_train_reward': Array(-0.00109941, dtype=float32), 'eval/episode_x_position': Array(1.007592, dtype=float32), 'eval/episode_x_velocity': Array(-0.03664692, dtype=float32), 'eval/episode_y_position': Array(0.0006737, dtype=float32), 'eval/episode_y_velocity': Array(-0.00046815, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568722, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04441025, dtype=float32), 'eval/episode_reward_std': Array(0.04616234, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04441025, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00355824, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133231, dtype=float32), 'eval/episode_x_position_std': Array(0.00568734, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04441025, dtype=float32), 'eval/episode_y_position_std': Array(0.00592228, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00986525, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.653757333755493, 'eval/sps': 6197.419575120264, 'num_steps': 4643840}
{'eval/walltime': 18902.4741294384, 'training/sps': 127.47103052603917, 'training/walltime': 36625.60702705383, 'training/entropy_loss': Array(0.11008849, dtype=float32), 'training/policy_loss': Array(0.2669714, dtype=float32), 'training/total_loss': Array(0.3770599, dtype=float32), 'training/v_loss': Array(2.8836302e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091548, dtype=float32), 'eval/episode_forward_reward': Array(-0.03980713, dtype=float32), 'eval/episode_reward': Array(-2.0398443, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03980713, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9988427, dtype=float32), 'eval/episode_train_reward': Array(-0.00119421, dtype=float32), 'eval/episode_x_position': Array(1.0073016, dtype=float32), 'eval/episode_x_velocity': Array(-0.03980713, dtype=float32), 'eval/episode_y_position': Array(0.00060347, dtype=float32), 'eval/episode_y_velocity': Array(-0.0007387, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00600938, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04547291, dtype=float32), 'eval/episode_reward_std': Array(0.04833583, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04547291, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00825997, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136419, dtype=float32), 'eval/episode_x_position_std': Array(0.00599971, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04547291, dtype=float32), 'eval/episode_y_position_std': Array(0.00612958, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01339136, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.644333839416504, 'eval/sps': 6200.248503810178, 'num_steps': 4648960}
{'eval/walltime': 18923.159078121185, 'training/sps': 127.27719591225325, 'training/walltime': 36665.83418607712, 'training/entropy_loss': Array(0.11292139, dtype=float32), 'training/policy_loss': Array(0.2675868, dtype=float32), 'training/total_loss': Array(0.3805082, dtype=float32), 'training/v_loss': Array(1.1926584e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089964, dtype=float32), 'eval/episode_forward_reward': Array(-0.0361832, dtype=float32), 'eval/episode_reward': Array(-2.0369682, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0361832, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9996996, dtype=float32), 'eval/episode_train_reward': Array(-0.0010855, dtype=float32), 'eval/episode_x_position': Array(1.0071228, dtype=float32), 'eval/episode_x_velocity': Array(-0.0361832, dtype=float32), 'eval/episode_y_position': Array(-0.00031165, dtype=float32), 'eval/episode_y_velocity': Array(-0.00071663, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00629675, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04266731, dtype=float32), 'eval/episode_reward_std': Array(0.04391022, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04266731, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00227893, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128002, dtype=float32), 'eval/episode_x_position_std': Array(0.00628415, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04266731, dtype=float32), 'eval/episode_y_position_std': Array(0.00556064, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01166203, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.684948682785034, 'eval/sps': 6188.074331870472, 'num_steps': 4654080}
{'eval/walltime': 18943.77501153946, 'training/sps': 127.21861236866621, 'training/walltime': 36706.07986950874, 'training/entropy_loss': Array(0.11284731, dtype=float32), 'training/policy_loss': Array(0.2721997, dtype=float32), 'training/total_loss': Array(0.385047, dtype=float32), 'training/v_loss': Array(4.292541e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094798, dtype=float32), 'eval/episode_forward_reward': Array(-0.034336, dtype=float32), 'eval/episode_reward': Array(-2.0345216, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.034336, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9991555, dtype=float32), 'eval/episode_train_reward': Array(-0.00103008, dtype=float32), 'eval/episode_x_position': Array(1.0076067, dtype=float32), 'eval/episode_x_velocity': Array(-0.034336, dtype=float32), 'eval/episode_y_position': Array(-0.0002374, dtype=float32), 'eval/episode_y_velocity': Array(-0.00088453, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589847, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04168478, dtype=float32), 'eval/episode_reward_std': Array(0.04411235, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04168478, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00832316, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125054, dtype=float32), 'eval/episode_x_position_std': Array(0.00584356, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04168478, dtype=float32), 'eval/episode_y_position_std': Array(0.00559047, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01046317, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.615933418273926, 'eval/sps': 6208.789939462117, 'num_steps': 4659200}
{'eval/walltime': 18964.451829195023, 'training/sps': 127.40341009703829, 'training/walltime': 36746.26717686653, 'training/entropy_loss': Array(0.1121079, dtype=float32), 'training/policy_loss': Array(0.26931238, dtype=float32), 'training/total_loss': Array(0.38142025, dtype=float32), 'training/v_loss': Array(3.1569205e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017281, dtype=float32), 'eval/episode_forward_reward': Array(-0.03815497, dtype=float32), 'eval/episode_reward': Array(-2.0545073, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03815497, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0230203, dtype=float32), 'eval/episode_train_reward': Array(-0.00114465, dtype=float32), 'eval/episode_x_position': Array(1.0153592, dtype=float32), 'eval/episode_x_velocity': Array(-0.03815497, dtype=float32), 'eval/episode_y_position': Array(4.3053093e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00048199, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08848283, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04287064, dtype=float32), 'eval/episode_reward_std': Array(0.17990069, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04287064, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26417664, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128612, dtype=float32), 'eval/episode_x_position_std': Array(0.08821294, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04287064, dtype=float32), 'eval/episode_y_position_std': Array(0.00585042, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01131223, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.676817655563354, 'eval/sps': 6190.507752800151, 'num_steps': 4664320}
{'eval/walltime': 18985.118800401688, 'training/sps': 127.12916769880353, 'training/walltime': 36786.541176080704, 'training/entropy_loss': Array(0.11241636, dtype=float32), 'training/policy_loss': Array(0.26846352, dtype=float32), 'training/total_loss': Array(0.38087988, dtype=float32), 'training/v_loss': Array(1.6711931e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0086693, dtype=float32), 'eval/episode_forward_reward': Array(-0.04960542, dtype=float32), 'eval/episode_reward': Array(-2.0488331, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04960542, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9977396, dtype=float32), 'eval/episode_train_reward': Array(-0.00148816, dtype=float32), 'eval/episode_x_position': Array(1.0068722, dtype=float32), 'eval/episode_x_velocity': Array(-0.04960542, dtype=float32), 'eval/episode_y_position': Array(0.00057098, dtype=float32), 'eval/episode_y_velocity': Array(-0.00018152, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00537042, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04523672, dtype=float32), 'eval/episode_reward_std': Array(0.04861351, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04523672, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01051895, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013571, dtype=float32), 'eval/episode_x_position_std': Array(0.00533961, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04523672, dtype=float32), 'eval/episode_y_position_std': Array(0.00614714, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01350689, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66697120666504, 'eval/sps': 6193.457121511853, 'num_steps': 4669440}
{'eval/walltime': 19005.83725976944, 'training/sps': 127.30601095720954, 'training/walltime': 36826.75922989845, 'training/entropy_loss': Array(0.11229192, dtype=float32), 'training/policy_loss': Array(0.2632004, dtype=float32), 'training/total_loss': Array(0.37549227, dtype=float32), 'training/v_loss': Array(3.2449663e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093659, dtype=float32), 'eval/episode_forward_reward': Array(-0.04534043, dtype=float32), 'eval/episode_reward': Array(-2.0459437, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04534043, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9992428, dtype=float32), 'eval/episode_train_reward': Array(-0.00136021, dtype=float32), 'eval/episode_x_position': Array(1.0075109, dtype=float32), 'eval/episode_x_velocity': Array(-0.04534043, dtype=float32), 'eval/episode_y_position': Array(4.3677574e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00027362, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558455, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04557064, dtype=float32), 'eval/episode_reward_std': Array(0.04710309, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04557064, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00432937, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136712, dtype=float32), 'eval/episode_x_position_std': Array(0.00564351, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04557064, dtype=float32), 'eval/episode_y_position_std': Array(0.00600981, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01166073, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.718459367752075, 'eval/sps': 6178.065546670415, 'num_steps': 4674560}
{'eval/walltime': 19026.470607995987, 'training/sps': 126.93449483546155, 'training/walltime': 36867.09499526024, 'training/entropy_loss': Array(0.11492939, dtype=float32), 'training/policy_loss': Array(0.26824278, dtype=float32), 'training/total_loss': Array(0.38317218, dtype=float32), 'training/v_loss': Array(5.249232e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0175269, dtype=float32), 'eval/episode_forward_reward': Array(-0.04081413, dtype=float32), 'eval/episode_reward': Array(-2.0552354, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04081413, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0210092, dtype=float32), 'eval/episode_train_reward': Array(-0.00122442, dtype=float32), 'eval/episode_x_position': Array(1.0156274, dtype=float32), 'eval/episode_x_velocity': Array(-0.04081413, dtype=float32), 'eval/episode_y_position': Array(-0.00041074, dtype=float32), 'eval/episode_y_velocity': Array(-0.00188884, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08770251, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04388275, dtype=float32), 'eval/episode_reward_std': Array(0.17944063, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04388275, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26467815, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131648, dtype=float32), 'eval/episode_x_position_std': Array(0.08743548, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04388275, dtype=float32), 'eval/episode_y_position_std': Array(0.0058637, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00838718, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.63334822654724, 'eval/sps': 6203.549641803305, 'num_steps': 4679680}
{'eval/walltime': 19047.141514778137, 'training/sps': 127.10385398510579, 'training/walltime': 36907.37701535225, 'training/entropy_loss': Array(0.11672533, dtype=float32), 'training/policy_loss': Array(0.2723148, dtype=float32), 'training/total_loss': Array(0.3890401, dtype=float32), 'training/v_loss': Array(1.3882251e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099874, dtype=float32), 'eval/episode_forward_reward': Array(-0.0382942, dtype=float32), 'eval/episode_reward': Array(-2.0377915, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0382942, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983487, dtype=float32), 'eval/episode_train_reward': Array(-0.00114883, dtype=float32), 'eval/episode_x_position': Array(1.0081275, dtype=float32), 'eval/episode_x_velocity': Array(-0.0382942, dtype=float32), 'eval/episode_y_position': Array(-0.00014044, dtype=float32), 'eval/episode_y_velocity': Array(0.00022362, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00606805, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04541002, dtype=float32), 'eval/episode_reward_std': Array(0.0490377, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04541002, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00982791, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013623, dtype=float32), 'eval/episode_x_position_std': Array(0.00600252, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04541002, dtype=float32), 'eval/episode_y_position_std': Array(0.00559079, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00978884, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67090678215027, 'eval/sps': 6192.277936763301, 'num_steps': 4684800}
{'eval/walltime': 19067.78886961937, 'training/sps': 127.22316836431752, 'training/walltime': 36947.621257543564, 'training/entropy_loss': Array(0.11552326, dtype=float32), 'training/policy_loss': Array(0.27500403, dtype=float32), 'training/total_loss': Array(0.39052728, dtype=float32), 'training/v_loss': Array(4.6838355e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0242677, dtype=float32), 'eval/episode_forward_reward': Array(-0.03524443, dtype=float32), 'eval/episode_reward': Array(-2.064791, dtype=float32), 'eval/episode_reward_alive': Array(1.015625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03524443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0441139, dtype=float32), 'eval/episode_train_reward': Array(-0.00105733, dtype=float32), 'eval/episode_x_position': Array(1.022326, dtype=float32), 'eval/episode_x_velocity': Array(-0.03524443, dtype=float32), 'eval/episode_y_position': Array(-8.924655e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00142168, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.12495203, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04226958, dtype=float32), 'eval/episode_reward_std': Array(0.24367562, dtype=float32), 'eval/episode_reward_alive_std': Array(0.12401959, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04226958, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3663199, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126809, dtype=float32), 'eval/episode_x_position_std': Array(0.12457593, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04226958, dtype=float32), 'eval/episode_y_position_std': Array(0.00573036, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01198596, dtype=float32), 'eval/avg_episode_length': Array(1.015625, dtype=float32), 'eval/epoch_eval_time': 20.6473548412323, 'eval/sps': 6199.341319227337, 'num_steps': 4689920}
{'eval/walltime': 19088.505612373352, 'training/sps': 127.18767339446904, 'training/walltime': 36987.876730918884, 'training/entropy_loss': Array(0.11440702, dtype=float32), 'training/policy_loss': Array(0.2744075, dtype=float32), 'training/total_loss': Array(0.38881457, dtype=float32), 'training/v_loss': Array(9.43724e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094607, dtype=float32), 'eval/episode_forward_reward': Array(-0.03720867, dtype=float32), 'eval/episode_reward': Array(-2.0368192, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03720867, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984944, dtype=float32), 'eval/episode_train_reward': Array(-0.00111626, dtype=float32), 'eval/episode_x_position': Array(1.0075605, dtype=float32), 'eval/episode_x_velocity': Array(-0.03720867, dtype=float32), 'eval/episode_y_position': Array(0.00034249, dtype=float32), 'eval/episode_y_velocity': Array(0.00028731, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0057902, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04280946, dtype=float32), 'eval/episode_reward_std': Array(0.04529285, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04280946, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00856205, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128428, dtype=float32), 'eval/episode_x_position_std': Array(0.00571147, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04280946, dtype=float32), 'eval/episode_y_position_std': Array(0.0057077, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01231955, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.716742753982544, 'eval/sps': 6178.577468477449, 'num_steps': 4695040}
{'eval/walltime': 19109.2140917778, 'training/sps': 127.13121252860378, 'training/walltime': 37028.15008234978, 'training/entropy_loss': Array(0.11108153, dtype=float32), 'training/policy_loss': Array(0.27272922, dtype=float32), 'training/total_loss': Array(0.38381076, dtype=float32), 'training/v_loss': Array(1.882092e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092456, dtype=float32), 'eval/episode_forward_reward': Array(-0.04366235, dtype=float32), 'eval/episode_reward': Array(-2.0434022, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04366235, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984298, dtype=float32), 'eval/episode_train_reward': Array(-0.00130987, dtype=float32), 'eval/episode_x_position': Array(1.0074015, dtype=float32), 'eval/episode_x_velocity': Array(-0.04366235, dtype=float32), 'eval/episode_y_position': Array(0.00023844, dtype=float32), 'eval/episode_y_velocity': Array(0.00029591, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00605812, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04463455, dtype=float32), 'eval/episode_reward_std': Array(0.04762289, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04463455, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01049451, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133904, dtype=float32), 'eval/episode_x_position_std': Array(0.0060561, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04463455, dtype=float32), 'eval/episode_y_position_std': Array(0.00579867, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0120263, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.708479404449463, 'eval/sps': 6181.042919669789, 'num_steps': 4700160}
{'eval/walltime': 19129.913848876953, 'training/sps': 127.23005611175542, 'training/walltime': 37068.392145872116, 'training/entropy_loss': Array(0.11138747, dtype=float32), 'training/policy_loss': Array(0.2679459, dtype=float32), 'training/total_loss': Array(0.37933335, dtype=float32), 'training/v_loss': Array(4.392418e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0170534, dtype=float32), 'eval/episode_forward_reward': Array(-0.04195585, dtype=float32), 'eval/episode_reward': Array(-2.0581841, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04195585, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0227823, dtype=float32), 'eval/episode_train_reward': Array(-0.00125868, dtype=float32), 'eval/episode_x_position': Array(1.0151682, dtype=float32), 'eval/episode_x_velocity': Array(-0.04195585, dtype=float32), 'eval/episode_y_position': Array(-0.00087321, dtype=float32), 'eval/episode_y_velocity': Array(-0.00074534, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08818989, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04260729, dtype=float32), 'eval/episode_reward_std': Array(0.17672028, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04260729, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26422033, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127822, dtype=float32), 'eval/episode_x_position_std': Array(0.08792068, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04260729, dtype=float32), 'eval/episode_y_position_std': Array(0.00622148, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01159984, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.69975709915161, 'eval/sps': 6183.647440251661, 'num_steps': 4705280}
{'eval/walltime': 19150.66330742836, 'training/sps': 127.17542236981961, 'training/walltime': 37108.651497125626, 'training/entropy_loss': Array(0.1125809, dtype=float32), 'training/policy_loss': Array(0.26944304, dtype=float32), 'training/total_loss': Array(0.38202393, dtype=float32), 'training/v_loss': Array(5.4026366e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093312, dtype=float32), 'eval/episode_forward_reward': Array(-0.04182197, dtype=float32), 'eval/episode_reward': Array(-2.037968, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04182197, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9948912, dtype=float32), 'eval/episode_train_reward': Array(-0.00125466, dtype=float32), 'eval/episode_x_position': Array(1.0074655, dtype=float32), 'eval/episode_x_velocity': Array(-0.04182197, dtype=float32), 'eval/episode_y_position': Array(-0.00046208, dtype=float32), 'eval/episode_y_velocity': Array(0.00100679, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00587754, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04281849, dtype=float32), 'eval/episode_reward_std': Array(0.0497749, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04281849, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01981717, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128455, dtype=float32), 'eval/episode_x_position_std': Array(0.00589178, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04281849, dtype=float32), 'eval/episode_y_position_std': Array(0.0058493, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00959593, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.74945855140686, 'eval/sps': 6168.8356678262, 'num_steps': 4710400}
{'eval/walltime': 19171.39609694481, 'training/sps': 127.01075363142331, 'training/walltime': 37148.96304440498, 'training/entropy_loss': Array(0.11172405, dtype=float32), 'training/policy_loss': Array(0.2679168, dtype=float32), 'training/total_loss': Array(0.37964085, dtype=float32), 'training/v_loss': Array(3.138209e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009626, dtype=float32), 'eval/episode_forward_reward': Array(-0.03809498, dtype=float32), 'eval/episode_reward': Array(-2.037412, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03809498, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981742, dtype=float32), 'eval/episode_train_reward': Array(-0.00114285, dtype=float32), 'eval/episode_x_position': Array(1.0077204, dtype=float32), 'eval/episode_x_velocity': Array(-0.03809498, dtype=float32), 'eval/episode_y_position': Array(-0.00102308, dtype=float32), 'eval/episode_y_velocity': Array(-0.00118319, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572586, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04224709, dtype=float32), 'eval/episode_reward_std': Array(0.04539707, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04224709, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00941006, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126741, dtype=float32), 'eval/episode_x_position_std': Array(0.00570074, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04224709, dtype=float32), 'eval/episode_y_position_std': Array(0.00597906, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01341279, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.732789516448975, 'eval/sps': 6173.795373673543, 'num_steps': 4715520}
{'eval/walltime': 19192.108415842056, 'training/sps': 127.2576371845108, 'training/walltime': 37189.19638609886, 'training/entropy_loss': Array(0.11304772, dtype=float32), 'training/policy_loss': Array(0.26718333, dtype=float32), 'training/total_loss': Array(0.38023102, dtype=float32), 'training/v_loss': Array(2.0126589e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0168809, dtype=float32), 'eval/episode_forward_reward': Array(-0.03774945, dtype=float32), 'eval/episode_reward': Array(-2.052761, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03774945, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0216918, dtype=float32), 'eval/episode_train_reward': Array(-0.00113248, dtype=float32), 'eval/episode_x_position': Array(1.0149543, dtype=float32), 'eval/episode_x_velocity': Array(-0.03774945, dtype=float32), 'eval/episode_y_position': Array(0.00031411, dtype=float32), 'eval/episode_y_velocity': Array(0.00093279, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08771525, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04647968, dtype=float32), 'eval/episode_reward_std': Array(0.17901032, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04647968, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2645127, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139439, dtype=float32), 'eval/episode_x_position_std': Array(0.08744409, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04647968, dtype=float32), 'eval/episode_y_position_std': Array(0.00566715, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01309828, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.712318897247314, 'eval/sps': 6179.897124749818, 'num_steps': 4720640}
{'eval/walltime': 19212.80569434166, 'training/sps': 127.05933678934994, 'training/walltime': 37229.49251961708, 'training/entropy_loss': Array(0.11218797, dtype=float32), 'training/policy_loss': Array(0.26872048, dtype=float32), 'training/total_loss': Array(0.38090843, dtype=float32), 'training/v_loss': Array(2.957959e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0082879, dtype=float32), 'eval/episode_forward_reward': Array(-0.04001754, dtype=float32), 'eval/episode_reward': Array(-2.0381765, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04001754, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969585, dtype=float32), 'eval/episode_train_reward': Array(-0.00120053, dtype=float32), 'eval/episode_x_position': Array(1.006411, dtype=float32), 'eval/episode_x_velocity': Array(-0.04001754, dtype=float32), 'eval/episode_y_position': Array(0.00026908, dtype=float32), 'eval/episode_y_velocity': Array(0.00032298, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00612109, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04415436, dtype=float32), 'eval/episode_reward_std': Array(0.04796936, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04415436, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01460584, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132463, dtype=float32), 'eval/episode_x_position_std': Array(0.00613193, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04415436, dtype=float32), 'eval/episode_y_position_std': Array(0.00557397, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01043921, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69727849960327, 'eval/sps': 6184.387962043103, 'num_steps': 4725760}
{'eval/walltime': 19233.42681980133, 'training/sps': 127.37191128028945, 'training/walltime': 37269.68976521492, 'training/entropy_loss': Array(0.11296226, dtype=float32), 'training/policy_loss': Array(0.26709536, dtype=float32), 'training/total_loss': Array(0.38005766, dtype=float32), 'training/v_loss': Array(3.563543e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097402, dtype=float32), 'eval/episode_forward_reward': Array(-0.03807767, dtype=float32), 'eval/episode_reward': Array(-2.0361726, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03807767, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969528, dtype=float32), 'eval/episode_train_reward': Array(-0.00114233, dtype=float32), 'eval/episode_x_position': Array(1.0078633, dtype=float32), 'eval/episode_x_velocity': Array(-0.03807767, dtype=float32), 'eval/episode_y_position': Array(-0.00044066, dtype=float32), 'eval/episode_y_velocity': Array(-0.00011755, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578579, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04310949, dtype=float32), 'eval/episode_reward_std': Array(0.04963978, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04310949, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0160074, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129328, dtype=float32), 'eval/episode_x_position_std': Array(0.00576198, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04310949, dtype=float32), 'eval/episode_y_position_std': Array(0.00590873, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01375158, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.62112545967102, 'eval/sps': 6207.226673943239, 'num_steps': 4730880}
{'eval/walltime': 19254.093764781952, 'training/sps': 127.34091960507162, 'training/walltime': 37309.896793842316, 'training/entropy_loss': Array(0.11430264, dtype=float32), 'training/policy_loss': Array(0.27007085, dtype=float32), 'training/total_loss': Array(0.38437352, dtype=float32), 'training/v_loss': Array(4.3653262e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096378, dtype=float32), 'eval/episode_forward_reward': Array(-0.04019588, dtype=float32), 'eval/episode_reward': Array(-2.0403361, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04019588, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9989345, dtype=float32), 'eval/episode_train_reward': Array(-0.00120588, dtype=float32), 'eval/episode_x_position': Array(1.0077677, dtype=float32), 'eval/episode_x_velocity': Array(-0.04019588, dtype=float32), 'eval/episode_y_position': Array(-7.40494e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00094886, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00608067, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04483876, dtype=float32), 'eval/episode_reward_std': Array(0.0477722, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04483876, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01016123, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134516, dtype=float32), 'eval/episode_x_position_std': Array(0.0060825, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04483876, dtype=float32), 'eval/episode_y_position_std': Array(0.00600435, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01364797, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.666944980621338, 'eval/sps': 6193.464980916196, 'num_steps': 4736000}
{'eval/walltime': 19274.74400782585, 'training/sps': 127.3315366336243, 'training/walltime': 37350.106785297394, 'training/entropy_loss': Array(0.11356063, dtype=float32), 'training/policy_loss': Array(0.27165347, dtype=float32), 'training/total_loss': Array(0.3852141, dtype=float32), 'training/v_loss': Array(3.0653252e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091746, dtype=float32), 'eval/episode_forward_reward': Array(-0.03886518, dtype=float32), 'eval/episode_reward': Array(-2.0385792, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03886518, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985483, dtype=float32), 'eval/episode_train_reward': Array(-0.00116596, dtype=float32), 'eval/episode_x_position': Array(1.0072907, dtype=float32), 'eval/episode_x_velocity': Array(-0.03886518, dtype=float32), 'eval/episode_y_position': Array(-0.00050444, dtype=float32), 'eval/episode_y_velocity': Array(-0.00289255, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00557791, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04252129, dtype=float32), 'eval/episode_reward_std': Array(0.04606343, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04252129, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00987773, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127564, dtype=float32), 'eval/episode_x_position_std': Array(0.00556683, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04252129, dtype=float32), 'eval/episode_y_position_std': Array(0.00575879, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01557132, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.650243043899536, 'eval/sps': 6198.474261435561, 'num_steps': 4741120}
{'eval/walltime': 19295.404755830765, 'training/sps': 127.19612507721708, 'training/walltime': 37390.359583854675, 'training/entropy_loss': Array(0.1135457, dtype=float32), 'training/policy_loss': Array(0.26789916, dtype=float32), 'training/total_loss': Array(0.38144484, dtype=float32), 'training/v_loss': Array(3.351792e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091078, dtype=float32), 'eval/episode_forward_reward': Array(-0.03589977, dtype=float32), 'eval/episode_reward': Array(-2.034357, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03589977, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973805, dtype=float32), 'eval/episode_train_reward': Array(-0.00107699, dtype=float32), 'eval/episode_x_position': Array(1.0072144, dtype=float32), 'eval/episode_x_velocity': Array(-0.03589977, dtype=float32), 'eval/episode_y_position': Array(0.00015569, dtype=float32), 'eval/episode_y_velocity': Array(-0.00060456, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00618123, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04335801, dtype=float32), 'eval/episode_reward_std': Array(0.04761706, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04335801, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01197769, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130074, dtype=float32), 'eval/episode_x_position_std': Array(0.00614754, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04335801, dtype=float32), 'eval/episode_y_position_std': Array(0.00602185, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00937486, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66074800491333, 'eval/sps': 6195.3226460900805, 'num_steps': 4746240}
{'eval/walltime': 19316.039079904556, 'training/sps': 127.36324889011499, 'training/walltime': 37430.55956339836, 'training/entropy_loss': Array(0.11522488, dtype=float32), 'training/policy_loss': Array(0.26902682, dtype=float32), 'training/total_loss': Array(0.3842517, dtype=float32), 'training/v_loss': Array(6.1883845e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093307, dtype=float32), 'eval/episode_forward_reward': Array(-0.03321182, dtype=float32), 'eval/episode_reward': Array(-2.0282922, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03321182, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9940841, dtype=float32), 'eval/episode_train_reward': Array(-0.00099635, dtype=float32), 'eval/episode_x_position': Array(1.0074201, dtype=float32), 'eval/episode_x_velocity': Array(-0.03321182, dtype=float32), 'eval/episode_y_position': Array(0.00127413, dtype=float32), 'eval/episode_y_velocity': Array(-0.00125779, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00585092, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04275862, dtype=float32), 'eval/episode_reward_std': Array(0.05146535, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04275862, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02181673, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128276, dtype=float32), 'eval/episode_x_position_std': Array(0.00587732, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04275862, dtype=float32), 'eval/episode_y_position_std': Array(0.00570605, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01182561, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.634324073791504, 'eval/sps': 6203.25626089095, 'num_steps': 4751360}
{'eval/walltime': 19336.70591020584, 'training/sps': 127.28678363408461, 'training/walltime': 37470.783692359924, 'training/entropy_loss': Array(0.11486805, dtype=float32), 'training/policy_loss': Array(0.27018103, dtype=float32), 'training/total_loss': Array(0.38504907, dtype=float32), 'training/v_loss': Array(9.0470714e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094588, dtype=float32), 'eval/episode_forward_reward': Array(-0.03843421, dtype=float32), 'eval/episode_reward': Array(-2.036543, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03843421, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969556, dtype=float32), 'eval/episode_train_reward': Array(-0.00115303, dtype=float32), 'eval/episode_x_position': Array(1.0075612, dtype=float32), 'eval/episode_x_velocity': Array(-0.03843421, dtype=float32), 'eval/episode_y_position': Array(-4.808209e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00175769, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589484, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04580291, dtype=float32), 'eval/episode_reward_std': Array(0.04722009, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04580291, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01452737, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137409, dtype=float32), 'eval/episode_x_position_std': Array(0.00587352, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04580291, dtype=float32), 'eval/episode_y_position_std': Array(0.00573066, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01030401, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66683030128479, 'eval/sps': 6193.499348182225, 'num_steps': 4756480}
{'eval/walltime': 19357.30716395378, 'training/sps': 127.23631738808105, 'training/walltime': 37511.023775577545, 'training/entropy_loss': Array(0.11292244, dtype=float32), 'training/policy_loss': Array(0.27168962, dtype=float32), 'training/total_loss': Array(0.38461205, dtype=float32), 'training/v_loss': Array(2.2029414e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0158609, dtype=float32), 'eval/episode_forward_reward': Array(-0.03910328, dtype=float32), 'eval/episode_reward': Array(-2.0531464, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03910328, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0206826, dtype=float32), 'eval/episode_train_reward': Array(-0.0011731, dtype=float32), 'eval/episode_x_position': Array(1.0139692, dtype=float32), 'eval/episode_x_velocity': Array(-0.03910328, dtype=float32), 'eval/episode_y_position': Array(-0.00051483, dtype=float32), 'eval/episode_y_velocity': Array(0.00150116, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08866921, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04376357, dtype=float32), 'eval/episode_reward_std': Array(0.17939405, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04376357, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26483175, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131291, dtype=float32), 'eval/episode_x_position_std': Array(0.08839004, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04376357, dtype=float32), 'eval/episode_y_position_std': Array(0.00607891, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0127849, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.601253747940063, 'eval/sps': 6213.214087166847, 'num_steps': 4761600}
{'eval/walltime': 19377.980128526688, 'training/sps': 126.97300467144188, 'training/walltime': 37551.34730744362, 'training/entropy_loss': Array(0.11299683, dtype=float32), 'training/policy_loss': Array(0.26833764, dtype=float32), 'training/total_loss': Array(0.38133445, dtype=float32), 'training/v_loss': Array(1.6612747e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091804, dtype=float32), 'eval/episode_forward_reward': Array(-0.03589217, dtype=float32), 'eval/episode_reward': Array(-2.035229, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03589217, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.99826, dtype=float32), 'eval/episode_train_reward': Array(-0.00107676, dtype=float32), 'eval/episode_x_position': Array(1.0072749, dtype=float32), 'eval/episode_x_velocity': Array(-0.03589217, dtype=float32), 'eval/episode_y_position': Array(0.00084393, dtype=float32), 'eval/episode_y_velocity': Array(0.00118762, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0060882, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04334192, dtype=float32), 'eval/episode_reward_std': Array(0.04587406, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04334192, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01110058, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130026, dtype=float32), 'eval/episode_x_position_std': Array(0.00604981, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04334192, dtype=float32), 'eval/episode_y_position_std': Array(0.00562606, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01155612, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672964572906494, 'eval/sps': 6191.66155626048, 'num_steps': 4766720}
{'eval/walltime': 19398.598200321198, 'training/sps': 127.02149133049392, 'training/walltime': 37591.655447006226, 'training/entropy_loss': Array(0.11366142, dtype=float32), 'training/policy_loss': Array(0.26615933, dtype=float32), 'training/total_loss': Array(0.3798207, dtype=float32), 'training/v_loss': Array(5.229589e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090163, dtype=float32), 'eval/episode_forward_reward': Array(-0.04241476, dtype=float32), 'eval/episode_reward': Array(-2.042923, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04241476, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9992359, dtype=float32), 'eval/episode_train_reward': Array(-0.00127244, dtype=float32), 'eval/episode_x_position': Array(1.0071822, dtype=float32), 'eval/episode_x_velocity': Array(-0.04241476, dtype=float32), 'eval/episode_y_position': Array(0.00013384, dtype=float32), 'eval/episode_y_velocity': Array(-0.00017029, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0062215, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04434254, dtype=float32), 'eval/episode_reward_std': Array(0.04710498, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04434254, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00814682, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133028, dtype=float32), 'eval/episode_x_position_std': Array(0.00623146, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04434254, dtype=float32), 'eval/episode_y_position_std': Array(0.00586017, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0111035, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.618071794509888, 'eval/sps': 6208.146002968299, 'num_steps': 4771840}
{'eval/walltime': 19419.271901369095, 'training/sps': 127.42233017301396, 'training/walltime': 37631.836787223816, 'training/entropy_loss': Array(0.1151056, dtype=float32), 'training/policy_loss': Array(0.2680469, dtype=float32), 'training/total_loss': Array(0.38315248, dtype=float32), 'training/v_loss': Array(2.503767e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088073, dtype=float32), 'eval/episode_forward_reward': Array(-0.03882738, dtype=float32), 'eval/episode_reward': Array(-2.0376315, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03882738, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9976392, dtype=float32), 'eval/episode_train_reward': Array(-0.00116482, dtype=float32), 'eval/episode_x_position': Array(1.006944, dtype=float32), 'eval/episode_x_velocity': Array(-0.03882738, dtype=float32), 'eval/episode_y_position': Array(0.00029509, dtype=float32), 'eval/episode_y_velocity': Array(-0.0005053, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571263, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04191744, dtype=float32), 'eval/episode_reward_std': Array(0.04466203, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04191744, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00980979, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125752, dtype=float32), 'eval/episode_x_position_std': Array(0.0057132, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04191744, dtype=float32), 'eval/episode_y_position_std': Array(0.00598075, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0151746, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67370104789734, 'eval/sps': 6191.440985987291, 'num_steps': 4776960}
{'eval/walltime': 19439.88820195198, 'training/sps': 127.0765613560341, 'training/walltime': 37672.127458810806, 'training/entropy_loss': Array(0.11214672, dtype=float32), 'training/policy_loss': Array(0.2726888, dtype=float32), 'training/total_loss': Array(0.38483554, dtype=float32), 'training/v_loss': Array(1.8561142e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090302, dtype=float32), 'eval/episode_forward_reward': Array(-0.04097765, dtype=float32), 'eval/episode_reward': Array(-2.0400639, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04097765, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978569, dtype=float32), 'eval/episode_train_reward': Array(-0.00122933, dtype=float32), 'eval/episode_x_position': Array(1.0071336, dtype=float32), 'eval/episode_x_velocity': Array(-0.04097765, dtype=float32), 'eval/episode_y_position': Array(0.00071203, dtype=float32), 'eval/episode_y_velocity': Array(-6.634949e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00501811, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04544151, dtype=float32), 'eval/episode_reward_std': Array(0.04952473, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04544151, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01264208, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136325, dtype=float32), 'eval/episode_x_position_std': Array(0.00498967, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04544151, dtype=float32), 'eval/episode_y_position_std': Array(0.00583073, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01214393, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.616300582885742, 'eval/sps': 6208.67936443733, 'num_steps': 4782080}
{'eval/walltime': 19460.55743288994, 'training/sps': 127.40845404454201, 'training/walltime': 37712.313175201416, 'training/entropy_loss': Array(0.10721472, dtype=float32), 'training/policy_loss': Array(0.26790902, dtype=float32), 'training/total_loss': Array(0.37512374, dtype=float32), 'training/v_loss': Array(1.2970888e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089294, dtype=float32), 'eval/episode_forward_reward': Array(-0.04282252, dtype=float32), 'eval/episode_reward': Array(-2.040741, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04282252, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966335, dtype=float32), 'eval/episode_train_reward': Array(-0.00128468, dtype=float32), 'eval/episode_x_position': Array(1.0071054, dtype=float32), 'eval/episode_x_velocity': Array(-0.04282252, dtype=float32), 'eval/episode_y_position': Array(-0.00012152, dtype=float32), 'eval/episode_y_velocity': Array(0.00148722, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570448, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04421982, dtype=float32), 'eval/episode_reward_std': Array(0.04794525, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04421982, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01562845, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132659, dtype=float32), 'eval/episode_x_position_std': Array(0.00572645, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04421982, dtype=float32), 'eval/episode_y_position_std': Array(0.00583138, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01408161, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.669230937957764, 'eval/sps': 6192.780001549836, 'num_steps': 4787200}
{'eval/walltime': 19481.24741458893, 'training/sps': 127.35644188050895, 'training/walltime': 37752.51530337334, 'training/entropy_loss': Array(0.10716203, dtype=float32), 'training/policy_loss': Array(-0.01632668, dtype=float32), 'training/total_loss': Array(0.09083535, dtype=float32), 'training/v_loss': Array(2.9158587e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098208, dtype=float32), 'eval/episode_forward_reward': Array(-0.03667129, dtype=float32), 'eval/episode_reward': Array(-2.0348234, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03667129, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9970517, dtype=float32), 'eval/episode_train_reward': Array(-0.00110014, dtype=float32), 'eval/episode_x_position': Array(1.0079265, dtype=float32), 'eval/episode_x_velocity': Array(-0.03667129, dtype=float32), 'eval/episode_y_position': Array(-0.0006066, dtype=float32), 'eval/episode_y_velocity': Array(0.00015711, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00561549, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04435379, dtype=float32), 'eval/episode_reward_std': Array(0.04793303, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04435379, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01747738, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133061, dtype=float32), 'eval/episode_x_position_std': Array(0.00564921, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04435379, dtype=float32), 'eval/episode_y_position_std': Array(0.00538235, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01457566, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.689981698989868, 'eval/sps': 6186.569029505195, 'num_steps': 4792320}
{'eval/walltime': 19501.941373586655, 'training/sps': 127.29419664450535, 'training/walltime': 37792.73708987236, 'training/entropy_loss': Array(0.10975169, dtype=float32), 'training/policy_loss': Array(0.00982583, dtype=float32), 'training/total_loss': Array(0.11957753, dtype=float32), 'training/v_loss': Array(1.874876e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092856, dtype=float32), 'eval/episode_forward_reward': Array(-0.03793417, dtype=float32), 'eval/episode_reward': Array(-2.038035, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03793417, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9989629, dtype=float32), 'eval/episode_train_reward': Array(-0.00113802, dtype=float32), 'eval/episode_x_position': Array(1.007417, dtype=float32), 'eval/episode_x_velocity': Array(-0.03793417, dtype=float32), 'eval/episode_y_position': Array(-0.00064226, dtype=float32), 'eval/episode_y_velocity': Array(0.00146512, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00574252, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04314505, dtype=float32), 'eval/episode_reward_std': Array(0.04510121, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04314505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00787334, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129435, dtype=float32), 'eval/episode_x_position_std': Array(0.005735, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04314505, dtype=float32), 'eval/episode_y_position_std': Array(0.00603978, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01157417, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69395899772644, 'eval/sps': 6185.379994908796, 'num_steps': 4797440}
{'eval/walltime': 19522.666315317154, 'training/sps': 127.21519539765981, 'training/walltime': 37832.98385429382, 'training/entropy_loss': Array(0.11330415, dtype=float32), 'training/policy_loss': Array(0.27007225, dtype=float32), 'training/total_loss': Array(0.3833764, dtype=float32), 'training/v_loss': Array(1.18955314e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091856, dtype=float32), 'eval/episode_forward_reward': Array(-0.04296346, dtype=float32), 'eval/episode_reward': Array(-2.043267, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04296346, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9990149, dtype=float32), 'eval/episode_train_reward': Array(-0.0012889, dtype=float32), 'eval/episode_x_position': Array(1.0072916, dtype=float32), 'eval/episode_x_velocity': Array(-0.04296346, dtype=float32), 'eval/episode_y_position': Array(0.00063006, dtype=float32), 'eval/episode_y_velocity': Array(-0.00081336, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580554, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04574711, dtype=float32), 'eval/episode_reward_std': Array(0.04837528, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04574711, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00627556, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137241, dtype=float32), 'eval/episode_x_position_std': Array(0.00582991, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04574711, dtype=float32), 'eval/episode_y_position_std': Array(0.00626589, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01393816, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.724941730499268, 'eval/sps': 6176.133166716337, 'num_steps': 4802560}
{'eval/walltime': 19543.308621168137, 'training/sps': 127.212453060765, 'training/walltime': 37873.231486320496, 'training/entropy_loss': Array(0.11247709, dtype=float32), 'training/policy_loss': Array(0.26794568, dtype=float32), 'training/total_loss': Array(0.38042277, dtype=float32), 'training/v_loss': Array(4.3004045e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090703, dtype=float32), 'eval/episode_forward_reward': Array(-0.04311682, dtype=float32), 'eval/episode_reward': Array(-2.0416207, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04311682, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972105, dtype=float32), 'eval/episode_train_reward': Array(-0.0012935, dtype=float32), 'eval/episode_x_position': Array(1.0072169, dtype=float32), 'eval/episode_x_velocity': Array(-0.04311682, dtype=float32), 'eval/episode_y_position': Array(-0.00088415, dtype=float32), 'eval/episode_y_velocity': Array(-0.00078537, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00616789, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04393284, dtype=float32), 'eval/episode_reward_std': Array(0.04680998, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04393284, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01447295, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131799, dtype=float32), 'eval/episode_x_position_std': Array(0.0061429, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04393284, dtype=float32), 'eval/episode_y_position_std': Array(0.00571905, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01238048, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.642305850982666, 'eval/sps': 6200.857642747631, 'num_steps': 4807680}
{'eval/walltime': 19564.002364873886, 'training/sps': 127.09754932219974, 'training/walltime': 37913.51550459862, 'training/entropy_loss': Array(0.11410545, dtype=float32), 'training/policy_loss': Array(0.26541853, dtype=float32), 'training/total_loss': Array(0.37952396, dtype=float32), 'training/v_loss': Array(2.4376139e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099118, dtype=float32), 'eval/episode_forward_reward': Array(-0.03921613, dtype=float32), 'eval/episode_reward': Array(-2.038951, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03921613, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.998558, dtype=float32), 'eval/episode_train_reward': Array(-0.00117648, dtype=float32), 'eval/episode_x_position': Array(1.0080416, dtype=float32), 'eval/episode_x_velocity': Array(-0.03921613, dtype=float32), 'eval/episode_y_position': Array(0.00036084, dtype=float32), 'eval/episode_y_velocity': Array(-0.00203442, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577681, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04367903, dtype=float32), 'eval/episode_reward_std': Array(0.04533659, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04367903, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01010854, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131037, dtype=float32), 'eval/episode_x_position_std': Array(0.00576741, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04367903, dtype=float32), 'eval/episode_y_position_std': Array(0.00557795, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01324676, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.69374370574951, 'eval/sps': 6185.444345888787, 'num_steps': 4812800}
{'eval/walltime': 19584.688148975372, 'training/sps': 127.05334473656879, 'training/walltime': 37953.81353855133, 'training/entropy_loss': Array(0.11064161, dtype=float32), 'training/policy_loss': Array(0.26843834, dtype=float32), 'training/total_loss': Array(0.37907994, dtype=float32), 'training/v_loss': Array(1.5751442e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093138, dtype=float32), 'eval/episode_forward_reward': Array(-0.03660758, dtype=float32), 'eval/episode_reward': Array(-2.0342278, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03660758, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996522, dtype=float32), 'eval/episode_train_reward': Array(-0.00109823, dtype=float32), 'eval/episode_x_position': Array(1.0074387, dtype=float32), 'eval/episode_x_velocity': Array(-0.03660758, dtype=float32), 'eval/episode_y_position': Array(-0.00038461, dtype=float32), 'eval/episode_y_velocity': Array(0.00095928, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00589801, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04264404, dtype=float32), 'eval/episode_reward_std': Array(0.04806011, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04264404, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.016605, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127932, dtype=float32), 'eval/episode_x_position_std': Array(0.00588826, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04264404, dtype=float32), 'eval/episode_y_position_std': Array(0.00564594, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01718621, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.685784101486206, 'eval/sps': 6187.824419515411, 'num_steps': 4817920}
{'eval/walltime': 19605.40357017517, 'training/sps': 127.05446928399762, 'training/walltime': 37994.11121582985, 'training/entropy_loss': Array(0.11134595, dtype=float32), 'training/policy_loss': Array(0.26707792, dtype=float32), 'training/total_loss': Array(0.37842387, dtype=float32), 'training/v_loss': Array(6.0341345e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009738, dtype=float32), 'eval/episode_forward_reward': Array(-0.03708845, dtype=float32), 'eval/episode_reward': Array(-2.037239, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03708845, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9990377, dtype=float32), 'eval/episode_train_reward': Array(-0.00111265, dtype=float32), 'eval/episode_x_position': Array(1.0078374, dtype=float32), 'eval/episode_x_velocity': Array(-0.03708845, dtype=float32), 'eval/episode_y_position': Array(0.00023473, dtype=float32), 'eval/episode_y_velocity': Array(-7.341098e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00572124, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0426816, dtype=float32), 'eval/episode_reward_std': Array(0.04521203, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0426816, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00855784, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128045, dtype=float32), 'eval/episode_x_position_std': Array(0.00573301, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0426816, dtype=float32), 'eval/episode_y_position_std': Array(0.00621424, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01308938, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.715421199798584, 'eval/sps': 6178.971634969437, 'num_steps': 4823040}
{'eval/walltime': 19626.112442731857, 'training/sps': 127.04425437348665, 'training/walltime': 38034.41213321686, 'training/entropy_loss': Array(0.11303031, dtype=float32), 'training/policy_loss': Array(0.26511648, dtype=float32), 'training/total_loss': Array(0.3781468, dtype=float32), 'training/v_loss': Array(1.5352928e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0080702, dtype=float32), 'eval/episode_forward_reward': Array(-0.0375673, dtype=float32), 'eval/episode_reward': Array(-2.0339994, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0375673, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.995305, dtype=float32), 'eval/episode_train_reward': Array(-0.00112702, dtype=float32), 'eval/episode_x_position': Array(1.0061735, dtype=float32), 'eval/episode_x_velocity': Array(-0.0375673, dtype=float32), 'eval/episode_y_position': Array(-0.00022807, dtype=float32), 'eval/episode_y_velocity': Array(0.00082028, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00553077, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04476912, dtype=float32), 'eval/episode_reward_std': Array(0.05068848, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04476912, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02101938, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134307, dtype=float32), 'eval/episode_x_position_std': Array(0.00550639, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04476912, dtype=float32), 'eval/episode_y_position_std': Array(0.00578154, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01318967, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.7088725566864, 'eval/sps': 6180.925574273808, 'num_steps': 4828160}
{'eval/walltime': 19646.786528110504, 'training/sps': 127.08338736267729, 'training/walltime': 38074.700640678406, 'training/entropy_loss': Array(0.1149072, dtype=float32), 'training/policy_loss': Array(0.14119962, dtype=float32), 'training/total_loss': Array(0.25610682, dtype=float32), 'training/v_loss': Array(2.1416873e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094438, dtype=float32), 'eval/episode_forward_reward': Array(-0.03567167, dtype=float32), 'eval/episode_reward': Array(-2.033186, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03567167, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964442, dtype=float32), 'eval/episode_train_reward': Array(-0.00107015, dtype=float32), 'eval/episode_x_position': Array(1.0075717, dtype=float32), 'eval/episode_x_velocity': Array(-0.03567167, dtype=float32), 'eval/episode_y_position': Array(0.00011298, dtype=float32), 'eval/episode_y_velocity': Array(-0.00239768, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00604696, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04304841, dtype=float32), 'eval/episode_reward_std': Array(0.0499448, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04304841, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0208734, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129145, dtype=float32), 'eval/episode_x_position_std': Array(0.00606427, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04304841, dtype=float32), 'eval/episode_y_position_std': Array(0.00611795, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01262251, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.67408537864685, 'eval/sps': 6191.325887248406, 'num_steps': 4833280}
{'eval/walltime': 19667.44979596138, 'training/sps': 127.07802170033368, 'training/walltime': 38114.990849256516, 'training/entropy_loss': Array(0.11591741, dtype=float32), 'training/policy_loss': Array(0.2688303, dtype=float32), 'training/total_loss': Array(0.38474774, dtype=float32), 'training/v_loss': Array(2.6313225e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092859, dtype=float32), 'eval/episode_forward_reward': Array(-0.04263673, dtype=float32), 'eval/episode_reward': Array(-2.0425556, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04263673, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986396, dtype=float32), 'eval/episode_train_reward': Array(-0.0012791, dtype=float32), 'eval/episode_x_position': Array(1.0074396, dtype=float32), 'eval/episode_x_velocity': Array(-0.04263673, dtype=float32), 'eval/episode_y_position': Array(0.0001687, dtype=float32), 'eval/episode_y_velocity': Array(-0.00118857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00553002, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04466107, dtype=float32), 'eval/episode_reward_std': Array(0.04803589, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04466107, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00915582, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133983, dtype=float32), 'eval/episode_x_position_std': Array(0.00554146, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04466107, dtype=float32), 'eval/episode_y_position_std': Array(0.00604378, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01155518, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.663267850875854, 'eval/sps': 6194.567138351956, 'num_steps': 4838400}
{'eval/walltime': 19688.13791179657, 'training/sps': 127.09265030656461, 'training/walltime': 38155.27642035484, 'training/entropy_loss': Array(0.11547991, dtype=float32), 'training/policy_loss': Array(0.2667927, dtype=float32), 'training/total_loss': Array(0.3822726, dtype=float32), 'training/v_loss': Array(4.2989966e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092533, dtype=float32), 'eval/episode_forward_reward': Array(-0.03513298, dtype=float32), 'eval/episode_reward': Array(-2.0345964, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03513298, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984095, dtype=float32), 'eval/episode_train_reward': Array(-0.00105399, dtype=float32), 'eval/episode_x_position': Array(1.0073783, dtype=float32), 'eval/episode_x_velocity': Array(-0.03513298, dtype=float32), 'eval/episode_y_position': Array(-0.00032108, dtype=float32), 'eval/episode_y_velocity': Array(-0.00016673, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00608809, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04287904, dtype=float32), 'eval/episode_reward_std': Array(0.04633636, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04287904, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01019059, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128637, dtype=float32), 'eval/episode_x_position_std': Array(0.00609463, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04287904, dtype=float32), 'eval/episode_y_position_std': Array(0.00583687, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00989569, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68811583518982, 'eval/sps': 6187.1269969533005, 'num_steps': 4843520}
{'eval/walltime': 19708.828995227814, 'training/sps': 126.9866141489001, 'training/walltime': 38195.59563064575, 'training/entropy_loss': Array(0.11658236, dtype=float32), 'training/policy_loss': Array(0.27176654, dtype=float32), 'training/total_loss': Array(0.38834894, dtype=float32), 'training/v_loss': Array(1.3959386e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096139, dtype=float32), 'eval/episode_forward_reward': Array(-0.04148033, dtype=float32), 'eval/episode_reward': Array(-2.039321, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04148033, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965963, dtype=float32), 'eval/episode_train_reward': Array(-0.00124441, dtype=float32), 'eval/episode_x_position': Array(1.0077546, dtype=float32), 'eval/episode_x_velocity': Array(-0.04148033, dtype=float32), 'eval/episode_y_position': Array(0.00033294, dtype=float32), 'eval/episode_y_velocity': Array(-0.00124012, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00533737, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04320583, dtype=float32), 'eval/episode_reward_std': Array(0.04721775, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04320583, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01624348, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129618, dtype=float32), 'eval/episode_x_position_std': Array(0.00531935, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04320583, dtype=float32), 'eval/episode_y_position_std': Array(0.0056955, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01248139, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.691083431243896, 'eval/sps': 6186.239615017828, 'num_steps': 4848640}
{'eval/walltime': 19729.472559928894, 'training/sps': 126.9519872677449, 'training/walltime': 38235.92583823204, 'training/entropy_loss': Array(0.11428993, dtype=float32), 'training/policy_loss': Array(0.2707643, dtype=float32), 'training/total_loss': Array(0.38505423, dtype=float32), 'training/v_loss': Array(2.958554e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091276, dtype=float32), 'eval/episode_forward_reward': Array(-0.03806812, dtype=float32), 'eval/episode_reward': Array(-2.0372946, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03806812, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980845, dtype=float32), 'eval/episode_train_reward': Array(-0.00114204, dtype=float32), 'eval/episode_x_position': Array(1.0072597, dtype=float32), 'eval/episode_x_velocity': Array(-0.03806812, dtype=float32), 'eval/episode_y_position': Array(-0.00085901, dtype=float32), 'eval/episode_y_velocity': Array(-0.00133937, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00622573, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04237916, dtype=float32), 'eval/episode_reward_std': Array(0.04688933, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04237916, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01250894, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127137, dtype=float32), 'eval/episode_x_position_std': Array(0.00619122, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04237916, dtype=float32), 'eval/episode_y_position_std': Array(0.00579856, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01349097, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.643564701080322, 'eval/sps': 6200.479512789837, 'num_steps': 4853760}
{'eval/walltime': 19750.193035840988, 'training/sps': 127.0795264465367, 'training/walltime': 38276.21556973457, 'training/entropy_loss': Array(0.11259855, dtype=float32), 'training/policy_loss': Array(0.2694716, dtype=float32), 'training/total_loss': Array(0.38207018, dtype=float32), 'training/v_loss': Array(3.1790423e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083783, dtype=float32), 'eval/episode_forward_reward': Array(-0.03547966, dtype=float32), 'eval/episode_reward': Array(-2.036188, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03547966, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9996438, dtype=float32), 'eval/episode_train_reward': Array(-0.00106439, dtype=float32), 'eval/episode_x_position': Array(1.0064609, dtype=float32), 'eval/episode_x_velocity': Array(-0.03547966, dtype=float32), 'eval/episode_y_position': Array(-0.00019487, dtype=float32), 'eval/episode_y_velocity': Array(0.0002196, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00578098, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04146364, dtype=float32), 'eval/episode_reward_std': Array(0.04280847, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04146364, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00286129, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124391, dtype=float32), 'eval/episode_x_position_std': Array(0.00582954, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04146364, dtype=float32), 'eval/episode_y_position_std': Array(0.00598935, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00974173, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.720475912094116, 'eval/sps': 6177.464289094298, 'num_steps': 4858880}
{'eval/walltime': 19770.84007549286, 'training/sps': 127.12028319927305, 'training/walltime': 38316.49238371849, 'training/entropy_loss': Array(0.11242025, dtype=float32), 'training/policy_loss': Array(0.2664225, dtype=float32), 'training/total_loss': Array(0.37884277, dtype=float32), 'training/v_loss': Array(2.924082e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093884, dtype=float32), 'eval/episode_forward_reward': Array(-0.02570404, dtype=float32), 'eval/episode_reward': Array(-2.0234554, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.02570404, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9969802, dtype=float32), 'eval/episode_train_reward': Array(-0.00077112, dtype=float32), 'eval/episode_x_position': Array(1.007412, dtype=float32), 'eval/episode_x_velocity': Array(-0.02570404, dtype=float32), 'eval/episode_y_position': Array(-0.00033206, dtype=float32), 'eval/episode_y_velocity': Array(-0.0015921, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568772, dtype=float32), 'eval/episode_forward_reward_std': Array(0.03826161, dtype=float32), 'eval/episode_reward_std': Array(0.04028524, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.03826161, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01441792, dtype=float32), 'eval/episode_train_reward_std': Array(0.00114785, dtype=float32), 'eval/episode_x_position_std': Array(0.00571278, dtype=float32), 'eval/episode_x_velocity_std': Array(0.03826161, dtype=float32), 'eval/episode_y_position_std': Array(0.00554142, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01318535, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.647039651870728, 'eval/sps': 6199.435955866077, 'num_steps': 4864000}
{'eval/walltime': 19791.544926404953, 'training/sps': 127.25577907114484, 'training/walltime': 38356.72631287575, 'training/entropy_loss': Array(0.11294244, dtype=float32), 'training/policy_loss': Array(0.26304036, dtype=float32), 'training/total_loss': Array(0.37598282, dtype=float32), 'training/v_loss': Array(2.4718883e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091386, dtype=float32), 'eval/episode_forward_reward': Array(-0.03792036, dtype=float32), 'eval/episode_reward': Array(-2.0357351, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03792036, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9966772, dtype=float32), 'eval/episode_train_reward': Array(-0.00113761, dtype=float32), 'eval/episode_x_position': Array(1.0072609, dtype=float32), 'eval/episode_x_velocity': Array(-0.03792036, dtype=float32), 'eval/episode_y_position': Array(0.00067405, dtype=float32), 'eval/episode_y_velocity': Array(-2.234237e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594147, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04423288, dtype=float32), 'eval/episode_reward_std': Array(0.04991401, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04423288, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01546984, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132699, dtype=float32), 'eval/episode_x_position_std': Array(0.00592046, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04423288, dtype=float32), 'eval/episode_y_position_std': Array(0.00550765, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00972951, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.704850912094116, 'eval/sps': 6182.126137659491, 'num_steps': 4869120}
{'eval/walltime': 19812.22492957115, 'training/sps': 127.49774650840978, 'training/walltime': 38396.883885383606, 'training/entropy_loss': Array(0.11617795, dtype=float32), 'training/policy_loss': Array(0.2679314, dtype=float32), 'training/total_loss': Array(0.38410938, dtype=float32), 'training/v_loss': Array(1.6560524e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0179617, dtype=float32), 'eval/episode_forward_reward': Array(-0.03625491, dtype=float32), 'eval/episode_reward': Array(-2.0517485, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03625491, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0222187, dtype=float32), 'eval/episode_train_reward': Array(-0.00108765, dtype=float32), 'eval/episode_x_position': Array(1.0160842, dtype=float32), 'eval/episode_x_velocity': Array(-0.03625491, dtype=float32), 'eval/episode_y_position': Array(-0.00144628, dtype=float32), 'eval/episode_y_velocity': Array(-0.00173192, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08777927, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04506933, dtype=float32), 'eval/episode_reward_std': Array(0.17890307, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04506933, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26434502, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135208, dtype=float32), 'eval/episode_x_position_std': Array(0.08750913, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04506933, dtype=float32), 'eval/episode_y_position_std': Array(0.00555145, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01470758, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.68000316619873, 'eval/sps': 6189.554178077438, 'num_steps': 4874240}
{'eval/walltime': 19832.902356624603, 'training/sps': 126.92561576842945, 'training/walltime': 38437.222472429276, 'training/entropy_loss': Array(0.11618234, dtype=float32), 'training/policy_loss': Array(0.27042705, dtype=float32), 'training/total_loss': Array(0.3866094, dtype=float32), 'training/v_loss': Array(4.0329434e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0176344, dtype=float32), 'eval/episode_forward_reward': Array(-0.03449821, dtype=float32), 'eval/episode_reward': Array(-2.04671, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03449821, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0189896, dtype=float32), 'eval/episode_train_reward': Array(-0.00103495, dtype=float32), 'eval/episode_x_position': Array(1.0157043, dtype=float32), 'eval/episode_x_velocity': Array(-0.03449821, dtype=float32), 'eval/episode_y_position': Array(-0.00023992, dtype=float32), 'eval/episode_y_velocity': Array(-0.00151017, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08803637, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04351714, dtype=float32), 'eval/episode_reward_std': Array(0.18004653, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04351714, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2652464, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130551, dtype=float32), 'eval/episode_x_position_std': Array(0.08777018, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04351714, dtype=float32), 'eval/episode_y_position_std': Array(0.00538441, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01146753, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.677427053451538, 'eval/sps': 6190.325308323787, 'num_steps': 4879360}
{'eval/walltime': 19853.621376037598, 'training/sps': 127.19049376163932, 'training/walltime': 38477.477053165436, 'training/entropy_loss': Array(0.11644736, dtype=float32), 'training/policy_loss': Array(0.2701569, dtype=float32), 'training/total_loss': Array(0.38660425, dtype=float32), 'training/v_loss': Array(7.7131204e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.017688, dtype=float32), 'eval/episode_forward_reward': Array(-0.03671359, dtype=float32), 'eval/episode_reward': Array(-2.05216, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03671359, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0221577, dtype=float32), 'eval/episode_train_reward': Array(-0.00110141, dtype=float32), 'eval/episode_x_position': Array(1.0158082, dtype=float32), 'eval/episode_x_velocity': Array(-0.03671359, dtype=float32), 'eval/episode_y_position': Array(0.00037063, dtype=float32), 'eval/episode_y_velocity': Array(0.00069402, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09021967, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04272316, dtype=float32), 'eval/episode_reward_std': Array(0.18005875, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04272316, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2643649, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128169, dtype=float32), 'eval/episode_x_position_std': Array(0.089946, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04272316, dtype=float32), 'eval/episode_y_position_std': Array(0.00613465, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01425004, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.719019412994385, 'eval/sps': 6177.89855053285, 'num_steps': 4884480}
{'eval/walltime': 19874.267843723297, 'training/sps': 127.24053765203864, 'training/walltime': 38517.71580171585, 'training/entropy_loss': Array(0.11491723, dtype=float32), 'training/policy_loss': Array(0.27278677, dtype=float32), 'training/total_loss': Array(0.387704, dtype=float32), 'training/v_loss': Array(8.364061e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100987, dtype=float32), 'eval/episode_forward_reward': Array(-0.04399591, dtype=float32), 'eval/episode_reward': Array(-2.0433452, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04399591, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9980292, dtype=float32), 'eval/episode_train_reward': Array(-0.00131988, dtype=float32), 'eval/episode_x_position': Array(1.0082827, dtype=float32), 'eval/episode_x_velocity': Array(-0.04399591, dtype=float32), 'eval/episode_y_position': Array(0.0004047, dtype=float32), 'eval/episode_y_velocity': Array(-0.00054552, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00614462, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04352161, dtype=float32), 'eval/episode_reward_std': Array(0.04664084, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04352161, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01257647, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130565, dtype=float32), 'eval/episode_x_position_std': Array(0.00613361, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04352161, dtype=float32), 'eval/episode_y_position_std': Array(0.00573967, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0180699, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.646467685699463, 'eval/sps': 6199.607697962675, 'num_steps': 4889600}
{'eval/walltime': 19894.950622558594, 'training/sps': 127.47755996463938, 'training/walltime': 38557.87973332405, 'training/entropy_loss': Array(0.11390787, dtype=float32), 'training/policy_loss': Array(0.27094805, dtype=float32), 'training/total_loss': Array(0.38485593, dtype=float32), 'training/v_loss': Array(2.36748e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009786, dtype=float32), 'eval/episode_forward_reward': Array(-0.03875412, dtype=float32), 'eval/episode_reward': Array(-2.0385034, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03875412, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985867, dtype=float32), 'eval/episode_train_reward': Array(-0.00116262, dtype=float32), 'eval/episode_x_position': Array(1.0079211, dtype=float32), 'eval/episode_x_velocity': Array(-0.03875412, dtype=float32), 'eval/episode_y_position': Array(0.00029735, dtype=float32), 'eval/episode_y_velocity': Array(-9.578769e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583316, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04358839, dtype=float32), 'eval/episode_reward_std': Array(0.0458453, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04358839, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01056447, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130765, dtype=float32), 'eval/episode_x_position_std': Array(0.00580661, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04358839, dtype=float32), 'eval/episode_y_position_std': Array(0.00603572, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0105007, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68277883529663, 'eval/sps': 6188.723527882961, 'num_steps': 4894720}
{'eval/walltime': 19915.60872387886, 'training/sps': 126.91515304296244, 'training/walltime': 38598.22164583206, 'training/entropy_loss': Array(0.11438189, dtype=float32), 'training/policy_loss': Array(0.2702862, dtype=float32), 'training/total_loss': Array(0.3846681, dtype=float32), 'training/v_loss': Array(5.271282e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009279, dtype=float32), 'eval/episode_forward_reward': Array(-0.04342129, dtype=float32), 'eval/episode_reward': Array(-2.0435348, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04342129, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9988108, dtype=float32), 'eval/episode_train_reward': Array(-0.00130264, dtype=float32), 'eval/episode_x_position': Array(1.0074251, dtype=float32), 'eval/episode_x_velocity': Array(-0.04342129, dtype=float32), 'eval/episode_y_position': Array(0.0006964, dtype=float32), 'eval/episode_y_velocity': Array(-0.00095679, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00536208, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04524155, dtype=float32), 'eval/episode_reward_std': Array(0.04684704, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04524155, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00771612, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135725, dtype=float32), 'eval/episode_x_position_std': Array(0.00533926, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04524155, dtype=float32), 'eval/episode_y_position_std': Array(0.00573071, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0117255, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.658101320266724, 'eval/sps': 6196.116381442326, 'num_steps': 4899840}
{'eval/walltime': 19936.259476661682, 'training/sps': 127.29077636661204, 'training/walltime': 38638.444513082504, 'training/entropy_loss': Array(0.11331269, dtype=float32), 'training/policy_loss': Array(0.26989612, dtype=float32), 'training/total_loss': Array(0.3832088, dtype=float32), 'training/v_loss': Array(1.3757719e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0092094, dtype=float32), 'eval/episode_forward_reward': Array(-0.03837422, dtype=float32), 'eval/episode_reward': Array(-2.0377388, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03837422, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982135, dtype=float32), 'eval/episode_train_reward': Array(-0.00115123, dtype=float32), 'eval/episode_x_position': Array(1.007363, dtype=float32), 'eval/episode_x_velocity': Array(-0.03837422, dtype=float32), 'eval/episode_y_position': Array(0.00031224, dtype=float32), 'eval/episode_y_velocity': Array(-0.00060658, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599201, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04352258, dtype=float32), 'eval/episode_reward_std': Array(0.04673086, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04352258, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01019031, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130568, dtype=float32), 'eval/episode_x_position_std': Array(0.00597032, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04352258, dtype=float32), 'eval/episode_y_position_std': Array(0.00564087, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01582451, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.650752782821655, 'eval/sps': 6198.321259575433, 'num_steps': 4904960}
{'eval/walltime': 19956.935843467712, 'training/sps': 127.09987898815676, 'training/walltime': 38678.72779297829, 'training/entropy_loss': Array(0.1125644, dtype=float32), 'training/policy_loss': Array(0.26857847, dtype=float32), 'training/total_loss': Array(0.38114285, dtype=float32), 'training/v_loss': Array(3.805545e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0167212, dtype=float32), 'eval/episode_forward_reward': Array(-0.04537132, dtype=float32), 'eval/episode_reward': Array(-2.059596, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04537132, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0206761, dtype=float32), 'eval/episode_train_reward': Array(-0.00136114, dtype=float32), 'eval/episode_x_position': Array(1.0148456, dtype=float32), 'eval/episode_x_velocity': Array(-0.04537132, dtype=float32), 'eval/episode_y_position': Array(0.00039144, dtype=float32), 'eval/episode_y_velocity': Array(-0.00148438, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08913006, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04337822, dtype=float32), 'eval/episode_reward_std': Array(0.18049863, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04337822, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26501626, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130135, dtype=float32), 'eval/episode_x_position_std': Array(0.0888667, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04337822, dtype=float32), 'eval/episode_y_position_std': Array(0.00585789, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01353098, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.676366806030273, 'eval/sps': 6190.642737227351, 'num_steps': 4910080}
{'eval/walltime': 19977.613784313202, 'training/sps': 126.93101733422773, 'training/walltime': 38719.06466341019, 'training/entropy_loss': Array(0.11213052, dtype=float32), 'training/policy_loss': Array(0.2638128, dtype=float32), 'training/total_loss': Array(0.37594333, dtype=float32), 'training/v_loss': Array(2.517681e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095671, dtype=float32), 'eval/episode_forward_reward': Array(-0.04040667, dtype=float32), 'eval/episode_reward': Array(-2.0388732, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04040667, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972544, dtype=float32), 'eval/episode_train_reward': Array(-0.0012122, dtype=float32), 'eval/episode_x_position': Array(1.0077078, dtype=float32), 'eval/episode_x_velocity': Array(-0.04040667, dtype=float32), 'eval/episode_y_position': Array(0.00104196, dtype=float32), 'eval/episode_y_velocity': Array(-0.00011297, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581408, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04415148, dtype=float32), 'eval/episode_reward_std': Array(0.04702333, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04415148, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01351802, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132454, dtype=float32), 'eval/episode_x_position_std': Array(0.00575028, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04415148, dtype=float32), 'eval/episode_y_position_std': Array(0.00572239, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01235291, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.677940845489502, 'eval/sps': 6190.17149514289, 'num_steps': 4915200}
{'eval/walltime': 19998.319866895676, 'training/sps': 127.25602113559943, 'training/walltime': 38759.29851603508, 'training/entropy_loss': Array(0.11439639, dtype=float32), 'training/policy_loss': Array(0.266444, dtype=float32), 'training/total_loss': Array(0.38084036, dtype=float32), 'training/v_loss': Array(8.1518403e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089412, dtype=float32), 'eval/episode_forward_reward': Array(-0.03969258, dtype=float32), 'eval/episode_reward': Array(-2.0395818, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03969258, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986987, dtype=float32), 'eval/episode_train_reward': Array(-0.00119078, dtype=float32), 'eval/episode_x_position': Array(1.0070846, dtype=float32), 'eval/episode_x_velocity': Array(-0.03969258, dtype=float32), 'eval/episode_y_position': Array(0.00033344, dtype=float32), 'eval/episode_y_velocity': Array(-0.00116063, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00550899, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04504012, dtype=float32), 'eval/episode_reward_std': Array(0.04739215, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04504012, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0067359, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013512, dtype=float32), 'eval/episode_x_position_std': Array(0.00548046, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04504012, dtype=float32), 'eval/episode_y_position_std': Array(0.00561848, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01688879, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.706082582473755, 'eval/sps': 6181.758403124646, 'num_steps': 4920320}
{'eval/walltime': 20018.975024223328, 'training/sps': 127.50634014147167, 'training/walltime': 38799.45338201523, 'training/entropy_loss': Array(0.11579057, dtype=float32), 'training/policy_loss': Array(0.26818937, dtype=float32), 'training/total_loss': Array(0.38397995, dtype=float32), 'training/v_loss': Array(2.820835e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093249, dtype=float32), 'eval/episode_forward_reward': Array(-0.04297542, dtype=float32), 'eval/episode_reward': Array(-2.040772, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04297542, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9965072, dtype=float32), 'eval/episode_train_reward': Array(-0.00128926, dtype=float32), 'eval/episode_x_position': Array(1.0074761, dtype=float32), 'eval/episode_x_velocity': Array(-0.04297542, dtype=float32), 'eval/episode_y_position': Array(0.00069282, dtype=float32), 'eval/episode_y_velocity': Array(-0.00231661, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00608127, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04468079, dtype=float32), 'eval/episode_reward_std': Array(0.04711481, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04468079, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01601692, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134042, dtype=float32), 'eval/episode_x_position_std': Array(0.00608083, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04468079, dtype=float32), 'eval/episode_y_position_std': Array(0.00586155, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01212251, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.655157327651978, 'eval/sps': 6196.9995178221525, 'num_steps': 4925440}
{'eval/walltime': 20039.664273500443, 'training/sps': 127.04374329528565, 'training/walltime': 38839.75446152687, 'training/entropy_loss': Array(0.11585209, dtype=float32), 'training/policy_loss': Array(0.265637, dtype=float32), 'training/total_loss': Array(0.38148916, dtype=float32), 'training/v_loss': Array(2.2696765e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095768, dtype=float32), 'eval/episode_forward_reward': Array(-0.03792416, dtype=float32), 'eval/episode_reward': Array(-2.0374115, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03792416, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9983497, dtype=float32), 'eval/episode_train_reward': Array(-0.00113772, dtype=float32), 'eval/episode_x_position': Array(1.007731, dtype=float32), 'eval/episode_x_velocity': Array(-0.03792416, dtype=float32), 'eval/episode_y_position': Array(-0.00018068, dtype=float32), 'eval/episode_y_velocity': Array(-0.00129921, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00571245, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04354171, dtype=float32), 'eval/episode_reward_std': Array(0.04747421, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04354171, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01121203, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130625, dtype=float32), 'eval/episode_x_position_std': Array(0.00569664, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04354171, dtype=float32), 'eval/episode_y_position_std': Array(0.00590195, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01158178, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.689249277114868, 'eval/sps': 6186.7880407620905, 'num_steps': 4930560}
{'eval/walltime': 20060.319139242172, 'training/sps': 127.59470778159317, 'training/walltime': 38879.8815176487, 'training/entropy_loss': Array(0.11594652, dtype=float32), 'training/policy_loss': Array(0.267987, dtype=float32), 'training/total_loss': Array(0.38393354, dtype=float32), 'training/v_loss': Array(5.6863896e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0087987, dtype=float32), 'eval/episode_forward_reward': Array(-0.03369649, dtype=float32), 'eval/episode_reward': Array(-2.032926, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03369649, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982188, dtype=float32), 'eval/episode_train_reward': Array(-0.00101089, dtype=float32), 'eval/episode_x_position': Array(1.0068631, dtype=float32), 'eval/episode_x_velocity': Array(-0.03369649, dtype=float32), 'eval/episode_y_position': Array(-0.00023559, dtype=float32), 'eval/episode_y_velocity': Array(-0.002027, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00573835, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04407154, dtype=float32), 'eval/episode_reward_std': Array(0.04594889, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04407154, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00966008, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132215, dtype=float32), 'eval/episode_x_position_std': Array(0.00571198, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04407154, dtype=float32), 'eval/episode_y_position_std': Array(0.00582168, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00961867, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.654865741729736, 'eval/sps': 6197.087001219146, 'num_steps': 4935680}
{'eval/walltime': 20080.963756084442, 'training/sps': 127.0653790286755, 'training/walltime': 38920.175734996796, 'training/entropy_loss': Array(0.11655535, dtype=float32), 'training/policy_loss': Array(0.27074444, dtype=float32), 'training/total_loss': Array(0.38729978, dtype=float32), 'training/v_loss': Array(1.9596672e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0168139, dtype=float32), 'eval/episode_forward_reward': Array(-0.0383694, dtype=float32), 'eval/episode_reward': Array(-2.051002, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.0383694, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0192938, dtype=float32), 'eval/episode_train_reward': Array(-0.00115108, dtype=float32), 'eval/episode_x_position': Array(1.0149069, dtype=float32), 'eval/episode_x_velocity': Array(-0.0383694, dtype=float32), 'eval/episode_y_position': Array(0.00085453, dtype=float32), 'eval/episode_y_velocity': Array(-0.00064583, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08948264, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04435147, dtype=float32), 'eval/episode_reward_std': Array(0.18139228, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04435147, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26529562, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133054, dtype=float32), 'eval/episode_x_position_std': Array(0.08921797, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04435147, dtype=float32), 'eval/episode_y_position_std': Array(0.00536533, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01210139, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.644616842269897, 'eval/sps': 6200.163508867829, 'num_steps': 4940800}
{'eval/walltime': 20101.623305797577, 'training/sps': 127.46028477924877, 'training/walltime': 38960.345110177994, 'training/entropy_loss': Array(0.11525217, dtype=float32), 'training/policy_loss': Array(0.26983565, dtype=float32), 'training/total_loss': Array(0.3850878, dtype=float32), 'training/v_loss': Array(8.6480156e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0173727, dtype=float32), 'eval/episode_forward_reward': Array(-0.03776311, dtype=float32), 'eval/episode_reward': Array(-2.0514107, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03776311, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.020327, dtype=float32), 'eval/episode_train_reward': Array(-0.00113289, dtype=float32), 'eval/episode_x_position': Array(1.0154853, dtype=float32), 'eval/episode_x_velocity': Array(-0.03776311, dtype=float32), 'eval/episode_y_position': Array(0.0003867, dtype=float32), 'eval/episode_y_velocity': Array(2.8021226e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0883937, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04440833, dtype=float32), 'eval/episode_reward_std': Array(0.18045376, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04440833, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2648397, dtype=float32), 'eval/episode_train_reward_std': Array(0.00133225, dtype=float32), 'eval/episode_x_position_std': Array(0.08812129, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04440833, dtype=float32), 'eval/episode_y_position_std': Array(0.00593707, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01040059, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.659549713134766, 'eval/sps': 6195.681986167451, 'num_steps': 4945920}
{'eval/walltime': 20122.26459646225, 'training/sps': 126.93758085534758, 'training/walltime': 39000.679894924164, 'training/entropy_loss': Array(0.11367072, dtype=float32), 'training/policy_loss': Array(0.27020043, dtype=float32), 'training/total_loss': Array(0.38387114, dtype=float32), 'training/v_loss': Array(5.3903444e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009064, dtype=float32), 'eval/episode_forward_reward': Array(-0.03475052, dtype=float32), 'eval/episode_reward': Array(-2.0325677, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03475052, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9967747, dtype=float32), 'eval/episode_train_reward': Array(-0.00104252, dtype=float32), 'eval/episode_x_position': Array(1.0071484, dtype=float32), 'eval/episode_x_velocity': Array(-0.03475052, dtype=float32), 'eval/episode_y_position': Array(-0.00037922, dtype=float32), 'eval/episode_y_velocity': Array(-0.00339469, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00581827, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04575461, dtype=float32), 'eval/episode_reward_std': Array(0.0496982, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04575461, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01548351, dtype=float32), 'eval/episode_train_reward_std': Array(0.00137264, dtype=float32), 'eval/episode_x_position_std': Array(0.005814, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04575461, dtype=float32), 'eval/episode_y_position_std': Array(0.00590304, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01324405, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.64129066467285, 'eval/sps': 6201.162615236526, 'num_steps': 4951040}
{'eval/walltime': 20142.96972632408, 'training/sps': 127.30937469445146, 'training/walltime': 39040.896886110306, 'training/entropy_loss': Array(0.11334927, dtype=float32), 'training/policy_loss': Array(0.26802242, dtype=float32), 'training/total_loss': Array(0.38137168, dtype=float32), 'training/v_loss': Array(1.0277914e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096731, dtype=float32), 'eval/episode_forward_reward': Array(-0.04654005, dtype=float32), 'eval/episode_reward': Array(-2.045797, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04654005, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978607, dtype=float32), 'eval/episode_train_reward': Array(-0.0013962, dtype=float32), 'eval/episode_x_position': Array(1.0078422, dtype=float32), 'eval/episode_x_velocity': Array(-0.04654005, dtype=float32), 'eval/episode_y_position': Array(-0.00057089, dtype=float32), 'eval/episode_y_velocity': Array(0.00147599, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00560973, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04640801, dtype=float32), 'eval/episode_reward_std': Array(0.04867699, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04640801, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01059357, dtype=float32), 'eval/episode_train_reward_std': Array(0.00139224, dtype=float32), 'eval/episode_x_position_std': Array(0.00561509, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04640801, dtype=float32), 'eval/episode_y_position_std': Array(0.00581176, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01257026, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.705129861831665, 'eval/sps': 6182.04284900228, 'num_steps': 4956160}
{'eval/walltime': 20163.6325404644, 'training/sps': 127.29530433181009, 'training/walltime': 39081.118322610855, 'training/entropy_loss': Array(0.11462513, dtype=float32), 'training/policy_loss': Array(0.2642334, dtype=float32), 'training/total_loss': Array(0.37885854, dtype=float32), 'training/v_loss': Array(9.141157e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0085487, dtype=float32), 'eval/episode_forward_reward': Array(-0.04075833, dtype=float32), 'eval/episode_reward': Array(-2.0374815, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04075833, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9955006, dtype=float32), 'eval/episode_train_reward': Array(-0.00122275, dtype=float32), 'eval/episode_x_position': Array(1.0067017, dtype=float32), 'eval/episode_x_velocity': Array(-0.04075833, dtype=float32), 'eval/episode_y_position': Array(-0.00018775, dtype=float32), 'eval/episode_y_velocity': Array(-0.00150728, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00558182, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04394994, dtype=float32), 'eval/episode_reward_std': Array(0.04962448, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04394994, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01799133, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013185, dtype=float32), 'eval/episode_x_position_std': Array(0.005572, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04394994, dtype=float32), 'eval/episode_y_position_std': Array(0.00591768, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01203834, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.662814140319824, 'eval/sps': 6194.7031576028485, 'num_steps': 4961280}
{'eval/walltime': 20184.31184387207, 'training/sps': 127.3416596101456, 'training/walltime': 39121.32511758804, 'training/entropy_loss': Array(0.11606233, dtype=float32), 'training/policy_loss': Array(0.2702003, dtype=float32), 'training/total_loss': Array(0.38626266, dtype=float32), 'training/v_loss': Array(7.0302972e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.010623, dtype=float32), 'eval/episode_forward_reward': Array(-0.0352251, dtype=float32), 'eval/episode_reward': Array(-2.0329075, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0352251, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996626, dtype=float32), 'eval/episode_train_reward': Array(-0.00105675, dtype=float32), 'eval/episode_x_position': Array(1.008696, dtype=float32), 'eval/episode_x_velocity': Array(-0.0352251, dtype=float32), 'eval/episode_y_position': Array(0.00012027, dtype=float32), 'eval/episode_y_velocity': Array(-0.00060441, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00549419, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04376851, dtype=float32), 'eval/episode_reward_std': Array(0.04935247, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04376851, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01452948, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131306, dtype=float32), 'eval/episode_x_position_std': Array(0.00550624, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04376851, dtype=float32), 'eval/episode_y_position_std': Array(0.00575417, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01288254, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.679303407669067, 'eval/sps': 6189.763623881561, 'num_steps': 4966400}
{'eval/walltime': 20205.00906729698, 'training/sps': 127.12185968212474, 'training/walltime': 39161.60143208504, 'training/entropy_loss': Array(0.1152911, dtype=float32), 'training/policy_loss': Array(0.26876038, dtype=float32), 'training/total_loss': Array(0.38405153, dtype=float32), 'training/v_loss': Array(4.0020325e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094287, dtype=float32), 'eval/episode_forward_reward': Array(-0.04072612, dtype=float32), 'eval/episode_reward': Array(-2.0378864, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04072612, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9959388, dtype=float32), 'eval/episode_train_reward': Array(-0.00122178, dtype=float32), 'eval/episode_x_position': Array(1.0075752, dtype=float32), 'eval/episode_x_velocity': Array(-0.04072612, dtype=float32), 'eval/episode_y_position': Array(-0.00052047, dtype=float32), 'eval/episode_y_velocity': Array(-0.00039795, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00605204, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04390617, dtype=float32), 'eval/episode_reward_std': Array(0.04741729, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04390617, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.0138154, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131719, dtype=float32), 'eval/episode_x_position_std': Array(0.00606035, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04390617, dtype=float32), 'eval/episode_y_position_std': Array(0.00568081, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01342112, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6972234249115, 'eval/sps': 6184.404418514283, 'num_steps': 4971520}
{'eval/walltime': 20225.73042869568, 'training/sps': 127.53576954223206, 'training/walltime': 39201.74703216553, 'training/entropy_loss': Array(0.11544145, dtype=float32), 'training/policy_loss': Array(0.2652628, dtype=float32), 'training/total_loss': Array(0.38070422, dtype=float32), 'training/v_loss': Array(1.2064558e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0166028, dtype=float32), 'eval/episode_forward_reward': Array(-0.04256796, dtype=float32), 'eval/episode_reward': Array(-2.0570579, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.04256796, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0210254, dtype=float32), 'eval/episode_train_reward': Array(-0.00127704, dtype=float32), 'eval/episode_x_position': Array(1.0147096, dtype=float32), 'eval/episode_x_velocity': Array(-0.04256796, dtype=float32), 'eval/episode_y_position': Array(0.00113142, dtype=float32), 'eval/episode_y_velocity': Array(-1.2651086e-05, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09115107, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04477673, dtype=float32), 'eval/episode_reward_std': Array(0.17823558, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04477673, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26461422, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013433, dtype=float32), 'eval/episode_x_position_std': Array(0.09089192, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04477673, dtype=float32), 'eval/episode_y_position_std': Array(0.00575488, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01173717, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.7213613986969, 'eval/sps': 6177.200307314244, 'num_steps': 4976640}
{'eval/walltime': 20246.412615060806, 'training/sps': 127.32692304739149, 'training/walltime': 39241.95848059654, 'training/entropy_loss': Array(0.11885972, dtype=float32), 'training/policy_loss': Array(0.2753443, dtype=float32), 'training/total_loss': Array(0.39420402, dtype=float32), 'training/v_loss': Array(1.6375209e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091535, dtype=float32), 'eval/episode_forward_reward': Array(-0.03829707, dtype=float32), 'eval/episode_reward': Array(-2.0380118, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03829707, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985657, dtype=float32), 'eval/episode_train_reward': Array(-0.00114891, dtype=float32), 'eval/episode_x_position': Array(1.0072663, dtype=float32), 'eval/episode_x_velocity': Array(-0.03829707, dtype=float32), 'eval/episode_y_position': Array(-0.00057641, dtype=float32), 'eval/episode_y_velocity': Array(-0.0015952, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00594342, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04234706, dtype=float32), 'eval/episode_reward_std': Array(0.0455548, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04234706, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00921733, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127041, dtype=float32), 'eval/episode_x_position_std': Array(0.00596503, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04234706, dtype=float32), 'eval/episode_y_position_std': Array(0.00568883, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00924604, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.682186365127563, 'eval/sps': 6188.900812528314, 'num_steps': 4981760}
{'eval/walltime': 20267.097909927368, 'training/sps': 127.31062378281817, 'training/walltime': 39282.175077199936, 'training/entropy_loss': Array(0.11474869, dtype=float32), 'training/policy_loss': Array(0.27256572, dtype=float32), 'training/total_loss': Array(0.3873144, dtype=float32), 'training/v_loss': Array(9.761651e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0169969, dtype=float32), 'eval/episode_forward_reward': Array(-0.03629667, dtype=float32), 'eval/episode_reward': Array(-2.0511444, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03629667, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0215712, dtype=float32), 'eval/episode_train_reward': Array(-0.0010889, dtype=float32), 'eval/episode_x_position': Array(1.0150621, dtype=float32), 'eval/episode_x_velocity': Array(-0.03629667, dtype=float32), 'eval/episode_y_position': Array(-7.945415e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00060583, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.09066077, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04167588, dtype=float32), 'eval/episode_reward_std': Array(0.17951745, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04167588, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26456946, dtype=float32), 'eval/episode_train_reward_std': Array(0.00125028, dtype=float32), 'eval/episode_x_position_std': Array(0.09039433, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04167588, dtype=float32), 'eval/episode_y_position_std': Array(0.00553969, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00950232, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.68529486656189, 'eval/sps': 6187.97076984936, 'num_steps': 4986880}
{'eval/walltime': 20287.761947631836, 'training/sps': 127.33598519928924, 'training/walltime': 39322.383663892746, 'training/entropy_loss': Array(0.11637274, dtype=float32), 'training/policy_loss': Array(0.26955125, dtype=float32), 'training/total_loss': Array(0.38592398, dtype=float32), 'training/v_loss': Array(3.4516376e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096784, dtype=float32), 'eval/episode_forward_reward': Array(-0.03461664, dtype=float32), 'eval/episode_reward': Array(-2.0335321, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03461664, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978771, dtype=float32), 'eval/episode_train_reward': Array(-0.0010385, dtype=float32), 'eval/episode_x_position': Array(1.007781, dtype=float32), 'eval/episode_x_velocity': Array(-0.03461664, dtype=float32), 'eval/episode_y_position': Array(0.00086964, dtype=float32), 'eval/episode_y_velocity': Array(0.00082151, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00547465, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04148023, dtype=float32), 'eval/episode_reward_std': Array(0.04571517, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04148023, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01271148, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124441, dtype=float32), 'eval/episode_x_position_std': Array(0.00547766, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04148023, dtype=float32), 'eval/episode_y_position_std': Array(0.00596083, dtype=float32), 'eval/episode_y_velocity_std': Array(0.00956488, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.664037704467773, 'eval/sps': 6194.336355296386, 'num_steps': 4992000}
{'eval/walltime': 20308.44051718712, 'training/sps': 127.38766025282067, 'training/walltime': 39362.57593989372, 'training/entropy_loss': Array(0.1156646, dtype=float32), 'training/policy_loss': Array(0.2691206, dtype=float32), 'training/total_loss': Array(0.3847852, dtype=float32), 'training/v_loss': Array(7.900155e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095143, dtype=float32), 'eval/episode_forward_reward': Array(-0.03664669, dtype=float32), 'eval/episode_reward': Array(-2.034137, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03664669, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9963908, dtype=float32), 'eval/episode_train_reward': Array(-0.0010994, dtype=float32), 'eval/episode_x_position': Array(1.0076426, dtype=float32), 'eval/episode_x_velocity': Array(-0.03664669, dtype=float32), 'eval/episode_y_position': Array(5.3337775e-05, dtype=float32), 'eval/episode_y_velocity': Array(0.00018187, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00612528, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04232579, dtype=float32), 'eval/episode_reward_std': Array(0.04976898, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04232579, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.019255, dtype=float32), 'eval/episode_train_reward_std': Array(0.00126977, dtype=float32), 'eval/episode_x_position_std': Array(0.0060875, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04232579, dtype=float32), 'eval/episode_y_position_std': Array(0.00583211, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01222025, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.678569555282593, 'eval/sps': 6189.983289598523, 'num_steps': 4997120}
{'eval/walltime': 20329.09781908989, 'training/sps': 126.99972633494362, 'training/walltime': 39402.89098739624, 'training/entropy_loss': Array(0.11751094, dtype=float32), 'training/policy_loss': Array(0.26782545, dtype=float32), 'training/total_loss': Array(0.3853364, dtype=float32), 'training/v_loss': Array(4.2916715e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016901, dtype=float32), 'eval/episode_forward_reward': Array(-0.03340685, dtype=float32), 'eval/episode_reward': Array(-2.0476885, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03340685, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.021092, dtype=float32), 'eval/episode_train_reward': Array(-0.00100221, dtype=float32), 'eval/episode_x_position': Array(1.014986, dtype=float32), 'eval/episode_x_velocity': Array(-0.03340685, dtype=float32), 'eval/episode_y_position': Array(0.00014315, dtype=float32), 'eval/episode_y_velocity': Array(-0.00098449, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08921643, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04074023, dtype=float32), 'eval/episode_reward_std': Array(0.17933103, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04074023, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2647211, dtype=float32), 'eval/episode_train_reward_std': Array(0.00122221, dtype=float32), 'eval/episode_x_position_std': Array(0.08894849, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04074023, dtype=float32), 'eval/episode_y_position_std': Array(0.00594053, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0120949, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.657301902770996, 'eval/sps': 6196.35616512096, 'num_steps': 5002240}
{'eval/walltime': 20349.790028095245, 'training/sps': 127.53908407829445, 'training/walltime': 39443.03554415703, 'training/entropy_loss': Array(0.11802438, dtype=float32), 'training/policy_loss': Array(0.2680902, dtype=float32), 'training/total_loss': Array(0.38611454, dtype=float32), 'training/v_loss': Array(4.335777e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0088491, dtype=float32), 'eval/episode_forward_reward': Array(-0.04499297, dtype=float32), 'eval/episode_reward': Array(-2.0428224, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04499297, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9964795, dtype=float32), 'eval/episode_train_reward': Array(-0.00134979, dtype=float32), 'eval/episode_x_position': Array(1.0070115, dtype=float32), 'eval/episode_x_velocity': Array(-0.04499297, dtype=float32), 'eval/episode_y_position': Array(0.00059361, dtype=float32), 'eval/episode_y_velocity': Array(-0.00218879, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00620382, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04554343, dtype=float32), 'eval/episode_reward_std': Array(0.04967973, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04554343, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01701919, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013663, dtype=float32), 'eval/episode_x_position_std': Array(0.00618966, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04554343, dtype=float32), 'eval/episode_y_position_std': Array(0.00582411, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01335603, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.692209005355835, 'eval/sps': 6185.903108115201, 'num_steps': 5007360}
{'eval/walltime': 20370.459954977036, 'training/sps': 127.0139290006071, 'training/walltime': 39483.34608364105, 'training/entropy_loss': Array(0.11610259, dtype=float32), 'training/policy_loss': Array(0.26956797, dtype=float32), 'training/total_loss': Array(0.38567054, dtype=float32), 'training/v_loss': Array(2.2246178e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0099822, dtype=float32), 'eval/episode_forward_reward': Array(-0.03882257, dtype=float32), 'eval/episode_reward': Array(-2.0378199, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03882257, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9978328, dtype=float32), 'eval/episode_train_reward': Array(-0.00116468, dtype=float32), 'eval/episode_x_position': Array(1.0081358, dtype=float32), 'eval/episode_x_velocity': Array(-0.03882257, dtype=float32), 'eval/episode_y_position': Array(-0.00019741, dtype=float32), 'eval/episode_y_velocity': Array(0.00038412, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00597406, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04399245, dtype=float32), 'eval/episode_reward_std': Array(0.04555673, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04399245, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00984311, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131977, dtype=float32), 'eval/episode_x_position_std': Array(0.0060204, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04399245, dtype=float32), 'eval/episode_y_position_std': Array(0.00612249, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01205729, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66992688179016, 'eval/sps': 6192.571494423898, 'num_steps': 5012480}
{'eval/walltime': 20391.140692710876, 'training/sps': 127.32516708850305, 'training/walltime': 39523.55808663368, 'training/entropy_loss': Array(0.11384962, dtype=float32), 'training/policy_loss': Array(0.27028453, dtype=float32), 'training/total_loss': Array(0.38413417, dtype=float32), 'training/v_loss': Array(4.4854254e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0083779, dtype=float32), 'eval/episode_forward_reward': Array(-0.04580656, dtype=float32), 'eval/episode_reward': Array(-2.045741, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04580656, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9985604, dtype=float32), 'eval/episode_train_reward': Array(-0.0013742, dtype=float32), 'eval/episode_x_position': Array(1.0065804, dtype=float32), 'eval/episode_x_velocity': Array(-0.04580656, dtype=float32), 'eval/episode_y_position': Array(-0.00026522, dtype=float32), 'eval/episode_y_velocity': Array(0.00163387, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00577046, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04326758, dtype=float32), 'eval/episode_reward_std': Array(0.04595354, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04326758, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00746957, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129803, dtype=float32), 'eval/episode_x_position_std': Array(0.00573967, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04326758, dtype=float32), 'eval/episode_y_position_std': Array(0.00587464, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01694518, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.680737733840942, 'eval/sps': 6189.334328753035, 'num_steps': 5017600}
{'eval/walltime': 20411.823068141937, 'training/sps': 127.31507617089277, 'training/walltime': 39563.77327680588, 'training/entropy_loss': Array(0.11409429, dtype=float32), 'training/policy_loss': Array(0.26705152, dtype=float32), 'training/total_loss': Array(0.3811458, dtype=float32), 'training/v_loss': Array(8.291515e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.009862, dtype=float32), 'eval/episode_forward_reward': Array(-0.03976585, dtype=float32), 'eval/episode_reward': Array(-2.0400329, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03976585, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.999074, dtype=float32), 'eval/episode_train_reward': Array(-0.00119298, dtype=float32), 'eval/episode_x_position': Array(1.0079783, dtype=float32), 'eval/episode_x_velocity': Array(-0.03976585, dtype=float32), 'eval/episode_y_position': Array(0.00015499, dtype=float32), 'eval/episode_y_velocity': Array(-0.00162119, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00570031, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04564098, dtype=float32), 'eval/episode_reward_std': Array(0.04858743, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04564098, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00881717, dtype=float32), 'eval/episode_train_reward_std': Array(0.00136923, dtype=float32), 'eval/episode_x_position_std': Array(0.00566957, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04564098, dtype=float32), 'eval/episode_y_position_std': Array(0.00593595, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01107857, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.68237543106079, 'eval/sps': 6188.844237290539, 'num_steps': 5022720}
{'eval/walltime': 20432.516657590866, 'training/sps': 127.20967843956235, 'training/walltime': 39604.02178668976, 'training/entropy_loss': Array(0.11490419, dtype=float32), 'training/policy_loss': Array(0.2705649, dtype=float32), 'training/total_loss': Array(0.38546908, dtype=float32), 'training/v_loss': Array(6.245248e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0100102, dtype=float32), 'eval/episode_forward_reward': Array(-0.03967884, dtype=float32), 'eval/episode_reward': Array(-2.0402052, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03967884, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9993358, dtype=float32), 'eval/episode_train_reward': Array(-0.00119037, dtype=float32), 'eval/episode_x_position': Array(1.0081561, dtype=float32), 'eval/episode_x_velocity': Array(-0.03967884, dtype=float32), 'eval/episode_y_position': Array(-0.00034385, dtype=float32), 'eval/episode_y_velocity': Array(-0.0008879, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.0060465, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04494029, dtype=float32), 'eval/episode_reward_std': Array(0.04670466, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04494029, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00375308, dtype=float32), 'eval/episode_train_reward_std': Array(0.00134821, dtype=float32), 'eval/episode_x_position_std': Array(0.00600149, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04494029, dtype=float32), 'eval/episode_y_position_std': Array(0.00552877, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01124277, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.693589448928833, 'eval/sps': 6185.490454224977, 'num_steps': 5027840}
{'eval/walltime': 20453.192792892456, 'training/sps': 126.95471688516031, 'training/walltime': 39644.351127147675, 'training/entropy_loss': Array(0.11456188, dtype=float32), 'training/policy_loss': Array(0.27167794, dtype=float32), 'training/total_loss': Array(0.38623983, dtype=float32), 'training/v_loss': Array(2.3165876e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096465, dtype=float32), 'eval/episode_forward_reward': Array(-0.03817879, dtype=float32), 'eval/episode_reward': Array(-2.0379934, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03817879, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986691, dtype=float32), 'eval/episode_train_reward': Array(-0.00114536, dtype=float32), 'eval/episode_x_position': Array(1.0077646, dtype=float32), 'eval/episode_x_velocity': Array(-0.03817879, dtype=float32), 'eval/episode_y_position': Array(-7.846115e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00154727, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00555024, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04286344, dtype=float32), 'eval/episode_reward_std': Array(0.04394695, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04286344, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00783421, dtype=float32), 'eval/episode_train_reward_std': Array(0.0012859, dtype=float32), 'eval/episode_x_position_std': Array(0.00550503, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04286344, dtype=float32), 'eval/episode_y_position_std': Array(0.00617404, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01044866, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.676135301589966, 'eval/sps': 6190.712051983766, 'num_steps': 5032960}
{'eval/walltime': 20473.903556108475, 'training/sps': 127.34086976830433, 'training/walltime': 39684.5581715107, 'training/entropy_loss': Array(0.11193147, dtype=float32), 'training/policy_loss': Array(0.27434528, dtype=float32), 'training/total_loss': Array(0.38627672, dtype=float32), 'training/v_loss': Array(2.0423845e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0095088, dtype=float32), 'eval/episode_forward_reward': Array(-0.03988994, dtype=float32), 'eval/episode_reward': Array(-2.0395763, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03988994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9984899, dtype=float32), 'eval/episode_train_reward': Array(-0.0011967, dtype=float32), 'eval/episode_x_position': Array(1.0076072, dtype=float32), 'eval/episode_x_velocity': Array(-0.03988994, dtype=float32), 'eval/episode_y_position': Array(-0.00115986, dtype=float32), 'eval/episode_y_velocity': Array(-0.00167836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00584152, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04265111, dtype=float32), 'eval/episode_reward_std': Array(0.04534281, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04265111, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00937815, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127953, dtype=float32), 'eval/episode_x_position_std': Array(0.00583165, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04265111, dtype=float32), 'eval/episode_y_position_std': Array(0.00612437, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01114022, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.710763216018677, 'eval/sps': 6180.361325409717, 'num_steps': 5038080}
{'eval/walltime': 20494.554686784744, 'training/sps': 126.95045251929432, 'training/walltime': 39724.88886666298, 'training/entropy_loss': Array(0.11148109, dtype=float32), 'training/policy_loss': Array(0.11078708, dtype=float32), 'training/total_loss': Array(0.22226818, dtype=float32), 'training/v_loss': Array(5.865285e-09, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0090518, dtype=float32), 'eval/episode_forward_reward': Array(-0.04043888, dtype=float32), 'eval/episode_reward': Array(-2.0390007, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04043888, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973488, dtype=float32), 'eval/episode_train_reward': Array(-0.00121317, dtype=float32), 'eval/episode_x_position': Array(1.0071671, dtype=float32), 'eval/episode_x_velocity': Array(-0.04043888, dtype=float32), 'eval/episode_y_position': Array(9.849842e-05, dtype=float32), 'eval/episode_y_velocity': Array(-0.00116766, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00599966, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04418201, dtype=float32), 'eval/episode_reward_std': Array(0.04889488, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04418201, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01801195, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132546, dtype=float32), 'eval/episode_x_position_std': Array(0.00597495, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04418201, dtype=float32), 'eval/episode_y_position_std': Array(0.00622876, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01130924, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65113067626953, 'eval/sps': 6198.207836972645, 'num_steps': 5043200}
{'eval/walltime': 20515.258243322372, 'training/sps': 127.41746278910055, 'training/walltime': 39765.07174181938, 'training/entropy_loss': Array(0.11328772, dtype=float32), 'training/policy_loss': Array(0.26523215, dtype=float32), 'training/total_loss': Array(0.37851986, dtype=float32), 'training/v_loss': Array(9.049672e-11, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0096109, dtype=float32), 'eval/episode_forward_reward': Array(-0.03682131, dtype=float32), 'eval/episode_reward': Array(-2.036598, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03682131, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9986722, dtype=float32), 'eval/episode_train_reward': Array(-0.00110464, dtype=float32), 'eval/episode_x_position': Array(1.0076978, dtype=float32), 'eval/episode_x_velocity': Array(-0.03682131, dtype=float32), 'eval/episode_y_position': Array(0.00036602, dtype=float32), 'eval/episode_y_velocity': Array(-0.00020909, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00568228, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04415187, dtype=float32), 'eval/episode_reward_std': Array(0.04637901, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04415187, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01038594, dtype=float32), 'eval/episode_train_reward_std': Array(0.00132456, dtype=float32), 'eval/episode_x_position_std': Array(0.00562844, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04415187, dtype=float32), 'eval/episode_y_position_std': Array(0.00573965, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01215556, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.703556537628174, 'eval/sps': 6182.5126406356, 'num_steps': 5048320}
{'eval/walltime': 20535.927129745483, 'training/sps': 127.03183633717063, 'training/walltime': 39805.37659883499, 'training/entropy_loss': Array(0.11649849, dtype=float32), 'training/policy_loss': Array(0.26648855, dtype=float32), 'training/total_loss': Array(0.38298705, dtype=float32), 'training/v_loss': Array(1.5821389e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098131, dtype=float32), 'eval/episode_forward_reward': Array(-0.04222081, dtype=float32), 'eval/episode_reward': Array(-2.0417116, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04222081, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982238, dtype=float32), 'eval/episode_train_reward': Array(-0.00126662, dtype=float32), 'eval/episode_x_position': Array(1.0079694, dtype=float32), 'eval/episode_x_velocity': Array(-0.04222081, dtype=float32), 'eval/episode_y_position': Array(0.00022775, dtype=float32), 'eval/episode_y_velocity': Array(0.00142779, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583593, dtype=float32), 'eval/episode_forward_reward_std': Array(0.0435413, dtype=float32), 'eval/episode_reward_std': Array(0.04703734, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.0435413, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01090769, dtype=float32), 'eval/episode_train_reward_std': Array(0.00130624, dtype=float32), 'eval/episode_x_position_std': Array(0.00584078, dtype=float32), 'eval/episode_x_velocity_std': Array(0.0435413, dtype=float32), 'eval/episode_y_position_std': Array(0.00530316, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01684077, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.668886423110962, 'eval/sps': 6192.883224559041, 'num_steps': 5053440}
{'eval/walltime': 20556.619438409805, 'training/sps': 127.45464971753223, 'training/walltime': 39845.547749996185, 'training/entropy_loss': Array(0.11519168, dtype=float32), 'training/policy_loss': Array(0.2722946, dtype=float32), 'training/total_loss': Array(0.38748628, dtype=float32), 'training/v_loss': Array(1.471208e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0091348, dtype=float32), 'eval/episode_forward_reward': Array(-0.0364432, dtype=float32), 'eval/episode_reward': Array(-2.035732, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0364432, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981956, dtype=float32), 'eval/episode_train_reward': Array(-0.0010933, dtype=float32), 'eval/episode_x_position': Array(1.0072504, dtype=float32), 'eval/episode_x_velocity': Array(-0.0364432, dtype=float32), 'eval/episode_y_position': Array(-0.00027068, dtype=float32), 'eval/episode_y_velocity': Array(-0.00131741, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586983, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04373037, dtype=float32), 'eval/episode_reward_std': Array(0.04804689, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04373037, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01289232, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131191, dtype=float32), 'eval/episode_x_position_std': Array(0.00585502, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04373037, dtype=float32), 'eval/episode_y_position_std': Array(0.00611677, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01379633, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.6923086643219, 'eval/sps': 6185.8733153686335, 'num_steps': 5058560}
{'eval/walltime': 20577.291686296463, 'training/sps': 126.93726646911708, 'training/walltime': 39885.88263463974, 'training/entropy_loss': Array(0.1146941, dtype=float32), 'training/policy_loss': Array(0.2661553, dtype=float32), 'training/total_loss': Array(0.38084942, dtype=float32), 'training/v_loss': Array(3.7559893e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0089722, dtype=float32), 'eval/episode_forward_reward': Array(-0.03326164, dtype=float32), 'eval/episode_reward': Array(-2.028274, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03326164, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9940147, dtype=float32), 'eval/episode_train_reward': Array(-0.00099785, dtype=float32), 'eval/episode_x_position': Array(1.0070711, dtype=float32), 'eval/episode_x_velocity': Array(-0.03326164, dtype=float32), 'eval/episode_y_position': Array(-0.00024181, dtype=float32), 'eval/episode_y_velocity': Array(-0.00146733, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00552346, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04161942, dtype=float32), 'eval/episode_reward_std': Array(0.05250761, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04161942, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.02679151, dtype=float32), 'eval/episode_train_reward_std': Array(0.00124858, dtype=float32), 'eval/episode_x_position_std': Array(0.00552775, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04161942, dtype=float32), 'eval/episode_y_position_std': Array(0.00601945, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01237363, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.672247886657715, 'eval/sps': 6191.876215000972, 'num_steps': 5063680}
{'eval/walltime': 20597.95728468895, 'training/sps': 127.28230757474249, 'training/walltime': 39926.10817813873, 'training/entropy_loss': Array(0.11723509, dtype=float32), 'training/policy_loss': Array(0.27843094, dtype=float32), 'training/total_loss': Array(0.39566606, dtype=float32), 'training/v_loss': Array(1.5360006e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097901, dtype=float32), 'eval/episode_forward_reward': Array(-0.03613827, dtype=float32), 'eval/episode_reward': Array(-2.0345407, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03613827, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9973183, dtype=float32), 'eval/episode_train_reward': Array(-0.00108415, dtype=float32), 'eval/episode_x_position': Array(1.0078919, dtype=float32), 'eval/episode_x_velocity': Array(-0.03613827, dtype=float32), 'eval/episode_y_position': Array(0.00131093, dtype=float32), 'eval/episode_y_velocity': Array(-0.00072661, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00611161, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04264541, dtype=float32), 'eval/episode_reward_std': Array(0.04644797, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04264541, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01726321, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127936, dtype=float32), 'eval/episode_x_position_std': Array(0.00609549, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04264541, dtype=float32), 'eval/episode_y_position_std': Array(0.00560179, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01077331, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.665598392486572, 'eval/sps': 6193.86855241207, 'num_steps': 5068800}
{'eval/walltime': 20618.607998609543, 'training/sps': 127.23081819660663, 'training/walltime': 39966.35000061989, 'training/entropy_loss': Array(0.09716913, dtype=float32), 'training/policy_loss': Array(0.2708254, dtype=float32), 'training/total_loss': Array(0.3679946, dtype=float32), 'training/v_loss': Array(9.886708e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0094694, dtype=float32), 'eval/episode_forward_reward': Array(-0.0368886, dtype=float32), 'eval/episode_reward': Array(-2.036858, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.0368886, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9988627, dtype=float32), 'eval/episode_train_reward': Array(-0.00110666, dtype=float32), 'eval/episode_x_position': Array(1.007586, dtype=float32), 'eval/episode_x_velocity': Array(-0.0368886, dtype=float32), 'eval/episode_y_position': Array(-0.00119651, dtype=float32), 'eval/episode_y_velocity': Array(-3.282912e-07, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00613885, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04319691, dtype=float32), 'eval/episode_reward_std': Array(0.04571975, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04319691, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.00878185, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129591, dtype=float32), 'eval/episode_x_position_std': Array(0.00610259, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04319691, dtype=float32), 'eval/episode_y_position_std': Array(0.0058972, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01044754, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65071392059326, 'eval/sps': 6198.332924091119, 'num_steps': 5073920}
{'eval/walltime': 20639.268128871918, 'training/sps': 127.2491147423515, 'training/walltime': 40006.58603692055, 'training/entropy_loss': Array(0.08571593, dtype=float32), 'training/policy_loss': Array(-0.1863892, dtype=float32), 'training/total_loss': Array(-0.10067324, dtype=float32), 'training/v_loss': Array(1.8465984e-08, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101027, dtype=float32), 'eval/episode_forward_reward': Array(-0.04131285, dtype=float32), 'eval/episode_reward': Array(-2.0404649, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.04131285, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.997913, dtype=float32), 'eval/episode_train_reward': Array(-0.00123939, dtype=float32), 'eval/episode_x_position': Array(1.0082235, dtype=float32), 'eval/episode_x_velocity': Array(-0.04131285, dtype=float32), 'eval/episode_y_position': Array(-0.00034229, dtype=float32), 'eval/episode_y_velocity': Array(-0.00122585, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00579684, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04405335, dtype=float32), 'eval/episode_reward_std': Array(0.04579201, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04405335, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01257669, dtype=float32), 'eval/episode_train_reward_std': Array(0.0013216, dtype=float32), 'eval/episode_x_position_std': Array(0.00577069, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04405335, dtype=float32), 'eval/episode_y_position_std': Array(0.00562654, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01390369, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.660130262374878, 'eval/sps': 6195.50788762967, 'num_steps': 5079040}
{'eval/walltime': 20659.949821472168, 'training/sps': 127.1154787421139, 'training/walltime': 40046.86437320709, 'training/entropy_loss': Array(0.08644681, dtype=float32), 'training/policy_loss': Array(-0.18620735, dtype=float32), 'training/total_loss': Array(-0.09976055, dtype=float32), 'training/v_loss': Array(9.854708e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0101739, dtype=float32), 'eval/episode_forward_reward': Array(-0.03711995, dtype=float32), 'eval/episode_reward': Array(-2.0364335, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03711995, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9982, dtype=float32), 'eval/episode_train_reward': Array(-0.0011136, dtype=float32), 'eval/episode_x_position': Array(1.0083089, dtype=float32), 'eval/episode_x_velocity': Array(-0.03711995, dtype=float32), 'eval/episode_y_position': Array(0.00034945, dtype=float32), 'eval/episode_y_velocity': Array(-0.00107687, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00580714, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04311105, dtype=float32), 'eval/episode_reward_std': Array(0.04691512, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04311105, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01165747, dtype=float32), 'eval/episode_train_reward_std': Array(0.00129333, dtype=float32), 'eval/episode_x_position_std': Array(0.00580454, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04311105, dtype=float32), 'eval/episode_y_position_std': Array(0.00637587, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01240498, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.681692600250244, 'eval/sps': 6189.048569383109, 'num_steps': 5084160}
{'eval/walltime': 20680.661461114883, 'training/sps': 127.33562353409121, 'training/walltime': 40087.0730741024, 'training/entropy_loss': Array(0.08737551, dtype=float32), 'training/policy_loss': Array(-0.18650058, dtype=float32), 'training/total_loss': Array(-0.09912509, dtype=float32), 'training/v_loss': Array(7.5501666e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0098674, dtype=float32), 'eval/episode_forward_reward': Array(-0.03857297, dtype=float32), 'eval/episode_reward': Array(-2.036006, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03857297, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.996276, dtype=float32), 'eval/episode_train_reward': Array(-0.00115719, dtype=float32), 'eval/episode_x_position': Array(1.0080053, dtype=float32), 'eval/episode_x_velocity': Array(-0.03857297, dtype=float32), 'eval/episode_y_position': Array(0.00045676, dtype=float32), 'eval/episode_y_velocity': Array(0.00017461, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00586223, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04370843, dtype=float32), 'eval/episode_reward_std': Array(0.05095423, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04370843, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01864315, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131125, dtype=float32), 'eval/episode_x_position_std': Array(0.00585087, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04370843, dtype=float32), 'eval/episode_y_position_std': Array(0.00587066, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0143862, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.711639642715454, 'eval/sps': 6180.099799342503, 'num_steps': 5089280}
{'eval/walltime': 20701.332668542862, 'training/sps': 127.09255252566577, 'training/walltime': 40127.358676195145, 'training/entropy_loss': Array(0.08878051, dtype=float32), 'training/policy_loss': Array(-0.18674675, dtype=float32), 'training/total_loss': Array(-0.09796624, dtype=float32), 'training/v_loss': Array(6.9764844e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.016932, dtype=float32), 'eval/episode_forward_reward': Array(-0.03312629, dtype=float32), 'eval/episode_reward': Array(-2.0453463, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03312629, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0190387, dtype=float32), 'eval/episode_train_reward': Array(-0.00099379, dtype=float32), 'eval/episode_x_position': Array(1.0149754, dtype=float32), 'eval/episode_x_velocity': Array(-0.03312629, dtype=float32), 'eval/episode_y_position': Array(-0.00012101, dtype=float32), 'eval/episode_y_velocity': Array(-0.00050486, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08819361, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04373797, dtype=float32), 'eval/episode_reward_std': Array(0.18011713, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04373797, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26514366, dtype=float32), 'eval/episode_train_reward_std': Array(0.00131214, dtype=float32), 'eval/episode_x_position_std': Array(0.08793052, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04373797, dtype=float32), 'eval/episode_y_position_std': Array(0.00593916, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01123259, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.671207427978516, 'eval/sps': 6192.187875138429, 'num_steps': 5094400}
{'eval/walltime': 20721.998558998108, 'training/sps': 127.41776292612317, 'training/walltime': 40167.54145669937, 'training/entropy_loss': Array(0.08966067, dtype=float32), 'training/policy_loss': Array(-0.17853722, dtype=float32), 'training/total_loss': Array(-0.08887656, dtype=float32), 'training/v_loss': Array(6.076606e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0183349, dtype=float32), 'eval/episode_forward_reward': Array(-0.03865812, dtype=float32), 'eval/episode_reward': Array(-2.0545115, dtype=float32), 'eval/episode_reward_alive': Array(1.0078125, dtype=float32), 'eval/episode_reward_linvel': Array(-0.03865812, dtype=float32), 'eval/episode_reward_quadctrl': Array(-3.0225062, dtype=float32), 'eval/episode_train_reward': Array(-0.00115974, dtype=float32), 'eval/episode_x_position': Array(1.016435, dtype=float32), 'eval/episode_x_velocity': Array(-0.03865812, dtype=float32), 'eval/episode_y_position': Array(-0.00086213, dtype=float32), 'eval/episode_y_velocity': Array(-0.00079211, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.08985011, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04503812, dtype=float32), 'eval/episode_reward_std': Array(0.17591, dtype=float32), 'eval/episode_reward_alive_std': Array(0.0880424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04503812, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26032445, dtype=float32), 'eval/episode_train_reward_std': Array(0.00135114, dtype=float32), 'eval/episode_x_position_std': Array(0.08957635, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04503812, dtype=float32), 'eval/episode_y_position_std': Array(0.00609671, dtype=float32), 'eval/episode_y_velocity_std': Array(0.0126933, dtype=float32), 'eval/avg_episode_length': Array(1.0078125, dtype=float32), 'eval/epoch_eval_time': 20.66589045524597, 'eval/sps': 6193.781016946579, 'num_steps': 5099520}
{'eval/walltime': 20742.65122270584, 'training/sps': 127.23899591901291, 'training/walltime': 40207.78069281578, 'training/entropy_loss': Array(0.09079486, dtype=float32), 'training/policy_loss': Array(-0.18484464, dtype=float32), 'training/total_loss': Array(-0.09404978, dtype=float32), 'training/v_loss': Array(5.5186156e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0102079, dtype=float32), 'eval/episode_forward_reward': Array(-0.03948544, dtype=float32), 'eval/episode_reward': Array(-2.0379348, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03948544, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9972649, dtype=float32), 'eval/episode_train_reward': Array(-0.00118456, dtype=float32), 'eval/episode_x_position': Array(1.0083342, dtype=float32), 'eval/episode_x_velocity': Array(-0.03948544, dtype=float32), 'eval/episode_y_position': Array(-0.00022696, dtype=float32), 'eval/episode_y_velocity': Array(-0.00080904, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00588808, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04243128, dtype=float32), 'eval/episode_reward_std': Array(0.04521975, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04243128, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01520306, dtype=float32), 'eval/episode_train_reward_std': Array(0.00127294, dtype=float32), 'eval/episode_x_position_std': Array(0.00586665, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04243128, dtype=float32), 'eval/episode_y_position_std': Array(0.00559112, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01254523, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.652663707733154, 'eval/sps': 6197.7477487357655, 'num_steps': 5104640}
{'eval/walltime': 20763.319989919662, 'training/sps': 127.52648884894843, 'training/walltime': 40247.92921447754, 'training/entropy_loss': Array(0.09215962, dtype=float32), 'training/policy_loss': Array(-0.17407417, dtype=float32), 'training/total_loss': Array(-0.08191456, dtype=float32), 'training/v_loss': Array(5.2384747e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0093517, dtype=float32), 'eval/episode_forward_reward': Array(-0.03653136, dtype=float32), 'eval/episode_reward': Array(-2.03581, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03653136, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9981828, dtype=float32), 'eval/episode_train_reward': Array(-0.00109594, dtype=float32), 'eval/episode_x_position': Array(1.0074638, dtype=float32), 'eval/episode_x_velocity': Array(-0.03653136, dtype=float32), 'eval/episode_y_position': Array(-0.00013506, dtype=float32), 'eval/episode_y_velocity': Array(0.00197783, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00583645, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04104906, dtype=float32), 'eval/episode_reward_std': Array(0.04292763, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04104906, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01148039, dtype=float32), 'eval/episode_train_reward_std': Array(0.00123147, dtype=float32), 'eval/episode_x_position_std': Array(0.00583699, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04104906, dtype=float32), 'eval/episode_y_position_std': Array(0.00544742, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01088904, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.66876721382141, 'eval/sps': 6192.918942664617, 'num_steps': 5109760}
{'eval/walltime': 20783.972660303116, 'training/sps': 127.03525548889209, 'training/walltime': 40288.232986688614, 'training/entropy_loss': Array(0.09280117, dtype=float32), 'training/policy_loss': Array(-0.18094034, dtype=float32), 'training/total_loss': Array(-0.08813918, dtype=float32), 'training/v_loss': Array(3.5346037e-10, dtype=float32), 'eval/episode_distance_from_origin': Array(1.0097811, dtype=float32), 'eval/episode_forward_reward': Array(-0.03625709, dtype=float32), 'eval/episode_reward': Array(-2.0332322, dtype=float32), 'eval/episode_reward_alive': Array(1., dtype=float32), 'eval/episode_reward_linvel': Array(-0.03625709, dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.9958873, dtype=float32), 'eval/episode_train_reward': Array(-0.00108771, dtype=float32), 'eval/episode_x_position': Array(1.0078932, dtype=float32), 'eval/episode_x_velocity': Array(-0.03625709, dtype=float32), 'eval/episode_y_position': Array(0.00092128, dtype=float32), 'eval/episode_y_velocity': Array(-0.00073865, dtype=float32), 'eval/episode_distance_from_origin_std': Array(0.00602681, dtype=float32), 'eval/episode_forward_reward_std': Array(0.04294761, dtype=float32), 'eval/episode_reward_std': Array(0.04715361, dtype=float32), 'eval/episode_reward_alive_std': Array(0., dtype=float32), 'eval/episode_reward_linvel_std': Array(0.04294761, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.01663854, dtype=float32), 'eval/episode_train_reward_std': Array(0.00128843, dtype=float32), 'eval/episode_x_position_std': Array(0.00602503, dtype=float32), 'eval/episode_x_velocity_std': Array(0.04294761, dtype=float32), 'eval/episode_y_position_std': Array(0.0058526, dtype=float32), 'eval/episode_y_velocity_std': Array(0.01084451, dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/epoch_eval_time': 20.65267038345337, 'eval/sps': 6197.745745390475, 'num_steps': 5114880}